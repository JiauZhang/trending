[
    {
        "id": "1",
        "title": "The Dead Internet Theory: A Survey on Artificial Interactions and the Future of Social Media",
        "author": [
            "Prathamesh Muzumdar",
            "Sumanth Cheemalapati",
            "Srikanth Reddy RamiReddy",
            "Kuldeep Singh",
            "George Kurian",
            "Apoorva Muley"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00007",
        "abstract": "The Dead Internet Theory (DIT) suggests that much of today's internet, particularly social media, is dominated by non-human activity, AI-generated content, and corporate agendas, leading to a decline in authentic human interaction. This study explores the origins, core claims, and implications of DIT, emphasizing its relevance in the context of social media platforms. The theory emerged as a response to the perceived homogenization of online spaces, highlighting issues like the proliferation of bots, algorithmically generated content, and the prioritization of engagement metrics over genuine user interaction. AI technologies play a central role in this phenomenon, as social media platforms increasingly use algorithms and machine learning to curate content, drive engagement, and maximize advertising revenue. While these tools enhance scalability and personalization, they also prioritize virality and consumption over authentic communication, contributing to the erosion of trust, the loss of content diversity, and a dehumanized internet experience. This study redefines DIT in the context of social media, proposing that the commodification of content consumption for revenue has taken precedence over meaningful human connectivity. By focusing on engagement metrics, platforms foster a sense of artificiality and disconnection, underscoring the need for human-centric approaches to revive authentic online interaction and community building.",
        "tags": [
            "DiT"
        ]
    },
    {
        "id": "2",
        "title": "IntelliChain: An Integrated Framework for Enhanced Socratic Method Dialogue with LLMs and Knowledge Graphs",
        "author": [
            "Changyong Qi",
            "Linzhao Jia",
            "Yuang Wei",
            "Yuan-Hao Jiang",
            "Xiaoqing Gu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00010",
        "abstract": "With the continuous advancement of educational technology, the demand for Large Language Models (LLMs) as intelligent educational agents in providing personalized learning experiences is rapidly increasing. This study aims to explore how to optimize the design and collaboration of a multi-agent system tailored for Socratic teaching through the integration of LLMs and knowledge graphs in a chain-of-thought dialogue approach, thereby enhancing the accuracy and reliability of educational applications. By incorporating knowledge graphs, this research has bolstered the capability of LLMs to handle specific educational content, ensuring the accuracy and relevance of the information provided. Concurrently, we have focused on developing an effective multi-agent collaboration mechanism to facilitate efficient information exchange and chain dialogues among intelligent agents, significantly improving the quality of educational interaction and learning outcomes. In empirical research within the domain of mathematics education, this framework has demonstrated notable advantages in enhancing the accuracy and credibility of educational interactions. This study not only showcases the potential application of LLMs and knowledge graphs in mathematics teaching but also provides valuable insights and methodologies for the development of future AI-driven educational solutions.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "3",
        "title": "Ethical Concerns of Generative AI and Mitigation Strategies: A Systematic Mapping Study",
        "author": [
            "Yutan Huang",
            "Chetan Arora",
            "Wen Cheng Houng",
            "Tanjila Kanij",
            "Anuradha Madulgalla",
            "John Grundy"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00015",
        "abstract": "[Context] Generative AI technologies, particularly Large Language Models (LLMs), have transformed numerous domains by enhancing convenience and efficiency in information retrieval, content generation, and decision-making processes. However, deploying LLMs also presents diverse ethical challenges, and their mitigation strategies remain complex and domain-dependent. [Objective] This paper aims to identify and categorize the key ethical concerns associated with using LLMs, examine existing mitigation strategies, and assess the outstanding challenges in implementing these strategies across various domains. [Method] We conducted a systematic mapping study, reviewing 39 studies that discuss ethical concerns and mitigation strategies related to LLMs. We analyzed these ethical concerns using five ethical dimensions that we extracted based on various existing guidelines, frameworks, and an analysis of the mitigation strategies and implementation challenges. [Results] Our findings reveal that ethical concerns in LLMs are multi-dimensional and context-dependent. While proposed mitigation strategies address some of these concerns, significant challenges still remain. [Conclusion] Our results highlight that ethical issues often hinder the practical implementation of the mitigation strategies, particularly in high-stake areas like healthcare and public governance; existing frameworks often lack adaptability, failing to accommodate evolving societal expectations and diverse contexts.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "4",
        "title": "Large Language Models for Education: ChemTAsk -- An Open-Source Paradigm for Automated Q&A in the Graduate Classroom",
        "author": [
            "Ryann M. Perez",
            "Marie Shimogawa",
            "Yannan Chang",
            "Hoang Ahn T. Phan",
            "Jason G. Marmorstein",
            "Evan S. K. Yanagawa",
            "E. James Petersson"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00016",
        "abstract": "Large language models (LLMs) show promise for aiding graduate level education, but are limited by their training data and potential confabulations. We developed ChemTAsk, an open-source pipeline that combines LLMs with retrieval-augmented generation (RAG) to provide accurate, context-specific assistance. ChemTAsk utilizes course materials, including lecture transcripts and primary publications, to generate accurate responses to student queries. Over nine weeks in an advanced biological chemistry course at the University of Pennsylvania, students could opt in to use ChemTAsk for assistance in any assignment or to understand class material. Comparative analysis showed ChemTAsk performed on par with human teaching assistants (TAs) in understanding student queries and providing accurate information, particularly excelling in creative problem-solving tasks. In contrast, TAs were more precise in their responses and tailored their assistance to the specifics of the class. Student feedback indicated that ChemTAsk was perceived as correct, helpful, and faster than TAs. Open-source and proprietary models from Meta and OpenAI respectively were tested on an original biological chemistry benchmark for future iterations of ChemTAsk. It was found that OpenAI models were more tolerant to deviations in the input prompt and excelled in self-assessment to safeguard for potential confabulations. Taken together, ChemTAsk demonstrates the potential of integrating LLMs with RAG to enhance educational support, offering a scalable tool for students and educators.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "5",
        "title": "A Dynamic and High-Precision Method for Scenario-Based HRA Synthetic Data Collection in Multi-Agent Collaborative Environments Driven by LLMs",
        "author": [
            "Xingyu Xiao",
            "Peng Chen",
            "Qianqian Jia",
            "Jiejuan Tong",
            "Jingang Liang",
            "Haitao Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00022",
        "abstract": "HRA (Human Reliability Analysis) data is crucial for advancing HRA methodologies. however, existing data collection methods lack the necessary granularity, and most approaches fail to capture dynamic features. Additionally, many methods require expert knowledge as input, making them time-consuming and labor-intensive. To address these challenges, we propose a new paradigm for the automated collection of HRA data. Our approach focuses on key indicators behind human error, specifically measuring workload in collaborative settings. This study introduces a novel, scenario-driven method for workload estimation, leveraging fine-tuned large language models (LLMs). By training LLMs on real-world operational data from high-temperature gas-cooled reactors (HTGRs), we simulate human behavior and cognitive load in real time across various collaborative scenarios. The method dynamically adapts to changes in operator workload, providing more accurate, flexible, and scalable workload estimates. The results demonstrate that the proposed WELLA (Workload Estimation with LLMs and Agents) outperforms existing commercial LLM-based methods in terms of prediction accuracy.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "6",
        "title": "Pushing the Limits of BFP on Narrow Precision LLM Inference",
        "author": [
            "Hui Wang",
            "Yuan Cheng",
            "Xiaomeng Han",
            "Zhengpeng Zhao",
            "Dawei Yang",
            "Zhe Jiang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00026",
        "abstract": "The substantial computational and memory demands of Large Language Models (LLMs) hinder their deployment. Block Floating Point (BFP) has proven effective in accelerating linear operations, a cornerstone of LLM workloads. However, as sequence lengths grow, nonlinear operations, such as Attention, increasingly become performance bottlenecks due to their quadratic computational complexity. These nonlinear operations are predominantly executed using inefficient floating-point formats, which renders the system challenging to optimize software efficiency and hardware overhead. In this paper, we delve into the limitations and potential of applying BFP to nonlinear operations. Given our findings, we introduce a hardware-software co-design framework (DB-Attn), including: (i) DBFP, an advanced BFP version, overcomes nonlinear operation challenges with a pivot-focus strategy for diverse data and an adaptive grouping strategy for flexible exponent sharing. (ii) DH-LUT, a novel lookup table algorithm dedicated to accelerating nonlinear operations with DBFP format. (iii) An RTL-level DBFP-based engine is implemented to support DB-Attn, applicable to FPGA and ASIC. Results show that DB-Attn provides significant performance improvements with negligible accuracy loss, achieving 74% GPU speedup on Softmax of LLaMA and 10x low overhead performance improvement over SOTA designs.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "7",
        "title": "VRank: Enhancing Verilog Code Generation from Large Language Models via Self-Consistency",
        "author": [
            "Zhuorui Zhao",
            "Ruidi Qiu",
            "Ing-Chao Lin",
            "Grace Li Zhang",
            "Bing Li",
            "Ulf Schlichtmann"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00028",
        "abstract": "Large Language Models (LLMs) have demonstrated promising capabilities in generating Verilog code from module specifications. To improve the quality of such generated Verilog codes, previous methods require either time-consuming manual inspection or generation of multiple Verilog codes, from which the one with the highest quality is selected with manually designed testbenches. To enhance the generation efficiency while maintaining the quality of the generated codes, we propose VRank, an automatic framework that generates Verilog codes with LLMs. In our framework, multiple code candidates are generated with LLMs by leveraging their probabilistic nature. Afterwards, we group Verilog code candidates into clusters based on identical outputs when tested against the same testbench, which is also generated by LLMs. Clusters are ranked based on the consistency they show on testbench. To determine the best candidate, Chain-of-Thought is further applied to select the best candidate from the top-ranked clusters. By systematically analyzing diverse outputs of generated codes, VRank reduces errors and enhances the overall quality of the generated Verilog code. Experimental results on the VerilogEval-Human benchmark demonstrate a significant 10.5% average increase in functional correctness (passl1) across multiple LLMs, demonstrating VRank's effectiveness in improving the accuracy of automated hardware description language generation for complex design tasks.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "8",
        "title": "Querying Databases with Function Calling",
        "author": [
            "Connor Shorten",
            "Charles Pierse",
            "Thomas Benjamin Smith",
            "Karel D'Oosterlinck",
            "Tuana Celik",
            "Erika Cardenas",
            "Leonie Monigatti",
            "Mohd Shukri Hasan",
            "Edward Schmuhl",
            "Daniel Williams",
            "Aravind Kesiraju",
            "Bob van Luijt"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00032",
        "abstract": "The capabilities of Large Language Models (LLMs) are rapidly accelerating largely thanks to their integration with external tools. Querying databases is among the most effective of these integrations, enabling LLMs to access private or continually updating data. While Function Calling is the most common method for interfacing external tools to LLMs, its application to database querying as a tool has been underexplored. We propose a tool definition for database querying that unifies accessing data with search queries, filters, or a combination both, as well as transforming results with aggregation and groupby operators. To evaluate its effectiveness, we conduct a study with 8 LLMs spanning 5 model families. We present a novel pipeline adapting the Gorilla LLM framework to create synthetic database schemas and queries. We primarily evaluate the models with the Exact Match of predicted and ground truth query APIs. Among the models tested, Claude 3.5 Sonnet achieves the highest performance with an Exact Match score of 74.3%, followed by GPT-4o mini at 73.7%, and GPT-4o at 71.8%. We further breakdown these results per API component utilized and across synthetic use cases. We find that LLMs are highly effective at utilizing operators on boolean properties, but struggle with text property filters. Across use cases we find robust results with the higher performing models such as GPT-4o, but significant performance variance across use cases from lower performing models. We additionally conduct ablation studies exploring the impact of parallel tool calling, adding a rationale as an argument of the tool call, using a separate tool per database collection, and tool calling with structured outputs. Our findings demonstrate the effectiveness of enabling LLMs to query databases with Function Calling. We have open-sourced our experimental code and results at http://github.com/weaviate/gorilla.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "9",
        "title": "MALT: Mechanistic Ablation of Lossy Translation in LLMs for a Low-Resource Language: Urdu",
        "author": [
            "Taaha Saleem Bajwa"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00041",
        "abstract": "LLMs are predominantly trained on English data, which leads to a significant drop in performance on low-resource languages. Understanding how LLMs handle these languages is crucial for improving their effectiveness. This study focuses on Urdu as a use case for exploring the challenges faced by LLMs in processing low-resource languages. LLMs primarily reason in English when prompted in another language, with the final layers acting as translators to convert the English response into the target language. This study finds that even for low-resource languages, the internal latent response of LLMs in English is quite coherent; however, the translation features are lossy and result in poor translations, leading to reduced performance. By mechanistically removing these translation features and using a separate translation model to translate the internal latent response of LLM, the performance of LLMs improves significantly while also preserving the cultural nuances of the input in low-resource languages.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "10",
        "title": "Optimization Strategies for Enhancing Resource Efficiency in Transformers & Large Language Models",
        "author": [
            "Tom Wallace",
            "Naser Ezzati-Jivan",
            "Beatrice Ombuki-Berman"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00046",
        "abstract": "Advancements in Natural Language Processing are heavily reliant on the Transformer architecture, whose improvements come at substantial resource costs due to ever-growing model sizes. This study explores optimization techniques, including Quantization, Knowledge Distillation, and Pruning, focusing on energy and computational efficiency while retaining performance. Among standalone methods, 4-bit Quantization significantly reduces energy use with minimal accuracy loss. Hybrid approaches, like NVIDIA's Minitron approach combining KD and Structured Pruning, further demonstrate promising trade-offs between size reduction and accuracy retention. A novel optimization equation is introduced, offering a flexible framework for comparing various methods. Through the investigation of these compression methods, we provide valuable insights for developing more sustainable and efficient LLMs, shining a light on the often-ignored concern of energy efficiency.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "11",
        "title": "HadamRNN: Binary and Sparse Ternary Orthogonal RNNs",
        "author": [
            "Armand Foucault",
            "Franck Mamalet",
            "FranÃ§ois Malgouyres"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00047",
        "abstract": "Binary and sparse ternary weights in neural networks enable faster computations and lighter representations, facilitating their use on edge devices with limited computational power. Meanwhile, vanilla RNNs are highly sensitive to changes in their recurrent weights, making the binarization and ternarization of these weights inherently challenging. To date, no method has successfully achieved binarization or ternarization of vanilla  RNN weights. We present a new approach leveraging the properties of Hadamard matrices to parameterize a subset of binary and sparse ternary orthogonal matrices. This method enables the training of orthogonal RNNs (ORNNs) with binary and sparse ternary recurrent weights, effectively creating a specific class of binary and sparse ternary vanilla RNNs. The resulting ORNNs, called HadamRNN and lock-HadamRNN, are evaluated on benchmarks such as the copy task, permuted and sequential MNIST tasks, and IMDB dataset. Despite binarization or sparse ternarization, these RNNs maintain performance levels comparable to state-of-the-art full-precision models, highlighting the effectiveness of our approach. Notably, our approach is the first solution with binary recurrent weights capable of tackling the copy task over 1000 timesteps.",
        "tags": [
            "RNN"
        ]
    },
    {
        "id": "12",
        "title": "Large Language Models are Few-shot Multivariate Time Series Classifiers",
        "author": [
            "Yakun Chen",
            "Zihao Li",
            "Chao Yang",
            "Xianzhi Wang",
            "Guandong Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00059",
        "abstract": "Large Language Models (LLMs) have been extensively applied in time series analysis. Yet, their utility in the few-shot classification (i.e., a crucial training scenario due to the limited training data available in industrial applications) concerning multivariate time series data remains underexplored. We aim to leverage the extensive pre-trained knowledge in LLMs to overcome the data scarcity problem within multivariate time series. Specifically, we propose LLMFew, an LLM-enhanced framework to investigate the feasibility and capacity of LLMs for few-shot multivariate time series classification. This model introduces a Patch-wise Temporal Convolution Encoder (PTCEnc) to align time series data with the textual embedding input of LLMs. We further fine-tune the pre-trained LLM decoder with Low-rank Adaptations (LoRA) to enhance its feature representation learning ability in time series data. Experimental results show that our model outperformed state-of-the-art baselines by a large margin, achieving 125.2% and 50.2% improvement in classification accuracy on Handwriting and EthanolConcentration datasets, respectively. Moreover, our experimental results demonstrate that LLM-based methods perform well across a variety of datasets in few-shot MTSC, delivering reliable results compared to traditional models. This success paves the way for their deployment in industrial environments where data are limited.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "LoRA"
        ]
    },
    {
        "id": "13",
        "title": "Israel-Hamas war through Telegram, Reddit and Twitter",
        "author": [
            "Despoina Antonakaki",
            "Sotiris Ioannidis"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00060",
        "abstract": "The Israeli-Palestinian conflict started on 7 October 2023, have resulted thus far to over 48,000 people killed including more than 17,000 children with a majority from Gaza, more than 30,000 people injured, over 10,000 missing, and over 1 million people displaced, fleeing conflict zones. The infrastructure damage includes the 87\\% of housing units, 80\\% of public buildings and 60\\% of cropland 17 out of 36 hospitals, 68\\% of road networks and 87\\% of school buildings damaged. This conflict has as well launched an online discussion across various social media platforms. Telegram was no exception due to its encrypted communication and highly involved audience. The current study will cover an analysis of the related discussion in relation to different participants of the conflict and sentiment represented in those discussion. To this end, we prepared a dataset of 125K messages shared on channels in Telegram spanning from 23 October 2025 until today. Additionally, we apply the same analysis in two publicly available datasets from Twitter containing 2001 tweets and from Reddit containing 2M opinions. We apply a volume analysis across the three datasets, entity extraction and then proceed to BERT topic analysis in order to extract common themes or topics. Next, we apply sentiment analysis to analyze the emotional tone of the discussions. Our findings hint at polarized narratives as the hallmark of how political factions and outsiders mold public opinion. We also analyze the sentiment-topic prevalence relationship, detailing the trends that may show manipulation and attempts of propaganda by the involved parties. This will give a better understanding of the online discourse on the Israel-Palestine conflict and contribute to the knowledge on the dynamics of social media communication during geopolitical crises.",
        "tags": [
            "BERT"
        ]
    },
    {
        "id": "14",
        "title": "Evaluating Large Language Models in Vulnerability Detection Under Variable Context Windows",
        "author": [
            "Jie Lin",
            "David Mohaisen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00064",
        "abstract": "This study examines the impact of tokenized Java code length on the accuracy and explicitness of ten major LLMs in vulnerability detection. Using chi-square tests and known ground truth, we found inconsistencies across models: some, like GPT-4, Mistral, and Mixtral, showed robustness, while others exhibited a significant link between tokenized length and performance. We recommend future LLM development focus on minimizing the influence of input length for better vulnerability detection. Additionally, preprocessing techniques that reduce token count while preserving code structure could enhance LLM accuracy and explicitness in these tasks.",
        "tags": [
            "Detection",
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "15",
        "title": "Privacy Preserving Charge Location Prediction for Electric Vehicles",
        "author": [
            "Robert Marlin",
            "Raja Jurdak",
            "Alsharif Abuadbba",
            "Dimity Miller"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00068",
        "abstract": "By 2050, electric vehicles (EVs) are projected to account for 70% of global vehicle sales. While EVs provide environmental benefits, they also pose challenges for energy generation, grid infrastructure, and data privacy. Current research on EV routing and charge management often overlooks privacy when predicting energy demands, leaving sensitive mobility data vulnerable. To address this, we developed a Federated Learning Transformer Network (FLTN) to predict EVs' next charge location with enhanced privacy measures. Each EV operates as a client, training an onboard FLTN model that shares only model weights, not raw data with a community-based Distributed Energy Resource Management System (DERMS), which aggregates them into a community global model. To further enhance privacy, non-transitory EVs use peer-to-peer weight sharing and augmentation within their community, obfuscating individual contributions and improving model accuracy. Community DERMS global model weights are then redistributed to EVs for continuous training. Our FLTN approach achieved up to 92% accuracy while preserving data privacy, compared to our baseline centralised model, which achieved 98% accuracy with no data privacy. Simulations conducted across diverse charge levels confirm the FLTN's ability to forecast energy demands over extended periods. We present a privacy-focused solution for forecasting EV charge location prediction, effectively mitigating data leakage risks.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "16",
        "title": "Can AI Solve the Peer Review Crisis? A Large Scale Experiment on LLM's Performance and Biases in Evaluating Economics Papers",
        "author": [
            "Pat Pataranutaporn",
            "Nattavudh Powdthavee",
            "Pattie Maes"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00070",
        "abstract": "We investigate whether artificial intelligence can address the peer review crisis in economics by analyzing 27,090 evaluations of 9,030 unique submissions using a large language model (LLM). The experiment systematically varies author characteristics (e.g., affiliation, reputation, gender) and publication quality (e.g., top-tier, mid-tier, low-tier, AI generated papers). The results indicate that LLMs effectively distinguish paper quality but exhibit biases favoring prominent institutions, male authors, and renowned economists. Additionally, LLMs struggle to differentiate high-quality AI-generated papers from genuine top-tier submissions. While LLMs offer efficiency gains, their susceptibility to bias necessitates cautious integration and hybrid peer review models to balance equity and accuracy.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "17",
        "title": "LLM Cyber Evaluations Don't Capture Real-World Risk",
        "author": [
            "KamilÄ LukoÅ¡iÅ«tÄ",
            "Adam Swanda"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00072",
        "abstract": "Large language models (LLMs) are demonstrating increasing prowess in cybersecurity applications, creating creating inherent risks alongside their potential for strengthening defenses. In this position paper, we argue that current efforts to evaluate risks posed by these capabilities are misaligned with the goal of understanding real-world impact. Evaluating LLM cybersecurity risk requires more than just measuring model capabilities -- it demands a comprehensive risk assessment that incorporates analysis of threat actor adoption behavior and potential for impact. We propose a risk assessment framework for LLM cyber capabilities and apply it to a case study of language models used as cybersecurity assistants. Our evaluation of frontier models reveals high compliance rates but moderate accuracy on realistic cyber assistance tasks. However, our framework suggests that this particular use case presents only moderate risk due to limited operational advantages and impact potential. Based on these findings, we recommend several improvements to align research priorities with real-world impact assessment, including closer academia-industry collaboration, more realistic modeling of attacker behavior, and inclusion of economic metrics in evaluations. This work represents an important step toward more effective assessment and mitigation of LLM-enabled cybersecurity risks.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "18",
        "title": "BTS: Harmonizing Specialized Experts into a Generalist LLM",
        "author": [
            "Qizhen Zhang",
            "Prajjwal Bhargava",
            "Chloe Bi",
            "Chris X. Cai",
            "Jakob Foerster",
            "Jeremy Fu",
            "Punit Singh Koura",
            "Ruan Silva",
            "Sheng Shen",
            "Emily Dinan",
            "Suchin Gururangan",
            "Mike Lewis"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00075",
        "abstract": "We present Branch-Train-Stitch (BTS), an efficient and flexible training algorithm for combining independently trained large language model (LLM) experts into a single, capable generalist model. Following Li et al., we start with a single seed language model which is branched into domain-specific (e.g., coding or math) experts with continual pretraining. BTS combines experts into a generalist model using lightweight stitch layers, which are inserted between frozen experts and the seed LLM, and trained on a small datamix of the expert domains. Stitch layers enable the seed LLM to integrate representations from any number of experts during the forward pass, allowing it to generalize to new domains, despite remaining frozen. Because BTS does not alter the constituent LLMs, BTS provides a modular and flexible approach: experts can be easily removed and new experts can be added with only a small amount of training. Compared to alternative model merging approaches, BTS yields the best generalist performance on a variety of downstream tasks, retaining the specialized capabilities of each of the experts.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "19",
        "title": "CerraData-4MM: A multimodal benchmark dataset on Cerrado for land use and land cover classification",
        "author": [
            "Mateus de Souza Miranda",
            "Ronny HÃ¤nsch",
            "Valdivino Alexandre de Santiago JÃºnior",
            "Thales Sehn KÃ¶rting",
            "Erison Carlos dos Santos Monteiro"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00083",
        "abstract": "The Cerrado faces increasing environmental pressures, necessitating accurate land use and land cover (LULC) mapping despite challenges such as class imbalance and visually similar categories. To address this, we present CerraData-4MM, a multimodal dataset combining Sentinel-1 Synthetic Aperture Radar (SAR) and Sentinel-2 MultiSpectral Imagery (MSI) with 10m spatial resolution. The dataset includes two hierarchical classification levels with 7 and 14 classes, respectively, focusing on the diverse Bico do Papagaio ecoregion. We highlight CerraData-4MM's capacity to benchmark advanced semantic segmentation techniques by evaluating a standard U-Net and a more sophisticated Vision Transformer (ViT) model. The ViT achieves superior performance in multimodal scenarios, with the highest macro F1-score of 57.60% and a mean Intersection over Union (mIoU) of 49.05% at the first hierarchical level. Both models struggle with minority classes, particularly at the second hierarchical level, where U-Net's performance drops to an F1-score of 18.16%. Class balancing improves representation for underrepresented classes but reduces overall accuracy, underscoring the trade-off in weighted training. CerraData-4MM offers a challenging benchmark for advancing deep learning models to handle class imbalance and multimodal data fusion. Code, trained models, and data are publicly available at https://github.com/ai4luc/CerraData-4MM.",
        "tags": [
            "Segmentation",
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "20",
        "title": "Efficient Beam Search for Large Language Models Using Trie-Based Decoding",
        "author": [
            "Brian J Chan",
            "Jui-Hung Cheng",
            "Mao Xun Huang",
            "Chao-Ting Chen",
            "Hen-Hsen Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00085",
        "abstract": "In Transformer-based sequence-to-sequence generation, beam search has proven effective in enhancing the quality of generated sequences compared to greedy decoding. Conventional beam search methods typically adopt either a sequential or batch-based approach. The sequential approach, while memory-efficient, requires multiple decoding passes to construct a complete search tree, leading to significantly slower inference. On the other hand, the batch-based approach enables parallel computation across beams, but at the expense of high memory consumption due to the need to maintain separate key-value (KV) caches for each beam. In this study, we introduce a novel trie (prefix-tree)-based parallel decoding method that addresses the memory inefficiency of batch-based beam search. By sharing a single KV cache among all beams that share the same prefix, the proposed method not only reduces memory consumption dramatically but also enables parallel decoding across all branches. This innovative use of a prefix tree offers an efficient alternative for beam search, achieving significant memory savings while preserving inference speed, making it particularly well-suited for memory-constrained environments or large-scale model deployments.",
        "tags": [
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "21",
        "title": "Ensembles of Low-Rank Expert Adapters",
        "author": [
            "Yinghao Li",
            "Vianne Gao",
            "Chao Zhang",
            "MohamadAli Torkamani"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00089",
        "abstract": "The training and fine-tuning of large language models (LLMs) often involve diverse textual data from multiple sources, which poses challenges due to conflicting gradient directions, hindering optimization and specialization. These challenges can undermine model generalization across tasks, resulting in reduced downstream performance. Recent research suggests that fine-tuning LLMs on carefully selected, task-specific subsets of data can match or even surpass the performance of using the entire dataset. Building on these insights, we propose the Ensembles of Low-Rank Expert Adapters (ELREA) framework to improve the model's capability to handle diverse tasks. ELREA clusters the training instructions based on their gradient directions, representing different areas of expertise and thereby reducing conflicts during optimization. Expert adapters are then trained on these clusters, utilizing the low-rank adaptation (LoRA) technique to ensure training efficiency and model scalability. During inference, ELREA combines predictions from the most relevant expert adapters based on the input data's gradient similarity to the training clusters, ensuring optimal adapter selection for each task. Experiments show that our method outperforms baseline LoRA adapters trained on the full dataset and other ensemble approaches with similar training and inference complexity across a range of domain-specific tasks.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "LoRA",
            "Low-Rank Adaptation"
        ]
    },
    {
        "id": "22",
        "title": "A Three-Branch Checks-and-Balances Frameworkfor Context-Aware Ethical Alignment of Large Language Models",
        "author": [
            "Edward Y. Chang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00136",
        "abstract": "This paper introduces a three-branch checks-and-balances framework for ethical alignment of Large Language Models (LLMs), inspired by governmental systems. It implements three independent yet interacting components: LLMs as the executive branch for knowledge generation, DIKE as the legislative branch establishing ethical guardrails, and ERIS as the judicial branch for contextual interpretation. The adversarial DIKE-ERIS duality enables adaptation to diverse cultural contexts while upholding consistent ethical principles. This architecture addresses limitations of reinforcement learning with human feedback (RLHF) by providing interpretable, adaptable, and culturally-aware ethical reasoning. Through self-supervised learning and adversarial testing, our framework demonstrates how emotional modeling can guide linguistic behaviors toward ethical outcomes while preserving independence across knowledge generation, ethical oversight, and contextual interpretation.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "23",
        "title": "ALBAR: Adversarial Learning approach to mitigate Biases in Action Recognition",
        "author": [
            "Joseph Fioresi",
            "Ishan Rajendrakumar Dave",
            "Mubarak Shah"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00156",
        "abstract": "Bias in machine learning models can lead to unfair decision making, and while it has been well-studied in the image and text domains, it remains underexplored in action recognition. Action recognition models often suffer from background bias (i.e., inferring actions based on background cues) and foreground bias (i.e., relying on subject appearance), which can be detrimental to real-life applications such as autonomous vehicles or assisted living monitoring. While prior approaches have mainly focused on mitigating background bias using specialized augmentations, we thoroughly study both biases. We propose ALBAR, a novel adversarial training method that mitigates foreground and background biases without requiring specialized knowledge of the bias attributes. Our framework applies an adversarial cross-entropy loss to the sampled static clip (where all the frames are the same) and aims to make its class probabilities uniform using a proposed entropy maximization loss. Additionally, we introduce a gradient penalty loss for regularization against the debiasing process. We evaluate our method on established background and foreground bias protocols, setting a new state-of-the-art and strongly improving combined debiasing performance by over 12% on HMDB51. Furthermore, we identify an issue of background leakage in the existing UCF101 protocol for bias evaluation which provides a shortcut to predict actions and does not provide an accurate measure of the debiasing capability of a model. We address this issue by proposing more fine-grained segmentation boundaries for the actor, where our method also outperforms existing approaches. Project Page: https://joefioresi718.github.io/ALBAR_webpage/",
        "tags": [
            "CLIP",
            "Segmentation"
        ]
    },
    {
        "id": "24",
        "title": "Resolving Editing-Unlearning Conflicts: A Knowledge Codebook Framework for Large Language Model Updating",
        "author": [
            "Binchi Zhang",
            "Zhengzhang Chen",
            "Zaiyi Zheng",
            "Jundong Li",
            "Haifeng Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00158",
        "abstract": "Large Language Models (LLMs) excel in natural language processing by encoding extensive human knowledge, but their utility relies on timely updates as knowledge evolves. Updating LLMs involves two key tasks simultaneously: unlearning to remove unwanted knowledge and editing to incorporate new information. Existing methods face two major challenges: ineffective knowledge storage (either too sparse or too dense) and task conflicts between editing and unlearning, as validated through our theoretical and experimental results. To address these issues, we propose LOKA, a conflict-free framework for LLM updating based on a knowledge codebook. During training, updated knowledge is stored in multiple codebook memories. To optimize knowledge storage, a similarity-aware knowledge mapping ensures that related knowledge pieces are clustered and allocated to the same memory. Additionally, LOKA resolves task conflicts by employing task-specific and multi-task memories guided by a conflict score. In the inference stage, LOKA retrieves the most relevant memory from the codebook and plugs it into the original LLM to apply the updated knowledge. A learning-based router controls codebook activation to further improve knowledge utilization. Extensive experiments demonstrate the effectiveness of LOKA in LLM knowledge updating tasks.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "25",
        "title": "Lifting by Gaussians: A Simple, Fast and Flexible Method for 3D Instance Segmentation",
        "author": [
            "Rohan Chacko",
            "Nicolai Haeni",
            "Eldar Khaliullin",
            "Lin Sun",
            "Douglas Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00173",
        "abstract": "We introduce Lifting By Gaussians (LBG), a novel approach for open-world instance segmentation of 3D Gaussian Splatted Radiance Fields (3DGS). Recently, 3DGS Fields have emerged as a highly efficient and explicit alternative to Neural Field-based methods for high-quality Novel View Synthesis. Our 3D instance segmentation method directly lifts 2D segmentation masks from SAM (alternately FastSAM, etc.), together with features from CLIP and DINOv2, directly fusing them onto 3DGS (or similar Gaussian radiance fields such as 2DGS). Unlike previous approaches, LBG requires no per-scene training, allowing it to operate seamlessly on any existing 3DGS reconstruction. Our approach is not only an order of magnitude faster and simpler than existing approaches; it is also highly modular, enabling 3D semantic segmentation of existing 3DGS fields without requiring a specific parametrization of the 3D Gaussians. Furthermore, our technique achieves superior semantic segmentation for 2D semantic novel view synthesis and 3D asset extraction results while maintaining flexibility and efficiency. We further introduce a novel approach to evaluate individually segmented 3D assets from 3D radiance field segmentation methods.",
        "tags": [
            "3D",
            "CLIP",
            "SAM",
            "Segmentation"
        ]
    },
    {
        "id": "26",
        "title": "The role of positional encodings in the ARC benchmark",
        "author": [
            "Guilherme H. Bandeira Costa",
            "Miguel Freire",
            "Arlindo L. Oliveira"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00174",
        "abstract": "The Abstraction and Reasoning Corpus challenges AI systems to perform abstract reasoning with minimal training data, a task intuitive for humans but demanding for machine learning models. Using CodeT5+ as a case study, we demonstrate how limitations in positional encoding hinder reasoning and impact performance. This work further examines the role of positional encoding across transformer architectures, highlighting its critical influence on models of varying sizes and configurations. Comparing several strategies, we find that while 2D positional encoding and Rotary Position Embedding offer competitive performance, 2D encoding excels in data-constrained scenarios, emphasizing its effectiveness for ARC tasks",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "27",
        "title": "Designing Scheduling for Diffusion Models via Spectral Analysis",
        "author": [
            "Roi Benita",
            "Michael Elad",
            "Joseph Keshet"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00180",
        "abstract": "Diffusion models (DMs) have emerged as powerful tools for modeling complex data distributions and generating realistic new samples. Over the years, advanced architectures and sampling methods have been developed to make these models practically usable. However, certain synthesis process decisions still rely on heuristics without a solid theoretical foundation. In our work, we offer a novel analysis of the DM's inference process, introducing a comprehensive frequency response perspective. Specifically, by relying on Gaussianity and shift-invariance assumptions, we present the inference process as a closed-form spectral transfer function, capturing how the generated signal evolves in response to the initial noise. We demonstrate how the proposed analysis can be leveraged for optimizing the noise schedule, ensuring the best alignment with the original dataset's characteristics. Our results lead to scheduling curves that are dependent on the frequency content of the data, offering a theoretical justification for some of the heuristics taken by practitioners.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "28",
        "title": "Byzantine-Resilient Zero-Order Optimization for Communication-Efficient Heterogeneous Federated Learning",
        "author": [
            "Maximilian Egger",
            "Mayank Bakshi",
            "Rawad Bitar"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00193",
        "abstract": "We introduce CyBeR-0, a Byzantine-resilient federated zero-order optimization method that is robust under Byzantine attacks and provides significant savings in uplink and downlink communication costs. We introduce transformed robust aggregation to give convergence guarantees for general non-convex objectives under client data heterogeneity. Empirical evaluations for standard learning tasks and fine-tuning large language models show that CyBeR-0 exhibits stable performance with only a few scalars per-round communication cost and reduced memory requirements.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "29",
        "title": "Physics-Informed Neural Network based Damage Identification for Truss Railroad Bridges",
        "author": [
            "Althaf Shajihan",
            "Kirill Mechitov",
            "Girish Chowdhary",
            "Billie F. Spencer Jr"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00194",
        "abstract": "Railroad bridges are a crucial component of the U.S. freight rail system, which moves over 40 percent of the nation's freight and plays a critical role in the economy. However, aging bridge infrastructure and increasing train traffic pose significant safety hazards and risk service disruptions. The U.S. rail network includes over 100,000 railroad bridges, averaging one every 1.4 miles of track, with steel bridges comprising over 50% of the network's total bridge length. Early identification and assessment of damage in these bridges remain challenging tasks. This study proposes a physics-informed neural network (PINN) based approach for damage identification in steel truss railroad bridges. The proposed approach employs an unsupervised learning approach, eliminating the need for large datasets typically required by supervised methods. The approach utilizes train wheel load data and bridge response during train crossing events as inputs for damage identification. The PINN model explicitly incorporates the governing differential equations of the linear time-varying (LTV) bridge-train system. Herein, this model employs a recurrent neural network (RNN) based architecture incorporating a custom Runge-Kutta (RK) integrator cell, designed for gradient-based learning. The proposed approach updates the bridge finite element model while also quantifying damage severity and localizing the affected structural members. A case study on the Calumet Bridge in Chicago, Illinois, with simulated damage scenarios, is used to demonstrate the model's effectiveness in identifying damage while maintaining low false-positive rates. Furthermore, the damage identification pipeline is designed to seamlessly integrate prior knowledge from inspections and drone surveys, also enabling context-aware updating and assessment of bridge's condition.",
        "tags": [
            "RNN"
        ]
    },
    {
        "id": "30",
        "title": "DermaSynth: Rich Synthetic Image-Text Pairs Using Open Access Dermatology Datasets",
        "author": [
            "Abdurrahim Yilmaz",
            "Furkan Yuceyalcin",
            "Ece Gokyayla",
            "Donghee Choi",
            "Ozan Erdem Ali Anil Demircali",
            "Rahmetullah Varol",
            "Ufuk Gorkem Kirabali",
            "Gulsum Gencoglan",
            "Joram M. Posma",
            "Burak Temelkuran"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00196",
        "abstract": "A major barrier to developing vision large language models (LLMs) in dermatology is the lack of large image--text pairs dataset. We introduce DermaSynth, a dataset comprising of 92,020 synthetic image--text pairs curated from 45,205 images (13,568 clinical and 35,561 dermatoscopic) for dermatology-related clinical tasks. Leveraging state-of-the-art LLMs, using Gemini 2.0, we used clinically related prompts and self-instruct method to generate diverse and rich synthetic texts. Metadata of the datasets were incorporated into the input prompts by targeting to reduce potential hallucinations. The resulting dataset builds upon open access dermatological image repositories (DERM12345, BCN20000, PAD-UFES-20, SCIN, and HIBA) that have permissive CC-BY-4.0 licenses. We also fine-tuned a preliminary Llama-3.2-11B-Vision-Instruct model, DermatoLlama 1.0, on 5,000 samples. We anticipate this dataset to support and accelerate AI research in dermatology. Data and code underlying this work are accessible at https://github.com/abdurrahimyilmaz/DermaSynth.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "31",
        "title": "Beyond Limited Data: Self-play LLM Theorem Provers with Iterative Conjecturing and Proving",
        "author": [
            "Kefan Dong",
            "Tengyu Ma"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00212",
        "abstract": "A fundamental challenge in formal theorem proving by LLMs is the lack of high-quality training data. Although reinforcement learning or expert iteration partially mitigates this issue by alternating between LLM generating proofs and finetuning them on correctly generated ones, performance quickly plateaus due to the scarcity of correct proofs (sparse rewards). To keep improving the models with limited data, we draw inspiration from mathematicians, who continuously develop new results, partly by proposing novel conjectures or exercises (which are often variants of known results) and attempting to solve them. We design the Self-play Theorem Prover (STP) that simultaneously takes on two roles, conjecturer and prover, each providing training signals to the other. The conjecturer is trained iteratively on previously generated conjectures that are barely provable by the current prover, which incentivizes it to generate increasingly challenging conjectures over time. The prover attempts to prove the conjectures with standard expert iteration. We evaluate STP with both Lean and Isabelle formal versifiers. With 19.8 billion tokens generated during the training in Lean, STP proves 26.3% of the statements in the LeanWorkbook dataset, doubling the previous best result of 13.2% achieved through expert iteration. The final model achieves state-of-the-art performance among whole-proof generation methods on miniF2F-test (61.1%, pass@3200), Proofnet-test (23.1%, pass@3200) and PutnamBench (8/644, pass@64).",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "32",
        "title": "Understanding Why Adam Outperforms SGD: Gradient Heterogeneity in Transformers",
        "author": [
            "Akiyoshi Tomihari",
            "Issei Sato"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00213",
        "abstract": "Transformer models are challenging to optimize with SGD and typically require adaptive optimizers such as Adam. However, the reasons behind the superior performance of Adam over SGD remain unclear. In this study, we investigate the optimization of transformer models by focusing on \\emph{gradient heterogeneity}, defined as the disparity in gradient norms among parameters. Our analysis shows that gradient heterogeneity hinders gradient-based optimization, including SGD, while sign-based optimization, a simplified variant of Adam, is less affected. We further examine gradient heterogeneity in transformer models and show that it is influenced by the placement of layer normalization. Additionally, we show that the momentum term in sign-based optimization is important for preventing the excessive growth of linear-head parameters in tasks with many classes. Experimental results from fine-tuning transformer models in both NLP and vision domains validate our theoretical analyses. This study provides insights into the optimization challenges of transformer models and offers guidance for designing future optimization algorithms. Code is available at \\url{https://github.com/tom4649/gradient-heterogeneity}.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "33",
        "title": "Should You Use Your Large Language Model to Explore or Exploit?",
        "author": [
            "Keegan Harris",
            "Aleksandrs Slivkins"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00225",
        "abstract": "We evaluate the ability of the current generation of large language models (LLMs) to help a decision-making agent facing an exploration-exploitation tradeoff. We use LLMs to explore and exploit in silos in various (contextual) bandit tasks. We find that while the current LLMs often struggle to exploit, in-context mitigations may be used to substantially improve performance for small-scale tasks. However even then, LLMs perform worse than a simple linear regression. On the other hand, we find that LLMs do help at exploring large action spaces with inherent semantics, by suggesting suitable candidates to explore.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "34",
        "title": "HackerRank-ASTRA: Evaluating Correctness & Consistency of Large Language Models on cross-domain multi-file project problems",
        "author": [
            "Jun Xing",
            "Mayur Bhatia",
            "Sahil Phulwani",
            "Darshan Suresh",
            "Rafik Matta"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00226",
        "abstract": "Evaluating the real-world applicability of large language models (LLMs) provides valuable insights for their development and use in software development tasks. Existing benchmarks often focus on standalone coding problems or specific libraries, overlooking multi-file, project-based scenarios and lacking a rigorous evaluation of consistency. The HackerRank-ASTRA Benchmark introduces project-based coding problems that mirror real-world scenarios. It evaluates model consistency through 32 runs (k = 32) and median standard deviation while incorporating taxonomy-level analysis to assess sub-skill capabilities. Initial evaluations on 65 problems show that the top three models -- o1, o1-preview, and Claude-3.5-Sonnet-1022 -- achieved comparable average scores of 75%, with no statistically significant differences in performance. Notably, Claude-3.5-Sonnet-1022 demonstrated the highest consistency across problems, with low variability (SD = 0.0497), which was statistically significant compared to other models, highlighting its reliability for real-world software development tasks.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "35",
        "title": "Fast Solvers for Discrete Diffusion Models: Theory and Applications of High-Order Algorithms",
        "author": [
            "Yinuo Ren",
            "Haoxuan Chen",
            "Yuchen Zhu",
            "Wei Guo",
            "Yongxin Chen",
            "Grant M. Rotskoff",
            "Molei Tao",
            "Lexing Ying"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00234",
        "abstract": "Discrete diffusion models have emerged as a powerful generative modeling framework for discrete data with successful applications spanning from text generation to image synthesis. However, their deployment faces challenges due to the high dimensionality of the state space, necessitating the development of efficient inference algorithms. Current inference approaches mainly fall into two categories: exact simulation and approximate methods such as $\\tau$-leaping. While exact methods suffer from unpredictable inference time and redundant function evaluations, $\\tau$-leaping is limited by its first-order accuracy. In this work, we advance the latter category by tailoring the first extension of high-order numerical inference schemes to discrete diffusion models, enabling larger step sizes while reducing error. We rigorously analyze the proposed schemes and establish the second-order accuracy of the $\\theta$-trapezoidal method in KL divergence. Empirical evaluations on GPT-2 level text and ImageNet-level image generation tasks demonstrate that our method achieves superior sample quality compared to existing approaches under equivalent computational constraints.",
        "tags": [
            "Diffusion",
            "GPT"
        ]
    },
    {
        "id": "36",
        "title": "Mordal: Automated Pretrained Model Selection for Vision Language Models",
        "author": [
            "Shiqi He",
            "Insu Jang",
            "Mosharaf Chowdhury"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00241",
        "abstract": "Incorporating multiple modalities into large language models (LLMs) is a powerful way to enhance their understanding of non-textual data, enabling them to perform multimodal tasks. Vision language models (VLMs) form the fastest growing category of multimodal models because of their many practical use cases, including in healthcare, robotics, and accessibility. Unfortunately, even though different VLMs in the literature demonstrate impressive visual capabilities in different benchmarks, they are handcrafted by human experts; there is no automated framework to create task-specific multimodal models.\nWe introduce Mordal, an automated multimodal model search framework that efficiently finds the best VLM for a user-defined task without manual intervention. Mordal achieves this both by reducing the number of candidates to consider during the search process and by minimizing the time required to evaluate each remaining candidate. Our evaluation shows that Mordal can find the best VLM for a given problem using up to $8.9\\times$--$11.6\\times$ lower GPU hours than grid search. In the process of our evaluation, we have also discovered new VLMs that outperform their state-of-the-art counterparts.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Robotics"
        ]
    },
    {
        "id": "37",
        "title": "Transformer-Based Vector Font Classification Using Different Font Formats: TrueType versus PostScript",
        "author": [
            "Takumu Fujioka",
            "Gouhei Tanaka"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00250",
        "abstract": "Modern fonts adopt vector-based formats, which ensure scalability without loss of quality. While many deep learning studies on fonts focus on bitmap formats, deep learning for vector fonts remains underexplored. In studies involving deep learning for vector fonts, the choice of font representation has often been made conventionally. However, the font representation format is one of the factors that can influence the computational performance of machine learning models in font-related tasks. Here we show that font representations based on PostScript outlines outperform those based on TrueType outlines in Transformer-based vector font classification. TrueType outlines represent character shapes as sequences of points and their associated flags, whereas PostScript outlines represent them as sequences of commands. In previous research, PostScript outlines have been predominantly used when fonts are treated as part of vector graphics, while TrueType outlines are mainly employed when focusing on fonts alone. Whether to use PostScript or TrueType outlines has been mainly determined by file format specifications and precedent settings in previous studies, rather than performance considerations. To date, few studies have compared which outline format provides better embedding representations. Our findings suggest that information aggregation is crucial in Transformer-based deep learning for vector graphics, as in tokenization in language models and patch division in bitmap-based image recognition models. This insight provides valuable guidance for selecting outline formats in future research on vector graphics.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "38",
        "title": "ProxSparse: Regularized Learning of Semi-Structured Sparsity Masks for Pretrained LLMs",
        "author": [
            "Hongyi Liu",
            "Rajarshi Saha",
            "Zhen Jia",
            "Youngsuk Park",
            "Jiaji Huang",
            "Shoham Sabach",
            "Yu-Xiang Wang",
            "George Karypis"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00258",
        "abstract": "Large Language Models (LLMs) have demonstrated exceptional performance in natural language processing tasks, yet their massive size makes serving them inefficient and costly. Semi-structured pruning has emerged as an effective method for model acceleration, but existing approaches are suboptimal because they focus on local, layer-wise optimizations using heuristic rules, failing to leverage global feedback. We present ProxSparse, a learning-based framework for mask selection enabled by regularized optimization. ProxSparse transforms the rigid, non-differentiable mask selection process into a smoother optimization procedure, allowing gradual mask exploration with flexibility. ProxSparse does not involve additional weight updates once the mask is determined. Our extensive evaluations on 7 widely used models show that ProxSparse consistently outperforms previously proposed semi-structured mask selection methods with significant improvement, demonstrating the effectiveness of our learned approach towards semi-structured pruning.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "39",
        "title": "MCM: Multi-layer Concept Map for Efficient Concept Learning from Masked Images",
        "author": [
            "Yuwei Sun",
            "Lu Mi",
            "Ippei Fujisawa",
            "Ryota Kanai"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00266",
        "abstract": "Masking strategies commonly employed in natural language processing are still underexplored in vision tasks such as concept learning, where conventional methods typically rely on full images. However, using masked images diversifies perceptual inputs, potentially offering significant advantages in concept learning with large-scale Transformer models. To this end, we propose Multi-layer Concept Map (MCM), the first work to devise an efficient concept learning method based on masked images. In particular, we introduce an asymmetric concept learning architecture by establishing correlations between different encoder and decoder layers, updating concept tokens using backward gradients from reconstruction tasks. The learned concept tokens at various levels of granularity help either reconstruct the masked image patches by filling in gaps or guide the reconstruction results in a direction that reflects specific concepts. Moreover, we present both quantitative and qualitative results across a wide range of metrics, demonstrating that MCM significantly reduces computational costs by training on fewer than 75% of the total image patches while enhancing concept prediction performance. Additionally, editing specific concept tokens in the latent space enables targeted image generation from masked images, aligning both the visible contextual patches and the provided concepts. By further adjusting the testing time mask ratio, we could produce a range of reconstructions that blend the visible patches with the provided concepts, proportional to the chosen ratios.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "40",
        "title": "Scaling Flaws of Verifier-Guided Search in Mathematical Reasoning",
        "author": [
            "Fei Yu",
            "Yingru Li",
            "Benyou Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00271",
        "abstract": "Large language models (LLMs) struggle with multi-step reasoning, where inference-time scaling has emerged as a promising strategy for performance improvement. Verifier-guided search outperforms repeated sampling when sample size is limited by selecting and prioritizing valid reasoning paths. However, we identify a critical limitation: scaling flaws, prevalent across different models (Mistral 7B and DeepSeekMath 7B), benchmarks (GSM8K and MATH), and verifiers (outcome value models and process reward models). As sample size increases, verifier-guided search exhibits diminishing advantages and eventually underperforms repeated sampling. Our analysis attributes this to verifier failures, where imperfect verifiers misrank candidates and erroneously prune all valid paths. These issues are further exacerbated in challenging and out-of-distribution problems, restricting search effectiveness. To mitigate verifier failures, we explore reducing reliance on verifiers and conduct preliminary investigations using two simple methods. Our findings reveal fundamental limitations in verifier-guided search and suggest future directions.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "41",
        "title": "On the study of frequency control and spectral bias in Wavelet-Based Kolmogorov Arnold networks: A path to physics-informed KANs",
        "author": [
            "Juan Daniel Meshir",
            "Abel Palafox",
            "Edgar Alejandro Guerrero"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00280",
        "abstract": "Spectral bias, the tendency of neural networks to prioritize learning low-frequency components of functions during the initial training stages, poses a significant challenge when approximating solutions with high-frequency details. This issue is particularly pronounced in physics-informed neural networks (PINNs), widely used to solve differential equations that describe physical phenomena. In the literature, contributions such as Wavelet Kolmogorov Arnold Networks (Wav-KANs) have demonstrated promising results in capturing both low- and high-frequency components. Similarly, Fourier features (FF) are often employed to address this challenge. However, the theoretical foundations of Wav-KANs, particularly the relationship between the frequency of the mother wavelet and spectral bias, remain underexplored. A more in-depth understanding of how Wav-KANs manage high-frequency terms could offer valuable insights for addressing oscillatory phenomena encountered in parabolic, elliptic, and hyperbolic differential equations. In this work, we analyze the eigenvalues of the neural tangent kernel (NTK) of Wav-KANs to enhance their ability to converge on high-frequency components, effectively mitigating spectral bias. Our theoretical findings are validated through numerical experiments, where we also discuss the limitations of traditional approaches, such as standard PINNs and Fourier features, in addressing multi-frequency problems.",
        "tags": [
            "Kolmogorov-Arnold Networks"
        ]
    },
    {
        "id": "42",
        "title": "Sigmoid Self-Attention is Better than Softmax Self-Attention: A Mixture-of-Experts Perspective",
        "author": [
            "Fanqi Yan",
            "Huy Nguyen",
            "Pedram Akbarian",
            "Nhat Ho",
            "Alessandro Rinaldo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00281",
        "abstract": "At the core of the popular Transformer architecture is the self-attention mechanism, which dynamically assigns softmax weights to each input token so that the model can focus on the most salient information. However, the softmax structure slows down the attention computation due to its row-wise nature, and inherently introduces competition among tokens: as the weight assigned to one token increases, the weights of others decrease. This competitive dynamic may narrow the focus of self-attention to a limited set of features, potentially overlooking other informative characteristics. Recent experimental studies have shown that using the element-wise sigmoid function helps eliminate token competition and reduce the computational overhead. Despite these promising empirical results, a rigorous comparison between sigmoid and softmax self-attention mechanisms remains absent in the literature. This paper closes this gap by theoretically demonstrating that sigmoid self-attention is more sample-efficient than its softmax counterpart. Toward that goal, we illustrate that each row of the self-attention matrix can be represented as a mixture of experts. Our analysis shows that ''experts'' in sigmoid self-attention require significantly less data to achieve the same approximation error as those in softmax self-attention. We corroborate our theoretical findings through extensive experiments on both synthetic and real-world datasets.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "43",
        "title": "Estimating LLM Uncertainty with Logits",
        "author": [
            "Huan Ma",
            "Jingdong Chen",
            "Guangyu Wang",
            "Changqing Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00290",
        "abstract": "In recent years, Large Language Models (LLMs) have seen remarkable advancements and have been extensively integrated across various fields. Despite their progress, LLMs are prone to hallucinations, producing responses that may not be dependable if the models lack sufficient grounding knowledge. To mitigate this issue, methods for estimating uncertainty have been adopted, with a focus on critical tokens as indicators of reliability. Nevertheless, probability-based approaches have shown limitations in assessing token-level reliability due to the erosion of evidence strength information acquired during training. In this paper, we introduce Logits-induced Token Uncertainty (LogU), a novel framework designed to estimate token-specific uncertainty in LLMs in real time, without the need for multiple sampling rounds. By leveraging evidence modeling for the implementation of LogU, we utilize the derived uncertainty measures to steer downstream tasks. Our experimental findings highlight the substantial effectiveness and potential of LogU, marking a significant advancement in addressing the challenge of model hallucinations.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "44",
        "title": "ChunkKV: Semantic-Preserving KV Cache Compression for Efficient Long-Context LLM Inference",
        "author": [
            "Xiang Liu",
            "Zhenheng Tang",
            "Peijie Dong",
            "Zeyu Li",
            "Bo Li",
            "Xuming Hu",
            "Xiaowen Chu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00299",
        "abstract": "To reduce memory costs in long-context inference with Large Language Models (LLMs), many recent works focus on compressing the key-value (KV) cache of different tokens. However, we identify that the previous KV cache compression methods measure token importance individually, neglecting the dependency between different tokens in the real-world language characterics. In light of this, we introduce ChunkKV, grouping the tokens in a chunk as a basic compressing unit, and retaining the most informative semantic chunks while discarding the less important ones. Furthermore, observing that ChunkKV exhibits higher similarity in the preserved indices across different layers, we propose layer-wise index reuse to further reduce computational overhead. We evaluated ChunkKV on cutting-edge long-context benchmarks including LongBench and Needle-In-A-HayStack, as well as the GSM8K and JailbreakV in-context learning benchmark. Our experiments with instruction tuning and multi-step reasoning (O1 and R1) LLMs, achieve up to 10\\% performance improvement under aggressive compression ratios compared to existing methods.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "45",
        "title": "Contextual Morphogenesis in Large Language Models: A Novel Approach to Self-Organizing Token Representations",
        "author": [
            "Alistair Dombrowski",
            "Beatrix Engelhardt",
            "Dimitri Fairbrother",
            "Henry Evidail"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00301",
        "abstract": "Token representations influence the efficiency and adaptability of language models, yet conventional tokenization strategies impose rigid segmentation boundaries that do not adjust dynamically to evolving contextual relationships. The introduction of contextual morphogenesis establishes a self-organizing mechanism that restructures token boundaries based on learned contextual dependencies, allowing embeddings to evolve progressively across iterative processing steps. Empirical evaluations demonstrate that dynamically adjusted tokenization contributes to reductions in perplexity while maintaining representational stability, particularly in linguistically complex domains where static segmentation fails to capture nuanced dependencies. Computational trade-offs associated with self-organizing token structures indicate that additional processing overhead remains within feasible limits, provided that optimization strategies account for segmentation update efficiency. Comparative assessments across different linguistic corpora suggest that adaptive tokenization preserves interpretability while improving alignment with contextual cues, reinforcing the potential of morphogenetic segmentation mechanisms to refine predictive accuracy. Stability analyses confirm that evolving token structures maintain consistent segmentation behaviors across varied text distributions, ensuring that representational adaptations remain linguistically coherent. The effectiveness of contextual morphogenesis in refining structural stability and predictive performance highlights its viability as an alternative to traditional tokenization methods. Further analysis of computational efficiency considerations suggests that hybrid strategies integrating both static and dynamic segmentation techniques may offer a balanced approach to optimizing representational flexibility while maintaining inference efficiency.",
        "tags": [
            "Large Language Models",
            "Segmentation"
        ]
    },
    {
        "id": "46",
        "title": "Riddle Me This! Stealthy Membership Inference for Retrieval-Augmented Generation",
        "author": [
            "Ali Naseh",
            "Yuefeng Peng",
            "Anshuman Suri",
            "Harsh Chaudhari",
            "Alina Oprea",
            "Amir Houmansadr"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00306",
        "abstract": "Retrieval-Augmented Generation (RAG) enables Large Language Models (LLMs) to generate grounded responses by leveraging external knowledge databases without altering model parameters. Although the absence of weight tuning prevents leakage via model parameters, it introduces the risk of inference adversaries exploiting retrieved documents in the model's context. Existing methods for membership inference and data extraction often rely on jailbreaking or carefully crafted unnatural queries, which can be easily detected or thwarted with query rewriting techniques common in RAG systems. In this work, we present Interrogation Attack (IA), a membership inference technique targeting documents in the RAG datastore. By crafting natural-text queries that are answerable only with the target document's presence, our approach demonstrates successful inference with just 30 queries while remaining stealthy; straightforward detectors identify adversarial prompts from existing methods up to ~76x more frequently than those generated by our attack. We observe a 2x improvement in TPR@1%FPR over prior inference attacks across diverse RAG configurations, all while costing less than $0.02 per document inference.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "47",
        "title": "A Diffusion Model Translator for Efficient Image-to-Image Translation",
        "author": [
            "Mengfei Xia",
            "Yu Zhou",
            "Ran Yi",
            "Yong-Jin Liu",
            "Wenping Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00307",
        "abstract": "Applying diffusion models to image-to-image translation (I2I) has recently received increasing attention due to its practical applications. Previous attempts inject information from the source image into each denoising step for an iterative refinement, thus resulting in a time-consuming implementation. We propose an efficient method that equips a diffusion model with a lightweight translator, dubbed a Diffusion Model Translator (DMT), to accomplish I2I. Specifically, we first offer theoretical justification that in employing the pioneering DDPM work for the I2I task, it is both feasible and sufficient to transfer the distribution from one domain to another only at some intermediate step. We further observe that the translation performance highly depends on the chosen timestep for domain transfer, and therefore propose a practical strategy to automatically select an appropriate timestep for a given task. We evaluate our approach on a range of I2I applications, including image stylization, image colorization, segmentation to image, and sketch to image, to validate its efficacy and general utility. The comparisons show that our DMT surpasses existing methods in both quality and efficiency. Code will be made publicly available.",
        "tags": [
            "DDPM",
            "Diffusion",
            "Segmentation"
        ]
    },
    {
        "id": "48",
        "title": "Sparse Gradient Compression for Fine-Tuning Large Language Models",
        "author": [
            "David H. Yang",
            "Mohammad Mohammadi Amiri",
            "Tejaswini Pedapati",
            "Subhajit Chaudhury",
            "Pin-Yu Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00311",
        "abstract": "Fine-tuning large language models (LLMs) for downstream tasks has become increasingly crucial due to their widespread use and the growing availability of open-source models. However, the high memory costs associated with fine-tuning remain a significant challenge, especially as models increase in size. To address this, parameter efficient fine-tuning (PEFT) methods have been proposed to minimize the number of parameters required for fine-tuning LLMs. However, these approaches often tie the number of optimizer states to dimensions of model parameters, limiting flexibility and control during fine-tuning. In this paper, we propose sparse gradient compression (SGC), a training regime designed to address these limitations. Our approach leverages inherent sparsity in gradients to compress optimizer states by projecting them onto a low-dimensonal subspace, with dimensionality independent of the original model's parameters. By enabling optimizer state updates in an arbitrary low-dimensional subspace, SGC offers a flexible tradeoff between memory efficiency and performance. We demonstrate through experiments that SGC can decrease memory usage in optimizer states more effectively than existing PEFT methods. Furthermore, by fine-tuning LLMs on various downstream tasks, we show that SGC can deliver superior performance while substantially lowering optimizer state memory requirements, particularly in both data-limited and memory-limited settings.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "49",
        "title": "Distributive Fairness in Large Language Models: Evaluating Alignment with Human Values",
        "author": [
            "Hadi Hosseini",
            "Samarth Khanna"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00313",
        "abstract": "The growing interest in employing large language models (LLMs) for decision-making in social and economic contexts has raised questions about their potential to function as agents in these domains. A significant number of societal problems involve the distribution of resources, where fairness, along with economic efficiency, play a critical role in the desirability of outcomes. In this paper, we examine whether LLM responses adhere to fundamental fairness concepts such as equitability, envy-freeness, and Rawlsian maximin, and investigate their alignment with human preferences. We evaluate the performance of several LLMs, providing a comparative benchmark of their ability to reflect these measures. Our results demonstrate a lack of alignment between current LLM responses and human distributional preferences. Moreover, LLMs are unable to utilize money as a transferable resource to mitigate inequality. Nonetheless, we demonstrate a stark contrast when (some) LLMs are tasked with selecting from a predefined menu of options rather than generating one. In addition, we analyze the robustness of LLM responses to variations in semantic factors (e.g. intentions or personas) or non-semantic prompting changes (e.g. templates or orderings). Finally, we highlight potential strategies aimed at enhancing the alignment of LLM behavior with well-established fairness concepts.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "50",
        "title": "MonoDINO-DETR: Depth-Enhanced Monocular 3D Object Detection Using a Vision Foundation Model",
        "author": [
            "Jihyeok Kim",
            "Seongwoo Moon",
            "Sungwon Nah",
            "David Hyunchul Shim"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00315",
        "abstract": "This paper proposes novel methods to enhance the performance of monocular 3D object detection models by leveraging the generalized feature extraction capabilities of a vision foundation model. Unlike traditional CNN-based approaches, which often suffer from inaccurate depth estimation and rely on multi-stage object detection pipelines, this study employs a Vision Transformer (ViT)-based foundation model as the backbone, which excels at capturing global features for depth estimation. It integrates a detection transformer (DETR) architecture to improve both depth estimation and object detection performance in a one-stage manner. Specifically, a hierarchical feature fusion block is introduced to extract richer visual features from the foundation model, further enhancing feature extraction capabilities. Depth estimation accuracy is further improved by incorporating a relative depth estimation model trained on large-scale data and fine-tuning it through transfer learning. Additionally, the use of queries in the transformer's decoder, which consider reference points and the dimensions of 2D bounding boxes, enhances recognition performance. The proposed model outperforms recent state-of-the-art methods, as demonstrated through quantitative and qualitative evaluations on the KITTI 3D benchmark and a custom dataset collected from high-elevation racing environments. Code is available at https://github.com/JihyeokKim/MonoDINO-DETR.",
        "tags": [
            "3D",
            "Depth Estimation",
            "Detection",
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "51",
        "title": "MODS: Moderating a Mixture of Document Speakers to Summarize Debatable Queries in Document Collections",
        "author": [
            "Nishant Balepur",
            "Alexa Siu",
            "Nedim Lipka",
            "Franck Dernoncourt",
            "Tong Sun",
            "Jordan Boyd-Graber",
            "Puneet Mathur"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00322",
        "abstract": "Query-focused summarization (QFS) gives a summary of documents to answer a query. Past QFS work assumes queries have one answer, ignoring debatable ones (Is law school worth it?). We introduce Debatable QFS (DQFS), a task to create summaries that answer debatable queries via documents with opposing perspectives; summaries must comprehensively cover all sources and balance perspectives, favoring no side. These goals elude LLM QFS systems, which: 1) lack structured content plans, failing to guide LLMs to write balanced summaries, and 2) use the same query to retrieve contexts across documents, failing to cover all perspectives specific to each document's content. To overcome this, we design MODS, a multi-LLM framework mirroring human panel discussions. MODS treats documents as individual Speaker LLMs and has a Moderator LLM that picks speakers to respond to tailored queries for planned topics. Speakers use tailored queries to retrieve relevant contexts from their documents and supply perspectives, which are tracked in a rich outline, yielding a content plan to guide the final summary. Experiments on ConflictingQA with controversial web queries and DebateQFS, our new dataset of debate queries from Debatepedia, show MODS beats SOTA by 38-59% in topic paragraph coverage and balance, based on new citation metrics. Users also find MODS's summaries to be readable and more balanced.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "52",
        "title": "From Few to Many: Self-Improving Many-Shot Reasoners Through Iterative Optimization and Generation",
        "author": [
            "Xingchen Wan",
            "Han Zhou",
            "Ruoxi Sun",
            "Hootan Nakhost",
            "Ke Jiang",
            "Sercan Ã. ArÄ±k"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00330",
        "abstract": "Recent advances in long-context large language models (LLMs) have led to the emerging paradigm of many-shot in-context learning (ICL), where it is observed that scaling many more demonstrating examples beyond the conventional few-shot setup in the context can lead to performance benefits. However, despite its promise, it is unclear what aspects dominate the benefits and whether simply scaling to more examples is the most effective way of improving many-shot ICL. In this work, we first provide an analysis of the factors driving many-shot ICL, and we find that 1) many-shot performance can still be attributed to often a few disproportionately influential examples and 2) identifying such influential examples (\"optimize\") and using them as demonstrations to regenerate new examples (\"generate\") can lead to further improvements. Inspired by the findings, we propose BRIDGE, an algorithm that alternates between the optimize step with Bayesian optimization to discover the influential sets of examples and the generate step to reuse this set to expand the reasoning paths of the examples back to the many-shot regime automatically. On Gemini, Claude, and Mistral LLMs of different sizes, we show that BRIDGE to significant improvements across a diverse set of tasks, including symbolic reasoning, numerical reasoning, and code generation.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "53",
        "title": "BiMaCoSR: Binary One-Step Diffusion Model Leveraging Flexible Matrix Compression for Real Super-Resolution",
        "author": [
            "Kai Liu",
            "Kaicheng Yang",
            "Zheng Chen",
            "Zhiteng Li",
            "Yong Guo",
            "Wenbo Li",
            "Linghe Kong",
            "Yulun Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00333",
        "abstract": "While super-resolution (SR) methods based on diffusion models (DM) have demonstrated inspiring performance, their deployment is impeded due to the heavy request of memory and computation. Recent researchers apply two kinds of methods to compress or fasten the DM. One is to compress the DM into 1-bit, aka binarization, alleviating the storage and computation pressure. The other distills the multi-step DM into only one step, significantly speeding up inference process. Nonetheless, it remains impossible to deploy DM to resource-limited edge devices. To address this problem, we propose BiMaCoSR, which combines binarization and one-step distillation to obtain extreme compression and acceleration. To prevent the catastrophic collapse of the model caused by binarization, we proposed sparse matrix branch (SMB) and low rank matrixbranch (LRM). Both auxiliary branches pass the full-precision (FP) information but in different ways. SMB absorbs the extreme values and its output is high rank, carrying abundant FP information. Whereas, the design of LRMB is inspired by LoRA and is initialized with the top r SVD components, outputting low rank representation. The computation and storage overhead of our proposed branches can be safely ignored. Comprehensive comparison experiments are conducted to exhibit BiMaCoSR outperforms current state-of-the-art binarization methods and gains competitive performance compared with FP one-step model. BiMaCoSR achieves a 23.8x compression ratio and a 27.4x speedup ratio compared to FP counterpart. Our code and model are available at https://github.com/Kai-Liu001/BiMaCoSR.",
        "tags": [
            "Diffusion",
            "LoRA",
            "Super Resolution"
        ]
    },
    {
        "id": "54",
        "title": "UGPhysics: A Comprehensive Benchmark for Undergraduate Physics Reasoning with Large Language Models",
        "author": [
            "Xin Xu",
            "Qiyun Xu",
            "Tong Xiao",
            "Tianhao Chen",
            "Yuchen Yan",
            "Jiaxin Zhang",
            "Shizhe Diao",
            "Can Yang",
            "Yang Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00334",
        "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in solving complex reasoning tasks, particularly in mathematics. However, the domain of physics reasoning presents unique challenges that have received significantly less attention. Existing benchmarks often fall short in evaluating LLMs' abilities on the breadth and depth of undergraduate-level physics, underscoring the need for a comprehensive evaluation. To fill this gap, we introduce UGPhysics, a large-scale and comprehensive benchmark specifically designed to evaluate UnderGraduate-level Physics (UGPhysics) reasoning with LLMs. UGPhysics includes 5,520 undergraduate-level physics problems in both English and Chinese, covering 13 subjects with seven different answer types and four distinct physics reasoning skills, all rigorously screened for data leakage. Additionally, we develop a Model-Assistant Rule-based Judgment (MARJ) pipeline specifically tailored for assessing answer correctness of physics problems, ensuring accurate evaluation. Our evaluation of 31 leading LLMs shows that the highest overall accuracy, 49.8% (achieved by OpenAI-o1-mini), emphasizes the necessity for models with stronger physics reasoning skills, beyond math abilities. We hope UGPhysics, along with MARJ, will drive future advancements in AI for physics reasoning.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "55",
        "title": "Denoising Score Matching with Random Features: Insights on Diffusion Models from Precise Learning Curves",
        "author": [
            "Anand Jerry George",
            "Rodrigo Veiga",
            "Nicolas Macris"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00336",
        "abstract": "We derive asymptotically precise expressions for test and train errors of denoising score matching (DSM) in generative diffusion models. The score function is parameterized by random features neural networks, with the target distribution being $d$-dimensional standard Gaussian. We operate in a regime where the dimension $d$, number of data samples $n$, and number of features $p$ tend to infinity while keeping the ratios $\\psi_n=\\frac{n}{d}$ and $\\psi_p=\\frac{p}{d}$ fixed. By characterizing the test and train errors, we identify regimes of generalization and memorization in diffusion models. Furthermore, our work sheds light on the conditions enhancing either generalization or memorization. Consistent with prior empirical observations, our findings indicate that the model complexity ($p$) and the number of noise samples per data sample ($m$) used during DSM significantly influence generalization and memorization behaviors.",
        "tags": [
            "Diffusion",
            "Score Matching"
        ]
    },
    {
        "id": "56",
        "title": "Challenges and Innovations in LLM-Powered Fake News Detection: A Synthesis of Approaches and Future Directions",
        "author": [
            "Jingyuan Yi",
            "Zeqiu Xu",
            "Tianyi Huang",
            "Peiyang Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00339",
        "abstract": "The pervasiveness of the dissemination of fake news through social media platforms poses critical risks to the trust of the general public, societal stability, and democratic institutions. This challenge calls for novel methodologies in detection, which can keep pace with the dynamic and multi-modal nature of misinformation. Recent works include powering the detection using large language model advances in multimodal frameworks, methodologies using graphs, and adversarial training in the literature of fake news. Based on the different approaches which can bring success, some key highlights will be underlined: enhanced LLM-improves accuracy through more advanced semantics and cross-modality fusion for robust detections. The review further identifies critical gaps in adaptability to dynamic social media trends, real-time, and cross-platform detection capabilities, as well as the ethical challenges thrown up by the misuse of LLMs. Future directions underline the development of style-agnostic models, cross-lingual detection frameworks, and robust policies with a view to mitigating LLM-driven misinformation. This synthesis thus lays a concrete foundation for those researchers and practitioners committed to reinforcing fake news detection systems with complications that keep on growing in the digital landscape.",
        "tags": [
            "Detection",
            "LLMs"
        ]
    },
    {
        "id": "57",
        "title": "Enhancing Token Filtering Efficiency in Large Language Model Training with Collider",
        "author": [
            "Di Chai",
            "Pengbo Li",
            "Feiyuan Zhang",
            "Yilun Jin",
            "Han Tian",
            "Junxue Zhang",
            "Kai Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00340",
        "abstract": "Token filtering has been proposed to enhance utility of large language models (LLMs) by eliminating inconsequential tokens during training. While using fewer tokens should reduce computational workloads, existing studies have not succeeded in achieving higher efficiency. This is primarily due to the insufficient sparsity caused by filtering tokens only in the output layers, as well as inefficient sparse GEMM (General Matrix Multiplication), even when having sufficient sparsity.\nThis paper presents Collider, a system unleashing the full efficiency of token filtering in LLM training. At its core, Collider filters activations of inconsequential tokens across all layers to maintain sparsity. Additionally, it features an automatic workflow that transforms sparse GEMM into dimension-reduced dense GEMM for optimized efficiency. Evaluations on three LLMs-TinyLlama-1.1B, Qwen2.5-1.5B, and Phi1.5-1.4B-demonstrate that Collider reduces backpropagation time by up to 35.1% and end-to-end training time by up to 22.0% when filtering 40% of tokens. Utility assessments of training TinyLlama on 15B tokens indicate that Collider sustains the utility advancements of token filtering by relatively improving model utility by 16.3% comparing to regular training, and reduces training time from 4.7 days to 3.5 days using 8 GPUs. Collider is designed for easy integration into existing LLM training frameworks, allowing systems already using token filtering to accelerate training with just one line of code.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "58",
        "title": "FinchGPT: a Transformer based language model for birdsong analysis",
        "author": [
            "Kosei Kobayashi",
            "Kosuke Matsuzaki",
            "Masaya Taniguchi",
            "Keisuke Sakaguchi",
            "Kentaro Inui",
            "Kentaro Abe"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00344",
        "abstract": "The long-range dependencies among the tokens, which originate from hierarchical structures, are a defining hallmark of human language. However, whether similar dependencies exist within the sequential vocalization of non-human animals remains a topic of investigation. Transformer architectures, known for their ability to model long-range dependencies among tokens, provide a powerful tool for investigating this phenomenon. In this study, we employed the Transformer architecture to analyze the songs of Bengalese finch (Lonchura striata domestica), which are characterized by their highly variable and complex syllable sequences. To this end, we developed FinchGPT, a Transformer-based model trained on a textualized corpus of birdsongs, which outperformed other architecture models in this domain. Attention weight analysis revealed that FinchGPT effectively captures long-range dependencies within syllables sequences. Furthermore, reverse engineering approaches demonstrated the impact of computational and biological manipulations on its performance: restricting FinchGPT's attention span and disrupting birdsong syntax through the ablation of specific brain nuclei markedly influenced the model's outputs. Our study highlights the transformative potential of large language models (LLMs) in deciphering the complexities of animal vocalizations, offering a novel framework for exploring the structural properties of non-human communication systems while shedding light on the computational distinctions between biological brains and artificial neural networks.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "59",
        "title": "Sampling in High-Dimensions using Stochastic Interpolants and Forward-Backward Stochastic Differential Equations",
        "author": [
            "Anand Jerry George",
            "Nicolas Macris"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00355",
        "abstract": "We present a class of diffusion-based algorithms to draw samples from high-dimensional probability distributions given their unnormalized densities. Ideally, our methods can transport samples from a Gaussian distribution to a specified target distribution in finite time. Our approach relies on the stochastic interpolants framework to define a time-indexed collection of probability densities that bridge a Gaussian distribution to the target distribution. Subsequently, we derive a diffusion process that obeys the aforementioned probability density at each time instant. Obtaining such a diffusion process involves solving certain Hamilton-Jacobi-Bellman PDEs. We solve these PDEs using the theory of forward-backward stochastic differential equations (FBSDE) together with machine learning-based methods. Through numerical experiments, we demonstrate that our algorithm can effectively draw samples from distributions that conventional methods struggle to handle.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "60",
        "title": "Do Audio-Visual Segmentation Models Truly Segment Sounding Objects?",
        "author": [
            "Jia Li",
            "Wenjie Zhao",
            "Ziru Huang",
            "Yunhui Guo",
            "Yapeng Tian"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00358",
        "abstract": "Unlike traditional visual segmentation, audio-visual segmentation (AVS) requires the model not only to identify and segment objects but also to determine whether they are sound sources. Recent AVS approaches, leveraging transformer architectures and powerful foundation models like SAM, have achieved impressive performance on standard benchmarks. Yet, an important question remains: Do these models genuinely integrate audio-visual cues to segment sounding objects? In this paper, we systematically investigate this issue in the context of robust AVS. Our study reveals a fundamental bias in current methods: they tend to generate segmentation masks based predominantly on visual salience, irrespective of the audio context. This bias results in unreliable predictions when sounds are absent or irrelevant. To address this challenge, we introduce AVSBench-Robust, a comprehensive benchmark incorporating diverse negative audio scenarios including silence, ambient noise, and off-screen sounds. We also propose a simple yet effective approach combining balanced training with negative samples and classifier-guided similarity learning. Our extensive experiments show that state-of-theart AVS methods consistently fail under negative audio conditions, demonstrating the prevalence of visual bias. In contrast, our approach achieves remarkable improvements in both standard metrics and robustness measures, maintaining near-perfect false positive rates while preserving highquality segmentation performance.",
        "tags": [
            "SAM",
            "Segmentation",
            "Transformer"
        ]
    },
    {
        "id": "61",
        "title": "Exploring Representation-Aligned Latent Space for Better Generation",
        "author": [
            "Wanghan Xu",
            "Xiaoyu Yue",
            "Zidong Wang",
            "Yao Teng",
            "Wenlong Zhang",
            "Xihui Liu",
            "Luping Zhou",
            "Wanli Ouyang",
            "Lei Bai"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00359",
        "abstract": "Generative models serve as powerful tools for modeling the real world, with mainstream diffusion models, particularly those based on the latent diffusion model paradigm, achieving remarkable progress across various tasks, such as image and video synthesis. Latent diffusion models are typically trained using Variational Autoencoders (VAEs), interacting with VAE latents rather than the real samples. While this generative paradigm speeds up training and inference, the quality of the generated outputs is limited by the latents' quality. Traditional VAE latents are often seen as spatial compression in pixel space and lack explicit semantic representations, which are essential for modeling the real world. In this paper, we introduce ReaLS (Representation-Aligned Latent Space), which integrates semantic priors to improve generation performance. Extensive experiments show that fundamental DiT and SiT trained on ReaLS can achieve a 15% improvement in FID metric. Furthermore, the enhanced semantic latent space enables more perceptual downstream tasks, such as segmentation and depth estimation.",
        "tags": [
            "Depth Estimation",
            "DiT",
            "Diffusion",
            "Segmentation",
            "VAE"
        ]
    },
    {
        "id": "62",
        "title": "Shape from Semantics: 3D Shape Generation from Multi-View Semantics",
        "author": [
            "Liangchen Li",
            "Caoliwen Wang",
            "Yuqi Zhou",
            "Bailin Deng",
            "Juyong Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00360",
        "abstract": "We propose ``Shape from Semantics'', which is able to create 3D models whose geometry and appearance match given semantics when observed from different views. Traditional ``Shape from X'' tasks usually use visual input (e.g., RGB images or depth maps) to reconstruct geometry, imposing strict constraints that limit creative explorations. As applications, works like Shadow Art and Wire Art often struggle to grasp the embedded semantics of their design through direct observation and rely heavily on specific setups for proper display. To address these limitations, our framework uses semantics as input, greatly expanding the design space to create objects that integrate multiple semantic elements and are easily discernible by observers. Considering that this task requires a rich imagination, we adopt various generative models and structure-to-detail pipelines. Specifically, we adopt multi-semantics Score Distillation Sampling (SDS) to distill 3D geometry and appearance from 2D diffusion models, ensuring that the initial shape is consistent with the semantic input. We then use image restoration and video generation models to add more details as supervision. Finally, we introduce neural signed distance field (SDF) representation to achieve detailed shape reconstruction. Our framework generates meshes with complex details, well-structured geometry, coherent textures, and smooth transitions, resulting in visually appealing and eye-catching designs. Project page: https://shapefromsemantics.github.io",
        "tags": [
            "3D",
            "Diffusion",
            "Video Generation"
        ]
    },
    {
        "id": "63",
        "title": "Soft Diffusion Actor-Critic: Efficient Online Reinforcement Learning for Diffusion Policy",
        "author": [
            "Haitong Ma",
            "Tianyi Chen",
            "Kai Wang",
            "Na Li",
            "Bo Dai"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00361",
        "abstract": "Diffusion policies have achieved superior performance in imitation learning and offline reinforcement learning (RL) due to their rich expressiveness. However, the vanilla diffusion training procedure requires samples from target distribution, which is impossible in online RL since we cannot sample from the optimal policy, making training diffusion policies highly non-trivial in online RL. Backpropagating policy gradient through the diffusion process incurs huge computational costs and instability, thus being expensive and impractical. To enable efficient diffusion policy training for online RL, we propose Soft Diffusion Actor-Critic (SDAC), exploiting the viewpoint of diffusion models as noise-perturbed energy-based models. The proposed SDAC relies solely on the state-action value function as the energy functions to train diffusion policies, bypassing sampling from the optimal policy while maintaining lightweight computations. We conducted comprehensive comparisons on MuJoCo benchmarks. The empirical results show that SDAC outperforms all recent diffusion-policy online RLs on most tasks, and improves more than 120% over soft actor-critic on complex locomotion tasks such as Humanoid and Ant.",
        "tags": [
            "Diffusion",
            "Energy-Based Models",
            "RL"
        ]
    },
    {
        "id": "64",
        "title": "NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding with Explicit Logic Reasoning",
        "author": [
            "Zhixi Cai",
            "Fucai Ke",
            "Simindokht Jahangard",
            "Maria Garcia de la Banda",
            "Reza Haffari",
            "Peter J. Stuckey",
            "Hamid Rezatofighi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00372",
        "abstract": "Visual Grounding (VG) tasks, such as referring expression detection and segmentation tasks are important for linking visual entities to context, especially in complex reasoning tasks that require detailed query interpretation. This paper explores VG beyond basic perception, highlighting challenges for methods that require reasoning like human cognition. Recent advances in large language methods (LLMs) and Vision-Language methods (VLMs) have improved abilities for visual comprehension, contextual understanding, and reasoning. These methods are mainly split into end-to-end and compositional methods, with the latter offering more flexibility. Compositional approaches that integrate LLMs and foundation models show promising performance but still struggle with complex reasoning with language-based logical representations. To address these limitations, we propose NAVER, a compositional visual grounding method that integrates explicit probabilistic logic reasoning within a finite-state automaton, equipped with a self-correcting mechanism. This design improves robustness and interpretability in inference through explicit logic reasoning. Our results show that NAVER achieves SoTA performance comparing to recent end-to-end and compositional baselines. The code is available at https://github.com/ControlNet/NAVER .",
        "tags": [
            "ControlNet",
            "Detection",
            "LLMs",
            "Segmentation"
        ]
    },
    {
        "id": "65",
        "title": "Masked Generative Nested Transformers with Decode Time Scaling",
        "author": [
            "Sahil Goyal",
            "Debapriya Tula",
            "Gagan Jain",
            "Pradeep Shenoy",
            "Prateek Jain",
            "Sujoy Paul"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00382",
        "abstract": "Recent advances in visual generation have made significant strides in producing content of exceptional quality. However, most methods suffer from a fundamental problem - a bottleneck of inference computational efficiency. Most of these algorithms involve multiple passes over a transformer model to generate tokens or denoise inputs. However, the model size is kept consistent throughout all iterations, which makes it computationally expensive. In this work, we aim to address this issue primarily through two key ideas - (a) not all parts of the generation process need equal compute, and we design a decode time model scaling schedule to utilize compute effectively, and (b) we can cache and reuse some of the computation. Combining these two ideas leads to using smaller models to process more tokens while large models process fewer tokens. These different-sized models do not increase the parameter size, as they share parameters. We rigorously experiment with ImageNet256$\\times$256 , UCF101, and Kinetics600 to showcase the efficacy of the proposed method for image/video generation and frame prediction. Our experiments show that with almost $3\\times$ less compute than baseline, our model obtains competitive performance.",
        "tags": [
            "Transformer",
            "Video Generation"
        ]
    },
    {
        "id": "66",
        "title": "The Impact of Persona-based Political Perspectives on Hateful Content Detection",
        "author": [
            "Stefano Civelli",
            "Pietro Bernardelle",
            "Gianluca Demartini"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00385",
        "abstract": "While pretraining language models with politically diverse content has been shown to improve downstream task fairness, such approaches require significant computational resources often inaccessible to many researchers and organizations. Recent work has established that persona-based prompting can introduce political diversity in model outputs without additional training. However, it remains unclear whether such prompting strategies can achieve results comparable to political pretraining for downstream tasks. We investigate this question using persona-based prompting strategies in multimodal hate-speech detection tasks, specifically focusing on hate speech in memes. Our analysis reveals that when mapping personas onto a political compass and measuring persona agreement, inherent political positioning has surprisingly little correlation with classification decisions. Notably, this lack of correlation persists even when personas are explicitly injected with stronger ideological descriptors. Our findings suggest that while LLMs can exhibit political biases in their responses to direct political questions, these biases may have less impact on practical classification tasks than previously assumed. This raises important questions about the necessity of computationally expensive political pretraining for achieving fair performance in downstream tasks.",
        "tags": [
            "Detection",
            "LLMs"
        ]
    },
    {
        "id": "67",
        "title": "FlexCloud: Direct, Modular Georeferencing and Drift-Correction of Point Cloud Maps",
        "author": [
            "Maximilian Leitenstern",
            "Marko Alten",
            "Christian Bolea-Schaser",
            "Dominik Kulmer",
            "Marcel Weinmann",
            "Markus Lienkamp"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00395",
        "abstract": "Current software stacks for real-world applications of autonomous driving leverage map information to ensure reliable localization, path planning, and motion prediction. An important field of research is the generation of point cloud maps, referring to the topic of simultaneous localization and mapping (SLAM). As most recent developments do not include global position data, the resulting point cloud maps suffer from internal distortion and missing georeferencing, preventing their use for map-based localization approaches. Therefore, we propose FlexCloud for an automatic georeferencing of point cloud maps created from SLAM. Our approach is designed to work modularly with different SLAM methods, utilizing only the generated local point cloud map and its odometry. Using the corresponding GNSS positions enables direct georeferencing without additional control points. By leveraging a 3D rubber-sheet transformation, we can correct distortions within the map caused by long-term drift while maintaining its structure. Our approach enables the creation of consistent, globally referenced point cloud maps from data collected by a mobile mapping system (MMS). The source code of our work is available at https://github.com/TUMFTM/FlexCloud.",
        "tags": [
            "3D",
            "SLAM"
        ]
    },
    {
        "id": "68",
        "title": "Minimalistic Video Saliency Prediction via Efficient Decoder & Spatio Temporal Action Cues",
        "author": [
            "Rohit Girmaji",
            "Siddharth Jain",
            "Bhav Beri",
            "Sarthak Bansal",
            "Vineet Gandhi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00397",
        "abstract": "This paper introduces ViNet-S, a 36MB model based on the ViNet architecture with a U-Net design, featuring a lightweight decoder that significantly reduces model size and parameters without compromising performance. Additionally, ViNet-A (148MB) incorporates spatio-temporal action localization (STAL) features, differing from traditional video saliency models that use action classification backbones. Our studies show that an ensemble of ViNet-S and ViNet-A, by averaging predicted saliency maps, achieves state-of-the-art performance on three visual-only and six audio-visual saliency datasets, outperforming transformer-based models in both parameter efficiency and real-time performance, with ViNet-S reaching over 1000fps.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "69",
        "title": "ALU: Agentic LLM Unlearning",
        "author": [
            "Debdeep Sanyal",
            "Murari Mandal"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00406",
        "abstract": "Information removal or suppression in large language models (LLMs) is a desired functionality, useful in AI regulation, legal compliance, safety, and privacy. LLM unlearning methods aim to remove information on demand from LLMs. Current LLM unlearning methods struggle to balance the unlearning efficacy and utility due to the competing nature of these objectives. Keeping the unlearning process computationally feasible without assuming access to the model weights is an overlooked area. We present the first agentic LLM unlearning (ALU) method, a multi-agent, retrain-free, model-agnostic approach to LLM unlearning that achieves effective unlearning while preserving the utility. Our ALU framework unlearns by involving multiple LLM agents, each designed for a specific step in the unlearning process, without the need to update model weights for any of the agents in the framework. Users can easily request any set of unlearning instances in any sequence, and ALU seamlessly adapts in real time. This is facilitated without requiring any changes in the underlying LLM model. Through extensive experiments on established benchmarks (TOFU, WMDP, WPU) and jailbreaking techniques (many shot, target masking, other languages), we demonstrate that ALU consistently stands out as the most robust LLM unlearning framework among current state-of-the-art methods while incurring a low constant-time cost. We further highlight ALU's superior performance compared to existing methods when evaluated at scale. Specifically, ALU is assessed on up to 1000 unlearning targets, exceeding the evaluation scope of all previously proposed LLM unlearning methods.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "70",
        "title": "Doing More with Less -- Implementing Routing Strategies in Large Language Model-Based Systems: An Extended Survey",
        "author": [
            "Clovis Varangot-Reille",
            "Christophe Bouvard",
            "Antoine Gourru",
            "Mathieu Ciancone",
            "Marion Schaeffer",
            "FranÃ§ois Jacquenet"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00409",
        "abstract": "Large Language Models (LLM)-based systems, i.e. interconnected elements that include an LLM as a central component (e.g., conversational agents), are typically monolithic static architectures that rely on a single LLM for all user queries. However, they often require different preprocessing strategies, levels of reasoning, or knowledge. Generalist LLMs (i.e. GPT-4), trained on very large multi-topic corpora, can perform well in a variety of tasks. However, they require significant financial, energy, and hardware resources that may not be justified for basic tasks. This implies potentially investing in unnecessary costs for a given query. To overcome this problem, a routing mechanism routes user queries to the most suitable components, such as smaller LLMs or experts in specific topics. This approach may improve response quality while minimising costs. Routing can be expanded to other components of the conversational agent architecture, such as the selection of optimal embedding strategies. This paper explores key considerations for integrating routing into LLM-based systems, focusing on resource management, cost definition, and strategy selection. Our main contributions include a formalisation of the problem, a novel taxonomy of existing approaches emphasising relevance and resource efficiency, and a comparative analysis of these strategies in relation to industry practices. Finally, we identify critical challenges and directions for future research.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "71",
        "title": "Social media polarization during conflict: Insights from an ideological stance dataset on Israel-Palestine Reddit comments",
        "author": [
            "Hasin Jawad Ali",
            "Ajwad Abrar",
            "S.M. Hozaifa Hossain",
            "M. Firoz Mridha"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00414",
        "abstract": "In politically sensitive scenarios like wars, social media serves as a platform for polarized discourse and expressions of strong ideological stances. While prior studies have explored ideological stance detection in general contexts, limited attention has been given to conflict-specific settings. This study addresses this gap by analyzing 9,969 Reddit comments related to the Israel-Palestine conflict, collected between October 2023 and August 2024. The comments were categorized into three stance classes: Pro-Israel, Pro-Palestine, and Neutral. Various approaches, including machine learning, pre-trained language models, neural networks, and prompt engineering strategies for open source large language models (LLMs), were employed to classify these stances. Performance was assessed using metrics such as accuracy, precision, recall, and F1-score. Among the tested methods, the Scoring and Reflective Re-read prompt in Mixtral 8x7B demonstrated the highest performance across all metrics. This study provides comparative insights into the effectiveness of different models for detecting ideological stances in highly polarized social media contexts. The dataset used in this research is publicly available for further exploration and validation.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "72",
        "title": "GO-GAN: Geometry Optimization Generative Adversarial Network for Achieving Optimized Structures with Targeted Physical Properties",
        "author": [
            "A. Padmaprabhan",
            "Shriram Hari",
            "Nived Philip Thomas",
            "Khaish Singh Chadha",
            "Sai Sidhardh",
            "Viswanath Chinthapenta",
            "Prabhat Kumar"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00416",
        "abstract": "This paper presents GO-GAN, a novel Generative Adversarial Network (GAN) architecture for geometry optimization (GO), specifically to generate structures based on user-specified input parameters. The architecture for GO-GAN proposed here combines a \\texttt{Pix2Pix} GAN with a new input mechanism, involving a dynamic batch gradient descent-based training loop that leverages dataset symmetries. The model, implemented here using \\texttt{TensorFlow} and \\texttt{Keras}, is trained using input images representing scalar physical properties generated by a custom MatLab code. After training, GO-GAN rapidly generates optimized geometries from input images representing scalar inputs of the physical properties. Results demonstrate GO-GAN's ability to produce acceptable designs with desirable variations. These variations are followed by the influence of discriminators during training and are of practical significance in ensuring adherence to specifications while enabling creative exploration of the design space.",
        "tags": [
            "GAN"
        ]
    },
    {
        "id": "73",
        "title": "Parameter Efficient Fine-Tuning of Segment Anything Model",
        "author": [
            "Carolin Teuber",
            "Anwai Archit",
            "Constantin Pape"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00418",
        "abstract": "Segmentation is an important analysis task for biomedical images, enabling the study of individual organelles, cells or organs. Deep learning has massively improved segmentation methods, but challenges remain in generalization to new conditions, requiring costly data annotation. Vision foundation models, such as Segment Anything Model (SAM), address this issue through broad segmentation capabilities. However, these models still require finetuning on annotated data, although with less annotations, to achieve optimal results for new conditions. As a downside, they require more computational resources. This makes parameter-efficient finetuning (PEFT) relevant for their application. We contribute the first comprehensive study of PEFT for SAM applied to biomedical segmentation by evaluating 9 PEFT methods on diverse datasets. We also provide an implementation of QLoRA for vision transformers and a new approach for resource-efficient finetuning of SAM. Our code is publicly available at https://github.com/computational-cell-analytics/peft-sam.",
        "tags": [
            "SAM",
            "Segment Anything",
            "Segmentation"
        ]
    },
    {
        "id": "74",
        "title": "MQuant: Unleashing the Inference Potential of Multimodal Large Language Models via Full Static Quantization",
        "author": [
            "JiangYong Yu",
            "Sifan Zhou",
            "Dawei Yang",
            "Shuo Wang",
            "Shuoyu Li",
            "Xing Hu",
            "Chen Xu",
            "Zukang Xu",
            "Changyong Shu",
            "Zhihang Yuan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00425",
        "abstract": "Multimodal large language models (MLLMs) have garnered widespread attention due to their ability to understand multimodal input. However, their large parameter sizes and substantial computational demands severely hinder their practical deployment and http://application.While quantization is an effective way to reduce model size and inference latency, its application to MLLMs remains underexplored. In this paper, we propose MQuant, a post-training quantization (PTQ) framework designed to tackle the unique challenges of multimodal large language models (MLLMs). Conventional quantization often struggles with MLLMs because of (a) high inference latency from large visual token counts, (b) distributional disparities between visual and textual tokens, and (c) extreme outliers introduced by Hadamard-based transformations. To address these issues, MQuant introduces: Modality-Specific Static Quantization (MSQ), assigning distinct static scales for visual vs. textual tokens; Attention-Invariant Flexible Switching (AIFS), reordering tokens to preserve casual attention while eliminating expensive token-wise scale computations; Rotation Magnitude Suppression (RMS), mitigating weight outliers arising from online Hadamard rotations. On five mainstream MLLMs (including Qwen-VL, MiniCPM-V, CogVLM2), MQuant under W4A8 achieves near-floating-point accuracy (<1% degradation) while reducing inference latency by up to 30%, significantly outperforming existing PTQ baselines. Our MQuant effectively bridges the gap for efficient and accurate MLLMs inference in resource-constrained devices. Code will be released.",
        "tags": [
            "Large Language Models",
            "Qwen"
        ]
    },
    {
        "id": "75",
        "title": "TeST-V: TEst-time Support-set Tuning for Zero-shot Video Classification",
        "author": [
            "Rui Yan",
            "Jin Wang",
            "Hongyu Qu",
            "Xiaoyu Du",
            "Dong Zhang",
            "Jinhui Tang",
            "Tieniu Tan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00426",
        "abstract": "Recently, adapting Vision Language Models (VLMs) to zero-shot visual classification by tuning class embedding with a few prompts (Test-time Prompt Tuning, TPT) or replacing class names with generated visual samples (support-set) has shown promising results. However, TPT cannot avoid the semantic gap between modalities while the support-set cannot be tuned. To this end, we draw on each other's strengths and propose a novel framework namely TEst-time Support-set Tuning for zero-shot Video Classification (TEST-V). It first dilates the support-set with multiple prompts (Multi-prompting Support-set Dilation, MSD) and then erodes the support-set via learnable weights to mine key cues dynamically (Temporal-aware Support-set Erosion, TSE). Specifically, i) MSD expands the support samples for each class based on multiple prompts enquired from LLMs to enrich the diversity of the support-set. ii) TSE tunes the support-set with factorized learnable weights according to the temporal prediction consistency in a self-supervised manner to dig pivotal supporting cues for each class. $\\textbf{TEST-V}$ achieves state-of-the-art results across four benchmarks and has good interpretability for the support-set dilation and erosion.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "76",
        "title": "CAT Pruning: Cluster-Aware Token Pruning For Text-to-Image Diffusion Models",
        "author": [
            "Xinle Cheng",
            "Zhuoming Chen",
            "Zhihao Jia"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00433",
        "abstract": "Diffusion models have revolutionized generative tasks, especially in the domain of text-to-image synthesis; however, their iterative denoising process demands substantial computational resources. In this paper, we present a novel acceleration strategy that integrates token-level pruning with caching techniques to tackle this computational challenge. By employing noise relative magnitude, we identify significant token changes across denoising iterations. Additionally, we enhance token selection by incorporating spatial clustering and ensuring distributional balance. Our experiments demonstrate reveal a 50%-60% reduction in computational costs while preserving the performance of the model, thereby markedly increasing the efficiency of diffusion models. The code is available at https://github.com/ada-cheng/CAT-Pruning",
        "tags": [
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "77",
        "title": "Secure Data Reconstruction: A Direct Data-Driven Approach",
        "author": [
            "Jiaqi Yan",
            "Ivan Markovsky",
            "John Lygeros"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00436",
        "abstract": "This paper addresses the problem of secure data reconstruction for unknown systems, where data collected from the system are susceptible to malicious manipulation. We aim to recover the real trajectory without prior knowledge of the system model. To achieve this, a behavioral language is used to represent the system, describing it using input/output trajectories instead of state-space models. We consider two attack scenarios. In the first scenario, up to $k$ entries of the collected data are malicious. On the other hand, the second scenario assumes that at most $k$ channels from sensors or actuators can be compromised, implying that any data collected from these channels might be falsified. For both scenarios, we formulate the trajectory recovery problem as an optimization problem and introduce sufficient conditions to ensure successful recovery of the true data. Since finding exact solutions to these problems can be computationally inefficient, we further approximate them using an $\\ell_1$-norm and group Least Absolute Shrinkage and Selection Operator (LASSO). We demonstrate that under certain conditions, these approximation problems also find the true trajectory while maintaining low computation complexity. Finally, we extend the proposed algorithms to noisy data. By reconstructing the secure trajectory, this work serves as a safeguard mechanism for subsequent data-driven control methods.",
        "tags": [
            "State Space Models"
        ]
    },
    {
        "id": "78",
        "title": "UniAttn: Reducing Inference Costs via Softmax Unification for Post-Training LLMs",
        "author": [
            "Yizhe Xiong",
            "Wei Huang",
            "Xin Ye",
            "Hui Chen",
            "Zijia Lin",
            "Haoran Lian",
            "Zhenpeng Su",
            "Jungong Han",
            "Guiguang Ding"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00439",
        "abstract": "Post-training is essential for adapting Large Language Models (LLMs) to real-world applications. Deploying post-trained models faces significant challenges due to substantial memory overhead and noticeable inference latency. Existing work has identified significant redundancies in LLMs and proposed efficient architectures, namely intra-layer KV sharing and cross-layer KV sharing. However, intra-layer KV sharing still results in high inference costs, while cross-layer KV sharing leads to significant performance degradation. As a result, both methods remain suboptimal for post-training pre-trained LLMs. In this paper, we identify that the \\texttt{Softmax} operation is a primary bottleneck for LLM inference and discover that it is actually highly redundant during post-training. We propose Softmax \\textbf{Uni}fication in \\textbf{Att}e\\textbf{n}tion (\\textbf{UniAttn}), a novel post-training method that unifies Softmax activations across transformer blocks to reduce LLM inference costs. Additionally, UniAttn adopts a linear projection to compensate for the errors induced by Softmax unification. Experiments show that UniAttn matches the performance of standard post-training while significantly reducing inference costs, outperforming existing efficient architectures during post-training. Our code will be available at \\url{https://github.com/Bostoncake/UniAttn}.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "79",
        "title": "HERA: Improving Long Document Summarization using Large Language Models with Context Packaging and Reordering",
        "author": [
            "Taiji Li",
            "Hao Chen",
            "Fei Yu",
            "Yin Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00448",
        "abstract": "Despite the rapid growth of context length of large language models (LLMs) , LLMs still perform poorly in long document summarization. An important reason for this is that relevant information about an event is scattered throughout long documents, and the messy narrative order impairs the accurate understanding and utilization of LLMs for long documents. To address these issues, we propose a novel summary generation framework, called HERA. Specifically, we first segment a long document by its semantic structure and retrieve text segments about the same event, and finally reorder them to form the input context. We evaluate our approach on two long document summarization datasets. The experimental results show that HERA outperforms foundation models in ROUGE, BERTScore and faithfulness metrics, while HERA does not require additional fine-tuning and resources.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "80",
        "title": "Explorations of the Softmax Space: Knowing When the Neural Network Doesn't Know...",
        "author": [
            "Daniel Sikar",
            "Artur d'Avila Garcez",
            "Tillman Weyde"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00456",
        "abstract": "Ensuring the reliability and safety of automated decision-making is crucial. This paper proposes a new approach for measuring the reliability of predictions in machine learning models. We analyze how the outputs of a trained neural network change using clustering to measure distances between outputs and class centroids. We propose this distance as a metric to evaluate the confidence of predictions. We assign each prediction to a cluster with centroid representing the mean softmax output for all correct predictions of a given class. We then define a safety threshold for a class as the smallest distance from an incorrect prediction to the given class centroid. We evaluate the approach on the MNIST and CIFAR-10 datasets using a Convolutional Neural Network and a Vision Transformer, respectively. The results show that our approach is consistent across these data sets and network models, and indicate that the proposed metric can offer an efficient way of determining when automated predictions are acceptable and when they should be deferred to human operators.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "81",
        "title": "MambaGlue: Fast and Robust Local Feature Matching With Mamba",
        "author": [
            "Kihwan Ryoo",
            "Hyungtae Lim",
            "Hyun Myung"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00462",
        "abstract": "In recent years, robust matching methods using deep learning-based approaches have been actively studied and improved in computer vision tasks. However, there remains a persistent demand for both robust and fast matching techniques. To address this, we propose a novel Mamba-based local feature matching approach, called MambaGlue, where Mamba is an emerging state-of-the-art architecture rapidly gaining recognition for its superior speed in both training and inference, and promising performance compared with Transformer architectures. In particular, we propose two modules: a) MambaAttention mixer to simultaneously and selectively understand the local and global context through the Mamba-based self-attention structure and b) deep confidence score regressor, which is a multi-layer perceptron (MLP)-based architecture that evaluates a score indicating how confidently matching predictions correspond to the ground-truth correspondences. Consequently, our MambaGlue achieves a balance between robustness and efficiency in real-world applications. As verified on various public datasets, we demonstrate that our MambaGlue yields a substantial performance improvement over baseline approaches while maintaining fast inference speed. Our code will be available on https://github.com/url-kaist/MambaGlue",
        "tags": [
            "Mamba",
            "Transformer"
        ]
    },
    {
        "id": "82",
        "title": "Enhancing Memory and Imagination Consistency in Diffusion-based World Models via Linear-Time Sequence Modeling",
        "author": [
            "Jia-Hua Lee",
            "Bor-Jiun Lin",
            "Wei-Fang Sun",
            "Chun-Yi Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00466",
        "abstract": "World models are crucial for enabling agents to simulate and plan within environments, yet existing approaches struggle with long-term dependencies and inconsistent predictions. We introduce EDELINE, a novel framework that integrates diffusion models with linear-time state space modelsto enhance memory retention and temporal consistency. EDELINE employs a recurrent embedding module based on Mamba SSMs for processing unbounded sequences, a unified architecture for joint reward and termination prediction, and dynamic loss harmonization to balance multi-task learning. Our results across multiple benchmarks demonstrate EDELINE's superiority and robustness over prior baselines in long-horizon tasks.",
        "tags": [
            "Diffusion",
            "Mamba",
            "SSMs"
        ]
    },
    {
        "id": "83",
        "title": "Weak-to-Strong Diffusion with Reflection",
        "author": [
            "Lichen Bai",
            "Masashi Sugiyama",
            "Zeke Xie"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00473",
        "abstract": "The goal of diffusion generative models is to align the learned distribution with the real data distribution through gradient score matching. However, inherent limitations in training data quality, modeling strategies, and architectural design lead to inevitable gap between generated outputs and real data. To reduce this gap, we propose Weak-to-Strong Diffusion (W2SD), a novel framework that utilizes the estimated difference between existing weak and strong models (i.e., weak-to-strong difference) to approximate the gap between an ideal model and a strong model. By employing a reflective operation that alternates between denoising and inversion with weak-to-strong difference, we theoretically understand that W2SD steers latent variables along sampling trajectories toward regions of the real data distribution. W2SD is highly flexible and broadly applicable, enabling diverse improvements through the strategic selection of weak-to-strong model pairs (e.g., DreamShaper vs. SD1.5, good experts vs. bad experts in MoE). Extensive experiments demonstrate that W2SD significantly improves human preference, aesthetic quality, and prompt adherence, achieving SOTA performance across various modalities (e.g., image, video), architectures (e.g., UNet-based, DiT-based, MoE), and benchmarks. For example, Juggernaut-XL with W2SD can improve with the HPSv2 winning rate up to 90% over the original results. Moreover, the performance gains achieved by W2SD markedly outweigh its additional computational overhead, while the cumulative improvements from different weak-to-strong difference further solidify its practical utility and deployability.",
        "tags": [
            "DiT",
            "Diffusion",
            "Score Matching"
        ]
    },
    {
        "id": "84",
        "title": "A framework for river connectivity classification using temporal image processing and attention based neural networks",
        "author": [
            "Timothy James Becker",
            "Derin Gezgin",
            "Jun Yi He Wu",
            "Mary Becker"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00474",
        "abstract": "Measuring the connectivity of water in rivers and streams is essential for effective water resource management. Increased extreme weather events associated with climate change can result in alterations to river and stream connectivity. While traditional stream flow gauges are costly to deploy and limited to large river bodies, trail camera methods are a low-cost and easily deployed alternative to collect hourly data. Image capturing, however requires stream ecologists to manually curate (select and label) tens of thousands of images per year. To improve this workflow, we developed an automated instream trail camera image classification system consisting of three parts: (1) image processing, (2) image augmentation and (3) machine learning. The image preprocessing consists of seven image quality filters, foliage-based luma variance reduction, resizing and bottom-center cropping. Images are balanced using variable amount of generative augmentation using diffusion models and then passed to a machine learning classification model in labeled form. By using the vision transformer architecture and temporal image enhancement in our framework, we are able to increase the 75% base accuracy to 90% for a new unseen site image. We make use of a dataset captured and labeled by staff from the Connecticut Department of Energy and Environmental Protection between 2018-2020. Our results indicate that a combination of temporal image processing and attention-based models are effective at classifying unseen river connectivity images.",
        "tags": [
            "Diffusion",
            "Transformer"
        ]
    },
    {
        "id": "85",
        "title": "Oscillations Make Neural Networks Robust to Quantization",
        "author": [
            "Jonathan WenshÃ¸j",
            "Bob Pepin",
            "Raghavendra Selvan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00490",
        "abstract": "We challenge the prevailing view that oscillations in Quantization Aware Training (QAT) are merely undesirable artifacts caused by the Straight-Through Estimator (STE). Through theoretical analysis of QAT in linear models, we demonstrate that the gradient of the loss function can be decomposed into two terms: the original full-precision loss and a term that causes quantization oscillations. Based on these insights, we propose a novel regularization method that induces oscillations to improve quantization robustness. Contrary to traditional methods that focuses on minimizing the effects of oscillations, our approach leverages the beneficial aspects of weight oscillations to preserve model performance under quantization. Our empirical results on ResNet-18 and Tiny ViT demonstrate that this counter-intuitive strategy matches QAT accuracy at >= 3-bit weight quantization, while maintaining close to full precision accuracy at bits greater than the target bit. Our work therefore provides a new perspective on model preparation for quantization, particularly for finding weights that are robust to changes in the bit of the quantizer -- an area where current methods struggle to match the accuracy of QAT at specific bits.",
        "tags": [
            "ViT"
        ]
    },
    {
        "id": "86",
        "title": "MetaOpenFOAM 2.0: Large Language Model Driven Chain of Thought for Automating CFD Simulation and Post-Processing",
        "author": [
            "Yuxuan Chen",
            "Xu Zhu",
            "Hua Zhou",
            "Zhuyin Ren"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00498",
        "abstract": "Computational Fluid Dynamics (CFD) is widely used in aerospace, energy, and biology to model fluid flow, heat transfer, and chemical reactions. While Large Language Models (LLMs) have transformed various domains, their application in CFD remains limited, particularly for complex tasks like post-processing. To bridge this gap, we introduce MetaOpenFOAM 2.0, which leverages Chain of Thought (COT) decomposition and iterative verification to enhance accessibility for non-expert users through natural language inputs. Tested on a new benchmark covering simulation (fluid flow, heat transfer, combustion) and post-processing (extraction, visualization), MetaOpenFOAM 2.0 achieved an Executability score of 6.3/7 and a pass rate of 86.9%, significantly outperforming MetaOpenFOAM 1.0 (2.1/7, 0%). Additionally, it proved cost-efficient, averaging $0.15 per case. An ablation study confirmed that COT-driven decomposition and iterative refinement substantially improved task performance. Furthermore, scaling laws showed that increasing COT steps enhanced accuracy while raising token usage, aligning with LLM post-training scaling trends. These results highlight the transformative potential of LLMs in automating CFD workflows for industrial and research applications. Code is available at https://github.com/Terry-cyx/MetaOpenFOAM",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "87",
        "title": "Video Latent Flow Matching: Optimal Polynomial Projections for Video Interpolation and Extrapolation",
        "author": [
            "Yang Cao",
            "Zhao Song",
            "Chiwun Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00500",
        "abstract": "This paper considers an efficient video modeling process called Video Latent Flow Matching (VLFM). Unlike prior works, which randomly sampled latent patches for video generation, our method relies on current strong pre-trained image generation models, modeling a certain caption-guided flow of latent patches that can be decoded to time-dependent video frames. We first speculate multiple images of a video are differentiable with respect to time in some latent space. Based on this conjecture, we introduce the HiPPO framework to approximate the optimal projection for polynomials to generate the probability path. Our approach gains the theoretical benefits of the bounded universal approximation error and timescale robustness. Moreover, VLFM processes the interpolation and extrapolation abilities for video generation with arbitrary frame rates. We conduct experiments on several text-to-video datasets to showcase the effectiveness of our method.",
        "tags": [
            "Flow Matching",
            "Text-to-Video",
            "Video Generation"
        ]
    },
    {
        "id": "88",
        "title": "Bridging Internal Probability and Self-Consistency for Effective and Efficient LLM Reasoning",
        "author": [
            "Zhi Zhou",
            "Tan Yuhao",
            "Zenan Li",
            "Yuan Yao",
            "Lan-Zhe Guo",
            "Xiaoxing Ma",
            "Yu-Feng Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00511",
        "abstract": "Recent advancements in large language models (LLMs) have demonstrated remarkable reasoning capabilities. However, single-shot inference often yields unreliable results for complex reasoning tasks, leading researchers to explore multiple reasoning paths through methods such as perplexity and self-consistency. In this paper, we present the first theoretical error decomposition analysis of these techniques, breaking down their error into estimation error and model error. Our analysis reveals a fundamental trade-off: perplexity methods suffer from substantial model error due to the absence of a proper consistency function, while self-consistency exhibits high estimation error due to a slow error convergence rate. To overcome these limitations, we propose Reasoning-Pruning Perplexity Consistency (RPC). This approach combines Perplexity Consistency, which seamlessly integrates LLM perplexity with self-consistency, and Reasoning Pruning, which eliminates low-probability reasoning paths to effectively prevent the degeneration of estimation error reduction. Theoretical analysis demonstrates that RPC not only accelerates the convergence rate of estimation error to an exponential level but also holds strong potential for further reducing model error. Extensive empirical evaluations on seven benchmark datasets confirm that RPC can significantly improve reasoning performance, sample efficiency, and confidence reliability.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "89",
        "title": "CoDocBench: A Dataset for Code-Documentation Alignment in Software Maintenance",
        "author": [
            "Kunal Pai",
            "Premkumar Devanbu",
            "Toufique Ahmed"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00519",
        "abstract": "One of the central tasks in software maintenance is being able to understand and develop code changes. Thus, given a natural language description of the desired new operation of a function, an agent (human or AI) might be asked to generate the set of edits to that function to implement the desired new operation; likewise, given a set of edits to a function, an agent might be asked to generate a changed description, of that function's new workings. Thus, there is an incentive to train a neural model for change-related tasks. Motivated by this, we offer a new, \"natural\", large dataset of coupled changes to code and documentation mined from actual high-quality GitHub projects, where each sample represents a single commit where the code and the associated docstring were changed together. We present the methodology for gathering the dataset, and some sample, challenging (but realistic) tasks where our dataset provides opportunities for both learning and evaluation. We find that current models (specifically Llama-3.1 405B, Mixtral 8$\\times$22B) do find these maintenance-related tasks challenging.",
        "tags": [
            "LLaMA"
        ]
    },
    {
        "id": "90",
        "title": "PolarQuant: Leveraging Polar Transformation for Efficient Key Cache Quantization and Decoding Acceleration",
        "author": [
            "Songhao Wu",
            "Ang Lv",
            "Xiao Feng",
            "Yufei Zhang",
            "Xun Zhang",
            "Guojun Yin",
            "Wei Lin",
            "Rui Yan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00527",
        "abstract": "The KV cache in large language models is a dominant factor in memory usage, limiting their broader applicability. Quantizing the cache to lower bit widths is an effective way to reduce computational costs; however, previous methods struggle with quantizing key vectors due to outliers, resulting in excessive overhead. We propose a novel quantization approach called PolarQuant, which efficiently addresses the outlier challenge. We observe that outliers typically appear in only one of two dimensions, which are rotated together by a specific angle when rotary position embeddings are applied. When represented as two-dimensional vectors, these dimensions exhibit well-structured patterns, with radii and angles smoothly distributed in polar coordinates. This alleviates the challenge of outliers on per-channel quantization, making them well-suited for quantization. Thus, PolarQuant divides key vectors into groups of two-dimensional sub-vectors, encoding them as the corresponding quantized radius and the polar angle, rather than quantizing original key vectors directly. PolarQuant achieves the superior efficiency in KV cache quantization and accelerates the decoding process by turning the query-key inner product into a table lookup, all while maintaining the downstream performance of full-precision models.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "91",
        "title": "VertiFormer: A Data-Efficient Multi-Task Transformer for Off-Road Robot Mobility",
        "author": [
            "Mohammad Nazeri",
            "Anuj Pokhrel",
            "Alexandyr Card",
            "Aniket Datar",
            "Garrett Warnell",
            "Xuesu Xiao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00543",
        "abstract": "Sophisticated learning architectures, e.g., Transformers, present a unique opportunity for robots to understand complex vehicle-terrain kinodynamic interactions for off-road mobility. While internet-scale data are available for Natural Language Processing (NLP) and Computer Vision (CV) tasks to train Transformers, real-world mobility data are difficult to acquire with physical robots navigating off-road terrain. Furthermore, training techniques specifically designed to process text and image data in NLP and CV may not apply to robot mobility. In this paper, we propose VertiFormer, a novel data-efficient multi-task Transformer model trained with only one hour of data to address such challenges of applying Transformer architectures for robot mobility on extremely rugged, vertically challenging, off-road terrain. Specifically, VertiFormer employs a new learnable masked modeling and next token prediction paradigm to predict the next pose, action, and terrain patch to enable a variety of off-road mobility tasks simultaneously, e.g., forward and inverse kinodynamics modeling. The non-autoregressive design mitigates computational bottlenecks and error propagation associated with autoregressive models. VertiFormer's unified modality representation also enhances learning of diverse temporal mappings and state representations, which, combined with multiple objective functions, further improves model generalization. Our experiments offer insights into effectively utilizing Transformers for off-road robot mobility with limited data and demonstrate our efficiently trained Transformer can facilitate multiple off-road mobility tasks onboard a physical mobile robot.",
        "tags": [
            "Robot",
            "Transformer"
        ]
    },
    {
        "id": "92",
        "title": "Milmer: a Framework for Multiple Instance Learning based Multimodal Emotion Recognition",
        "author": [
            "Zaitian Wang",
            "Jian He",
            "Yu Liang",
            "Xiyuan Hu",
            "Tianhao Peng",
            "Kaixin Wang",
            "Jiakai Wang",
            "Chenlong Zhang",
            "Weili Zhang",
            "Shuang Niu",
            "Xiaoyang Xie"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00547",
        "abstract": "Emotions play a crucial role in human behavior and decision-making, making emotion recognition a key area of interest in human-computer interaction (HCI). This study addresses the challenges of emotion recognition by integrating facial expression analysis with electroencephalogram (EEG) signals, introducing a novel multimodal framework-Milmer. The proposed framework employs a transformer-based fusion approach to effectively integrate visual and physiological modalities. It consists of an EEG preprocessing module, a facial feature extraction and balancing module, and a cross-modal fusion module. To enhance visual feature extraction, we fine-tune a pre-trained Swin Transformer on emotion-related datasets. Additionally, a cross-attention mechanism is introduced to balance token representation across modalities, ensuring effective feature integration. A key innovation of this work is the adoption of a multiple instance learning (MIL) approach, which extracts meaningful information from multiple facial expression images over time, capturing critical temporal dynamics often overlooked in previous studies. Extensive experiments conducted on the DEAP dataset demonstrate the superiority of the proposed framework, achieving a classification accuracy of 96.72% in the four-class emotion recognition task. Ablation studies further validate the contributions of each module, highlighting the significance of advanced feature extraction and fusion strategies in enhancing emotion recognition performance. Our code are available at https://github.com/liangyubuaa/Milmer.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "93",
        "title": "Muti-Fidelity Prediction and Uncertainty Quantification with Laplace Neural Operators for Parametric Partial Differential Equations",
        "author": [
            "Haoyang Zheng",
            "Guang Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00550",
        "abstract": "Laplace Neural Operators (LNOs) have recently emerged as a promising approach in scientific machine learning due to the ability to learn nonlinear maps between functional spaces. However, this framework often requires substantial amounts of high-fidelity (HF) training data, which is often prohibitively expensive to acquire. To address this, we propose multi-fidelity Laplace Neural Operators (MF-LNOs), which combine a low-fidelity (LF) base model with parallel linear/nonlinear HF correctors and dynamic inter-fidelity weighting. This allows us to exploit correlations between LF and HF datasets and achieve accurate inference of quantities of interest even with sparse HF data. We further incorporate a modified replica exchange stochastic gradient Langevin algorithm, which enables a more effective posterior distribution estimation and uncertainty quantification in model predictions. Extensive validation across four canonical dynamical systems (the Lorenz system, Duffing oscillator, Burgers equation, and Brusselator reaction-diffusion system) demonstrates the framework's effectiveness. The results show significant improvements, with testing losses reduced by 40% to 80% compared to traditional approaches. This validates MF-LNO as a versatile tool for surrogate modeling in parametric PDEs, offering significant improvements in data efficiency and uncertainty-aware prediction.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "94",
        "title": "Optimal Sensor Placement in Power Transformers Using Physics-Informed Neural Networks",
        "author": [
            "Sirui Li",
            "Federica Bragone",
            "Matthieu Barreau",
            "Tor Laneryd",
            "Kateryna Morozovska"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00552",
        "abstract": "Our work aims at simulating and predicting the temperature conditions inside a power transformer using Physics-Informed Neural Networks (PINNs). The predictions obtained are then used to determine the optimal placement for temperature sensors inside the transformer under the constraint of a limited number of sensors, enabling efficient performance monitoring. The method consists of combining PINNs with Mixed Integer Optimization Programming to obtain the optimal temperature reconstruction inside the transformer. First, we extend our PINN model for the thermal modeling of power transformers to solve the heat diffusion equation from 1D to 2D space. Finally, we construct an optimal sensor placement model inside the transformer that can be applied to problems in 1D and 2D.",
        "tags": [
            "Diffusion",
            "Transformer"
        ]
    },
    {
        "id": "95",
        "title": "Assessment of ChatGPT for Engineering Statics Analysis",
        "author": [
            "Benjamin Hope",
            "Jayden Bracey",
            "Sahar Choukir",
            "Derek Warner"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00562",
        "abstract": "Large language models (LLMs) such as OpenAI's ChatGPT hold potential for automating engineering analysis, yet their reliability in solving multi-step statics problems remains uncertain. This study evaluates the performance of ChatGPT-4o and ChatGPT-o1-preview on foundational statics tasks, from simple calculations of Newton's second law of motion to beam and truss analyses and compares their results to first-year engineering students on a typical statics exam. To enhance accuracy, we developed a Custom GPT, embedding refined prompts directly into its instructions. This optimized model achieved an 82% score, surpassing the 75% student average, demonstrating the impact of tailored guidance. Despite these improvements, LLMs continued to exhibit errors in nuanced or open-ended problems, such as misidentifying tension and compression in truss members. These findings highlight both the promise and current limitations of AI in structural analysis, emphasizing the need for improved reasoning, multimodal capabilities, and targeted training data for future AI-driven automation in civil and mechanical engineering.",
        "tags": [
            "ChatGPT",
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "96",
        "title": "Contrastive Forward-Forward: A Training Algorithm of Vision Transformer",
        "author": [
            "Hossein Aghagolzadeh",
            "Mehdi Ezoji"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00571",
        "abstract": "Although backpropagation is widely accepted as a training algorithm for artificial neural networks, researchers are always looking for inspiration from the brain to find ways with potentially better performance. Forward-Forward is a new training algorithm that is more similar to what occurs in the brain, although there is a significant performance gap compared to backpropagation. In the Forward-Forward algorithm, the loss functions are placed after each layer, and the updating of a layer is done using two local forward passes and one local backward pass. Forward-Forward is in its early stages and has been designed and evaluated on simple multi-layer perceptron networks to solve image classification tasks. In this work, we have extended the use of this algorithm to a more complex and modern network, namely the Vision Transformer. Inspired by insights from contrastive learning, we have attempted to revise this algorithm, leading to the introduction of Contrastive Forward-Forward. Experimental results show that our proposed algorithm performs significantly better than the baseline Forward-Forward leading to an increase of up to 10% in accuracy and boosting the convergence speed by 5 to 20 times on Vision Transformer. Furthermore, if we take Cross Entropy as the baseline loss function in backpropagation, it will be demonstrated that the proposed modifications to the baseline Forward-Forward reduce its performance gap compared to backpropagation on Vision Transformer, and even outperforms it in certain conditions, such as inaccurate supervision.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "97",
        "title": "Understanding Multimodal LLMs Under Distribution Shifts: An Information-Theoretic Approach",
        "author": [
            "Changdae Oh",
            "Zhen Fang",
            "Shawn Im",
            "Xuefeng Du",
            "Yixuan Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00577",
        "abstract": "Multimodal large language models (MLLMs) have shown promising capabilities but struggle under distribution shifts, where evaluation data differ from instruction tuning distributions. Although previous works have provided empirical evaluations, we argue that establishing a formal framework that can characterize and quantify the risk of MLLMs is necessary to ensure the safe and reliable application of MLLMs in the real world. By taking an information-theoretic perspective, we propose the first theoretical framework that enables the quantification of the maximum risk of MLLMs under distribution shifts. Central to our framework is the introduction of Effective Mutual Information (EMI), a principled metric that quantifies the relevance between input queries and model responses. We derive an upper bound for the EMI difference between in-distribution (ID) and out-of-distribution (OOD) data, connecting it to visual and textual distributional discrepancies. Extensive experiments on real benchmark datasets, spanning 61 shift scenarios empirically validate our theoretical insights.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "98",
        "title": "Defense Against the Dark Prompts: Mitigating Best-of-N Jailbreaking with Prompt Evaluation",
        "author": [
            "Stuart Armstrong",
            "Matija Franklin",
            "Connor Stevens",
            "Rebecca Gorman"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00580",
        "abstract": "Recent work showed Best-of-N (BoN) jailbreaking using repeated use of random augmentations (such as capitalization, punctuation, etc) is effective against all major large language models (LLMs). We have found that $100\\%$ of the BoN paper's successful jailbreaks (confidence interval $[99.65\\%, 100.00\\%]$) and $99.8\\%$ of successful jailbreaks in our replication (confidence interval $[99.28\\%, 99.98\\%]$) were blocked with our Defense Against The Dark Prompts (DATDP) method. The DATDP algorithm works by repeatedly utilizing an evaluation LLM to evaluate a prompt for dangerous or manipulative behaviors--unlike some other approaches, DATDP also explicitly looks for jailbreaking attempts--until a robust safety rating is generated. This success persisted even when utilizing smaller LLMs to power the evaluation (Claude and LLaMa-3-8B-instruct proved almost equally capable). These results show that, though language models are sensitive to seemingly innocuous changes to inputs, they seem also capable of successfully evaluating the dangers of these inputs. Versions of DATDP can therefore be added cheaply to generative AI systems to produce an immediate significant increase in safety.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "99",
        "title": "Converting Transformers into DGNNs Form",
        "author": [
            "Jie Zhang",
            "Kuan-Chieh Wang",
            "Bo-Wei Chiu",
            "Min-Te Sun"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00585",
        "abstract": "Recent advances in deep learning have established Transformer architectures as the predominant modeling paradigm. Central to the success of Transformers is the self-attention mechanism, which scores the similarity between query and key matrices to modulate a value matrix. This operation bears striking similarities to digraph convolution, prompting an investigation into whether digraph convolution could serve as an alternative to self-attention. In this study, we formalize this concept by introducing a synthetic unitary digraph convolution based on the digraph Fourier transform. The resulting model, which we term Converter, effectively converts a Transformer into a Directed Graph Neural Network (DGNN) form. We have tested Converter on Long-Range Arena benchmark, long document classification, and DNA sequence-based taxonomy classification. Our experimental results demonstrate that Converter achieves superior performance while maintaining computational efficiency and architectural simplicity, which establishes it as a lightweight yet powerful Transformer variant.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "100",
        "title": "M+: Extending MemoryLLM with Scalable Long-Term Memory",
        "author": [
            "Yu Wang",
            "Dmitry Krotov",
            "Yuanzhe Hu",
            "Yifan Gao",
            "Wangchunshu Zhou",
            "Julian McAuley",
            "Dan Gutfreund",
            "Rogerio Feris",
            "Zexue He"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00592",
        "abstract": "Equipping large language models (LLMs) with latent-space memory has attracted increasing attention as they can extend the context window of existing language models. However, retaining information from the distant past remains a challenge. For example, MemoryLLM (Wang et al., 2024a), as a representative work with latent-space memory, compresses past information into hidden states across all layers, forming a memory pool of 1B parameters. While effective for sequence lengths up to 16k tokens, it struggles to retain knowledge beyond 20k tokens. In this work, we address this limitation by introducing M+, a memory-augmented model based on MemoryLLM that significantly enhances long-term information retention. M+ integrates a long-term memory mechanism with a co-trained retriever, dynamically retrieving relevant information during text generation. We evaluate M+ on diverse benchmarks, including long-context understanding and knowledge retention tasks. Experimental results show that M+ significantly outperforms MemoryLLM and recent strong baselines, extending knowledge retention from under 20k to over 160k tokens with similar GPU memory overhead.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "101",
        "title": "Fast Vision Mamba: Pooling Spatial Dimensions for Accelerated Processing",
        "author": [
            "Saarthak Kapse",
            "Robin Betz",
            "Srinivasan Sivanandan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00594",
        "abstract": "State Space Models (SSMs) with selective scan (Mamba) have been adapted into efficient vision models. Mamba, unlike Vision Transformers, achieves linear complexity for token interactions through a recurrent hidden state process. This sequential processing is enhanced by a parallel scan algorithm, which reduces the computational time of recurrent steps from $L$ sequential steps to $log(L)$ parallel steps with respect to the number of input tokens ($L$). In this work, we propose Fast Vision Mamba (FastVim), that further reduces the computational time of the SSM block by reducing the number of recurrent steps in Vision Mamba models while still retaining model performance. By alternately pooling tokens along image dimensions across Mamba blocks, we obtain a 2$\\times$ reduction in the number of parallel steps in SSM block. Our model offers up to $72.5\\%$ speedup in inference speed compared to baseline Vision Mamba models on high resolution (2048$\\times$2048) images. Our experiments demonstrate state-of-the-art performance with dramatically improved throughput in a range of tasks such as image classification, cell perturbation prediction, segmentation, and object detection. Code is made available at https://github.com/insitro/FastVim",
        "tags": [
            "Detection",
            "Mamba",
            "SSMs",
            "Segmentation",
            "State Space Models"
        ]
    },
    {
        "id": "102",
        "title": "RPGBENCH: Evaluating Large Language Models as Role-Playing Game Engines",
        "author": [
            "Pengfei Yu",
            "Dongming Shen",
            "Silin Meng",
            "Jaewon Lee",
            "Weisu Yin",
            "Andrea Yaoyun Cui",
            "Zhenlin Xu",
            "Yi Zhu",
            "Xingjian Shi",
            "Mu Li",
            "Alex Smola"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00595",
        "abstract": "We present RPGBench, the first benchmark designed to evaluate large language models (LLMs) as text-based role-playing game (RPG) engines. RPGBench comprises two core tasks: Game Creation (GC) and Game Simulation (GS). In GC, an LLM must craft a valid and playable RPG world using a structured event-state representation, ensuring logical coherence and proper termination conditions. In GS, the LLM simulates interactive gameplay across multiple rounds while consistently updating states and enforcing game rules. To comprehensively assess performance, RPGBench integrates objective and subjective evaluation methodologies. Objective measures verify adherence to event mechanics and check variable updates without requiring human intervention. Subjective measures, such as content interestingness, action quality, and role-playing capability, are evaluated via an LLM-as-a-judge framework, where a strong LLM grades each candidate's outputs. Empirical results demonstrate that state-of-the-art LLMs can produce engaging stories but often struggle to implement consistent, verifiable game mechanics, particularly in long or complex scenarios. By combining structured, rule-based assessments with LLM-based judgments, RPGBench provides a new standard for evaluating how well LLMs can balance creativity, coherence, and complexity in text-based RPGs, opening avenues for more immersive and controllable interactive storytelling.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "103",
        "title": "Mitigating Heterogeneous Token Overfitting in LLM Knowledge Editing",
        "author": [
            "Tianci Liu",
            "Zihan Dong",
            "Linjun Zhang",
            "Haoyu Wang",
            "Jing Gao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00602",
        "abstract": "Large language models (LLMs) have achieved remarkable performance on various natural language tasks. However, they are trained on static corpora and their knowledge can become outdated quickly in the fast-changing world. This motivates the development of knowledge editing (KE) to update specific knowledge in LLMs without changing unrelated others or compromising their pre-trained capabilities. Previous efforts sought to update a small amount of parameters of a LLM and proved effective for making selective updates. Nonetheless, the edited LLM often exhibits degraded ability to reason about the new knowledge. In this work, we identify a key issue: heterogeneous token overfitting (HTO), where the LLM overfits different tokens in the provided knowledge at varying rates. To tackle this, we propose OVERTONE, a token-level smoothing method that mitigates HTO by adaptively refining the target distribution. Theoretically, OVERTONE offers better parameter updates with negligible computation overhead. It also induces an implicit DPO but does not require preference data pairs. Extensive experiments across four editing methods, two LLMs, and diverse scenarios demonstrate the effectiveness and versatility of our method.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "104",
        "title": "Enhancing Code Consistency in AI Research with Large Language Models and Retrieval-Augmented Generation",
        "author": [
            "Rajat Keshri",
            "Arun George Zachariah",
            "Michael Boone"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00611",
        "abstract": "Ensuring that code accurately reflects the algorithms and methods described in research papers is critical for maintaining credibility and fostering trust in AI research. This paper presents a novel system designed to verify code implementations against the algorithms and methodologies outlined in corresponding research papers. Our system employs Retrieval-Augmented Generation to extract relevant details from both the research papers and code bases, followed by a structured comparison using Large Language Models. This approach improves the accuracy and comprehensiveness of code implementation verification while contributing to the transparency, explainability, and reproducibility of AI research. By automating the verification process, our system reduces manual effort, enhances research credibility, and ultimately advances the state of the art in code verification.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "105",
        "title": "Efficient Language Modeling for Low-Resource Settings with Hybrid RNN-Transformer Architectures",
        "author": [
            "Gabriel Lindenmaier",
            "Sean Papay",
            "Sebastian PadÃ³"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00617",
        "abstract": "Transformer-based language models have recently been at the forefront of active research in text generation. However, these models' advances come at the price of prohibitive training costs, with parameter counts in the billions and compute requirements measured in petaflop/s-decades. In this paper, we investigate transformer-based architectures for improving model performance in a low-data regime by selectively replacing attention layers with feed-forward and quasi-recurrent neural network layers. We test these architectures on the standard Enwik8 and Wikitext-103 corpora. Our results show that our reduced architectures outperform existing models with a comparable number of parameters, and obtain comparable performance to larger models while significantly reducing the number of parameters.",
        "tags": [
            "RNN",
            "Transformer"
        ]
    },
    {
        "id": "106",
        "title": "Strengthening Generative Robot Policies through Predictive World Modeling",
        "author": [
            "Han Qi",
            "Haocheng Yin",
            "Yilun Du",
            "Heng Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00622",
        "abstract": "We present generative predictive control (GPC), a learning control framework that (i) clones a generative diffusion-based policy from expert demonstrations, (ii) trains a predictive action-conditioned world model from both expert demonstrations and random explorations, and (iii) synthesizes an online planner that ranks and optimizes the action proposals from (i) by looking ahead into the future using the world model from (ii). Crucially, we show that conditional video diffusion allows learning (near) physics-accurate visual world models and enable robust visual foresight. Focusing on planar pushing with rich contact and collision, we show GPC dominates behavior cloning across state-based and vision-based, simulated and real-world experiments.",
        "tags": [
            "Diffusion",
            "Robot"
        ]
    },
    {
        "id": "107",
        "title": "Advanced Weakly-Supervised Formula Exploration for Neuro-Symbolic Mathematical Reasoning",
        "author": [
            "Yuxuan Wu",
            "Hideki Nakayama"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00629",
        "abstract": "In recent years, neuro-symbolic methods have become a popular and powerful approach that augments artificial intelligence systems with the capability to perform abstract, logical, and quantitative deductions with enhanced precision and controllability. Recent studies successfully performed symbolic reasoning by leveraging various machine learning models to explicitly or implicitly predict intermediate labels that provide symbolic instructions. However, these intermediate labels are not always prepared for every task as a part of training data, and pre-trained models, represented by Large Language Models (LLMs), also do not consistently generate valid symbolic instructions with their intrinsic knowledge. On the other hand, existing work developed alternative learning techniques that allow the learning system to autonomously uncover optimal symbolic instructions. Nevertheless, their performance also exhibits limitations when faced with relatively huge search spaces or more challenging reasoning problems. In view of this, in this work, we put forward an advanced practice for neuro-symbolic reasoning systems to explore the intermediate labels with weak supervision from problem inputs and final outputs. Our experiments on the Mathematics dataset illustrated the effectiveness of our proposals from multiple aspects.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "108",
        "title": "Patterns and Purposes: A Cross-Journal Analysis of AI Tool Usage in Academic Writing",
        "author": [
            "Ziyang Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00632",
        "abstract": "This study investigates the use of AI tools in academic writing through analysis of AI usage declarations in journals. Using a mixed-methods approach combining content analysis, statistical analysis, and text mining, this research analyzed 168 AI declarations from 8,859 articles across 27 categories. Results show that ChatGPT dominates academic writing assistance (77% usage), with significant differences in tool usage between native and non-native English speakers (p = 0.0483) and between international and non-international teams (p = 0.0012). The study reveals that improving readability (51%) and grammar checking (22%) are the primary purposes of AI tool usage. These findings provide insights for journal policy development and understanding the evolving role of AI in academic writing.",
        "tags": [
            "ChatGPT"
        ]
    },
    {
        "id": "109",
        "title": "SimulPL: Aligning Human Preferences in Simultaneous Machine Translation",
        "author": [
            "Donglei Yu",
            "Yang Zhao",
            "Jie Zhu",
            "Yangyifan Xu",
            "Yu Zhou",
            "Chengqing Zong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00634",
        "abstract": "Simultaneous Machine Translation (SiMT) generates translations while receiving streaming source inputs. This requires the SiMT model to learn a read/write policy, deciding when to translate and when to wait for more source input. Numerous linguistic studies indicate that audiences in SiMT scenarios have distinct preferences, such as accurate translations, simpler syntax, and no unnecessary latency. Aligning SiMT models with these human preferences is crucial to improve their performances. However, this issue still remains unexplored. Additionally, preference optimization for SiMT task is also challenging. Existing methods focus solely on optimizing the generated responses, ignoring human preferences related to latency and the optimization of read/write policy during the preference optimization phase. To address these challenges, we propose Simultaneous Preference Learning (SimulPL), a preference learning framework tailored for the SiMT task. In the SimulPL framework, we categorize SiMT human preferences into five aspects: \\textbf{translation quality preference}, \\textbf{monotonicity preference}, \\textbf{key point preference}, \\textbf{simplicity preference}, and \\textbf{latency preference}. By leveraging the first four preferences, we construct human preference prompts to efficiently guide GPT-4/4o in generating preference data for the SiMT task. In the preference optimization phase, SimulPL integrates \\textbf{latency preference} into the optimization objective and enables SiMT models to improve the read/write policy, thereby aligning with human preferences more effectively. Experimental results indicate that SimulPL exhibits better alignment with human preferences across all latency levels in Zh$\\rightarrow$En, De$\\rightarrow$En and En$\\rightarrow$Zh SiMT tasks. Our data and code will be available at \\url{https://github.com/EurekaForNLP/SimulPL}.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "110",
        "title": "Zeroth-order Informed Fine-Tuning for Diffusion Model: A Recursive Likelihood Ratio Optimizer",
        "author": [
            "Tao Ren",
            "Zishi Zhang",
            "Zehao Li",
            "Jingyang Jiang",
            "Shentao Qin",
            "Guanghao Li",
            "Yan Li",
            "Yi Zheng",
            "Xinping Li",
            "Min Zhan",
            "Yijie Peng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00639",
        "abstract": "The probabilistic diffusion model (DM), generating content by inferencing through a recursive chain structure, has emerged as a powerful framework for visual generation. After pre-training on enormous unlabeled data, the model needs to be properly aligned to meet requirements for downstream applications. How to efficiently align the foundation DM is a crucial task. Contemporary methods are either based on Reinforcement Learning (RL) or truncated Backpropagation (BP). However, RL and truncated BP suffer from low sample efficiency and biased gradient estimation respectively, resulting in limited improvement or, even worse, complete training failure. To overcome the challenges, we propose the Recursive Likelihood Ratio (RLR) optimizer, a zeroth-order informed fine-tuning paradigm for DM. The zeroth-order gradient estimator enables the computation graph rearrangement within the recursive diffusive chain, making the RLR's gradient estimator an unbiased one with the lower variance than other methods. We provide theoretical guarantees for the performance of the RLR. Extensive experiments are conducted on image and video generation tasks to validate the superiority of the RLR. Furthermore, we propose a novel prompt technique that is natural for the RLR to achieve a synergistic effect.",
        "tags": [
            "Diffusion",
            "RL",
            "Video Generation"
        ]
    },
    {
        "id": "111",
        "title": "CollabLLM: From Passive Responders to Active Collaborators",
        "author": [
            "Shirley Wu",
            "Michel Galley",
            "Baolin Peng",
            "Hao Cheng",
            "Gavin Li",
            "Yao Dou",
            "Weixin Cai",
            "James Zou",
            "Jure Leskovec",
            "Jianfeng Gao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00640",
        "abstract": "Large Language Models are typically trained with next-turn rewards, limiting their ability to optimize for long-term interaction. As a result, they often respond passively to ambiguous or open-ended user requests, failing to help users reach their ultimate intents and leading to inefficient conversations. To address these limitations, we introduce CollabLLM, a novel and general training framework that enhances multiturn human-LLM collaboration. Its key innovation is a collaborative simulation that estimates the long-term contribution of responses using Multiturn-aware Rewards. By reinforcement fine-tuning these rewards, CollabLLM goes beyond responding to user requests, and actively uncovers user intent and offers insightful suggestions-a key step towards more human-centered AI. We also devise a multiturn interaction benchmark with three challenging tasks such as document creation. CollabLLM significantly outperforms our baselines with averages of 18.5% higher task performance and 46.3% improved interactivity by LLM judges. Finally, we conduct a large user study with 201 judges, where CollabLLM increases user satisfaction by 17.6% and reduces user spent time by 10.4%.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "112",
        "title": "Evaluating Small Language Models for News Summarization: Implications and Factors Influencing Performance",
        "author": [
            "Borui Xu",
            "Yao Chen",
            "Zeyi Wen",
            "Weiguo Liu",
            "Bingsheng He"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00641",
        "abstract": "The increasing demand for efficient summarization tools in resource-constrained environments highlights the need for effective solutions. While large language models (LLMs) deliver superior summarization quality, their high computational resource requirements limit practical use applications. In contrast, small language models (SLMs) present a more accessible alternative, capable of real-time summarization on edge devices. However, their summarization capabilities and comparative performance against LLMs remain underexplored. This paper addresses this gap by presenting a comprehensive evaluation of 19 SLMs for news summarization across 2,000 news samples, focusing on relevance, coherence, factual consistency, and summary length. Our findings reveal significant variations in SLM performance, with top-performing models such as Phi3-Mini and Llama3.2-3B-Ins achieving results comparable to those of 70B LLMs while generating more concise summaries. Notably, SLMs are better suited for simple prompts, as overly complex prompts may lead to a decline in summary quality. Additionally, our analysis indicates that instruction tuning does not consistently enhance the news summarization capabilities of SLMs. This research not only contributes to the understanding of SLMs but also provides practical insights for researchers seeking efficient summarization solutions that balance performance and resource use.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "113",
        "title": "Towards Robust Multimodal Large Language Models Against Jailbreak Attacks",
        "author": [
            "Ziyi Yin",
            "Yuanpu Cao",
            "Han Liu",
            "Ting Wang",
            "Jinghui Chen",
            "Fenhlong Ma"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00653",
        "abstract": "While multimodal large language models (MLLMs) have achieved remarkable success in recent advancements, their susceptibility to jailbreak attacks has come to light. In such attacks, adversaries exploit carefully crafted prompts to coerce models into generating harmful or undesirable content. Existing defense mechanisms often rely on external inference steps or safety alignment training, both of which are less effective and impractical when facing sophisticated adversarial perturbations in white-box scenarios. To address these challenges and bolster MLLM robustness, we introduce SafeMLLM by adopting an adversarial training framework that alternates between an attack step for generating adversarial noise and a model updating step. At the attack step, SafeMLLM generates adversarial perturbations through a newly proposed contrastive embedding attack (CoE-Attack), which optimizes token embeddings under a contrastive objective. SafeMLLM then updates model parameters to neutralize the perturbation effects while preserving model utility on benign inputs. We evaluate SafeMLLM across six MLLMs and six jailbreak methods spanning multiple modalities. Experimental results show that SafeMLLM effectively defends against diverse attacks, maintaining robust performance and utilities.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "114",
        "title": "EmoTalkingGaussian: Continuous Emotion-conditioned Talking Head Synthesis",
        "author": [
            "Junuk Cha",
            "Seongro Yoon",
            "Valeriya Strizhkova",
            "Francois Bremond",
            "Seungryul Baek"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00654",
        "abstract": "3D Gaussian splatting-based talking head synthesis has recently gained attention for its ability to render high-fidelity images with real-time inference speed. However, since it is typically trained on only a short video that lacks the diversity in facial emotions, the resultant talking heads struggle to represent a wide range of emotions. To address this issue, we propose a lip-aligned emotional face generator and leverage it to train our EmoTalkingGaussian model. It is able to manipulate facial emotions conditioned on continuous emotion values (i.e., valence and arousal); while retaining synchronization of lip movements with input audio. Additionally, to achieve the accurate lip synchronization for in-the-wild audio, we introduce a self-supervised learning method that leverages a text-to-speech network and a visual-audio synchronization network. We experiment our EmoTalkingGaussian on publicly available videos and have obtained better results than state-of-the-arts in terms of image quality (measured in PSNR, SSIM, LPIPS), emotion expression (measured in V-RMSE, A-RMSE, V-SA, A-SA, Emotion Accuracy), and lip synchronization (measured in LMD, Sync-E, Sync-C), respectively.",
        "tags": [
            "3D",
            "Gaussian Splatting",
            "Talking Head"
        ]
    },
    {
        "id": "115",
        "title": "Cross-Modal Synergies: Unveiling the Potential of Motion-Aware Fusion Networks in Handling Dynamic and Static ReID Scenarios",
        "author": [
            "Fuxi Ling",
            "Hongye Liu",
            "Guoqiang Huang",
            "Jing Li",
            "Hong Wu",
            "Zhihao Tang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00665",
        "abstract": "Navigating the complexities of person re-identification (ReID) in varied surveillance scenarios, particularly when occlusions occur, poses significant challenges. We introduce an innovative Motion-Aware Fusion (MOTAR-FUSE) network that utilizes motion cues derived from static imagery to significantly enhance ReID capabilities. This network incorporates a dual-input visual adapter capable of processing both images and videos, thereby facilitating more effective feature extraction. A unique aspect of our approach is the integration of a motion consistency task, which empowers the motion-aware transformer to adeptly capture the dynamics of human motion. This technique substantially improves the recognition of features in scenarios where occlusions are prevalent, thereby advancing the ReID process. Our comprehensive evaluations across multiple ReID benchmarks, including holistic, occluded, and video-based scenarios, demonstrate that our MOTAR-FUSE network achieves superior performance compared to existing approaches.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "116",
        "title": "Safety Alignment Depth in Large Language Models: A Markov Chain Perspective",
        "author": [
            "Ching-Chia Kao",
            "Chia-Mu Yu",
            "Chun-Shien Lu",
            "Chu-Song Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00669",
        "abstract": "Large Language Models (LLMs) are increasingly adopted in high-stakes scenarios, yet their safety mechanisms often remain fragile. Simple jailbreak prompts or even benign fine-tuning can bypass these protocols, underscoring the need to understand where and how they fail. Recent findings suggest that vulnerabilities emerge when alignment is confined to only the initial output tokens. Unfortunately, even with the introduction of deep safety alignment, determining the optimal safety depth remains an unresolved challenge. By leveraging the equivalence between autoregressive language models and Markov chains, this paper offers the first theoretical result on how to identify the ideal depth for safety alignment, and demonstrates how permutation-based data augmentation can tighten these bounds. Crucially, we reveal a fundamental interaction between alignment depth and ensemble width-indicating that broader ensembles can compensate for shallower alignments. These insights provide a theoretical foundation for designing more robust, scalable safety strategies that complement existing alignment approaches, opening new avenues for research into safer, more reliable LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "117",
        "title": "Rethinking Mixture-of-Agents: Is Mixing Different Large Language Models Beneficial?",
        "author": [
            "Wenzhe Li",
            "Yong Lin",
            "Mengzhou Xia",
            "Chi Jin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00674",
        "abstract": "Ensembling outputs from diverse sources is a straightforward yet effective approach to boost performance. Mixture-of-Agents (MoA) is one such popular ensemble method that aggregates outputs from multiple different Large Language Models (LLMs). This paper raises the question in the context of language models: is mixing different LLMs truly beneficial? We propose Self-MoA -- an ensemble method that aggregates outputs from only the single top-performing LLM. Our extensive experiments reveal that, surprisingly, Self-MoA outperforms standard MoA that mixes different LLMs in a large number of scenarios: Self-MoA achieves $6.6\\%$ improvement over MoA on the AlpacaEval 2.0 benchmark, and an average of $3.8\\%$ improvement across various benchmarks, including MMLU, CRUX, and MATH. Applying Self-MoA to one of the top-ranking models in AlpacaEval 2.0 directly achieves the new state-of-the-art performance on the leaderboard. To understand the effectiveness of Self-MoA, we systematically investigate the trade-off between diversity and quality of outputs under various MoA settings. We confirm that the MoA performance is rather sensitive to the quality, and mixing different LLMs often lowers the average quality of the models. To complement the study, we identify the scenarios where mixing different LLMs could be helpful. This paper further introduces a sequential version of Self-MoA, that is capable of aggregating a large number of LLM outputs on-the-fly over multiple rounds, and is as effective as aggregating all outputs at once.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "118",
        "title": "LLM-based event log analysis techniques: A survey",
        "author": [
            "Siraaj Akhtar",
            "Saad Khan",
            "Simon Parkinson"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00677",
        "abstract": "Event log analysis is an important task that security professionals undertake. Event logs record key information on activities that occur on computing devices, and due to the substantial number of events generated, they consume a large amount of time and resources to analyse. This demanding and repetitive task is also prone to errors. To address these concerns, researchers have developed automated techniques to improve the event log analysis process. Large Language Models (LLMs) have recently demonstrated the ability to successfully perform a wide range of tasks that individuals would usually partake in, to high standards, and at a pace and degree of complexity that outperform humans. Due to this, researchers are rapidly investigating the use of LLMs for event log analysis. This includes fine-tuning, Retrieval-Augmented Generation (RAG) and in-context learning, which affect performance. These works demonstrate good progress, yet there is a need to understand the developing body of knowledge, identify commonalities between works, and identify key challenges and potential solutions to further developments in this domain. This paper aims to survey LLM-based event log analysis techniques, providing readers with an in-depth overview of the domain, gaps identified in previous research, and concluding with potential avenues to explore in future.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "119",
        "title": "How Contaminated Is Your Benchmark? Quantifying Dataset Leakage in Large Language Models with Kernel Divergence",
        "author": [
            "Hyeong Kyu Choi",
            "Maxim Khanov",
            "Hongxin Wei",
            "Yixuan Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00678",
        "abstract": "Dataset contamination, where evaluation datasets overlap with pre-training corpora, inflates performance metrics and undermines the reliability of model evaluations. Quantifying dataset contamination thus becomes essential to ensure that performance evaluations genuinely reflect a model's ability to generalize to unseen data, rather than relying on memorized examples. To address this problem, we propose Kernel Divergence Score (KDS), a novel method that quantifies dataset contamination by computing the divergence between the kernel similarity matrix of sample embeddings, before and after fine-tuning on the benchmark dataset. Leveraging the insight that fine-tuning affects unseen samples more significantly than seen ones, KDS provides a reliable measure of contamination. Through extensive experiments on controlled contamination scenarios, KDS demonstrates a near-perfect correlation with contamination levels and outperforms existing baselines. Additionally, we perform comprehensive ablation studies to analyze the impact of key design choices, providing deeper insights into the components and effectiveness of KDS. These ablations highlight the importance of leveraging fine-grained kernel-based information and confirm the reliability of the proposed framework across diverse datasets and settings.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "120",
        "title": "A Survey of Quantized Graph Representation Learning: Connecting Graph Structures with Large Language Models",
        "author": [
            "Qika Lin",
            "Zhen Peng",
            "Kaize Shi",
            "Kai He",
            "Yiming Xu",
            "Erik Cambria",
            "Mengling Feng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00681",
        "abstract": "Recent years have witnessed rapid advances in graph representation learning, with the continuous embedding approach emerging as the dominant paradigm. However, such methods encounter issues regarding parameter efficiency, interpretability, and robustness. Thus, Quantized Graph Representation (QGR) learning has recently gained increasing interest, which represents the graph structure with discrete codes instead of conventional continuous embeddings. Given its analogous representation form to natural language, QGR also possesses the capability to seamlessly integrate graph structures with large language models (LLMs). As this emerging paradigm is still in its infancy yet holds significant promise, we undertake this thorough survey to promote its rapid future prosperity. We first present the background of the general quantization methods and their merits. Moreover, we provide an in-depth demonstration of current QGR studies from the perspectives of quantized strategies, training objectives, distinctive designs, knowledge graph quantization, and applications. We further explore the strategies for code dependence learning and integration with LLMs. At last, we give discussions and conclude future directions, aiming to provide a comprehensive picture of QGR and inspire future research.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "121",
        "title": "High-Order Matching for One-Step Shortcut Diffusion Models",
        "author": [
            "Bo Chen",
            "Chengyue Gong",
            "Xiaoyu Li",
            "Yingyu Liang",
            "Zhizhou Sha",
            "Zhenmei Shi",
            "Zhao Song",
            "Mingda Wan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00688",
        "abstract": "One-step shortcut diffusion models [Frans, Hafner, Levine and Abbeel, ICLR 2025] have shown potential in vision generation, but their reliance on first-order trajectory supervision is fundamentally limited. The Shortcut model's simplistic velocity-only approach fails to capture intrinsic manifold geometry, leading to erratic trajectories, poor geometric alignment, and instability-especially in high-curvature regions. These shortcomings stem from its inability to model mid-horizon dependencies or complex distributional features, leaving it ill-equipped for robust generative modeling. In this work, we introduce HOMO (High-Order Matching for One-Step Shortcut Diffusion), a game-changing framework that leverages high-order supervision to revolutionize distribution transportation. By incorporating acceleration, jerk, and beyond, HOMO not only fixes the flaws of the Shortcut model but also achieves unprecedented smoothness, stability, and geometric precision. Theoretically, we prove that HOMO's high-order supervision ensures superior approximation accuracy, outperforming first-order methods. Empirically, HOMO dominates in complex settings, particularly in high-curvature regions where the Shortcut model struggles. Our experiments show that HOMO delivers smoother trajectories and better distributional alignment, setting a new standard for one-step generative models.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "122",
        "title": "Leveraging LLMs for Dynamic IoT Systems Generation through Mixed-Initiative Interaction",
        "author": [
            "Bassam Adnan",
            "Sathvika Miryala",
            "Aneesh Sambu",
            "Karthik Vaidhyanathan",
            "Martina De Sanctis",
            "Romina Spalazzese"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00689",
        "abstract": "IoT systems face significant challenges in adapting to user needs, which are often under-specified and evolve with changing environmental contexts. To address these complexities, users should be able to explore possibilities, while IoT systems must learn and support users in the process of providing proper services, e.g., to serve novel experiences. The IoT-Together paradigm aims to meet this demand through the Mixed-Initiative Interaction (MII) paradigm that facilitates a collaborative synergy between users and IoT systems, enabling the co-creation of intelligent and adaptive solutions that are precisely aligned with user-defined goals. This work advances IoT-Together by integrating Large Language Models (LLMs) into its architecture. Our approach enables intelligent goal interpretation through a multi-pass dialogue framework and dynamic service generation at runtime according to user needs. To demonstrate the efficacy of our methodology, we design and implement the system in the context of a smart city tourism case study. We evaluate the system's performance using agent-based simulation and user studies. Results indicate efficient and accurate service identification and high adaptation quality. The empirical evidence indicates that the integration of Large Language Models (LLMs) into IoT architectures can significantly enhance the architectural adaptability of the system while ensuring real-world usability.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "123",
        "title": "Learning Autonomous Code Integration for Math Language Models",
        "author": [
            "Haozhe Wang",
            "Long Li",
            "Chao Qu",
            "Fengming Zhu",
            "Weidi Xu",
            "Wei Chu",
            "Fangzhen Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00691",
        "abstract": "Recent research on tool integration for math Large Language Models (LLMs) aims to combine complementary strengths of chain-of-thought (CoT) reasoning and code execution. However, we discover a critical limitation: current tool-integrated math LLMs rely on externally dictated instructions to decide whether to use CoT or code, lacking the autonomy to choose the most appropriate method independently. This prompts us to study \\emph{Autonomous Code integration} for math LLMs, which enables models to \\emph{independently} develop their own methodology-selection strategy in the absence of reliable supervision. To address this challenge, we propose an innovative Expectation-Maximization (EM) formulation that refines the model's decision-making through the exploration of its capabilities. This framework alternates between (a) computing a reference strategy that improves the model's belief over its capabilities through self-exploration, and (b) updating the model based on the refined belief. We further enhance this framework with an efficient implementation, incorporating a novel data synthesis strategy and off-policy reinforcement learning. Extensive experiments demonstrate that our approach, using only a public query set, significantly boosts the performance of existing math LLMs, raising accuracy by nearly 20\\% to 65.28\\% on the challenging MATH benchmark, while reducing code executions by up to 65\\% .",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "124",
        "title": "Leveraging Large Language Models to Predict Antibody Biological Activity Against Influenza A Hemagglutinin",
        "author": [
            "Ella Barkan",
            "Ibrahim Siddiqui",
            "Kevin J. Cheng",
            "Alex Golts",
            "Yoel Shoshan",
            "Jeffrey K. Weber",
            "Yailin Campos Mota",
            "Michal Ozery-Flato",
            "Giuseppe A. Sautto"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00694",
        "abstract": "Monoclonal antibodies (mAbs) represent one of the most prevalent FDA-approved modalities for treating autoimmune diseases, infectious diseases, and cancers. However, discovery and development of therapeutic antibodies remains a time-consuming and expensive process. Recent advancements in machine learning (ML) and artificial intelligence (AI) have shown significant promise in revolutionizing antibody discovery and optimization. In particular, models that predict antibody biological activity enable in-silico evaluation of binding and functional properties; such models can prioritize antibodies with the highest likelihoods of success in costly and time-intensive laboratory testing procedures. We here explore an AI model for predicting the binding and receptor blocking activity of antibodies against influenza A hemagglutinin (HA) antigens. Our present model is developed with the MAMMAL framework for biologics discovery to predict antibody-antigen interactions using only sequence information. To evaluate the model's performance, we tested it under various data split conditions to mimic real-world scenarios.\nOur models achieved an AUROC $\\geq$ 0.91 for predicting the activity of existing antibodies against seen HAs and an AUROC of 0.9 for unseen HAs. For novel antibody activity prediction, the AUROC was 0.73, which further declined to 0.63-0.66 under stringent constraints on similarity to existing antibodies. These results demonstrate the potential of AI foundation models to transform antibody design by reducing dependence on extensive laboratory testing and enabling more efficient prioritization of antibody candidates. Moreover, our findings emphasize the critical importance of diverse and comprehensive antibody datasets to improve the generalization of prediction models, particularly for novel antibody development.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "125",
        "title": "S2CFormer: Reorienting Learned Image Compression from Spatial Interaction to Channel Aggregation",
        "author": [
            "Yunuo Chen",
            "Qian Li",
            "Bing He",
            "Donghui Feng",
            "Ronghua Wu",
            "Qi Wang",
            "Li Song",
            "Guo Lu",
            "Wenjun Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00700",
        "abstract": "Transformers have achieved significant success in learned image compression (LIC), with Swin Transformers emerging as the mainstream choice for nonlinear transforms. A common belief is that their sophisticated spatial operations contribute most to their efficacy. However, the crucial role of the feed-forward network (FFN) based Channel Aggregation module within the transformer architecture has been largely overlooked, and the over-design of spatial operations leads to a suboptimal trade-off between decoding latency and R-D performance. In this paper, we reevaluate the key factors behind the competence of transformers in LIC. By replacing spatial operations with identity mapping, we are surprised to find that channel operations alone can approach the R-D performance of the leading methods. This solid lower bound of performance emphasizes that the presence of channel aggregation is more essential for the LIC model to achieve competitive performance, while the previously complex spatial interactions are partly redundant. Based on this insight, we initiate the \"S2CFormer\" paradigm, a general architecture that reorients the focus of LIC from Spatial Interaction to Channel Aggregation. We present two instantiations of the S2CFormer: S2C-Conv, and S2C-Attention. Each one incorporates a simple operator for spatial interaction and serves as nonlinear transform blocks for our LIC models. Both models demonstrate state-of-the-art (SOTA) R-D performance and significantly faster decoding speed. These results also motivate further exploration of advanced FFN structures to enhance the R-D performance while maintaining model efficiency. With these foundations, we introduce S2C-Hybrid, an enhanced LIC model that combines the strengths of different S2CFormer instantiations. This model outperforms all the existing methods on several datasets, setting a new benchmark for efficient and high-performance LIC.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "126",
        "title": "Model Provenance Testing for Large Language Models",
        "author": [
            "Ivica Nikolic",
            "Teodora Baluta",
            "Prateek Saxena"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00706",
        "abstract": "Large language models are increasingly customized through fine-tuning and other adaptations, creating challenges in enforcing licensing terms and managing downstream impacts. Tracking model origins is crucial both for protecting intellectual property and for identifying derived models when biases or vulnerabilities are discovered in foundation models. We address this challenge by developing a framework for testing model provenance: Whether one model is derived from another. Our approach is based on the key observation that real-world model derivations preserve significant similarities in model outputs that can be detected through statistical analysis. Using only black-box access to models, we employ multiple hypothesis testing to compare model similarities against a baseline established by unrelated models. On two comprehensive real-world benchmarks spanning models from 30M to 4B parameters and comprising over 600 models, our tester achieves 90-95% precision and 80-90% recall in identifying derived models. These results demonstrate the viability of systematic provenance verification in production environments even when only API access is available.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "127",
        "title": "PhiP-G: Physics-Guided Text-to-3D Compositional Scene Generation",
        "author": [
            "Qixuan Li",
            "Chao Wang",
            "Zongjin He",
            "Yan Peng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00708",
        "abstract": "Text-to-3D asset generation has achieved significant optimization under the supervision of 2D diffusion priors. However, when dealing with compositional scenes, existing methods encounter several challenges: 1). failure to ensure that composite scene layouts comply with physical laws; 2). difficulty in accurately capturing the assets and relationships described in complex scene descriptions; 3). limited autonomous asset generation capabilities among layout approaches leveraging large language models (LLMs). To avoid these compromises, we propose a novel framework for compositional scene generation, PhiP-G, which seamlessly integrates generation techniques with layout guidance based on a world model. Leveraging LLM-based agents, PhiP-G analyzes the complex scene description to generate a scene graph, and integrating a multimodal 2D generation agent and a 3D Gaussian generation method for targeted assets creation. For the stage of layout, PhiP-G employs a physical pool with adhesion capabilities and a visual supervision agent, forming a world model for layout prediction and planning. Extensive experiments demonstrate that PhiP-G significantly enhances the generation quality and physical rationality of the compositional scenes. Notably, PhiP-G attains state-of-the-art (SOTA) performance in CLIP scores, achieves parity with the leading methods in generation quality as measured by the T$^3$Bench, and improves efficiency by 24x.",
        "tags": [
            "3D",
            "CLIP",
            "Diffusion",
            "LLMs",
            "Large Language Models",
            "Text-to-3D"
        ]
    },
    {
        "id": "128",
        "title": "RankFlow: A Multi-Role Collaborative Reranking Workflow Utilizing Large Language Models",
        "author": [
            "Can Jin",
            "Hongwu Peng",
            "Anxiang Zhang",
            "Nuo Chen",
            "Jiahui Zhao",
            "Xi Xie",
            "Kuangzheng Li",
            "Shuya Feng",
            "Kai Zhong",
            "Caiwen Ding",
            "Dimitris N. Metaxas"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00709",
        "abstract": "In an Information Retrieval (IR) system, reranking plays a critical role by sorting candidate passages according to their relevance to a specific query. This process demands a nuanced understanding of the variations among passages linked to the query. In this work, we introduce RankFlow, a multi-role reranking workflow that leverages the capabilities of Large Language Models (LLMs) and role specializations to improve reranking performance. RankFlow enlists LLMs to fulfill four distinct roles: the query Rewriter, the pseudo Answerer, the passage Summarizer, and the Reranker. This orchestrated approach enables RankFlow to: (1) accurately interpret queries, (2) draw upon LLMs' extensive pre-existing knowledge, (3) distill passages into concise versions, and (4) assess passages in a comprehensive manner, resulting in notably better reranking results. Our experimental results reveal that RankFlow outperforms existing leading approaches on widely recognized IR benchmarks, such as TREC-DL, BEIR, and NovelEval. Additionally, we investigate the individual contributions of each role in RankFlow. Code is available at https://github.com/jincan333/RankFlow.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "129",
        "title": "VIKSER: Visual Knowledge-Driven Self-Reinforcing Reasoning Framework",
        "author": [
            "Chunbai Zhang",
            "Chao Wang",
            "Yang Zhou",
            "Yan Peng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00711",
        "abstract": "Visual reasoning refers to the task of solving questions about visual information. Current visual reasoning methods typically employ pre-trained vision-language model (VLM) strategies or deep neural network approaches. However, existing efforts are constrained by limited reasoning interpretability, while hindering by the phenomenon of underspecification in the question text. Additionally, the absence of fine-grained visual knowledge limits the precise understanding of subject behavior in visual reasoning tasks. To address these issues, we propose VIKSER (Visual Knowledge-Driven Self-Reinforcing Reasoning Framework). Specifically, VIKSER, trained using knowledge distilled from large language models, extracts fine-grained visual knowledge with the assistance of visual relationship detection techniques. Subsequently, VIKSER utilizes fine-grained visual knowledge to paraphrase the question with underspecification. Additionally, we design a novel prompting method called Chain-of-Evidence (CoE), which leverages the power of ``evidence for reasoning'' to endow VIKSER with interpretable reasoning capabilities. Meanwhile, the integration of self-reflection technology empowers VIKSER with the ability to learn and improve from its mistakes. Experiments conducted on widely used datasets demonstrate that VIKSER achieves new state-of-the-art (SOTA) results in relevant tasks.",
        "tags": [
            "Detection",
            "Large Language Models"
        ]
    },
    {
        "id": "130",
        "title": "\"I am bad\": Interpreting Stealthy, Universal and Robust Audio Jailbreaks in Audio-Language Models",
        "author": [
            "Isha Gupta",
            "David Khachaturov",
            "Robert Mullins"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00718",
        "abstract": "The rise of multimodal large language models has introduced innovative human-machine interaction paradigms but also significant challenges in machine learning safety. Audio-Language Models (ALMs) are especially relevant due to the intuitive nature of spoken communication, yet little is known about their failure modes. This paper explores audio jailbreaks targeting ALMs, focusing on their ability to bypass alignment mechanisms. We construct adversarial perturbations that generalize across prompts, tasks, and even base audio samples, demonstrating the first universal jailbreaks in the audio modality, and show that these remain effective in simulated real-world conditions. Beyond demonstrating attack feasibility, we analyze how ALMs interpret these audio adversarial examples and reveal them to encode imperceptible first-person toxic speech - suggesting that the most effective perturbations for eliciting toxic outputs specifically embed linguistic features within the audio signal. These results have important implications for understanding the interactions between different modalities in multimodal models, and offer actionable insights for enhancing defenses against adversarial audio attacks.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "131",
        "title": "Vision and Language Reference Prompt into SAM for Few-shot Segmentation",
        "author": [
            "Kosuke Sakurai",
            "Ryotaro Shimizu",
            "Masayuki Goto"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00719",
        "abstract": "Segment Anything Model (SAM) represents a large-scale segmentation model that enables powerful zero-shot capabilities with flexible prompts. While SAM can segment any object in zero-shot, it requires user-provided prompts for each target image and does not attach any label information to masks. Few-shot segmentation models addressed these issues by inputting annotated reference images as prompts to SAM and can segment specific objects in target images without user-provided prompts. Previous SAM-based few-shot segmentation models only use annotated reference images as prompts, resulting in limited accuracy due to a lack of reference information. In this paper, we propose a novel few-shot segmentation model, Vision and Language reference Prompt into SAM (VLP-SAM), that utilizes the visual information of the reference images and the semantic information of the text labels by inputting not only images but also language as reference information. In particular, VLP-SAM is a simple and scalable structure with minimal learnable parameters, which inputs prompt embeddings with vision-language information into SAM using a multimodal vision-language model. To demonstrate the effectiveness of VLP-SAM, we conducted experiments on the PASCAL-5i and COCO-20i datasets, and achieved high performance in the few-shot segmentation task, outperforming the previous state-of-the-art model by a large margin (6.3% and 9.5% in mIoU, respectively). Furthermore, VLP-SAM demonstrates its generality in unseen objects that are not included in the training data. Our code is available at https://github.com/kosukesakurai1/VLP-SAM.",
        "tags": [
            "SAM",
            "Segment Anything",
            "Segmentation"
        ]
    },
    {
        "id": "132",
        "title": "Demystifying Cost-Efficiency in LLM Serving over Heterogeneous GPUs",
        "author": [
            "Youhe Jiang",
            "Fangcheng Fu",
            "Xiaozhe Yao",
            "Guoliang He",
            "Xupeng Miao",
            "Ana Klimovic",
            "Bin Cui",
            "Binhang Yuan",
            "Eiko Yoneki"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00722",
        "abstract": "Recent advancements in Large Language Models (LLMs) have led to increasingly diverse requests, accompanied with varying resource (compute and memory) demands to serve them. However, this in turn degrades the cost-efficiency of LLM serving as common practices primarily rely on homogeneous GPU resources. In response to this problem, this work conducts a thorough study about serving LLMs over heterogeneous GPU resources on cloud platforms. The rationale is that different GPU types exhibit distinct compute and memory characteristics, aligning well with the divergent resource demands of diverse requests. Particularly, through comprehensive benchmarking, we discover that the cost-efficiency of LLM serving can be substantially optimized by meticulously determining GPU composition, deployment configurations, and workload assignments. Subsequently, we design a scheduling algorithm via mixed-integer linear programming, aiming at deducing the most cost-efficient serving plan under the constraints of price budget and real-time GPU availability. Remarkably, our approach effectively outperforms homogeneous and heterogeneous baselines under a wide array of scenarios, covering diverse workload traces, varying GPU availablilities, and multi-model serving. This casts new light on more accessible and efficient LLM serving over heterogeneous cloud resources.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "133",
        "title": "Understanding and Mitigating the High Computational Cost in Path Data Diffusion",
        "author": [
            "Dingyuan Shi",
            "Lulu Zhang",
            "Yongxin Tong",
            "Ke Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00725",
        "abstract": "Advancements in mobility services, navigation systems, and smart transportation technologies have made it possible to collect large amounts of path data. Modeling the distribution of this path data, known as the Path Generation (PG) problem, is crucial for understanding urban mobility patterns and developing intelligent transportation systems. Recent studies have explored using diffusion models to address the PG problem due to their ability to capture multimodal distributions and support conditional generation. A recent work devises a diffusion process explicitly in graph space and achieves state-of-the-art performance. However, this method suffers a high computation cost in terms of both time and memory, which prohibits its application. In this paper, we analyze this method both theoretically and experimentally and find that the main culprit of its high computation cost is its explicit design of the diffusion process in graph space. To improve efficiency, we devise a Latent-space Path Diffusion (LPD) model, which operates in latent space instead of graph space. Our LPD significantly reduces both time and memory costs by up to 82.8% and 83.1%, respectively. Despite these reductions, our approach does not suffer from performance degradation. It outperforms the state-of-the-art method in most scenarios by 24.5%~34.0%.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "134",
        "title": "Meta-Prompt Optimization for LLM-Based Sequential Decision Making",
        "author": [
            "Mingze Kong",
            "Zhiyong Wang",
            "Yao Shu",
            "Zhongxiang Dai"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00728",
        "abstract": "Large language models (LLMs) have recently been employed as agents to solve sequential decision-making tasks such as Bayesian optimization and multi-armed bandits (MAB). These works usually adopt an LLM for sequential action selection by providing it with a fixed, manually designed meta-prompt. However, numerous previous works have found that the prompt has a significant impact on the performance of the LLM, which calls for a method to automatically optimize the meta-prompt for LLM-based agents. Unfortunately, the non-stationarity in the reward observations during LLM-based sequential decision-making makes meta-prompt optimization highly challenging. To address this challenge, we draw inspirations from adversarial bandit algorithms, which are inherently capable of handling non-stationary reward observations. Building on this foundation, we propose our EXPonential-weight algorithm for prompt Optimization} (EXPO) to automatically optimize the task description and meta-instruction in the meta-prompt for LLM-based agents. We also extend EXPO to additionally optimize the exemplars (i.e., history of interactions) in the meta-prompt to further enhance the performance, hence introducing our EXPO-ES algorithm. We use extensive experiments to show that our algorithms significantly improve the performance of LLM-based sequential decision-making.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "135",
        "title": "From Compliance to Exploitation: Jailbreak Prompt Attacks on Multimodal LLMs",
        "author": [
            "Chun Wai Chiu",
            "Linghan Huang",
            "Bo Li",
            "Huaming Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00735",
        "abstract": "Large Language Models (LLMs) have seen widespread applications across various domains due to their growing ability to process diverse types of input data, including text, audio, image and video. While LLMs have demonstrated outstanding performance in understanding and generating contexts for different scenarios, they are vulnerable to prompt-based attacks, which are mostly via text input. In this paper, we introduce the first voice-based jailbreak attack against multimodal LLMs, termed as Flanking Attack, which can process different types of input simultaneously towards the multimodal LLMs. Our work is motivated by recent advancements in monolingual voice-driven large language models, which have introduced new attack surfaces beyond traditional text-based vulnerabilities for LLMs. To investigate these risks, we examine the frontier multimodal LLMs, which can be accessed via different types of inputs such as audio input, focusing on how adversarial prompts can bypass its defense mechanisms. We propose a novel strategy, in which the disallowed prompt is flanked by benign, narrative-driven prompts. It is integrated in the Flanking Attack which attempts to humanizes the interaction context and execute the attack through a fictional setting. To better evaluate the attack performance, we present a semi-automated self-assessment framework for policy violation detection. We demonstrate that Flank Attack is capable of manipulating state-of-the-art LLMs into generating misaligned and forbidden outputs, which achieves an average attack success rate ranging from 0.67 to 0.93 across seven forbidden scenarios. These findings highlight both the potency of prompt-based obfuscation in voice-enabled contexts and the limitations of current LLMs' moderation safeguards and the urgent need for advanced defense strategies to address the challenges posed by evolving, context-rich attacks.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "136",
        "title": "AgentBreeder: Mitigating the AI Safety Impact of Multi-Agent Scaffolds",
        "author": [
            "J Rosser",
            "Jakob Nicolaus Foerster"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00757",
        "abstract": "Scaffolding Large Language Models (LLMs) into multi-agent systems often improves performance on complex tasks, but the safety impact of such scaffolds has not been as thoroughly explored. In this paper, we introduce AGENTBREEDER a framework for multi-objective evolutionary search over scaffolds. Our REDAGENTBREEDER evolves scaffolds towards jailbreaking the base LLM while achieving high task success, while BLUEAGENTBREEDER instead aims to combine safety with task reward. We evaluate the systems discovered by the different instances of AGENTBREEDER and popular baselines using widely recognized reasoning, mathematics, and safety benchmarks. Our work highlights and mitigates the safety risks due to multi-agent scaffolding.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "137",
        "title": "Structural Latency Perturbation in Large Language Models Through Recursive State Induction",
        "author": [
            "Michael Mangrum",
            "Jonathan Pemberton",
            "Benedict Wetherby",
            "Philip Montague"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00758",
        "abstract": "Computational efficiency has remained a critical consideration in scaling high-capacity language models, with inference latency and resource consumption presenting significant constraints on real-time applications. The study has introduced a structured latency perturbation mechanism that modifies computational pathways through recursive state induction, enabling dynamic suppression of redundant activations while preserving generative fidelity. A formal mathematical framework has been established to describe recursive perturbations, ensuring that modifications remain adaptive rather than statically imposed. Experiments have demonstrated that applying recursive state adjustments reduces inference latency across varying sequence lengths, with longer text generations benefiting from cumulative efficiency improvements. Comparative evaluations against structured pruning and quantization have indicated that latency gains can be achieved without compromising token retention or memory utilization. The analysis of computational overhead has suggested that selectively suppressing redundant activations contributes to improved power efficiency, particularly in scenarios requiring extended text generation. An assessment of linguistic stability has shown that token-level consistency remains largely intact under controlled perturbation thresholds, reinforcing the viability of structural latency modifications as an alternative to weight-centric optimization techniques. The results have supported the hypothesis that recursive state induction offers an effective method for reducing computational complexity without requiring architectural modifications or external augmentation.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "138",
        "title": "FIRE: Flexible Integration of Data Quality Ratings for Effective Pre-Training",
        "author": [
            "Liangyu Xu",
            "Xuemiao Zhang",
            "Feiyu Duan",
            "Sirui Wang",
            "Jingang Wang",
            "Xunliang Cai"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00761",
        "abstract": "Selecting high-quality data can significantly improve the pre-training efficiency of large language models (LLMs). Existing methods often rely on heuristic techniques and single quality signals, limiting their ability to comprehensively evaluate data quality. In this work, we propose FIRE, a flexible and scalable framework for integrating multiple data quality raters, which allows for a comprehensive assessment of data quality across various dimensions. FIRE aligns multiple quality signals into a unified space, and integrates diverse data quality raters to provide a comprehensive quality signal for each data point. Further, we introduce a progressive data selection scheme based on FIRE that iteratively refines the selection of high-quality data points, balancing computational complexity with the refinement of orthogonality. Experiments on the SlimPajama dataset reveal that FIRE consistently outperforms other selection methods and significantly enhances the pre-trained model across a wide range of downstream tasks, with a 2.9\\% average performance boost and reducing the FLOPs necessary to achieve a certain performance level by more than half.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "139",
        "title": "Transfer Learning in Physics-Informed Neural Networks: Full Fine-Tuning, Lightweight Fine-Tuning, and Low-Rank Adaptation",
        "author": [
            "Yizheng Wang",
            "Jinshuai Bai",
            "Mohammad Sadegh Eshaghi",
            "Cosmin Anitescu",
            "Xiaoying Zhuang",
            "Timon Rabczuk",
            "Yinghua Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00782",
        "abstract": "AI for PDEs has garnered significant attention, particularly Physics-Informed Neural Networks (PINNs). However, PINNs are typically limited to solving specific problems, and any changes in problem conditions necessitate retraining. Therefore, we explore the generalization capability of transfer learning in the strong and energy form of PINNs across different boundary conditions, materials, and geometries. The transfer learning methods we employ include full finetuning, lightweight finetuning, and Low-Rank Adaptation (LoRA). The results demonstrate that full finetuning and LoRA can significantly improve convergence speed while providing a slight enhancement in accuracy.",
        "tags": [
            "LoRA",
            "Low-Rank Adaptation"
        ]
    },
    {
        "id": "140",
        "title": "Vision-centric Token Compression in Large Language Model",
        "author": [
            "Ling Xing",
            "Alex Jinpeng Wang",
            "Rui Yan",
            "Jinhui Tang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00791",
        "abstract": "Large Language Models (LLMs) have revolutionized natural language processing, excelling in handling longer sequences. However, the inefficiency and redundancy in processing extended in-context tokens remain a challenge. Many attempts to address this rely on compressing tokens with smaller text encoders, yet we question whether text encoders are truly indispensable. Our journey leads to an unexpected discovery-a much smaller vision encoder, applied directly to sequences of text tokens, can rival text encoders on text tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small text understanding benchmarks, VIST leads to comparable results with 16% fewer FLOPs and 50% less memory usage. We further uncover significant token redundancy and devise a frequency-based masking strategy to guide the focus of the visual encoder toward the most critical tokens. Interestingly, we observe the trained visual encoder performs like a summarizer, selectively ignoring less important words such as prepositions and conjunctions. This approach delivers remarkable results, outperforming traditional text encoder-based methods by 5.7% on average over benchmarks like TriviaQA, NQ, PopQA, TREF, SST2, and SST5, setting a new standard for token efficiency in LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "141",
        "title": "RTBAgent: A LLM-based Agent System for Real-Time Bidding",
        "author": [
            "Leng Cai",
            "Junxuan He",
            "Yikai Li",
            "Junjie Liang",
            "Yuanping Lin",
            "Ziming Quan",
            "Yawen Zeng",
            "Jin Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00792",
        "abstract": "Real-Time Bidding (RTB) enables advertisers to place competitive bids on impression opportunities instantaneously, striving for cost-effectiveness in a highly competitive landscape. Although RTB has widely benefited from the utilization of technologies such as deep learning and reinforcement learning, the reliability of related methods often encounters challenges due to the discrepancies between online and offline environments and the rapid fluctuations of online bidding. To handle these challenges, RTBAgent is proposed as the first RTB agent system based on large language models (LLMs), which synchronizes real competitive advertising bidding environments and obtains bidding prices through an integrated decision-making process. Specifically, obtaining reasoning ability through LLMs, RTBAgent is further tailored to be more professional for RTB via involved auxiliary modules, i.e., click-through rate estimation model, expert strategy knowledge, and daily reflection. In addition, we propose a two-step decision-making process and multi-memory retrieval mechanism, which enables RTBAgent to review historical decisions and transaction records and subsequently make decisions more adaptive to market changes in real-time bidding. Empirical testing with real advertising datasets demonstrates that RTBAgent significantly enhances profitability. The RTBAgent code will be publicly accessible at: https://github.com/CaiLeng/RTBAgent.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "142",
        "title": "Data Fusion for Full-Range Response Reconstruction via Diffusion Models",
        "author": [
            "Wingho Feng",
            "Quanwang Li",
            "Chen Wang",
            "Jian-sheng Fan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00795",
        "abstract": "Accurately capturing the full-range response of structures is crucial in structural health monitoring (SHM) for ensuring safety and operational integrity. However, limited sensor deployment due to cost, accessibility, or scale often hinders comprehensive monitoring. This paper presents a novel data fusion framework utilizing diffusion models to reconstruct the full-range structural response from sparse and heterogeneous sensor measurements. We incorporate Diffusion Posterior Sampling (DPS) into the reconstruction framework, using sensor measurements as probabilistic constraints to guide the sampling process. A lightweight neural network serves as the surrogate forward model within the DPS algorithm, which maps full-range structural responses to local sensor data. This approach enables flexibility in sensor configurations while reducing computational costs. The proposed framework is validated on a steel plate shear wall exhibiting nonlinear responses. Comparative experiments are conducted with three forward models. Among these, the neural network surrogate model achieves a desirable reconstruction accuracy, with a weighted mean absolute percentage error (WMAPE) as low as 1.57%, while also demonstrating superior adaptability and computational efficiency. Additional experiments explore the impact of sensor placement strategies and noise levels. Results show that even under sparse measurements or high noise conditions, the WMAPE remains capped at 15%, demonstrating the robustness in challenging scenarios. The proposed framework shows new possibilities for probabilistic modeling and decision-making in SHM, offering a novel data fusion approach for full-range monitoring of structures.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "143",
        "title": "ProPINN: Demystifying Propagation Failures in Physics-Informed Neural Networks",
        "author": [
            "Haixu Wu",
            "Yuezhou Ma",
            "Hang Zhou",
            "Huikun Weng",
            "Jianmin Wang",
            "Mingsheng Long"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00803",
        "abstract": "Physics-informed neural networks (PINNs) have earned high expectations in solving partial differential equations (PDEs), but their optimization usually faces thorny challenges due to the unique derivative-dependent loss function. By analyzing the loss distribution, previous research observed the propagation failure phenomenon of PINNs, intuitively described as the correct supervision for model outputs cannot ``propagate'' from initial states or boundaries to the interior domain. Going beyond intuitive understanding, this paper provides the first formal and in-depth study of propagation failure and its root cause. Based on a detailed comparison with classical finite element methods, we ascribe the failure to the conventional single-point-processing architecture of PINNs and further prove that propagation failure is essentially caused by the lower gradient correlation of PINN models on nearby collocation points. Compared to superficial loss maps, this new perspective provides a more precise quantitative criterion to identify where and why PINN fails. The theoretical finding also inspires us to present a new PINN architecture, named ProPINN, which can effectively unite the gradient of region points for better propagation. ProPINN can reliably resolve PINN failure modes and significantly surpass advanced Transformer-based models with 46% relative promotion.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "144",
        "title": "Synthetic Artifact Auditing: Tracing LLM-Generated Synthetic Data Usage in Downstream Applications",
        "author": [
            "Yixin Wu",
            "Ziqing Yang",
            "Yun Shen",
            "Michael Backes",
            "Yang Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00808",
        "abstract": "Large language models (LLMs) have facilitated the generation of high-quality, cost-effective synthetic data for developing downstream models and conducting statistical analyses in various domains. However, the increased reliance on synthetic data may pose potential negative impacts. Numerous studies have demonstrated that LLM-generated synthetic data can perpetuate and even amplify societal biases and stereotypes, and produce erroneous outputs known as ``hallucinations'' that deviate from factual knowledge. In this paper, we aim to audit artifacts, such as classifiers, generators, or statistical plots, to identify those trained on or derived from synthetic data and raise user awareness, thereby reducing unexpected consequences and risks in downstream applications. To this end, we take the first step to introduce synthetic artifact auditing to assess whether a given artifact is derived from LLM-generated synthetic data. We then propose an auditing framework with three methods including metric-based auditing, tuning-based auditing, and classification-based auditing. These methods operate without requiring the artifact owner to disclose proprietary training details. We evaluate our auditing framework on three text classification tasks, two text summarization tasks, and two data visualization tasks across three training scenarios. Our evaluation demonstrates the effectiveness of all proposed auditing methods across all these tasks. For instance, black-box metric-based auditing can achieve an average accuracy of $0.868 \\pm 0.071$ for auditing classifiers and $0.880 \\pm 0.052$ for auditing generators using only 200 random queries across three scenarios. We hope our research will enhance model transparency and regulatory compliance, ensuring the ethical and responsible use of synthetic data.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "145",
        "title": "Disentangling Length Bias In Preference Learning Via Response-Conditioned Modeling",
        "author": [
            "Jianfeng Cai",
            "Jinhua Zhu",
            "Ruopei Sun",
            "Yue Wang",
            "Li Li",
            "Wengang Zhou",
            "Houqiang Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00814",
        "abstract": "Reinforcement Learning from Human Feedback (RLHF) has achieved considerable success in aligning large language models (LLMs) by modeling human preferences with a learnable reward model and employing a reinforcement learning algorithm to maximize the reward model's scores. However, these reward models are susceptible to exploitation through various superficial confounding factors, with length bias emerging as a particularly significant concern. Moreover, while the pronounced impact of length bias on preference modeling suggests that LLMs possess an inherent sensitivity to length perception, our preliminary investigations reveal that fine-tuned LLMs consistently struggle to adhere to explicit length instructions. To address these two limitations, we propose a novel framework wherein the reward model explicitly differentiates between human semantic preferences and response length requirements. Specifically, we introduce a Response-conditioned Bradley-Terry (Rc-BT) model that enhances the reward model's capability in length bias mitigating and length instruction following, through training on our augmented dataset. Furthermore, we propose the Rc-DPO algorithm to leverage the Rc-BT model for direct policy optimization (DPO) of LLMs, simultaneously mitigating length bias and promoting adherence to length instructions. Extensive evaluations demonstrate that our approach substantially improves both preference modeling and length instruction compliance, with its effectiveness validated across various foundational models and preference datasets.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "146",
        "title": "Sundial: A Family of Highly Capable Time Series Foundation Models",
        "author": [
            "Yong Liu",
            "Guo Qin",
            "Zhiyuan Shi",
            "Zhi Chen",
            "Caiyin Yang",
            "Xiangdong Huang",
            "Jianmin Wang",
            "Mingsheng Long"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00816",
        "abstract": "We introduce Sundial, a family of native, flexible, and scalable time series foundation models. To predict the next-patch's distribution, we propose a TimeFlow Loss based on flow-matching, which facilitates native pre-training of Transformers on time series without discrete tokenization. Conditioned on arbitrary-length time series, our model is pre-trained without specifying any prior distribution and can generate multiple probable predictions, achieving flexibility in representation learning beyond using parametric densities. Towards time series foundation models, we leverage minimal but crucial adaptations of Transformers and curate TimeBench with 1 trillion time points, comprising mostly real-world datasets and synthetic data. By mitigating mode collapse through TimeFlow Loss, we pre-train a family of Sundial models on TimeBench, which exhibit unprecedented model capacity and generalization performance on zero-shot forecasting. In addition to presenting good scaling behavior, Sundial achieves new state-of-the-art on both point forecasting and probabilistic forecasting benchmarks. We believe that Sundial's pioneering generative paradigm will facilitate a wide variety of forecasting scenarios.",
        "tags": [
            "Flow Matching"
        ]
    },
    {
        "id": "147",
        "title": "Probing Large Language Models in Reasoning and Translating Complex Linguistic Puzzles",
        "author": [
            "Zheng-Lin Lin",
            "Yu-Fei Shih",
            "Shu-Kai Hsieh"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00817",
        "abstract": "This paper investigates the utilization of Large Language Models (LLMs) for solving complex linguistic puzzles, a domain requiring advanced reasoning and adept translation capabilities akin to human cognitive processes. We explore specific prompting techniques designed to enhance ability of LLMs to reason and elucidate their decision-making pathways, with a focus on Input-Output Prompting (IO), Chain-of-Thought Prompting (CoT), and Solo Performance Prompting (SPP). Utilizing datasets from the Puzzling Machine Competition and various Linguistics Olympiads, we employ a comprehensive set of metrics to assess the performance of GPT-4 0603, a prominent LLM, across these prompting methods. Our findings illuminate the potential of LLMs in linguistic reasoning and complex translation tasks, highlighting their capabilities and identifying limitations in the context of linguistic puzzles. This research contributes significantly to the broader field of Natural Language Processing (NLP) by providing insights into the optimization of LLM applications for improved reasoning and translation accuracy, thereby enriching the ongoing dialogue in NLP advancements.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "148",
        "title": "Weak Supervision Dynamic KL-Weighted Diffusion Models Guided by Large Language Models",
        "author": [
            "Julian Perry",
            "Frank Sanders",
            "Carter Scott"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00826",
        "abstract": "In this paper, we presents a novel method for improving text-to-image generation by combining Large Language Models (LLMs) with diffusion models, a hybrid approach aimed at achieving both higher quality and efficiency in image synthesis from text descriptions. Our approach introduces a new dynamic KL-weighting strategy to optimize the diffusion process, along with incorporating semantic understanding from pre-trained LLMs to guide the generation process. The proposed method significantly improves both the visual quality and alignment of generated images with text descriptions, addressing challenges such as computational inefficiency, instability in training, and robustness to textual variability. We evaluate our method on the COCO dataset and demonstrate its superior performance over traditional GAN-based models, both quantitatively and qualitatively. Extensive experiments, including ablation studies and human evaluations, confirm that our method outperforms existing approaches in terms of image realism, relevance to the input text, and overall aesthetic quality. Our approach also shows promise in scalability to other multimodal tasks, making it a versatile solution for a wide range of generative applications.",
        "tags": [
            "Diffusion",
            "GAN",
            "LLMs",
            "Large Language Models",
            "Text-to-Image"
        ]
    },
    {
        "id": "149",
        "title": "A Comprehensive Analysis on LLM-based Node Classification Algorithms",
        "author": [
            "Xixi Wu",
            "Yifei Shen",
            "Fangzhou Ge",
            "Caihua Shan",
            "Yizhu Jiao",
            "Xiangguo Sun",
            "Hong Cheng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00829",
        "abstract": "Node classification is a fundamental task in graph analysis, with broad applications across various fields. Recent breakthroughs in Large Language Models (LLMs) have enabled LLM-based approaches for this task. Although many studies demonstrate the impressive performance of LLM-based methods, the lack of clear design guidelines may hinder their practical application. In this work, we aim to establish such guidelines through a fair and systematic comparison of these algorithms. As a first step, we developed LLMNodeBed, a comprehensive codebase and testbed for node classification using LLMs. It includes ten datasets, eight LLM-based algorithms, and three learning paradigms, and is designed for easy extension with new methods and datasets. Subsequently, we conducted extensive experiments, training and evaluating over 2,200 models, to determine the key settings (e.g., learning paradigms and homophily) and components (e.g., model size) that affect performance. Our findings uncover eight insights, e.g., (1) LLM-based methods can significantly outperform traditional methods in a semi-supervised setting, while the advantage is marginal in a supervised setting; (2) Graph Foundation Models can beat open-source LLMs but still fall short of strong LLMs like GPT-4o in a zero-shot setting. We hope that the release of LLMNodeBed, along with our insights, will facilitate reproducible research and inspire future studies in this field. Codes and datasets are released at \\href{https://llmnodebed.github.io/}{https://llmnodebed.github.io/}.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "150",
        "title": "Cross multiscale vision transformer for deep fake detection",
        "author": [
            "Akhshan P",
            "Taneti Sanjay",
            "Chandrakala S"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00833",
        "abstract": "The proliferation of deep fake technology poses significant challenges to digital media authenticity, necessitating robust detection mechanisms. This project evaluates deep fake detection using the SP Cup's 2025 deep fake detection challenge dataset. We focused on exploring various deep learning models for detecting deep fake content, utilizing traditional deep learning techniques alongside newer architectures. Our approach involved training a series of models and rigorously assessing their performance using metrics such as accuracy.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "151",
        "title": "Explainability in Practice: A Survey of Explainable NLP Across Various Domains",
        "author": [
            "Hadi Mohammadi",
            "Ayoub Bagheri",
            "Anastasia Giachanou",
            "Daniel L. Oberski"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00837",
        "abstract": "Natural Language Processing (NLP) has become a cornerstone in many critical sectors, including healthcare, finance, and customer relationship management. This is especially true with the development and use of advanced models such as GPT-based architectures and BERT, which are widely used in decision-making processes. However, the black-box nature of these advanced NLP models has created an urgent need for transparency and explainability. This review explores explainable NLP (XNLP) with a focus on its practical deployment and real-world applications, examining its implementation and the challenges faced in domain-specific contexts. The paper underscores the importance of explainability in NLP and provides a comprehensive perspective on how XNLP can be designed to meet the unique demands of various sectors, from healthcare's need for clear insights to finance's emphasis on fraud detection and risk assessment. Additionally, this review aims to bridge the knowledge gap in XNLP literature by offering a domain-specific exploration and discussing underrepresented areas such as real-world applicability, metric evaluation, and the role of human interaction in model assessment. The paper concludes by suggesting future research directions that could enhance the understanding and broader application of XNLP.",
        "tags": [
            "BERT",
            "Detection",
            "GPT"
        ]
    },
    {
        "id": "152",
        "title": "Activation Approximations Can Incur Safety Vulnerabilities Even in Aligned LLMs: Comprehensive Analysis and Defense",
        "author": [
            "Jiawen Zhang",
            "Kejia Chen",
            "Lipeng He",
            "Jian Lou",
            "Dan Li",
            "Zunlei Feng",
            "Mingli Song",
            "Jian Liu",
            "Kui Ren",
            "Xiaohu Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00840",
        "abstract": "Large Language Models (LLMs) have showcased remarkable capabilities across various domains. Accompanying the evolving capabilities and expanding deployment scenarios of LLMs, their deployment challenges escalate due to their sheer scale and the advanced yet complex activation designs prevalent in notable model series, such as Llama, Gemma, and Mistral. These challenges have become particularly pronounced in resource-constrained deployment scenarios, where mitigating inference efficiency bottlenecks is imperative. Among various recent efforts, activation approximation has emerged as a promising avenue for pursuing inference efficiency, sometimes considered indispensable in applications such as private inference. Despite achieving substantial speedups with minimal impact on utility, even appearing sound and practical for real-world deployment, the safety implications of activation approximations remain unclear. In this work, we fill this critical gap in LLM safety by conducting the first systematic safety evaluation of activation approximations. Our safety vetting spans seven sota techniques across three popular categories, revealing consistent safety degradation across ten safety-aligned LLMs.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "153",
        "title": "SecPE: Secure Prompt Ensembling for Private and Robust Large Language Models",
        "author": [
            "Jiawen Zhang",
            "Kejia Chen",
            "Zunlei Feng",
            "Jian Lou",
            "Mingli Song",
            "Jian Liu",
            "Xiaohu Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00847",
        "abstract": "With the growing popularity of LLMs among the general public users, privacy-preserving and adversarial robustness have become two pressing demands for LLM-based services, which have largely been pursued separately but rarely jointly. In this paper, to the best of our knowledge, we are among the first attempts towards robust and private LLM inference by tightly integrating two disconnected fields: private inference and prompt ensembling. The former protects users' privacy by encrypting inference data transmitted and processed by LLMs, while the latter enhances adversarial robustness by yielding an aggregated output from multiple prompted LLM responses. Although widely recognized as effective individually, private inference for prompt ensembling together entails new challenges that render the naive combination of existing techniques inefficient. To overcome the hurdles, we propose SecPE, which designs efficient fully homomorphic encryption (FHE) counterparts for the core algorithmic building blocks of prompt ensembling. We conduct extensive experiments on 8 tasks to evaluate the accuracy, robustness, and efficiency of SecPE. The results show that SecPE maintains high clean accuracy and offers better robustness at the expense of merely $2.5\\%$ efficiency overhead compared to baseline private inference methods, indicating a satisfactory ``accuracy-robustness-efficiency'' tradeoff. For the efficiency of the encrypted Argmax operation that incurs major slowdown for prompt ensembling, SecPE is 35.4x faster than the state-of-the-art peers, which can be of independent interest beyond this work.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "154",
        "title": "RealRAG: Retrieval-augmented Realistic Image Generation via Self-reflective Contrastive Learning",
        "author": [
            "Yuanhuiyi Lyu",
            "Xu Zheng",
            "Lutao Jiang",
            "Yibo Yan",
            "Xin Zou",
            "Huiyu Zhou",
            "Linfeng Zhang",
            "Xuming Hu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00848",
        "abstract": "Recent text-to-image generative models, e.g., Stable Diffusion V3 and Flux, have achieved notable progress. However, these models are strongly restricted to their limited knowledge, a.k.a., their own fixed parameters, that are trained with closed datasets. This leads to significant hallucinations or distortions when facing fine-grained and unseen novel real-world objects, e.g., the appearance of the Tesla Cybertruck. To this end, we present the first real-object-based retrieval-augmented generation framework (RealRAG), which augments fine-grained and unseen novel object generation by learning and retrieving real-world images to overcome the knowledge gaps of generative models. Specifically, to integrate missing memory for unseen novel object generation, we train a reflective retriever by self-reflective contrastive learning, which injects the generator's knowledge into the sef-reflective negatives, ensuring that the retrieved augmented images compensate for the model's missing knowledge. Furthermore, the real-object-based framework integrates fine-grained visual knowledge for the generative models, tackling the distortion problem and improving the realism for fine-grained object generation. Our Real-RAG is superior in its modular application to all types of state-of-the-art text-to-image generative models and also delivers remarkable performance boosts with all of them, such as a gain of 16.18% FID score with the auto-regressive model on the Stanford Car benchmark.",
        "tags": [
            "Diffusion",
            "FLUX",
            "RAG",
            "Text-to-Image"
        ]
    },
    {
        "id": "155",
        "title": "Psychometric-Based Evaluation for Theorem Proving with Large Language Models",
        "author": [
            "Jianyu Zhang",
            "Yongwang Zhao",
            "Long Zhang",
            "Jilin Hu",
            "Xiaokun Luan",
            "Zhiwei Xu",
            "Feng Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00855",
        "abstract": "Large language models (LLMs) for formal theorem proving have become a prominent research focus. At present, the proving ability of these LLMs is mainly evaluated through proof pass rates on datasets such as miniF2F. However, this evaluation method overlooks the varying importance of theorems. As a result, it fails to highlight the real performance disparities between LLMs and leads to high evaluation costs. This study proposes a psychometric-based evaluation method for theorem proving with LLMs, comprising two main components: Dataset Annotation and Adaptive Evaluation. First, we propose a metric calculation method to annotate the dataset with difficulty and discrimination metrics. Specifically, we annotate each theorem in the miniF2F dataset and grade them into varying difficulty levels according to the performance of LLMs, resulting in an enhanced dataset: miniF2F-Graded. Experimental results show that the difficulty grading in miniF2F-Graded better reflects the theorem difficulty perceived by LLMs. Secondly, we design an adaptive evaluation method to dynamically select the most suitable theorems for testing based on the annotated metrics and the real-time performance of LLMs. We apply this method to evaluate 10 LLMs. The results show that our method finely highlights the performance disparities between LLMs. It also reduces evaluation costs by using only 23% of the theorems in the dataset.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "156",
        "title": "HintEval: A Comprehensive Framework for Hint Generation and Evaluation for Questions",
        "author": [
            "Jamshid Mozafari",
            "Bhawna Piryani",
            "Abdelrahman Abdallah",
            "Adam Jatowt"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00857",
        "abstract": "Large Language Models (LLMs) are transforming how people find information, and many users turn nowadays to chatbots to obtain answers to their questions. Despite the instant access to abundant information that LLMs offer, it is still important to promote critical thinking and problem-solving skills. Automatic hint generation is a new task that aims to support humans in answering questions by themselves by creating hints that guide users toward answers without directly revealing them. In this context, hint evaluation focuses on measuring the quality of hints, helping to improve the hint generation approaches. However, resources for hint research are currently spanning different formats and datasets, while the evaluation tools are missing or incompatible, making it hard for researchers to compare and test their models. To overcome these challenges, we introduce HintEval, a Python library that makes it easy to access diverse datasets and provides multiple approaches to generate and evaluate hints. HintEval aggregates the scattered resources into a single toolkit that supports a range of research goals and enables a clear, multi-faceted, and reliable evaluation. The proposed library also includes detailed online documentation, helping users quickly explore its features and get started. By reducing barriers to entry and encouraging consistent evaluation practices, HintEval offers a major step forward for facilitating hint generation and analysis research within the NLP/IR community.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "157",
        "title": "Predicting potentially unfair clauses in Chilean terms of services with natural language processing",
        "author": [
            "Christoffer Loeffler",
            "Andrea MartÃ­nez Freile",
            "TomÃ¡s Rey Pizarro"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00865",
        "abstract": "This study addresses the growing concern of information asymmetry in consumer contracts, exacerbated by the proliferation of online services with complex Terms of Service that are rarely even read. Even though research on automatic analysis methods is conducted, the problem is aggravated by the general focus on English-language Machine Learning approaches and on major jurisdictions, such as the European Union. We introduce a new methodology and a substantial dataset addressing this gap. We propose a novel annotation scheme with four categories and a total of 20 classes, and apply it on 50 online Terms of Service used in Chile. Our evaluation of transformer-based models highlights how factors like language- and/or domain-specific pre-training, few-shot sample size, and model architecture affect the detection and classification of potentially abusive clauses. Results show a large variability in performance for the different tasks and models, with the highest macro-F1 scores for the detection task ranging from 79% to 89% and micro-F1 scores up to 96%, while macro-F1 scores for the classification task range from 60% to 70% and micro-F1 scores from 64% to 80%. Notably, this is the first Spanish-language multi-label classification dataset for legal clauses, applying Chilean law and offering a comprehensive evaluation of Spanish-language models in the legal domain. Our work lays the ground for future research in method development for rarely considered legal analysis and potentially leads to practical applications to support consumers in Chile and Latin America as a whole.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "158",
        "title": "Language Models Use Trigonometry to Do Addition",
        "author": [
            "Subhash Kantamneni",
            "Max Tegmark"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00873",
        "abstract": "Mathematical reasoning is an increasingly important indicator of large language model (LLM) capabilities, yet we lack understanding of how LLMs process even simple mathematical tasks. To address this, we reverse engineer how three mid-sized LLMs compute addition. We first discover that numbers are represented in these LLMs as a generalized helix, which is strongly causally implicated for the tasks of addition and subtraction, and is also causally relevant for integer division, multiplication, and modular arithmetic. We then propose that LLMs compute addition by manipulating this generalized helix using the \"Clock\" algorithm: to solve $a+b$, the helices for $a$ and $b$ are manipulated to produce the $a+b$ answer helix which is then read out to model logits. We model influential MLP outputs, attention head outputs, and even individual neuron preactivations with these helices and verify our understanding with causal interventions. By demonstrating that LLMs represent numbers on a helix and manipulate this helix to perform addition, we present the first representation-level explanation of an LLM's mathematical capability.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "159",
        "title": "Towards Automation of Cognitive Modeling using Large Language Models",
        "author": [
            "Milena Rmus",
            "Akshay K. Jagadish",
            "Marvin Mathony",
            "Tobias Ludwig",
            "Eric Schulz"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00879",
        "abstract": "Computational cognitive models, which formalize theories of cognition, enable researchers to quantify cognitive processes and arbitrate between competing theories by fitting models to behavioral data. Traditionally, these models are handcrafted, which requires significant domain knowledge, coding expertise, and time investment. Previous work has demonstrated that Large Language Models (LLMs) are adept at pattern recognition in-context, solving complex problems, and generating executable code. In this work, we leverage these abilities to explore the potential of LLMs in automating the generation of cognitive models based on behavioral data. We evaluated the LLM in two different tasks: model identification (relating data to a source model), and model generation (generating the underlying cognitive model). We performed these tasks across two cognitive domains - decision making and learning. In the case of data simulated from canonical cognitive models, we found that the LLM successfully identified and generated the ground truth model. In the case of human data, where behavioral noise and lack of knowledge of the true underlying process pose significant challenges, the LLM generated models that are identical or close to the winning model from cognitive science literature. Our findings suggest that LLMs can have a transformative impact on cognitive modeling. With this project, we aim to contribute to an ongoing effort of automating scientific discovery in cognitive science.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "160",
        "title": "SimPER: A Minimalist Approach to Preference Alignment without Hyperparameters",
        "author": [
            "Teng Xiao",
            "Yige Yuan",
            "Zhengyu Chen",
            "Mingxiao Li",
            "Shangsong Liang",
            "Zhaochun Ren",
            "Vasant G Honavar"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00883",
        "abstract": "Existing preference optimization objectives for language model alignment require additional hyperparameters that must be extensively tuned to achieve optimal performance, increasing both the complexity and time required for fine-tuning large language models. In this paper, we propose a simple yet effective hyperparameter-free preference optimization algorithm for http://alignment.We observe that promising performance can be achieved simply by optimizing inverse perplexity, which is calculated as the inverse of the exponentiated average log-likelihood of the chosen and rejected responses in the preference dataset. The resulting simple learning objective, SimPER, is easy to implement and eliminates the need for expensive hyperparameter tuning and a reference model, making it both computationally and memory efficient. Extensive experiments on widely used real-world benchmarks, including MT-Bench, AlpacaEval 2, and 10 key benchmarks of the Open LLM Leaderboard with 5 base models, demonstrate that SimPER consistently and significantly outperforms existing approaches-even without any hyperparameters or a reference model . For example, despite its simplicity, SimPER outperforms state-of-the-art methods by up to 5.7 points on AlpacaEval 2 and achieves the highest average ranking across 10 benchmarks on the Open LLM Leaderboard. The source code for SimPER is publicly available at: https://github.com/tengxiao1/SimPER.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "161",
        "title": "MorphBPE: A Morpho-Aware Tokenizer Bridging Linguistic Complexity for Efficient LLM Training Across Morphologies",
        "author": [
            "Ehsaneddin Asgari",
            "Yassine El Kheir",
            "Mohammad Ali Sadraei Javaheri"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00894",
        "abstract": "Tokenization is fundamental to Natural Language Processing (NLP), directly impacting model efficiency and linguistic fidelity. While Byte Pair Encoding (BPE) is widely used in Large Language Models (LLMs), it often disregards morpheme boundaries, leading to suboptimal segmentation, particularly in morphologically rich languages. We introduce MorphBPE, a morphology-aware extension of BPE that integrates linguistic structure into subword tokenization while preserving statistical efficiency. Additionally, we propose two morphology-based evaluation metrics: (i) Morphological Consistency F1-Score, which quantifies the consistency between morpheme sharing and token sharing, contributing to LLM training convergence, and (ii) Morphological Edit Distance, which measures alignment between morphemes and tokens concerning interpretability. Experiments on English, Russian, Hungarian, and Arabic across 300M and 1B parameter LLMs demonstrate that MorphBPE consistently reduces cross-entropy loss, accelerates convergence, and improves morphological alignment scores. Fully compatible with existing LLM pipelines, MorphBPE requires minimal modifications for integration. The MorphBPE codebase and tokenizer playground will be available at: https://github.com/llm-lab-org/MorphBPE and https://tokenizer.llm-lab.org",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Segmentation"
        ]
    },
    {
        "id": "162",
        "title": "Embracing Dialectic Intersubjectivity: Coordination of Different Perspectives in Content Analysis with LLM Persona Simulation",
        "author": [
            "Taewoo Kang",
            "Kjerstin Thorson",
            "Tai-Quan Peng",
            "Dan Hiaeshutter-Rice",
            "Sanguk Lee",
            "Stuart Soroka"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00903",
        "abstract": "This study attempts to advancing content analysis methodology from consensus-oriented to coordination-oriented practices, thereby embracing diverse coding outputs and exploring the dynamics among differential perspectives. As an exploratory investigation of this approach, we evaluate six GPT-4o configurations to analyze sentiment in Fox News and MSNBC transcripts on Biden and Trump during the 2020 U.S. presidential campaign, examining patterns across these models. By assessing each model's alignment with ideological perspectives, we explore how partisan selective processing could be identified in LLM-Assisted Content Analysis (LACA). Findings reveal that partisan persona LLMs exhibit stronger ideological biases when processing politically congruent content. Additionally, intercoder reliability is higher among same-partisan personas compared to cross-partisan pairs. This approach enhances the nuanced understanding of LLM outputs and advances the integrity of AI-driven social science research, enabling simulations of real-world implications.",
        "tags": [
            "GPT",
            "LLMs"
        ]
    },
    {
        "id": "163",
        "title": "The Accuracy, Robustness, and Readability of LLM-Generated Sustainability-Related Word Definitions",
        "author": [
            "Alice Heiman"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00916",
        "abstract": "A common language with standardized definitions is crucial for effective climate discussions. However, concerns exist about LLMs misrepresenting climate terms. We compared 300 official IPCC glossary definitions with those generated by GPT-4o-mini, Llama3.1 8B, and Mistral 7B, analyzing adherence, robustness, and readability using SBERT sentence embeddings. The LLMs scored an average adherence of $0.57-0.59 \\pm 0.15$, and their definitions proved harder to read than the originals. Model-generated definitions vary mainly among words with multiple or ambiguous definitions, showing the potential to highlight terms that need standardization. The results show how LLMs could support environmental discourse while emphasizing the need to align model outputs with established terminology for clarity and consistency.",
        "tags": [
            "GPT",
            "LLMs"
        ]
    },
    {
        "id": "164",
        "title": "Attention Sinks and Outlier Features: A 'Catch, Tag, and Release' Mechanism for Embeddings",
        "author": [
            "Stephen Zhang",
            "Mustafa Khan",
            "Vardan Papyan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00919",
        "abstract": "Two prominent features of large language models (LLMs) is the presence of large-norm (outlier) features and the tendency for tokens to attend very strongly to a select few tokens. Despite often having no semantic relevance, these select tokens, called attention sinks, along with the large outlier features, have proven important for model performance, compression, and streaming. Consequently, investigating the roles of these phenomena within models and exploring how they might manifest in the model parameters has become an area of active interest. Through an empirical investigation, we demonstrate that attention sinks utilize outlier features to: catch a sequence of tokens, tag the captured tokens by applying a common perturbation, and then release the tokens back into the residual stream, where the tagged tokens are eventually retrieved. We prove that simple tasks, like averaging, necessitate the 'catch, tag, release' mechanism hence explaining why it would arise organically in modern LLMs. Our experiments also show that the creation of attention sinks can be completely captured in the model parameters using low-rank matrices, which has important implications for model compression and substantiates the success of recent approaches that incorporate a low-rank term to offset performance degradation.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "165",
        "title": "Blink of an eye: a simple theory for feature localization in generative models",
        "author": [
            "Marvin Li",
            "Aayush Karan",
            "Sitan Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00921",
        "abstract": "Large language models (LLMs) can exhibit undesirable and unexpected behavior in the blink of an eye. In a recent Anthropic demo, Claude switched from coding to Googling pictures of Yellowstone, and these sudden shifts in behavior have also been observed in reasoning patterns and jailbreaks. This phenomenon is not unique to autoregressive models: in diffusion models, key features of the final output are decided in narrow ``critical windows'' of the generation process. In this work we develop a simple, unifying theory to explain this phenomenon. We show that it emerges generically as the generation process localizes to a sub-population of the distribution it models. While critical windows have been studied at length in diffusion models, existing theory heavily relies on strong distributional assumptions and the particulars of Gaussian diffusion. In contrast to existing work our theory (1) applies to autoregressive and diffusion models; (2) makes no distributional assumptions; (3) quantitatively improves previous bounds even when specialized to diffusions; and (4) requires basic tools and no stochastic calculus or statistical physics-based machinery. We also identify an intriguing connection to the all-or-nothing phenomenon from statistical inference. Finally, we validate our predictions empirically for LLMs and find that critical windows often coincide with failures in problem solving for various math and reasoning benchmarks.",
        "tags": [
            "Diffusion",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "166",
        "title": "Huff-LLM: End-to-End Lossless Compression for Efficient LLM Inference",
        "author": [
            "Patrick Yubeaton",
            "Tareq Mahmoud",
            "Shehab Naga",
            "Pooria Taheri",
            "Tianhua Xia",
            "Arun George",
            "Yasmein Khalil",
            "Sai Qian Zhang",
            "Siddharth Joshi",
            "Chinmay Hegde",
            "Siddharth Garg"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00922",
        "abstract": "As they become more capable, large language models (LLMs) have continued to rapidly increase in size. This has exacerbated the difficulty in running state of the art LLMs on small, edge devices. Standard techniques advocate solving this problem through lossy compression techniques such as quantization or pruning. However, such compression techniques are lossy, and have been shown to change model behavior in unpredictable manners. We propose Huff-LLM, an \\emph{end-to-end, lossless} model compression method that lets users store LLM weights in compressed format \\emph{everywhere} -- cloud, disk, main memory, and even in on-chip memory/buffers. This allows us to not only load larger models in main memory, but also reduces bandwidth required to load weights on chip, and makes more efficient use of on-chip weight buffers. In addition to the memory savings achieved via compression, we also show latency and energy efficiency improvements when performing inference with the compressed model.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "167",
        "title": "SAM-guided Pseudo Label Enhancement for Multi-modal 3D Semantic Segmentation",
        "author": [
            "Mingyu Yang",
            "Jitong Lu",
            "Hun-Seok Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00960",
        "abstract": "Multi-modal 3D semantic segmentation is vital for applications such as autonomous driving and virtual reality (VR). To effectively deploy these models in real-world scenarios, it is essential to employ cross-domain adaptation techniques that bridge the gap between training data and real-world data. Recently, self-training with pseudo-labels has emerged as a predominant method for cross-domain adaptation in multi-modal 3D semantic segmentation. However, generating reliable pseudo-labels necessitates stringent constraints, which often result in sparse pseudo-labels after pruning. This sparsity can potentially hinder performance improvement during the adaptation process. We propose an image-guided pseudo-label enhancement approach that leverages the complementary 2D prior knowledge from the Segment Anything Model (SAM) to introduce more reliable pseudo-labels, thereby boosting domain adaptation performance. Specifically, given a 3D point cloud and the SAM masks from its paired image data, we collect all 3D points covered by each SAM mask that potentially belong to the same object. Then our method refines the pseudo-labels within each SAM mask in two steps. First, we determine the class label for each mask using majority voting and employ various constraints to filter out unreliable mask labels. Next, we introduce Geometry-Aware Progressive Propagation (GAPP) which propagates the mask label to all 3D points within the SAM mask while avoiding outliers caused by 2D-3D misalignment. Experiments conducted across multiple datasets and domain adaptation scenarios demonstrate that our proposed method significantly increases the quantity of high-quality pseudo-labels and enhances the adaptation performance over baseline methods.",
        "tags": [
            "3D",
            "SAM",
            "Segment Anything",
            "Segmentation"
        ]
    },
    {
        "id": "168",
        "title": "PDE-Controller: LLMs for Autoformalization and Reasoning of PDEs",
        "author": [
            "Mauricio Soroco",
            "Jialin Song",
            "Mengzhou Xia",
            "Kye Emond",
            "Weiran Sun",
            "Wuyang Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00963",
        "abstract": "While recent AI-for-math has made strides in pure mathematics, areas of applied mathematics, particularly PDEs, remain underexplored despite their significant real-world applications. We present PDE-Controller, a framework that enables large language models (LLMs) to control systems governed by partial differential equations (PDEs). Our approach enables LLMs to transform informal natural language instructions into formal specifications, and then execute reasoning and planning steps to improve the utility of PDE control. We build a holistic solution comprising datasets (both human-written cases and 2 million synthetic samples), math-reasoning models, and novel evaluation metrics, all of which require significant effort. Our PDE-Controller significantly outperforms prompting the latest open-source and GPT models in reasoning, autoformalization, and program synthesis, achieving up to a 62% improvement in utility gain for PDE control. By bridging the gap between language generation and PDE systems, we demonstrate the potential of LLMs in addressing complex scientific and engineering challenges. We will release all data, model checkpoints, and code at https://pde-controller.github.io/.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "169",
        "title": "CLIP-UP: A Simple and Efficient Mixture-of-Experts CLIP Training Recipe with Sparse Upcycling",
        "author": [
            "Xinze Wang",
            "Chen Chen",
            "Yinfei Yang",
            "Hong-You Chen",
            "Bowen Zhang",
            "Aditya Pal",
            "Xiangxin Zhu",
            "Xianzhi Du"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00965",
        "abstract": "Mixture-of-Experts (MoE) models are crucial for scaling model capacity while controlling inference costs. While integrating MoE into multimodal models like CLIP improves performance, training these models is notoriously challenging and expensive. We propose CLIP-Upcycling (CLIP-UP), an efficient alternative training strategy that converts a pre-trained dense CLIP model into a sparse MoE architecture. Through extensive experimentation with various settings and auxiliary losses, we demonstrate that CLIP-UP significantly reduces training complexity and cost. Remarkably, our sparse CLIP B/16 model, trained with CLIP-UP, outperforms its dense counterpart by 7.2% and 6.6% on COCO and Flickr30k text-to-image Recall@1 benchmarks respectively. It even surpasses the larger CLIP L/14 model on this task while using only 30% of the inference FLOPs. We further demonstrate the generalizability of our training recipe across different scales, establishing sparse upcycling as a practical and scalable approach for building efficient, high-performance CLIP models.",
        "tags": [
            "CLIP",
            "Text-to-Image"
        ]
    },
    {
        "id": "170",
        "title": "CoDe: Blockwise Control for Denoising Diffusion Models",
        "author": [
            "Anuj Singh",
            "Sayak Mukherjee",
            "Ahmad Beirami",
            "Hadi Jamali-Rad"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00968",
        "abstract": "Aligning diffusion models to downstream tasks often requires finetuning new models or gradient-based guidance at inference time to enable sampling from the reward-tilted posterior. In this work, we explore a simple inference-time gradient-free guidance approach, called controlled denoising (CoDe), that circumvents the need for differentiable guidance functions and model finetuning. CoDe is a blockwise sampling method applied during intermediate denoising steps, allowing for alignment with downstream rewards. Our experiments demonstrate that, despite its simplicity, CoDe offers a favorable trade-off between reward alignment, prompt instruction following, and inference cost, achieving a competitive performance against the state-of-the-art baselines. Our code is available at: https://github.com/anujinho/code.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "171",
        "title": "Wizard of Shopping: Target-Oriented E-commerce Dialogue Generation with Decision Tree Branching",
        "author": [
            "Xiangci Li",
            "Zhiyu Chen",
            "Jason Ingyu Choi",
            "Nikhita Vedula",
            "Besnik Fetahu",
            "Oleg Rokhlenko",
            "Shervin Malmasi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00969",
        "abstract": "The goal of conversational product search (CPS) is to develop an intelligent, chat-based shopping assistant that can directly interact with customers to understand shopping intents, ask clarification questions, and find relevant products. However, training such assistants is hindered mainly due to the lack of reliable and large-scale datasets. Prior human-annotated CPS datasets are extremely small in size and lack integration with real-world product search systems. We propose a novel approach, TRACER, which leverages large language models (LLMs) to generate realistic and natural conversations for different shopping domains. TRACER's novelty lies in grounding the generation to dialogue plans, which are product search trajectories predicted from a decision tree model, that guarantees relevant product discovery in the shortest number of search conditions. We also release the first target-oriented CPS dataset Wizard of Shopping (WoS), containing highly natural and coherent conversations (3.6k) from three shopping domains. Finally, we demonstrate the quality and effectiveness of WoS via human evaluations and downstream tasks.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "172",
        "title": "Pushing the Boundaries of State Space Models for Image and Video Generation",
        "author": [
            "Yicong Hong",
            "Long Mai",
            "Yuan Yao",
            "Feng Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00972",
        "abstract": "While Transformers have become the dominant architecture for visual generation, linear attention models, such as the state-space models (SSM), are increasingly recognized for their efficiency in processing long visual sequences. However, the essential efficiency of these models comes from formulating a limited recurrent state, enforcing causality among tokens that are prone to inconsistent modeling of N-dimensional visual data, leaving questions on their capacity to generate long non-causal sequences. In this paper, we explore the boundary of SSM on image and video generation by building the largest-scale diffusion SSM-Transformer hybrid model to date (5B parameters) based on the sub-quadratic bi-directional Hydra and self-attention, and generate up to 2K images and 360p 8 seconds (16 FPS) videos. Our results demonstrate that the model can produce faithful results aligned with complex text prompts and temporal consistent videos with high dynamics, suggesting the great potential of using SSMs for visual generation tasks.",
        "tags": [
            "Diffusion",
            "SSMs",
            "State Space Models",
            "Transformer",
            "Video Generation"
        ]
    },
    {
        "id": "173",
        "title": "Context-Aware Hierarchical Merging for Long Document Summarization",
        "author": [
            "Litu Ou",
            "Mirella Lapata"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00977",
        "abstract": "Hierarchical Merging is a technique commonly used to summarize very long texts ($>$100K tokens) by breaking down the input into smaller sections, summarizing those sections individually, and then merging or combining those summaries into a final coherent summary. Although it helps address the limitations of large language models (LLMs) with fixed input length constraints, the recursive merging process can amplify LLM hallucinations, increasing the risk of factual inaccuracies. In this paper, we seek to mitigate hallucinations by enriching hierarchical merging with context from the source document. Specifically, we propose different approaches to contextual augmentation ranging from \\emph{replacing} intermediate summaries with relevant input context, to \\emph{refining} them while using the context as supporting evidence, and \\emph{aligning} them implicitly (via citations) to the input. Experimental results on datasets representing legal and narrative domains show that contextual augmentation consistently outperforms zero-shot and hierarchical merging baselines for the Llama 3.1 model family. Our analysis further reveals that refinement methods tend to perform best when paired with extractive summarization for identifying relevant input.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "174",
        "title": "Forecasting VIX using interpretable Kolmogorov-Arnold networks",
        "author": [
            "So-Yoon Cho",
            "Sungchul Lee",
            "Hyun-Gyoon Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00980",
        "abstract": "This paper presents the use of Kolmogorov-Arnold Networks (KANs) for forecasting the CBOE Volatility Index (VIX). Unlike traditional MLP-based neural networks that are often criticized for their black-box nature, KAN offers an interpretable approach via learnable spline-based activation functions and symbolification. Based on a parsimonious architecture with symbolic functions, KAN expresses a forecast of the VIX as a closed-form in terms of explanatory variables, and provide interpretable insights into key characteristics of the VIX, including mean reversion and the leverage effect. Through in-depth empirical analysis across multiple datasets and periods, we show that KANs achieve competitive forecasting performance while requiring significantly fewer parameters compared to MLP-based neural network models. Our findings demonstrate the capacity and potential of KAN as an interpretable financial time-series forecasting method.",
        "tags": [
            "KAN",
            "Kolmogorov-Arnold Networks"
        ]
    },
    {
        "id": "175",
        "title": "RandLoRA: Full-rank parameter-efficient fine-tuning of large models",
        "author": [
            "Paul Albert",
            "Frederic Z. Zhang",
            "Hemanth Saratchandran",
            "Cristian Rodriguez-Opazo",
            "Anton van den Hengel",
            "Ehsan Abbasnejad"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00987",
        "abstract": "Low-Rank Adaptation (LoRA) and its variants have shown impressive results in reducing the number of trainable parameters and memory requirements of large transformer networks while maintaining fine-tuning performance. However, the low-rank nature of the weight update inherently limits the representation power of fine-tuned models, potentially compromising performance on complex tasks. This raises a critical question: when a performance gap between LoRA and standard fine-tuning is observed, is it due to the reduced number of trainable parameters or the rank deficiency? This paper aims to answer this question by introducing RandLoRA, a parameter-efficient method that performs full-rank updates using a learned linear combinations of low-rank, non-trainable random matrices. Our method limits the number of trainable parameters by restricting optimization to diagonal scaling matrices applied to the fixed random matrices. This allows us to effectively overcome the low-rank limitations while maintaining parameter and memory efficiency during training. Through extensive experimentation across vision, language, and vision-language benchmarks, we systematically evaluate the limitations of LoRA and existing random basis methods. Our findings reveal that full-rank updates are beneficial across vision and language tasks individually, and even more so for vision-language tasks, where RandLoRA significantly reduces -- and sometimes eliminates -- the performance gap between standard fine-tuning and LoRA, demonstrating its efficacy.",
        "tags": [
            "LoRA",
            "Low-Rank Adaptation",
            "Transformer"
        ]
    },
    {
        "id": "176",
        "title": "PlotGen: Multi-Agent LLM-based Scientific Data Visualization via Multimodal Feedback",
        "author": [
            "Kanika Goswami",
            "Puneet Mathur",
            "Ryan Rossi",
            "Franck Dernoncourt"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00988",
        "abstract": "Scientific data visualization is pivotal for transforming raw data into comprehensible visual representations, enabling pattern recognition, forecasting, and the presentation of data-driven insights. However, novice users often face difficulties due to the complexity of selecting appropriate tools and mastering visualization techniques. Large Language Models (LLMs) have recently demonstrated potential in assisting code generation, though they struggle with accuracy and require iterative debugging. In this paper, we propose PlotGen, a novel multi-agent framework aimed at automating the creation of precise scientific visualizations. PlotGen orchestrates multiple LLM-based agents, including a Query Planning Agent that breaks down complex user requests into executable steps, a Code Generation Agent that converts pseudocode into executable Python code, and three retrieval feedback agents - a Numeric Feedback Agent, a Lexical Feedback Agent, and a Visual Feedback Agent - that leverage multimodal LLMs to iteratively refine the data accuracy, textual labels, and visual correctness of generated plots via self-reflection. Extensive experiments show that PlotGen outperforms strong baselines, achieving a 4-6 percent improvement on the MatPlotBench dataset, leading to enhanced user trust in LLM-generated visualizations and improved novice productivity due to a reduction in debugging time needed for plot errors.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "177",
        "title": "ChartCitor: Multi-Agent Framework for Fine-Grained Chart Visual Attribution",
        "author": [
            "Kanika Goswami",
            "Puneet Mathur",
            "Ryan Rossi",
            "Franck Dernoncourt"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00989",
        "abstract": "Large Language Models (LLMs) can perform chart question-answering tasks but often generate unverified hallucinated responses. Existing answer attribution methods struggle to ground responses in source charts due to limited visual-semantic context, complex visual-text alignment requirements, and difficulties in bounding box prediction across complex layouts. We present ChartCitor, a multi-agent framework that provides fine-grained bounding box citations by identifying supporting evidence within chart images. The system orchestrates LLM agents to perform chart-to-table extraction, answer reformulation, table augmentation, evidence retrieval through pre-filtering and re-ranking, and table-to-chart mapping. ChartCitor outperforms existing baselines across different chart types. Qualitative user studies show that ChartCitor helps increase user trust in Generative AI by providing enhanced explainability for LLM-assisted chart QA and enables professionals to be more productive.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "178",
        "title": "Self-supervised Analogical Learning using Language Models",
        "author": [
            "Ben Zhou",
            "Sarthak Jain",
            "Yi Zhang",
            "Qiang Ning",
            "Shuai Wang",
            "Yassine Benajiba",
            "Dan Roth"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00996",
        "abstract": "Large language models have been shown to suffer from reasoning inconsistency issues. That is, they fail more in situations unfamiliar to the training data, even though exact or very similar reasoning paths exist in more common cases that they can successfully solve. Such observations motivate us to propose methods that encourage models to understand the high-level and abstract reasoning processes during training instead of only the final answer. This way, models can transfer the exact solution to similar cases, regardless of their relevance to the pre-training data distribution. In this work, we propose SAL, a self-supervised analogical learning framework. SAL mimics the human analogy process and trains models to explicitly transfer high-quality symbolic solutions from cases that they know how to solve to other rare cases in which they tend to fail more. We show that the resulting models after SAL learning outperform base language models on a wide range of reasoning benchmarks, such as StrategyQA, GSM8K, and HotpotQA, by 2% to 20%. At the same time, we show that our model is more generalizable and controllable through analytical studies.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "179",
        "title": "MergeME: Model Merging Techniques for Homogeneous and Heterogeneous MoEs",
        "author": [
            "Yuhang Zhou",
            "Giannis Karamanolakis",
            "Victor Soto",
            "Anna Rumshisky",
            "Mayank Kulkarni",
            "Furong Huang",
            "Wei Ai",
            "Jianhua Lu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00997",
        "abstract": "The recent success of specialized Large Language Models (LLMs) in domains such as mathematical reasoning and coding has led to growing interest in methods for merging these expert LLMs into a unified Mixture-of-Experts (MoE) model, with the goal of enhancing performance in each domain while retaining effectiveness on general tasks. However, the effective merging of expert models remains an open challenge, especially for models with highly divergent weight parameters or different architectures. State-of-the-art MoE merging methods only work with homogeneous model architectures and rely on simple unweighted averaging to merge expert layers, which does not address parameter interference and requires extensive fine-tuning of the merged MoE to restore performance. To address these limitations, this paper introduces new MoE merging techniques, including strategies to mitigate parameter interference, routing heuristics to reduce the need for MoE fine-tuning, and a novel method for merging experts with different architectures. Extensive experiments across multiple domains demonstrate the effectiveness of our proposed methods, reducing fine-tuning costs, improving performance over state-of-the-art methods, and expanding the applicability of MoE merging.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "180",
        "title": "Encrypted Large Model Inference: The Equivariant Encryption Paradigm",
        "author": [
            "James Buban",
            "Hongyang Zhang",
            "Claudio Angione",
            "Harry Yang",
            "Ahmad Farhan",
            "Seyfal Sultanov",
            "Michael Du",
            "Xuran Ma",
            "Zihao Wang",
            "Yue Zhao",
            "Arria Owlia",
            "Fielding Johnston",
            "Patrick Colangelo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01013",
        "abstract": "Large scale deep learning model, such as modern language models and diffusion architectures, have revolutionized applications ranging from natural language processing to computer vision. However, their deployment in distributed or decentralized environments raises significant privacy concerns, as sensitive data may be exposed during inference. Traditional techniques like secure multi-party computation, homomorphic encryption, and differential privacy offer partial remedies but often incur substantial computational overhead, latency penalties, or limited compatibility with non-linear network operations. In this work, we introduce Equivariant Encryption (EE), a novel paradigm designed to enable secure, \"blind\" inference on encrypted data with near zero performance overhead. Unlike fully homomorphic approaches that encrypt the entire computational graph, EE selectively obfuscates critical internal representations within neural network layers while preserving the exact functionality of both linear and a prescribed set of non-linear operations. This targeted encryption ensures that raw inputs, intermediate activations, and outputs remain confidential, even when processed on untrusted infrastructure. We detail the theoretical foundations of EE, compare its performance and integration complexity against conventional privacy preserving techniques, and demonstrate its applicability across a range of architectures, from convolutional networks to large language models. Furthermore, our work provides a comprehensive threat analysis, outlining potential attack vectors and baseline strategies, and benchmarks EE against standard inference pipelines in decentralized settings. The results confirm that EE maintains high fidelity and throughput, effectively bridging the gap between robust data confidentiality and the stringent efficiency requirements of modern, large scale model inference.",
        "tags": [
            "Diffusion",
            "Large Language Models"
        ]
    },
    {
        "id": "181",
        "title": "Refining Adaptive Zeroth-Order Optimization at Ease",
        "author": [
            "Yao Shu",
            "Qixin Zhang",
            "Kun He",
            "Zhongxiang Dai"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01014",
        "abstract": "Recently, zeroth-order (ZO) optimization plays an essential role in scenarios where gradient information is inaccessible or unaffordable, such as black-box systems and resource-constrained environments. While existing adaptive methods such as ZO-AdaMM have shown promise, they are fundamentally limited by their underutilization of moment information during optimization, usually resulting in underperforming convergence. To overcome these limitations, this paper introduces Refined Adaptive Zeroth-Order Optimization (R-AdaZO). Specifically, we first show the untapped variance reduction effect of first moment estimate on ZO gradient estimation, which improves the accuracy and stability of ZO updates. We then refine the second moment estimate based on these variance-reduced gradient estimates to better capture the geometry of the optimization landscape, enabling a more effective scaling of ZO updates. We present rigorous theoretical analysis to show (I) the first analysis to the variance reduction of first moment estimate in ZO optimization, (II) the improved second moment estimates with a more accurate approximation of its variance-free ideal, (III) the first variance-aware convergence framework for adaptive ZO methods, which may be of independent interest, and (IV) the faster convergence of R-AdaZO than existing baselines like ZO-AdaMM. Our extensive experiments, including synthetic problems, black-box adversarial attack, and memory-efficient fine-tuning of large language models (LLMs), further verify the superior convergence of R-AdaZO, indicating that R-AdaZO offers an improved solution for real-world ZO optimization challenges.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "182",
        "title": "Knowing When to Stop: Dynamic Context Cutoff for Large Language Models",
        "author": [
            "Roy Xie",
            "Junlin Wang",
            "Paul Rosu",
            "Chunyuan Deng",
            "Bolun Sun",
            "Zihao Lin",
            "Bhuwan Dhingra"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01025",
        "abstract": "Large language models (LLMs) process entire input contexts indiscriminately, which is inefficient in cases where the information required to answer a query is localized within the context. We present dynamic context cutoff, a human-inspired method enabling LLMs to self-terminate processing upon acquiring sufficient task-relevant information. Through analysis of model internals, we discover that specific attention heads inherently encode \"sufficiency signals\" - detectable through lightweight classifiers - that predict when critical information has been processed. This reveals a new efficiency paradigm: models' internal understanding naturally dictates processing needs rather than external compression heuristics. Comprehensive experiments across six QA datasets (up to 40K tokens) with three model families (LLaMA/Qwen/Mistral, 1B0-70B) demonstrate 1.33x average token reduction while improving accuracy by 1.3%. Furthermore, our method demonstrates better performance with the same rate of token reduction compared to other context efficiency methods. Additionally, we observe an emergent scaling phenomenon: while smaller models require require probing for sufficiency detection, larger models exhibit intrinsic self-assessment capabilities through prompting.",
        "tags": [
            "Detection",
            "LLMs",
            "LLaMA",
            "Large Language Models",
            "Qwen"
        ]
    },
    {
        "id": "183",
        "title": "Comprehensive Modeling Approaches for Forecasting Bitcoin Transaction Fees: A Comparative Study",
        "author": [
            "Jiangqin Ma",
            "Erfan Mahmoudinia"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01029",
        "abstract": "Transaction fee prediction in Bitcoin's ecosystem represents a crucial challenge affecting both user costs and miner revenue optimization. This study presents a systematic evaluation of six predictive models for forecasting Bitcoin transaction fees across a 24-hour horizon (144 blocks): SARIMAX, Prophet, Time2Vec, Time2Vec with Attention, a Hybrid model combining SARIMAX with Gradient Boosting, and the Temporal Fusion Transformer (TFT). Our approach integrates comprehensive feature engineering spanning mempool metrics, network parameters, and historical fee patterns to capture the multifaceted dynamics of fee behavior.\nThrough rigorous 5-fold cross-validation and independent testing, our analysis reveals that traditional statistical approaches outperform more complex deep learning architectures. The SARIMAX model achieves superior accuracy on the independent test set, while Prophet demonstrates strong performance during cross-validation. Notably, sophisticated deep learning models like Time2Vec and TFT show comparatively lower predictive power despite their architectural complexity. This performance disparity likely stems from the relatively constrained training dataset of 91 days, suggesting that deep learning models may achieve enhanced results with extended historical data.\nThese findings offer significant practical implications for cryptocurrency stakeholders, providing empirically-validated guidance for fee-sensitive decision making while illuminating critical considerations in model selection based on data constraints. The study establishes a foundation for advanced fee prediction while highlighting the current advantages of traditional statistical methods in this domain.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "184",
        "title": "PARA: Parameter-Efficient Fine-tuning with Prompt Aware Representation Adjustment",
        "author": [
            "Zequan Liu",
            "Yi Zhao",
            "Ming Tan",
            "Wei Zhu",
            "Aaron Xuxiang Tian"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01033",
        "abstract": "In the realm of parameter-efficient fine-tuning (PEFT) methods, while options like LoRA are available, there is a persistent demand in the industry for a PEFT approach that excels in both efficiency and performance within the context of single-backbone multi-tenant applications. This paper introduces a new and straightforward PEFT technique, termed \\underline{P}rompt \\underline{A}ware \\underline{R}epresentation \\underline{A}djustment (PARA). The core of our proposal is to integrate a lightweight vector generator within each Transformer layer. This generator produces vectors that are responsive to input prompts, thereby adjusting the hidden representations accordingly. Our extensive experimentation across diverse tasks has yielded promising results. Firstly, the PARA method has been shown to surpass current PEFT benchmarks in terms of performance, despite having a similar number of adjustable parameters. Secondly, it has proven to be more efficient than LoRA in the single-backbone multi-tenant scenario, highlighting its significant potential for industrial adoption.",
        "tags": [
            "LoRA",
            "Transformer"
        ]
    },
    {
        "id": "185",
        "title": "Geoinformatics-Guided Machine Learning for Power Plant Classification",
        "author": [
            "Blessing Austin-Gabriel",
            "Aparna S. Varde",
            "Hao Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01039",
        "abstract": "This paper proposes an approach in the area of Knowledge-Guided Machine Learning (KGML) via a novel integrated framework comprising CNN (Convolutional Neural Networks) and ViT (Vision Transformers) along with GIS (Geographic Information Systems) to enhance power plant classification in the context of energy management. Knowledge from geoinformatics derived through Spatial Masks (SM) in GIS is infused into an architecture of CNN and ViT, in this proposed KGML approach. It is found to provide much better performance compared to the baseline of CNN and ViT only in the classification of multiple types of power plants from real satellite imagery, hence emphasizing the vital role of the geoinformatics-guided approach. This work makes a contribution to the main theme of KGML that can be beneficial in many AI systems today. It makes broader impacts on AI in Smart Cities, and Environmental Computing.",
        "tags": [
            "ViT"
        ]
    },
    {
        "id": "186",
        "title": "Internal Activation as the Polar Star for Steering Unsafe LLM Behavior",
        "author": [
            "Peixuan Han",
            "Cheng Qian",
            "Xiusi Chen",
            "Yuji Zhang",
            "Denghui Zhang",
            "Heng Ji"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01042",
        "abstract": "Large language models (LLMs) have demonstrated exceptional capabilities across a wide range of tasks but also pose significant risks due to their potential to generate harmful content. Although existing safety mechanisms can improve model safety, they often lead to overly cautious behavior and fail to fully utilize LLMs' internal cognitive processes. Drawing inspiration from cognitive science, where humans rely on reflective reasoning (System 2 thinking) to regulate language and behavior, we empirically demonstrate that LLMs also possess a similar capacity for internal assessment and regulation, which can be actively detected.\nBuilding on this insight, we introduce SafeSwitch, a framework that dynamically regulates unsafe outputs by monitoring and utilizing the model's internal states. Our empirical results show that SafeSwitch reduces harmful outputs by over 80% on safety benchmarks while maintaining strong utility. Compared to traditional safety alignment methods, SafeSwitch delivers more informative and context-aware refusals, demonstrates resilience to unseen queries, and achieves these benefits while only tuning less than 6% of the original parameters. These features make SafeSwitch a promising approach for implementing nuanced safety controls in LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "187",
        "title": "WonderHuman: Hallucinating Unseen Parts in Dynamic 3D Human Reconstruction",
        "author": [
            "Zilong Wang",
            "Zhiyang Dou",
            "Yuan Liu",
            "Cheng Lin",
            "Xiao Dong",
            "Yunhui Guo",
            "Chenxu Zhang",
            "Xin Li",
            "Wenping Wang",
            "Xiaohu Guo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01045",
        "abstract": "In this paper, we present WonderHuman to reconstruct dynamic human avatars from a monocular video for high-fidelity novel view synthesis. Previous dynamic human avatar reconstruction methods typically require the input video to have full coverage of the observed human body. However, in daily practice, one typically has access to limited viewpoints, such as monocular front-view videos, making it a cumbersome task for previous methods to reconstruct the unseen parts of the human avatar. To tackle the issue, we present WonderHuman, which leverages 2D generative diffusion model priors to achieve high-quality, photorealistic reconstructions of dynamic human avatars from monocular videos, including accurate rendering of unseen body parts. Our approach introduces a Dual-Space Optimization technique, applying Score Distillation Sampling (SDS) in both canonical and observation spaces to ensure visual consistency and enhance realism in dynamic human reconstruction. Additionally, we present a View Selection strategy and Pose Feature Injection to enforce the consistency between SDS predictions and observed data, ensuring pose-dependent effects and higher fidelity in the reconstructed avatar. In the experiments, our method achieves SOTA performance in producing photorealistic renderings from the given monocular video, particularly for those challenging unseen parts. The project page and source code can be found at https://wyiguanw.github.io/WonderHuman/.",
        "tags": [
            "3D",
            "Diffusion"
        ]
    },
    {
        "id": "188",
        "title": "Emotional Face-to-Speech",
        "author": [
            "Jiaxin Ye",
            "Boyuan Cao",
            "Hongming Shan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01046",
        "abstract": "How much can we infer about an emotional voice solely from an expressive face? This intriguing question holds great potential for applications such as virtual character dubbing and aiding individuals with expressive language disorders. Existing face-to-speech methods offer great promise in capturing identity characteristics but struggle to generate diverse vocal styles with emotional expression. In this paper, we explore a new task, termed emotional face-to-speech, aiming to synthesize emotional speech directly from expressive facial cues. To that end, we introduce DEmoFace, a novel generative framework that leverages a discrete diffusion transformer (DiT) with curriculum learning, built upon a multi-level neural audio codec. Specifically, we propose multimodal DiT blocks to dynamically align text and speech while tailoring vocal styles based on facial emotion and identity. To enhance training efficiency and generation quality, we further introduce a coarse-to-fine curriculum learning algorithm for multi-level token processing. In addition, we develop an enhanced predictor-free guidance to handle diverse conditioning scenarios, enabling multi-conditional generation and disentangling complex attributes effectively. Extensive experimental results demonstrate that DEmoFace generates more natural and consistent speech compared to baselines, even surpassing speech-driven methods. Demos are shown at https://demoface-ai.github.io/.",
        "tags": [
            "DiT",
            "Diffusion",
            "Diffusion Transformer",
            "Transformer"
        ]
    },
    {
        "id": "189",
        "title": "Diffusion Model as a Noise-Aware Latent Reward Model for Step-Level Preference Optimization",
        "author": [
            "Tao Zhang",
            "Cheng Da",
            "Kun Ding",
            "Kun Jin",
            "Yan Li",
            "Tingting Gao",
            "Di Zhang",
            "Shiming Xiang",
            "Chunhong Pan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01051",
        "abstract": "Preference optimization for diffusion models aims to align them with human preferences for images. Previous methods typically leverage Vision-Language Models (VLMs) as pixel-level reward models to approximate human preferences. However, when used for step-level preference optimization, these models face challenges in handling noisy images of different timesteps and require complex transformations into pixel space. In this work, we demonstrate that diffusion models are inherently well-suited for step-level reward modeling in the latent space, as they can naturally extract features from noisy latent images. Accordingly, we propose the Latent Reward Model (LRM), which repurposes components of diffusion models to predict preferences of latent images at various timesteps. Building on LRM, we introduce Latent Preference Optimization (LPO), a method designed for step-level preference optimization directly in the latent space. Experimental results indicate that LPO not only significantly enhances performance in aligning diffusion models with general, aesthetic, and text-image alignment preferences, but also achieves 2.5-28$\\times$ training speedup compared to existing preference optimization methods. Our code will be available at https://github.com/casiatao/LPO.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "190",
        "title": "Knowledge Synthesis of Photosynthesis Research Using a Large Language Model",
        "author": [
            "Seungri Yoon",
            "Woosang Jeon",
            "Sanghyeok Choi",
            "Taehyeong Kim",
            "Tae In Ahn"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01059",
        "abstract": "The development of biological data analysis tools and large language models (LLMs) has opened up new possibilities for utilizing AI in plant science research, with the potential to contribute significantly to knowledge integration and research gap identification. Nonetheless, current LLMs struggle to handle complex biological data and theoretical models in photosynthesis research and often fail to provide accurate scientific contexts. Therefore, this study proposed a photosynthesis research assistant (PRAG) based on OpenAI's GPT-4o with retrieval-augmented generation (RAG) techniques and prompt optimization. Vector databases and an automated feedback loop were used in the prompt optimization process to enhance the accuracy and relevance of the responses to photosynthesis-related queries. PRAG showed an average improvement of 8.7% across five metrics related to scientific writing, with a 25.4% increase in source transparency. Additionally, its scientific depth and domain coverage were comparable to those of photosynthesis research papers. A knowledge graph was used to structure PRAG's responses with papers within and outside the database, which allowed PRAG to match key entities with 63% and 39.5% of the database and test papers, respectively. PRAG can be applied for photosynthesis research and broader plant science domains, paving the way for more in-depth data analysis and predictive capabilities.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "191",
        "title": "OmniHuman-1: Rethinking the Scaling-Up of One-Stage Conditioned Human Animation Models",
        "author": [
            "Gaojie Lin",
            "Jianwen Jiang",
            "Jiaqi Yang",
            "Zerong Zheng",
            "Chao Liang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01061",
        "abstract": "End-to-end human animation, such as audio-driven talking human generation, has undergone notable advancements in the recent few years. However, existing methods still struggle to scale up as large general video generation models, limiting their potential in real applications. In this paper, we propose OmniHuman, a Diffusion Transformer-based framework that scales up data by mixing motion-related conditions into the training phase. To this end, we introduce two training principles for these mixed conditions, along with the corresponding model architecture and inference strategy. These designs enable OmniHuman to fully leverage data-driven motion generation, ultimately achieving highly realistic human video generation. More importantly, OmniHuman supports various portrait contents (face close-up, portrait, half-body, full-body), supports both talking and singing, handles human-object interactions and challenging body poses, and accommodates different image styles. Compared to existing end-to-end audio-driven methods, OmniHuman not only produces more realistic videos, but also offers greater flexibility in inputs. It also supports multiple driving modalities (audio-driven, video-driven and combined driving signals). Video samples are provided on the ttfamily project page (https://omnihuman-lab.github.io)",
        "tags": [
            "Diffusion",
            "Diffusion Transformer",
            "Transformer",
            "Video Generation"
        ]
    },
    {
        "id": "192",
        "title": "FastKV: KV Cache Compression for Fast Long-Context Processing with Token-Selective Propagation",
        "author": [
            "Dongwon Jo",
            "Jiwon Song",
            "Yulhwa Kim",
            "Jae-Joon Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01068",
        "abstract": "While large language models (LLMs) excel at handling long-context sequences, they require substantial key-value (KV) caches to store contextual information, which can heavily burden computational efficiency and memory usage. Previous efforts to compress these KV caches primarily focused on reducing memory demands but were limited in enhancing latency. To address this issue, we introduce FastKV, a KV cache compression method designed to enhance latency for long-context sequences. To enhance processing speeds while maintaining accuracy, FastKV adopts a novel Token-Selective Propagation (TSP) approach that retains the full context information in the initial layers of LLMs and selectively propagates only a portion of this information in deeper layers even in the prefill stage. Additionally, FastKV incorporates grouped-query attention (GQA)-aware KV cache compression to exploit the advantages of GQA in both memory and computational efficiency. Our experimental results show that FastKV achieves 2.00$\\times$ and 1.40$\\times$ improvements in time-to-first-token (TTFT) and throughput, respectively, compared to HeadKV, the state-of-the-art KV cache compression method. Moreover, FastKV successfully maintains accuracy on long-context benchmarks at levels comparable to the baselines. Our code is available at https://github.com/dongwonjo/FastKV.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "193",
        "title": "BC-GAN: A Generative Adversarial Network for Synthesizing a Batch of Collocated Clothing",
        "author": [
            "Dongliang Zhou",
            "Haijun Zhang",
            "Jianghong Ma",
            "Jianyang Shi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01080",
        "abstract": "Collocated clothing synthesis using generative networks has become an emerging topic in the field of fashion intelligence, as it has significant potential economic value to increase revenue in the fashion industry. In previous studies, several works have attempted to synthesize visually-collocated clothing based on a given clothing item using generative adversarial networks (GANs) with promising results. These works, however, can only accomplish the synthesis of one collocated clothing item each time. Nevertheless, users may require different clothing items to meet their multiple choices due to their personal tastes and different dressing scenarios. To address this limitation, we introduce a novel batch clothing generation framework, named BC-GAN, which is able to synthesize multiple visually-collocated clothing images simultaneously. In particular, to further improve the fashion compatibility of synthetic results, BC-GAN proposes a new fashion compatibility discriminator in a contrastive learning perspective by fully exploiting the collocation relationship among all clothing items. Our model was examined in a large-scale dataset with compatible outfits constructed by ourselves. Extensive experiment results confirmed the effectiveness of our proposed BC-GAN in comparison to state-of-the-art methods in terms of diversity, visual authenticity, and fashion compatibility.",
        "tags": [
            "GAN"
        ]
    },
    {
        "id": "194",
        "title": "The Jumping Reasoning Curve? Tracking the Evolution of Reasoning Performance in GPT-[n] and o-[n] Models on Multimodal Puzzles",
        "author": [
            "Vernon Y.H. Toh",
            "Yew Ken Chia",
            "Deepanway Ghosal",
            "Soujanya Poria"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01081",
        "abstract": "The releases of OpenAI's o1 and o3 mark a significant paradigm shift in Large Language Models towards advanced reasoning capabilities. Notably, o3 outperformed humans in novel problem-solving and skill acquisition on the Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI). However, this benchmark is limited to symbolic patterns, whereas humans often perceive and reason about multimodal scenarios involving both vision and language data. Thus, there is an urgent need to investigate advanced reasoning capabilities in multimodal tasks. To this end, we track the evolution of the GPT-[n] and o-[n] series models on challenging multimodal puzzles, requiring fine-grained visual perception with abstract or algorithmic reasoning. The superior performance of o1 comes at nearly 750 times the computational cost of GPT-4o, raising concerns about its efficiency. Our results reveal a clear upward trend in reasoning capabilities across model iterations, with notable performance jumps across GPT-series models and subsequently to o1. Nonetheless, we observe that the o1 model still struggles with simple multimodal puzzles requiring abstract reasoning. Furthermore, its performance in algorithmic puzzles remains poor. We plan to continuously track new models in the series and update our results in this paper accordingly. All resources used in this evaluation are openly available https://github.com/declare-lab/LLM-PuzzleTest.",
        "tags": [
            "GPT",
            "Large Language Models"
        ]
    },
    {
        "id": "195",
        "title": "Tool Unlearning for Tool-Augmented LLMs",
        "author": [
            "Jiali Cheng",
            "Hadi Amiri"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01083",
        "abstract": "Tool-augmented large language models (LLMs) are often trained on datasets of query-response pairs, which embed the ability to use tools or APIs directly into the parametric knowledge of LLMs. Tool-augmented LLMs need the ability to forget learned tools due to security vulnerabilities, privacy regulations, or tool deprecations. However, ``tool unlearning'' has not been investigated in unlearning literature. We introduce this novel task, which requires addressing distinct challenges compared to traditional unlearning: knowledge removal rather than forgetting individual samples, the high cost of optimizing LLMs, and the need for principled evaluation metrics. To bridge these gaps, we propose ToolDelete, the first approach for unlearning tools from tool-augmented LLMs. It implements three key properties to address the above challenges for effective tool unlearning and introduces a new membership inference attack (MIA) model for effective evaluation. Extensive experiments on multiple tool learning datasets and tool-augmented LLMs show that ToolDelete effectively unlearns randomly selected tools, while preserving the LLM's knowledge on non-deleted tools and maintaining performance on general tasks.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "196",
        "title": "Continuous Autoregressive Modeling with Stochastic Monotonic Alignment for Speech Synthesis",
        "author": [
            "Weiwei Lin",
            "Chenghan He"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01084",
        "abstract": "We propose a novel autoregressive modeling approach for speech synthesis, combining a variational autoencoder (VAE) with a multi-modal latent space and an autoregressive model that uses Gaussian Mixture Models (GMM) as the conditional probability distribution. Unlike previous methods that rely on residual vector quantization, our model leverages continuous speech representations from the VAE's latent space, greatly simplifying the training and inference pipelines. We also introduce a stochastic monotonic alignment mechanism to enforce strict monotonic alignments. Our approach significantly outperforms the state-of-the-art autoregressive model VALL-E in both subjective and objective evaluations, achieving these results with only 10.3\\% of VALL-E's parameters. This demonstrates the potential of continuous speech language models as a more efficient alternative to existing quantization-based speech language models. Sample audio can be found at https://tinyurl.com/gmm-lm-tts.",
        "tags": [
            "VAE",
            "Vector Quantization"
        ]
    },
    {
        "id": "197",
        "title": "Federated Linear Dueling Bandits",
        "author": [
            "Xuhan Huang",
            "Yan Hu",
            "Zhiyan Li",
            "Zhiyong Wang",
            "Benyou Wang",
            "Zhongxiang Dai"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01085",
        "abstract": "Contextual linear dueling bandits have recently garnered significant attention due to their widespread applications in important domains such as recommender systems and large language models. Classical dueling bandit algorithms are typically only applicable to a single agent. However, many applications of dueling bandits involve multiple agents who wish to collaborate for improved performance yet are unwilling to share their data. This motivates us to draw inspirations from federated learning, which involves multiple agents aiming to collaboratively train their neural networks via gradient descent (GD) without sharing their raw data. Previous works have developed federated linear bandit algorithms which rely on closed-form updates of the bandit parameters (e.g., the linear function parameter) to achieve collaboration. However, in linear dueling bandits, the linear function parameter lacks a closed-form expression and its estimation requires minimizing a loss function. This renders these previous methods inapplicable. In this work, we overcome this challenge through an innovative and principled combination of online gradient descent (for minimizing the loss function to estimate the linear function parameters) and federated learning, hence introducing the first federated linear dueling bandit algorithms. Through rigorous theoretical analysis, we prove that our algorithms enjoy a sub-linear upper bound on its cumulative regret. We also use empirical experiments to demonstrate the effectiveness of our algorithms and the practical benefit of collaboration.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "198",
        "title": "Classic4Children: Adapting Chinese Literary Classics for Children with Large Language Model",
        "author": [
            "Jiali Chen",
            "Xusen Hei",
            "Yuqi Xue",
            "Zihan Wu",
            "Jiayuan Xie",
            "Yi Cai"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01090",
        "abstract": "Chinese literary classics hold significant cultural and educational value, offering deep insights into morality, history, and human nature. These works often include classical Chinese and complex narratives, making them difficult for children to read. To bridge this gap, we introduce a child-friendly literary adaptation (CLA) task to adapt the Chinese literary classic into engaging and accessible text for children. However, recent large language models (LLMs) overlook children's reading preferences (\\ie, vivid character portrayals, concise narrative structures, and appropriate readability), which poses challenges in CLA. In this paper, we propose a method called InstructChild, which augments the LLM with these preferences for adaptation. Specifically, we first obtain the characters' personalities and narrative structure as additional information for fine-grained instruction tuning. Then, we devise a readability metric as the reward to align the LLM with the children's reading level. Finally, a lookahead decoding strategy is applied to improve the readability of the generated text during inference. To support the evaluation of CLA task, we construct the Classic4Children dataset, which comprises both the original and child-friendly versions of the Four Great Classical Novels of Chinese literature. Experimental results show that our InstructChild significantly improves automatic and human evaluation performance.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "199",
        "title": "Enhancing Feature Tracking Reliability for Visual Navigation using Real-Time Safety Filter",
        "author": [
            "Dabin Kim",
            "Inkyu Jang",
            "Youngsoo Han",
            "Sunwoo Hwang",
            "H. Jin Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01092",
        "abstract": "Vision sensors are extensively used for localizing a robot's pose, particularly in environments where global localization tools such as GPS or motion capture systems are unavailable. In many visual navigation systems, localization is achieved by detecting and tracking visual features or landmarks, which provide information about the sensor's relative pose. For reliable feature tracking and accurate pose estimation, it is crucial to maintain visibility of a sufficient number of features. This requirement can sometimes conflict with the robot's overall task objective. In this paper, we approach it as a constrained control problem. By leveraging the invariance properties of visibility constraints within the robot's kinematic model, we propose a real-time safety filter based on quadratic programming. This filter takes a reference velocity command as input and produces a modified velocity that minimally deviates from the reference while ensuring the information score from the currently visible features remains above a user-specified threshold. Numerical simulations demonstrate that the proposed safety filter preserves the invariance condition and ensures the visibility of more features than the required minimum. We also validated its real-world performance by integrating it into a visual simultaneous localization and mapping (SLAM) algorithm, where it maintained high estimation quality in challenging environments, outperforming a simple tracking controller.",
        "tags": [
            "Pose Estimation",
            "Robot",
            "SLAM"
        ]
    },
    {
        "id": "200",
        "title": "ZebraLogic: On the Scaling Limits of LLMs for Logical Reasoning",
        "author": [
            "Bill Yuchen Lin",
            "Ronan Le Bras",
            "Kyle Richardson",
            "Ashish Sabharwal",
            "Radha Poovendran",
            "Peter Clark",
            "Yejin Choi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01100",
        "abstract": "We investigate the logical reasoning capabilities of large language models (LLMs) and their scalability in complex non-monotonic reasoning. To this end, we introduce ZebraLogic, a comprehensive evaluation framework for assessing LLM reasoning performance on logic grid puzzles derived from constraint satisfaction problems (CSPs). ZebraLogic enables the generation of puzzles with controllable and quantifiable complexity, facilitating a systematic study of the scaling limits of models such as Llama, o1 models, and DeepSeek-R1. By encompassing a broad range of search space complexities and diverse logical constraints, ZebraLogic provides a structured environment to evaluate reasoning under increasing difficulty.\nOur results reveal a significant decline in accuracy as problem complexity grows -- a phenomenon we term the curse of complexity. This limitation persists even with larger models and increased inference-time computation, suggesting inherent constraints in current LLM reasoning capabilities. Additionally, we explore strategies to enhance logical reasoning, including Best-of-N sampling, backtracking mechanisms, and self-verification prompts. Our findings offer critical insights into the scalability of LLM reasoning, highlight fundamental limitations, and outline potential directions for improvement.",
        "tags": [
            "DeepSeek",
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "201",
        "title": "VidSketch: Hand-drawn Sketch-Driven Video Generation with Diffusion Control",
        "author": [
            "Lifan Jiang",
            "Shuang Chen",
            "Boxi Wu",
            "Xiaotong Guan",
            "Jiahui Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01101",
        "abstract": "With the advancement of generative artificial intelligence, previous studies have achieved the task of generating aesthetic images from hand-drawn sketches, fulfilling the public's needs for drawing. However, these methods are limited to static images and lack the ability to control video animation generation using hand-drawn sketches. To address this gap, we propose VidSketch, the first method capable of generating high-quality video animations directly from any number of hand-drawn sketches and simple text prompts, bridging the divide between ordinary users and professional artists. Specifically, our method introduces a Level-Based Sketch Control Strategy to automatically adjust the guidance strength of sketches during the generation process, accommodating users with varying drawing skills. Furthermore, a TempSpatial Attention mechanism is designed to enhance the spatiotemporal consistency of generated video animations, significantly improving the coherence across frames. You can find more detailed cases on our official website.",
        "tags": [
            "Diffusion",
            "Video Generation"
        ]
    },
    {
        "id": "202",
        "title": "LayerTracer: Cognitive-Aligned Layered SVG Synthesis via Diffusion Transformer",
        "author": [
            "Yiren Song",
            "Danze Chen",
            "Mike Zheng Shou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01105",
        "abstract": "Generating cognitive-aligned layered SVGs remains challenging due to existing methods' tendencies toward either oversimplified single-layer outputs or optimization-induced shape redundancies. We propose LayerTracer, a diffusion transformer based framework that bridges this gap by learning designers' layered SVG creation processes from a novel dataset of sequential design operations. Our approach operates in two phases: First, a text-conditioned DiT generates multi-phase rasterized construction blueprints that simulate human design workflows. Second, layer-wise vectorization with path deduplication produces clean, editable SVGs. For image vectorization, we introduce a conditional diffusion mechanism that encodes reference images into latent tokens, guiding hierarchical reconstruction while preserving structural integrity. Extensive experiments demonstrate LayerTracer's superior performance against optimization-based and neural baselines in both generation quality and editability, effectively aligning AI-generated vectors with professional design cognition.",
        "tags": [
            "DiT",
            "Diffusion",
            "Diffusion Transformer",
            "Transformer"
        ]
    },
    {
        "id": "203",
        "title": "GFM-RAG: Graph Foundation Model for Retrieval Augmented Generation",
        "author": [
            "Linhao Luo",
            "Zicheng Zhao",
            "Gholamreza Haffari",
            "Dinh Phung",
            "Chen Gong",
            "Shirui Pan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01113",
        "abstract": "Retrieval-augmented generation (RAG) has proven effective in integrating knowledge into large language models (LLMs). However, conventional RAGs struggle to capture complex relationships between pieces of knowledge, limiting their performance in intricate reasoning that requires integrating knowledge from multiple sources. Recently, graph-enhanced retrieval augmented generation (GraphRAG) builds graph structure to explicitly model these relationships, enabling more effective and efficient retrievers. Nevertheless, its performance is still hindered by the noise and incompleteness within the graph structure. To address this, we introduce GFM-RAG, a novel graph foundation model (GFM) for retrieval augmented generation. GFM-RAG is powered by an innovative graph neural network that reasons over graph structure to capture complex query-knowledge relationships. The GFM with 8M parameters undergoes a two-stage training process on large-scale datasets, comprising 60 knowledge graphs with over 14M triples and 700k documents. This results in impressive performance and generalizability for GFM-RAG, making it the first graph foundation model applicable to unseen datasets for retrieval without any fine-tuning required. Extensive experiments on three multi-hop QA datasets and seven domain-specific RAG datasets demonstrate that GFM-RAG achieves state-of-the-art performance while maintaining efficiency and alignment with neural scaling laws, highlighting its potential for further improvement.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "204",
        "title": "Picky LLMs and Unreliable RMs: An Empirical Study on Safety Alignment after Instruction Tuning",
        "author": [
            "Guanlin Li",
            "Kangjie Chen",
            "Shangwei Guo",
            "Jie Zhang",
            "Han Qiu",
            "Chao Zhang",
            "Guoyin Wang",
            "Tianwei Zhang",
            "Jiwei Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01116",
        "abstract": "Large language models (LLMs) have emerged as powerful tools for addressing a wide range of general inquiries and tasks. Despite this, fine-tuning aligned LLMs on smaller, domain-specific datasets, critical to adapting them to specialized tasks, can inadvertently degrade their safety alignment, even when the datasets are benign. This phenomenon makes models more susceptible to providing inappropriate responses. In this study, we systematically examine the factors contributing to safety alignment degradation in benign fine-tuning scenarios. Our analysis identifies three critical factors affecting aligned LLMs: answer structure, identity calibration, and role-play. Additionally, we evaluate the reliability of state-of-the-art reward models (RMs), which are often used to guide alignment processes. Our findings reveal that these RMs frequently fail to accurately reflect human preferences regarding safety, underscoring their limitations in practical applications. By uncovering these challenges, our work highlights the complexities of maintaining safety alignment during fine-tuning and offers guidance to help developers balance utility and safety in LLMs. Datasets and fine-tuning code used in our experiments can be found in https://github.com/GuanlinLee/llm_instruction_tuning.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "205",
        "title": "Learning to Learn Weight Generation via Trajectory Diffusion",
        "author": [
            "Yunchuan Guan",
            "Yu Liu",
            "Ke Zhou",
            "Zhiqi Shen",
            "Serge Belongie",
            "Jenq-Neng Hwang",
            "Lei Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01117",
        "abstract": "Diffusion-based algorithms have emerged as promising techniques for weight generation, particularly in scenarios like multi-task learning that require frequent weight updates. However, existing solutions suffer from limited cross-task transferability. In addition, they only utilize optimal weights as training samples, ignoring the value of other weights in the optimization process. To address these issues, we propose Lt-Di, which integrates the diffusion algorithm with meta-learning to generate weights for unseen tasks. Furthermore, we extend the vanilla diffusion algorithm into a trajectory diffusion algorithm to utilize other weights along the optimization trajectory. Trajectory diffusion decomposes the entire diffusion chain into multiple shorter ones, improving training and inference efficiency. We analyze the convergence properties of the weight generation paradigm and improve convergence efficiency without additional time overhead. Our experiments demonstrate Lt-Di's higher accuracy while reducing computational overhead across various tasks, including zero-shot and few-shot learning, multi-domain generalization, and large-scale language model http://fine-tuning.Our code is released at https://github.com/tuantuange/Lt-Di.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "206",
        "title": "Large Language Model-Enhanced Multi-Armed Bandits",
        "author": [
            "Jiahang Sun",
            "Zhiyong Wang",
            "Runhan Yang",
            "Chenjun Xiao",
            "John C.S. Lui",
            "Zhongxiang Dai"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01118",
        "abstract": "Large language models (LLMs) have been adopted to solve sequential decision-making tasks such as multi-armed bandits (MAB), in which an LLM is directly instructed to select the arms to pull in every iteration. However, this paradigm of direct arm selection using LLMs has been shown to be suboptimal in many MAB tasks. Therefore, we propose an alternative approach which combines the strengths of classical MAB and LLMs. Specifically, we adopt a classical MAB algorithm as the high-level framework and leverage the strong in-context learning capability of LLMs to perform the sub-task of reward prediction. Firstly, we incorporate the LLM-based reward predictor into the classical Thompson sampling (TS) algorithm and adopt a decaying schedule for the LLM temperature to ensure a transition from exploration to exploitation. Next, we incorporate the LLM-based reward predictor (with a temperature of 0) into a regression oracle-based MAB algorithm equipped with an explicit exploration mechanism. We also extend our TS-based algorithm to dueling bandits where only the preference feedback between pairs of arms is available, which requires non-trivial algorithmic modifications. We conduct empirical evaluations using both synthetic MAB tasks and experiments designed using real-world text datasets, in which the results show that our algorithms consistently outperform previous baseline methods based on direct arm selection. Interestingly, we also demonstrate that in challenging tasks where the arms lack semantic meanings that can be exploited by the LLM, our approach achieves considerably better performance than LLM-based direct arm selection.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "207",
        "title": "Learning Efficient Positional Encodings with Graph Neural Networks",
        "author": [
            "Charilaos I. Kanatsoulis",
            "Evelyn Choi",
            "Stephanie Jegelka",
            "Jure Leskovec",
            "Alejandro Ribeiro"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01122",
        "abstract": "Positional encodings (PEs) are essential for effective graph representation learning because they provide position awareness in inherently position-agnostic transformer architectures and increase the expressive capacity of Graph Neural Networks (GNNs). However, designing powerful and efficient PEs for graphs poses significant challenges due to the absence of canonical node ordering and the scale of the graph. {In this work, we identify four key properties that graph PEs should satisfy}: stability, expressive power, scalability, and genericness. We find that existing eigenvector-based PE methods often fall short of jointly satisfying these criteria. To address this gap, we introduce PEARL, a novel framework of learnable PEs for graphs. Our primary insight is that message-passing GNNs function as nonlinear mappings of eigenvectors, enabling the design of GNN architectures for generating powerful and efficient PEs. A crucial challenge lies in initializing node attributes in a manner that is both expressive and permutation equivariant. We tackle this by initializing GNNs with random node inputs or standard basis vectors, thereby unlocking the expressive power of message-passing operations, while employing statistical pooling functions to maintain permutation equivariance. Our analysis demonstrates that PEARL approximates equivariant functions of eigenvectors with linear complexity, while rigorously establishing its stability and high expressive power. Experimental evaluations show that PEARL outperforms lightweight versions of eigenvector-based PEs and achieves comparable performance to full eigenvector-based PEs, but with one or two orders of magnitude lower complexity. Our code is available at https://github.com/ehejin/Pearl-PE.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "208",
        "title": "Language Models Prefer What They Know: Relative Confidence Estimation via Confidence Preferences",
        "author": [
            "Vaishnavi Shrivastava",
            "Ananya Kumar",
            "Percy Liang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01126",
        "abstract": "Language models (LMs) should provide reliable confidence estimates to help users detect mistakes in their outputs and defer to human experts when necessary. Asking a language model to assess its confidence (\"Score your confidence from 0-1.\") is a natural way of evaluating its uncertainty. However, models struggle to provide absolute assessments of confidence (i.e. judging confidence in answering a question independent of other questions) and the coarse-grained scores they produce are not useful for evaluating the correctness of their answers. We propose relative confidence estimation, where we match up questions against each other and ask the model to make relative judgments of confidence (\"Which question are you more confident in answering correctly?\"). Treating each question as a \"player\" in a series of matchups against other questions and the model's preferences as match outcomes, we can use rank aggregation methods like Elo rating and Bradley-Terry to translate the model's confidence preferences into confidence scores. We evaluate relative confidence estimation against absolute confidence estimation and self-consistency confidence methods on five state-of-the-art LMs -- GPT-4, GPT-4o, Gemini 1.5 Pro, Claude 3.5 Sonnet, and Llama 3.1 405B -- across 14 challenging STEM, social science, and commonsense reasoning question answering tasks. Our results demonstrate that relative confidence estimation consistently provides more reliable confidence scores than absolute confidence estimation, with average gains of 3.5% in selective classification AUC over direct absolute confidence estimation methods and 1.7% over self-consistency approaches across all models and datasets.",
        "tags": [
            "GPT",
            "LLaMA"
        ]
    },
    {
        "id": "209",
        "title": "DeepRAG: Thinking to Retrieval Step by Step for Large Language Models",
        "author": [
            "Xinyan Guan",
            "Jiali Zeng",
            "Fandong Meng",
            "Chunlei Xin",
            "Yaojie Lu",
            "Hongyu Lin",
            "Xianpei Han",
            "Le Sun",
            "Jie Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01142",
        "abstract": "Large Language Models (LLMs) have shown remarkable potential in reasoning while they still suffer from severe factual hallucinations due to timeliness, accuracy, and coverage of parametric knowledge. Meanwhile, integrating reasoning with retrieval-augmented generation (RAG) remains challenging due to ineffective task decomposition and redundant retrieval, which can introduce noise and degrade response quality. In this paper, we propose DeepRAG, a framework that models retrieval-augmented reasoning as a Markov Decision Process (MDP), enabling strategic and adaptive retrieval. By iteratively decomposing queries, DeepRAG dynamically determines whether to retrieve external knowledge or rely on parametric reasoning at each step. Experiments show that DeepRAG improves retrieval efficiency while improving answer accuracy by 21.99%, demonstrating its effectiveness in optimizing retrieval-augmented reasoning.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "210",
        "title": "A Discontinuous Galerkin Method for H(curl)-Elliptic Hemivariational Inequalities",
        "author": [
            "Xiajie Huang",
            "Fei Wang",
            "Weimin Han",
            "Min Ling"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01148",
        "abstract": "In this paper, we develop a Discontinuous Galerkin (DG) method for solving H(curl)-elliptic hemivariational inequalities. By selecting an appropriate numerical flux, we construct an Interior Penalty Discontinuous Galerkin (IPDG) scheme. A comprehensive numerical analysis of the IPDG method is conducted, addressing key aspects such as consistency, boundedness, stability, and the existence, uniqueness, uniform boundedness of the numerical solutions. Building on these properties, we establish a priori error estimates, demonstrating the optimal convergence order of the numerical solutions under suitable solution regularity assumptions. Finally, a numerical example is presented to illustrate the theoretically predicted convergence order and to show the effectiveness of the proposed method.",
        "tags": [
            "FLUX"
        ]
    },
    {
        "id": "211",
        "title": "Jailbreaking with Universal Multi-Prompts",
        "author": [
            "Yu-Ling Hsu",
            "Hsuan Su",
            "Shang-Tse Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01154",
        "abstract": "Large language models (LLMs) have seen rapid development in recent years, revolutionizing various applications and significantly enhancing convenience and productivity. However, alongside their impressive capabilities, ethical concerns and new types of attacks, such as jailbreaking, have emerged. While most prompting techniques focus on optimizing adversarial inputs for individual cases, resulting in higher computational costs when dealing with large datasets. Less research has addressed the more general setting of training a universal attacker that can transfer to unseen tasks. In this paper, we introduce JUMP, a prompt-based method designed to jailbreak LLMs using universal multi-prompts. We also adapt our approach for defense, which we term DUMP. Experimental results demonstrate that our method for optimizing universal multi-prompts outperforms existing techniques.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "212",
        "title": "Radiant Foam: Real-Time Differentiable Ray Tracing",
        "author": [
            "Shrisudhan Govindarajan",
            "Daniel Rebain",
            "Kwang Moo Yi",
            "Andrea Tagliasacchi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01157",
        "abstract": "Research on differentiable scene representations is consistently moving towards more efficient, real-time models. Recently, this has led to the popularization of splatting methods, which eschew the traditional ray-based rendering of radiance fields in favor of rasterization. This has yielded a significant improvement in rendering speeds due to the efficiency of rasterization algorithms and hardware, but has come at a cost: the approximations that make rasterization efficient also make implementation of light transport phenomena like reflection and refraction much more difficult. We propose a novel scene representation which avoids these approximations, but keeps the efficiency and reconstruction quality of splatting by leveraging a decades-old efficient volumetric mesh ray tracing algorithm which has been largely overlooked in recent computer vision research. The resulting model, which we name Radiant Foam, achieves rendering speed and quality comparable to Gaussian Splatting, without the constraints of rasterization. Unlike ray traced Gaussian models that use hardware ray tracing acceleration, our method requires no special hardware or APIs beyond the standard features of a programmable GPU.",
        "tags": [
            "Gaussian Splatting"
        ]
    },
    {
        "id": "213",
        "title": "AtmosSci-Bench: Evaluating the Recent Advance of Large Language Model for Atmospheric Science",
        "author": [
            "Chenyue Li",
            "Wen Deng",
            "Mengqian Lu",
            "Binhang Yuan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01159",
        "abstract": "The rapid advancements in large language models (LLMs), particularly in their reasoning capabilities, hold transformative potential for addressing complex challenges in atmospheric science. However, leveraging LLMs effectively in this domain requires a robust and comprehensive evaluation benchmark. To address this need, we present AtmosSci-Bench, a novel benchmark designed to systematically assess LLM performance across five core categories of atmospheric science problems: hydrology, atmospheric dynamics, atmospheric physics, geophysics, and physical oceanography. We employ a template-based question generation framework, enabling scalable and diverse multiple-choice questions curated from graduate-level atmospheric science problems. We conduct a comprehensive evaluation of representative LLMs, categorized into four groups: instruction-tuned models, advanced reasoning models, math-augmented models, and domain-specific climate models. Our analysis provides some interesting insights into the reasoning and problem-solving capabilities of LLMs in atmospheric science. We believe AtmosSci-Bench can serve as a critical step toward advancing LLM applications in climate service by offering a standard and rigorous evaluation framework. Our source codes are currently available at https://github.com/Relaxed-System-Lab/AtmosSci-Bench.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "214",
        "title": "Joint Localization and Activation Editing for Low-Resource Fine-Tuning",
        "author": [
            "Wen Lai",
            "Alexander Fraser",
            "Ivan Titov"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01179",
        "abstract": "Parameter-efficient fine-tuning (PEFT) methods, such as LoRA, are commonly used to adapt LLMs. However, the effectiveness of standard PEFT methods is limited in low-resource scenarios with only a few hundred examples. Recent advances in interpretability research have inspired the emergence of activation editing techniques, which modify the activations of specific model components. These methods, due to their extremely small parameter counts, show promise for small datasets. However, their performance is highly dependent on identifying the correct modules to edit and often lacks stability across different datasets. In this paper, we propose Joint Localization and Activation Editing (JoLA), a method that jointly learns (1) which heads in the Transformer to edit (2) whether the intervention should be additive, multiplicative, or both and (3) the intervention parameters themselves - the vectors applied as additive offsets or multiplicative scalings to the head output. Through evaluations on three benchmarks spanning commonsense reasoning, natural language understanding, and natural language generation, we demonstrate that JoLA consistently outperforms existing methods.",
        "tags": [
            "LLMs",
            "LoRA",
            "Transformer"
        ]
    },
    {
        "id": "215",
        "title": "Deep Active Speech Cancellation with Multi-Band Mamba Network",
        "author": [
            "Yehuda Mishaly",
            "Lior Wolf",
            "Eliya Nachmani"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01185",
        "abstract": "We present a novel deep learning network for Active Speech Cancellation (ASC), advancing beyond Active Noise Cancellation (ANC) methods by effectively canceling both noise and speech signals. The proposed Multi-Band Mamba architecture segments input audio into distinct frequency bands, enabling precise anti-signal generation and improved phase alignment across frequencies. Additionally, we introduce an optimization-driven loss function that provides near-optimal supervisory signals for anti-signal generation. Experimental results demonstrate substantial performance gains, achieving up to 7.2dB improvement in ANC scenarios and 6.2dB in ASC, significantly outperforming existing methods. Audio samples are available at https://mishalydev.github.io/DeepASC-Demo",
        "tags": [
            "Mamba"
        ]
    },
    {
        "id": "216",
        "title": "Skewed Memorization in Large Language Models: Quantification and Decomposition",
        "author": [
            "Hao Li",
            "Di Huang",
            "Ziyu Wang",
            "Amir M. Rahmani"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01187",
        "abstract": "Memorization in Large Language Models (LLMs) poses privacy and security risks, as models may unintentionally reproduce sensitive or copyrighted data. Existing analyses focus on average-case scenarios, often neglecting the highly skewed distribution of memorization. This paper examines memorization in LLM supervised fine-tuning (SFT), exploring its relationships with training duration, dataset size, and inter-sample similarity. By analyzing memorization probabilities over sequence lengths, we link this skewness to the token generation process, offering insights for estimating memorization and comparing it to established metrics. Through theoretical analysis and empirical evaluation, we provide a comprehensive understanding of memorization behaviors and propose strategies to detect and mitigate risks, contributing to more privacy-preserving LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "217",
        "title": "Dance recalibration for dance coherency with recurrent convolution block",
        "author": [
            "Seungho Eum",
            "Ihjoon Cho",
            "Junghyeon Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01190",
        "abstract": "With the recent advancements in generative AI such as GAN, Diffusion, and VAE, the use of generative AI for dance generation has seen significant progress and received considerable interest. In this study, We propose R-Lodge, an enhanced version of Lodge. R-Lodge incorporates Recurrent Sequential Representation Learning named Dance Recalibration to original coarse-to-fine long dance generation model. R-Lodge utilizes Dance Recalibration method using $N$ Dance Recalibration Block to address the lack of consistency in the coarse dance representation of the Lodge model. By utilizing this method, each generated dance motion incorporates a bit of information from the previous dance motions. We evaluate R-Lodge on FineDance dataset and the results show that R-Lodge enhances the consistency of the whole generated dance motions.",
        "tags": [
            "Diffusion",
            "GAN",
            "VAE"
        ]
    },
    {
        "id": "218",
        "title": "Nearly Lossless Adaptive Bit Switching",
        "author": [
            "Haiduo Huang",
            "Zhenhua Liu",
            "Tian Xia",
            "Wenzhe zhao",
            "Pengju Ren"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01199",
        "abstract": "Model quantization is widely applied for compressing and accelerating deep neural networks (DNNs). However, conventional Quantization-Aware Training (QAT) focuses on training DNNs with uniform bit-width. The bit-width settings vary across different hardware and transmission demands, which induces considerable training and storage costs. Hence, the scheme of one-shot joint training multiple precisions is proposed to address this issue. Previous works either store a larger FP32 model to switch between different precision models for higher accuracy or store a smaller INT8 model but compromise accuracy due to using shared quantization parameters. In this paper, we introduce the Double Rounding quantization method, which fully utilizes the quantized representation range to accomplish nearly lossless bit-switching while reducing storage by using the highest integer precision instead of full precision. Furthermore, we observe a competitive interference among different precisions during one-shot joint training, primarily due to inconsistent gradients of quantization scales during backward propagation. To tackle this problem, we propose an Adaptive Learning Rate Scaling (ALRS) technique that dynamically adapts learning rates for various precisions to optimize the training process. Additionally, we extend our Double Rounding to one-shot mixed precision training and develop a Hessian-Aware Stochastic Bit-switching (HASB) strategy. Experimental results on the ImageNet-1K classification demonstrate that our methods have enough advantages to state-of-the-art one-shot joint QAT in both multi-precision and mixed-precision. We also validate the feasibility of our method on detection and segmentation tasks, as well as on LLMs task. Our codes are available at https://github.com/haiduo/Double-Rounding.",
        "tags": [
            "Detection",
            "LLMs",
            "Segmentation"
        ]
    },
    {
        "id": "219",
        "title": "Theoretical Analysis of KL-regularized RLHF with Multiple Reference Models",
        "author": [
            "Gholamali Aminian",
            "Amir R. Asadi",
            "Idan Shenfeld",
            "Youssef Mroueh"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01203",
        "abstract": "Recent methods for aligning large language models (LLMs) with human feedback predominantly rely on a single reference model, which limits diversity, model overfitting, and underutilizes the wide range of available pre-trained models. Incorporating multiple reference models has the potential to address these limitations by broadening perspectives, reducing bias, and leveraging the strengths of diverse open-source LLMs. However, integrating multiple reference models into reinforcement learning with human feedback (RLHF) frameworks poses significant theoretical challenges, particularly in reverse KL-regularization, where achieving exact solutions has remained an open problem. This paper presents the first \\emph{exact solution} to the multiple reference model problem in reverse KL-regularized RLHF. We introduce a comprehensive theoretical framework that includes rigorous statistical analysis and provides sample complexity guarantees. Additionally, we extend our analysis to forward KL-regularized RLHF, offering new insights into sample complexity requirements in multiple reference scenarios. Our contributions lay the foundation for more advanced and adaptable LLM alignment techniques, enabling the effective use of multiple reference models. This work paves the way for developing alignment frameworks that are both theoretically sound and better suited to the challenges of modern AI ecosystems.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "220",
        "title": "OCR Error Post-Correction with LLMs in Historical Documents: No Free Lunches",
        "author": [
            "Jenna Kanerva",
            "Cassandra Ledins",
            "Siiri KÃ¤pyaho",
            "Filip Ginter"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01205",
        "abstract": "Optical Character Recognition (OCR) systems often introduce errors when transcribing historical documents, leaving room for post-correction to improve text quality. This study evaluates the use of open-weight LLMs for OCR error correction in historical English and Finnish datasets. We explore various strategies, including parameter optimization, quantization, segment length effects, and text continuation methods. Our results demonstrate that while modern LLMs show promise in reducing character error rates (CER) in English, a practically useful performance for Finnish was not reached. Our findings highlight the potential and limitations of LLMs in scaling OCR post-correction for large historical corpora.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "221",
        "title": "Almost Surely Safe Alignment of Large Language Models at Inference-Time",
        "author": [
            "Xiaotong Ji",
            "Shyam Sundhar Ramesh",
            "Matthieu Zimmer",
            "Ilija Bogunovic",
            "Jun Wang",
            "Haitham Bou Ammar"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01208",
        "abstract": "Even highly capable large language models (LLMs) can produce biased or unsafe responses, and alignment techniques, such as RLHF, aimed at mitigating this issue, are expensive and prone to overfitting as they retrain the LLM. This paper introduces a novel inference-time alignment approach that ensures LLMs generate safe responses almost surely, i.e., with a probability approaching one. We achieve this by framing the safe generation of inference-time responses as a constrained Markov decision process within the LLM's latent space. Crucially, we augment a safety state that tracks the evolution of safety constraints and enables us to demonstrate formal safety guarantees upon solving the MDP in the latent space. Building on this foundation, we propose InferenceGuard, a practical implementation that safely aligns LLMs without modifying the model weights. Empirically, we demonstrate InferenceGuard effectively balances safety and task performance, outperforming existing inference-time alignment methods in generating safe and aligned responses.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "222",
        "title": "Exploring Few-Shot Defect Segmentation in General Industrial Scenarios with Metric Learning and Vision Foundation Models",
        "author": [
            "Tongkun Liu",
            "Bing Li",
            "Xiao Jin",
            "Yupeng Shi",
            "Qiuying Li",
            "Xiang Wei"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01216",
        "abstract": "Industrial defect segmentation is critical for manufacturing quality control. Due to the scarcity of training defect samples, few-shot semantic segmentation (FSS) holds significant value in this field. However, existing studies mostly apply FSS to tackle defects on simple textures, without considering more diverse scenarios. This paper aims to address this gap by exploring FSS in broader industrial products with various defect types. To this end, we contribute a new real-world dataset and reorganize some existing datasets to build a more comprehensive few-shot defect segmentation (FDS) benchmark. On this benchmark, we thoroughly investigate metric learning-based FSS methods, including those based on meta-learning and those based on Vision Foundation Models (VFMs). We observe that existing meta-learning-based methods are generally not well-suited for this task, while VFMs hold great potential. We further systematically study the applicability of various VFMs in this task, involving two paradigms: feature matching and the use of Segment Anything (SAM) models. We propose a novel efficient FDS method based on feature matching. Meanwhile, we find that SAM2 is particularly effective for addressing FDS through its video track mode. The contributed dataset and code will be available at: https://github.com/liutongkun/GFDS.",
        "tags": [
            "SAM",
            "Segment Anything",
            "Segmentation"
        ]
    },
    {
        "id": "223",
        "title": "On the Robustness of Temporal Factual Knowledge in Language Models",
        "author": [
            "Hichem Ammar Khodja",
            "FrÃ©dÃ©ric BÃ©chet",
            "Quentin Brabant",
            "Alexis Nasr",
            "GwÃ©nolÃ© LecorvÃ©"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01220",
        "abstract": "This paper explores the temporal robustness of language models (LMs) in handling factual knowledge. While LMs can often complete simple factual statements, their ability to manage temporal facts (those valid only within specific timeframes) remains uncertain. We design a controlled experiment to test the robustness of temporal factual knowledge inside LMs, which we use to evaluate several pretrained and instruction-tuned models using prompts on popular Wikidata facts, assessing their performance across different temporal granularities (Day, Month, and Year). Our findings indicate that even very large state-of-the-art models, such as Llama-3.1-70B, vastly lack robust knowledge of temporal facts. In addition, they are incapable of generalizing their knowledge from one granularity to another. These results highlight the inherent limitations of using LMs as temporal knowledge bases. The source code and data to reproduce our experiments will be released.",
        "tags": [
            "LLaMA"
        ]
    },
    {
        "id": "224",
        "title": "The dark deep side of DeepSeek: Fine-tuning attacks against the safety alignment of CoT-enabled models",
        "author": [
            "Zhiyuan Xu",
            "Joseph Gardiner",
            "Sana Belguith"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01225",
        "abstract": "Large language models are typically trained on vast amounts of data during the pre-training phase, which may include some potentially harmful information. Fine-tuning attacks can exploit this by prompting the model to reveal such behaviours, leading to the generation of harmful content. In this paper, we focus on investigating the performance of the Chain of Thought based reasoning model, DeepSeek, when subjected to fine-tuning attacks. Specifically, we explore how fine-tuning manipulates the model's output, exacerbating the harmfulness of its responses while examining the interaction between the Chain of Thought reasoning and adversarial inputs. Through this study, we aim to shed light on the vulnerability of Chain of Thought enabled models to fine-tuning attacks and the implications for their safety and ethical deployment.",
        "tags": [
            "DeepSeek",
            "Large Language Models"
        ]
    },
    {
        "id": "225",
        "title": "How Good are Learned Cost Models, Really? Insights from Query Optimization Tasks",
        "author": [
            "Roman Heinrich",
            "Manisha Luthra",
            "Johannes Wehrstein",
            "Harald Kornmayer",
            "Carsten Binnig"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01229",
        "abstract": "Traditionally, query optimizers rely on cost models to choose the best execution plan from several candidates, making precise cost estimates critical for efficient query execution. In recent years, cost models based on machine learning have been proposed to overcome the weaknesses of traditional cost models. While these models have been shown to provide better prediction accuracy, only limited efforts have been made to investigate how well Learned Cost Models (LCMs) actually perform in query optimization and how they affect overall query performance. In this paper, we address this by a systematic study evaluating LCMs on three of the core query optimization tasks: join ordering, access path selection, and physical operator selection. In our study, we compare seven state-of-the-art LCMs to a traditional cost model and, surprisingly, find that the traditional model often still outperforms LCMs in these tasks. We conclude by highlighting major takeaways and recommendations to guide future research toward making LCMs more effective for query optimization.",
        "tags": [
            "LCMs"
        ]
    },
    {
        "id": "226",
        "title": "Peering Behind the Shield: Guardrail Identification in Large Language Models",
        "author": [
            "Ziqing Yang",
            "Yixin Wu",
            "Rui Wen",
            "Michael Backes",
            "Yang Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01241",
        "abstract": "Human-AI conversations have gained increasing attention since the era of large language models. Consequently, more techniques, such as input/output guardrails and safety alignment, are proposed to prevent potential misuse of such Human-AI conversations. However, the ability to identify these guardrails has significant implications, both for adversarial exploitation and for auditing purposes by red team operators. In this work, we propose a novel method, AP-Test, which identifies the presence of a candidate guardrail by leveraging guardrail-specific adversarial prompts to query the AI agent. Extensive experiments of four candidate guardrails under diverse scenarios showcase the effectiveness of our method. The ablation study further illustrates the importance of the components we designed, such as the loss terms.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "227",
        "title": "Learnable polynomial, trigonometric, and tropical activations",
        "author": [
            "Ismail Khalfaoui-Hassani",
            "Stefan Kesselheim"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01247",
        "abstract": "This paper investigates scalable neural networks with learnable activation functions based on orthogonal function bases and tropical polynomials, targeting ImageNet-1K classification and next token prediction on OpenWebText. Traditional activations, such as ReLU, are static. In contrast, learnable activations enable the network to adapt dynamically during training. However, stability issues, such as vanishing or exploding gradients, arise with improper variance management in deeper networks. To remedy this, we propose an initialization scheme that single-handedly preserves unitary variance in transformers and convolutional networks, ensuring stable gradient flow even in deep architectures. Extensive experiments demonstrate that networks with Hermite, Fourier, and Tropical-based learnable activations significantly improve over GPT-2 and ConvNeXt networks in terms of accuracy and perplexity in train and test, highlighting the viability of learnable activations in large-scale tasks. The activation functions developed here are the subject of a library coded entirely in pure PyTorch: torchortho, available at https://github.com/K-H-Ismail/torchortho.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "228",
        "title": "Analysis of Student-LLM Interaction in a Software Engineering Project",
        "author": [
            "Agrawal Naman",
            "Ridwan Shariffdeen",
            "Guanlin Wang",
            "Sanka Rasnayaka",
            "Ganesh Neelakanta Iyer"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01273",
        "abstract": "Large Language Models (LLMs) are becoming increasingly competent across various domains, educators are showing a growing interest in integrating these LLMs into the learning process. Especially in software engineering, LLMs have demonstrated qualitatively better capabilities in code summarization, code generation, and debugging. Despite various research on LLMs for software engineering tasks in practice, limited research captures the benefits of LLMs for pedagogical advancements and their impact on the student learning process. To this extent, we analyze 126 undergraduate students' interaction with an AI assistant during a 13-week semester to understand the benefits of AI for software engineering learning. We analyze the conversations, code generated, code utilized, and the human intervention levels to integrate the code into the code base.\nOur findings suggest that students prefer ChatGPT over CoPilot. Our analysis also finds that ChatGPT generates responses with lower computational complexity compared to CoPilot. Furthermore, conversational-based interaction helps improve the quality of the code generated compared to auto-generated code. Early adoption of LLMs in software engineering is crucial to remain competitive in the rapidly developing landscape. Hence, the next generation of software engineers must acquire the necessary skills to interact with AI to improve productivity.",
        "tags": [
            "ChatGPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "229",
        "title": "Augmented Knowledge Graph Querying leveraging LLMs",
        "author": [
            "Marco Arazzi",
            "Davide Ligari",
            "Serena Nicolazzo",
            "Antonino Nocera"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01298",
        "abstract": "Adopting Knowledge Graphs (KGs) as a structured, semantic-oriented, data representation model has significantly improved data integration, reasoning, and querying capabilities across different domains. This is especially true in modern scenarios such as Industry 5.0, in which the integration of data produced by humans, smart devices, and production processes plays a crucial role. However, the management, retrieval, and visualization of data from a KG using formal query languages can be difficult for non-expert users due to their technical complexity, thus limiting their usage inside industrial environments. For this reason, we introduce SparqLLM, a framework that utilizes a Retrieval-Augmented Generation (RAG) solution, to enhance the querying of Knowledge Graphs (KGs). SparqLLM executes the Extract, Transform, and Load (ETL) pipeline to construct KGs from raw data. It also features a natural language interface powered by Large Language Models (LLMs) to enable automatic SPARQL query generation. By integrating template-based methods as retrieved-context for the LLM, SparqLLM enhances query reliability and reduces semantic errors, ensuring more accurate and efficient KG interactions. Moreover, to improve usability, the system incorporates a dynamic visualization dashboard that adapts to the structure of the retrieved data, presenting the query results in an intuitive format. Rigorous experimental evaluations demonstrate that SparqLLM achieves high query accuracy, improved robustness, and user-friendly interaction with KGs, establishing it as a scalable solution to access semantic data.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "230",
        "title": "Heterogeneous Image GNN: Graph-Conditioned Diffusion for Image Synthesis",
        "author": [
            "Rupert Menneer",
            "Christos Margadji",
            "Sebastian W. Pattinson"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01309",
        "abstract": "We introduce a novel method for conditioning diffusion-based image synthesis models with heterogeneous graph data. Existing approaches typically incorporate conditioning variables directly into model architectures, either through cross-attention layers that attend to text latents or image concatenation that spatially restrict generation. However, these methods struggle to handle complex scenarios involving diverse, relational conditioning variables, which are more naturally represented as unstructured graphs. This paper presents Heterogeneous Image Graphs (HIG), a novel representation that models conditioning variables and target images as two interconnected graphs, enabling efficient handling of variable-length conditioning inputs and their relationships. We also propose a magnitude-preserving GNN that integrates the HIG into the existing EDM2 diffusion model using a ControlNet approach. Our approach improves upon the SOTA on a variety of conditioning inputs for the COCO-stuff and Visual Genome datasets, and showcases the ability to condition on graph attributes and relationships represented by edges in the HIG.",
        "tags": [
            "ControlNet",
            "Diffusion"
        ]
    },
    {
        "id": "231",
        "title": "The Homework Wars: Exploring Emotions, Behaviours, and Conflicts in Parent-Child Homework Interactions",
        "author": [
            "Nan Gao",
            "Yibin Liu",
            "Xin Tang",
            "Yanyan Liu",
            "Chun Yu",
            "Yun Huang",
            "Yuntao Wang",
            "Flora D. Salim",
            "Xuhai Orson Xu",
            "Jun Wei",
            "Yuanchun Shi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01325",
        "abstract": "Parental involvement in homework is a crucial aspect of family education, but it often leads to emotional strain and conflicts that can severely impact family well-being. This paper presents findings from a 4-week in situ study involving 78 families in China, where we collected and analyzed 602 valid audio recordings (totalling 475 hours) and daily surveys. Leveraging large language models (LLMs) to analyze parent-child conversations, we gained a nuanced understanding of emotional and behavioural dynamics that overcomes the limitations of traditional one-time surveys and interviews. Our findings reveal significant emotional shifts in parents before and after homework involvement and summarise a range of positive, neutral and negative parental behaviours. We also catalogue seven common conflicts, with Knowledge Conflict being the most frequent. Notably, we found that even well-intentioned parental behaviours, such as Unlabelled Praise, were significantly positively correlated with specific conflict types. This work advances ubiquitous computing's research to sense and understand complex family dynamics, while offering evidence-based insights for designing future ambient intelligent systems to support healthy family education environments.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "232",
        "title": "Neural Preconditioning Operator for Efficient PDE Solves",
        "author": [
            "Zhihao Li",
            "Di Xiao",
            "Zhilu Lai",
            "Wei Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01337",
        "abstract": "We introduce the Neural Preconditioning Operator (NPO), a novel approach designed to accelerate Krylov solvers in solving large, sparse linear systems derived from partial differential equations (PDEs). Unlike classical preconditioners that often require extensive tuning and struggle to generalize across different meshes or parameters, NPO employs neural operators trained via condition and residual losses. This framework seamlessly integrates with existing neural network models, serving effectively as a preconditioner to enhance the performance of Krylov subspace methods. Further, by melding algebraic multigrid principles with a transformer-based architecture, NPO significantly reduces iteration counts and runtime for solving Poisson, Diffusion, and Linear Elasticity problems on both uniform and irregular meshes. Our extensive numerical experiments demonstrate that NPO outperforms traditional methods and contemporary neural approaches across various resolutions, ensuring robust convergence even on grids as large as 4096, far exceeding its initial training limits. These findings underscore the potential of data-driven preconditioning to transform the computational efficiency of high-dimensional PDE applications.",
        "tags": [
            "Diffusion",
            "Transformer"
        ]
    },
    {
        "id": "233",
        "title": "PSSD: Making Large Language Models Self-denial via Human Psyche Structure",
        "author": [
            "Jinzhi Liao",
            "Zenghua Liao",
            "Xiang Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01344",
        "abstract": "The enhance of accuracy in reasoning results of LLMs arouses the community's interests, wherein pioneering studies investigate post-hoc strategies to rectify potential mistakes. Despite extensive efforts, they are all stuck in a state of resource competition demanding significant time and computing expenses. The cause of the situation lies in the failure of identifying the fundamental feature of the solutions in this line, coined as the self-denial of LLMs. In other words, LLMs should confidently determine the potential existence of mistakes and carefully execute the targeted correction. As the whole procedure conducts within LLMs, supporting and persuasive references are hard to acquire, while the absence of specific steps towards refining hidden mistakes persists even when errors are acknowledged. In response to the challenges, we present PSSD, which refers to and implements the human psyche structure such that three distinct and interconnected roles contribute to human reasoning. Specifically, PSSD leverages the recent multi-agent paradigm, and is further enhanced with three innovatively conceived roles: (1) the intuition-based id role that provides initial attempts based on benign LLMs; (2) the rule-driven superego role that summarizes rules to regulate the above attempts, and returns specific key points as guidance; and (3) the script-centric ego role that absorbs all procedural information to generate executable script for the final answer prediction. Extensive experiments demonstrate that the proposed design not only better enhance reasoning capabilities, but also seamlessly integrate with current models, leading to superior performance.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "234",
        "title": "Bayesian Approximation-Based Trajectory Prediction and Tracking with 4D Radar",
        "author": [
            "Dong-In Kim",
            "Dong-Hee Paek",
            "Seung-Hyun Song",
            "Seung-Hyun Kong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01357",
        "abstract": "Accurate 3D multi-object tracking (MOT) is vital for autonomous vehicles, yet LiDAR and camera-based methods degrade in adverse weather. Meanwhile, Radar-based solutions remain robust but often suffer from limited vertical resolution and simplistic motion models. Existing Kalman filter-based approaches also rely on fixed noise covariance, hampering adaptability when objects make sudden maneuvers. We propose Bayes-4DRTrack, a 4D Radar-based MOT framework that adopts a transformer-based motion prediction network to capture nonlinear motion dynamics and employs Bayesian approximation in both detection and prediction steps. Moreover, our two-stage data association leverages Doppler measurements to better distinguish closely spaced targets. Evaluated on the K-Radar dataset (including adverse weather scenarios), Bayes-4DRTrack demonstrates a 5.7% gain in Average Multi-Object Tracking Accuracy (AMOTA) over methods with traditional motion models and fixed noise covariance. These results showcase enhanced robustness and accuracy in demanding, real-world conditions.",
        "tags": [
            "3D",
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "235",
        "title": "Inverse Bridge Matching Distillation",
        "author": [
            "Nikita Gushchin",
            "David Li",
            "Daniil Selikhanovych",
            "Evgeny Burnaev",
            "Dmitry Baranchuk",
            "Alexander Korotin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01362",
        "abstract": "Learning diffusion bridge models is easy; making them fast and practical is an art. Diffusion bridge models (DBMs) are a promising extension of diffusion models for applications in image-to-image translation. However, like many modern diffusion and flow models, DBMs suffer from the problem of slow inference. To address it, we propose a novel distillation technique based on the inverse bridge matching formulation and derive the tractable objective to solve it in practice. Unlike previously developed DBM distillation techniques, the proposed method can distill both conditional and unconditional types of DBMs, distill models in a one-step generator, and use only the corrupted images for training. We evaluate our approach for both conditional and unconditional types of bridge matching on a wide set of setups, including super-resolution, JPEG restoration, sketch-to-image, and other tasks, and show that our distillation technique allows us to accelerate the inference of DBMs from 4x to 100x and even provide better generation quality than used teacher model depending on particular setup.",
        "tags": [
            "Diffusion",
            "Super Resolution"
        ]
    },
    {
        "id": "236",
        "title": "Meursault as a Data Point",
        "author": [
            "Abhinav Pratap",
            "Amit Pathak"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01364",
        "abstract": "In an era dominated by datafication, the reduction of human experiences to quantifiable metrics raises profound philosophical and ethical questions. This paper explores these issues through the lens of Meursault, the protagonist of Albert Camus' The Stranger, whose emotionally detached existence epitomizes the existential concept of absurdity. Using natural language processing (NLP) techniques including emotion detection (BERT), sentiment analysis (VADER), and named entity recognition (spaCy)-this study quantifies key events and behaviors in Meursault's life. Our analysis reveals the inherent limitations of applying algorithmic models to complex human experiences, particularly those rooted in existential alienation and moral ambiguity. By examining how modern AI tools misinterpret Meursault's actions and emotions, this research underscores the broader ethical dilemmas of reducing nuanced human narratives to data points, challenging the foundational assumptions of our data-driven society. The findings presented in this paper serve as a critique of the increasing reliance on data-driven narratives and advocate for incorporating humanistic values in artificial intelligence.",
        "tags": [
            "BERT",
            "Detection"
        ]
    },
    {
        "id": "237",
        "title": "CE-LoRA: Computation-Efficient LoRA Fine-Tuning for Language Models",
        "author": [
            "Guanduo Chen",
            "Yutong He",
            "Yipeng Hu",
            "Kun Yuan",
            "Binhang Yuan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01378",
        "abstract": "Large Language Models (LLMs) demonstrate exceptional performance across various tasks but demand substantial computational resources even for fine-tuning computation. Although Low-Rank Adaptation (LoRA) significantly alleviates memory consumption during fine-tuning, its impact on computational cost reduction is limited. This paper identifies the computation of activation gradients as the primary bottleneck in LoRA's backward propagation and introduces the Computation-Efficient LoRA (CE-LoRA) algorithm, which enhances computational efficiency while preserving memory efficiency. CE-LoRA leverages two key techniques: Approximated Matrix Multiplication, which replaces dense multiplications of large and complete matrices with sparse multiplications involving only critical rows and columns, and the Double-LoRA technique, which reduces error propagation in activation gradients. Theoretically, CE-LoRA converges at the same rate as LoRA, $ \\mathcal{O}(1/\\sqrt{T}) $, where $T$ is the number of iteartions. Empirical evaluations confirm that CE-LoRA significantly reduces computational costs compared to LoRA without notable performance degradation.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "LoRA",
            "Low-Rank Adaptation"
        ]
    },
    {
        "id": "238",
        "title": "InfoBridge: Mutual Information estimation via Bridge Matching",
        "author": [
            "Sergei Kholkin",
            "Ivan Butakov",
            "Evgeny Burnaev",
            "Nikita Gushchin",
            "Alexander Korotin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01383",
        "abstract": "Diffusion bridge models have recently become a powerful tool in the field of generative modeling. In this work, we leverage their power to address another important problem in machine learning and information theory - the estimation of the mutual information (MI) between two random variables. We show that by using the theory of diffusion bridges, one can construct an unbiased estimator for data posing difficulties for conventional MI estimators. We showcase the performance of our estimator on a series of standard MI estimation benchmarks.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "239",
        "title": "Topic-FlipRAG: Topic-Orientated Adversarial Opinion Manipulation Attacks to Retrieval-Augmented Generation Models",
        "author": [
            "Yuyang Gong",
            "Zhuo Chen",
            "Miaokun Chen",
            "Fengchang Yu",
            "Wei Lu",
            "Xiaofeng Wang",
            "Xiaozhong Liu",
            "Jiawei Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01386",
        "abstract": "Retrieval-Augmented Generation (RAG) systems based on Large Language Models (LLMs) have become essential for tasks such as question answering and content generation. However, their increasing impact on public opinion and information dissemination has made them a critical focus for security research due to inherent vulnerabilities. Previous studies have predominantly addressed attacks targeting factual or single-query manipulations. In this paper, we address a more practical scenario: topic-oriented adversarial opinion manipulation attacks on RAG models, where LLMs are required to reason and synthesize multiple perspectives, rendering them particularly susceptible to systematic knowledge poisoning. Specifically, we propose Topic-FlipRAG, a two-stage manipulation attack pipeline that strategically crafts adversarial perturbations to influence opinions across related queries. This approach combines traditional adversarial ranking attack techniques and leverages the extensive internal relevant knowledge and reasoning capabilities of LLMs to execute semantic-level perturbations. Experiments show that the proposed attacks effectively shift the opinion of the model's outputs on specific topics, significantly impacting user information perception. Current mitigation methods cannot effectively defend against such attacks, highlighting the necessity for enhanced safeguards for RAG systems, and offering crucial insights for LLM security research.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "240",
        "title": "TeLL-Drive: Enhancing Autonomous Driving with Teacher LLM-Guided Deep Reinforcement Learning",
        "author": [
            "Chengkai Xu",
            "Jiaqi Liu",
            "Peng Hang",
            "Jian Sun"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01387",
        "abstract": "Although Deep Reinforcement Learning (DRL) and Large Language Models (LLMs) each show promise in addressing decision-making challenges in autonomous driving, DRL often suffers from high sample complexity, while LLMs have difficulty ensuring real-time decision making. To address these limitations, we propose TeLL-Drive, a hybrid framework that integrates an Teacher LLM to guide an attention-based Student DRL policy. By incorporating risk metrics, historical scenario retrieval, and domain heuristics into context-rich prompts, the LLM produces high-level driving strategies through chain-of-thought reasoning. A self-attention mechanism then fuses these strategies with the DRL agent's exploration, accelerating policy convergence and boosting robustness across diverse driving conditions. Our experimental results, evaluated across multiple traffic scenarios, show that TeLL-Drive outperforms existing baseline methods, including other LLM-based approaches, in terms of success rates, average returns, and real-time feasibility. Ablation studies underscore the importance of each model component, especially the synergy between the attention mechanism and LLM-driven guidance. These findings suggest that TeLL-Drive significantly enhances both the adaptability and safety of autonomous driving systems, while offering a more efficient and scalable approach for policy learning. Full validation results are available on our website.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "241",
        "title": "Plan-Then-Execute: An Empirical Study of User Trust and Team Performance When Using LLM Agents As A Daily Assistant",
        "author": [
            "Gaole He",
            "Gianluca Demartini",
            "Ujwal Gadiraju"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01390",
        "abstract": "Since the explosion in popularity of ChatGPT, large language models (LLMs) have continued to impact our everyday lives. Equipped with external tools that are designed for a specific purpose (e.g., for flight booking or an alarm clock), LLM agents exercise an increasing capability to assist humans in their daily work. Although LLM agents have shown a promising blueprint as daily assistants, there is a limited understanding of how they can provide daily assistance based on planning and sequential decision making capabilities. We draw inspiration from recent work that has highlighted the value of 'LLM-modulo' setups in conjunction with humans-in-the-loop for planning tasks. We conducted an empirical study (N = 248) of LLM agents as daily assistants in six commonly occurring tasks with different levels of risk typically associated with them (e.g., flight ticket booking and credit card payments). To ensure user agency and control over the LLM agent, we adopted LLM agents in a plan-then-execute manner, wherein the agents conducted step-wise planning and step-by-step execution in a simulation environment. We analyzed how user involvement at each stage affects their trust and collaborative team performance. Our findings demonstrate that LLM agents can be a double-edged sword -- (1) they can work well when a high-quality plan and necessary user involvement in execution are available, and (2) users can easily mistrust the LLM agents with plans that seem plausible. We synthesized key insights for using LLM agents as daily assistants to calibrate user trust and achieve better overall task outcomes. Our work has important implications for the future design of daily assistants and human-AI collaboration with LLM agents.",
        "tags": [
            "ChatGPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "242",
        "title": "Annotation Tool and Dataset for Fact-Checking Podcasts",
        "author": [
            "Vinay Setty",
            "Adam James Becker"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01402",
        "abstract": "Podcasts are a popular medium on the web, featuring diverse and multilingual content that often includes unverified claims. Fact-checking podcasts is a challenging task, requiring transcription, annotation, and claim verification, all while preserving the contextual details of spoken content. Our tool offers a novel approach to tackle these challenges by enabling real-time annotation of podcasts during playback. This unique capability allows users to listen to the podcast and annotate key elements, such as check-worthy claims, claim spans, and contextual errors, simultaneously. By integrating advanced transcription models like OpenAI's Whisper and leveraging crowdsourced annotations, we create high-quality datasets to fine-tune multilingual transformer models such as XLM-RoBERTa for tasks like claim detection and stance classification. Furthermore, we release the annotated podcast transcripts and sample annotations with preliminary experiments.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "243",
        "title": "AdaSVD: Adaptive Singular Value Decomposition for Large Language Models",
        "author": [
            "Li Zhiteng",
            "Xia Mingyuan",
            "Zhang Jingyuan",
            "Hui Zheng",
            "Kong Linghe",
            "Zhang Yulun",
            "Yang Xiaokang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01403",
        "abstract": "Large language models (LLMs) have achieved remarkable success in natural language processing (NLP) tasks, yet their substantial memory requirements present significant challenges for deployment on resource-constrained devices. Singular Value Decomposition (SVD) has emerged as a promising compression technique for LLMs, offering considerable reductions in memory overhead. However, existing SVD-based methods often struggle to effectively mitigate the errors introduced by SVD truncation, leading to a noticeable performance gap when compared to the original models. Furthermore, applying a uniform compression ratio across all transformer layers fails to account for the varying importance of different layers. To address these challenges, we propose AdaSVD, an adaptive SVD-based LLM compression approach. Specifically, AdaSVD introduces adaComp, which adaptively compensates for SVD truncation errors by alternately updating the singular matrices U and V^T. Additionally, AdaSVD introduces adaCR, which adaptively assigns layer-specific compression ratios based on the relative importance of each layer. Extensive experiments across multiple LLM families and evaluation metrics demonstrate that AdaSVD consistently outperforms state-of-the-art (SOTA) SVD-based methods, achieving superior performance with significantly reduced memory requirements. The code and models will be available at https://github.com/ZHITENGLI/AdaSVD.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "244",
        "title": "GRADIEND: Monosemantic Feature Learning within Neural Networks Applied to Gender Debiasing of Transformer Models",
        "author": [
            "Jonathan Drechsel",
            "Steffen Herbold"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01406",
        "abstract": "AI systems frequently exhibit and amplify social biases, including gender bias, leading to harmful consequences in critical areas. This study introduces a novel encoder-decoder approach that leverages model gradients to learn a single monosemantic feature neuron encoding gender information. We show that our method can be used to debias transformer-based language models, while maintaining other capabilities. We demonstrate the effectiveness of our approach across multiple encoder-only based models and highlight its potential for broader applications.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "245",
        "title": "Human Body Restoration with One-Step Diffusion Model and A New Benchmark",
        "author": [
            "Jue Gong",
            "Jingkai Wang",
            "Zheng Chen",
            "Xing Liu",
            "Hong Gu",
            "Yulun Zhang",
            "Xiaokang Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01411",
        "abstract": "Human body restoration, as a specific application of image restoration, is widely applied in practice and plays a vital role across diverse fields. However, thorough research remains difficult, particularly due to the lack of benchmark datasets. In this study, we propose a high-quality dataset automated cropping and filtering (HQ-ACF) pipeline. This pipeline leverages existing object detection datasets and other unlabeled images to automatically crop and filter high-quality human images. Using this pipeline, we constructed a person-based restoration with sophisticated objects and natural activities (\\emph{PERSONA}) dataset, which includes training, validation, and test sets. The dataset significantly surpasses other human-related datasets in both quality and content richness. Finally, we propose \\emph{OSDHuman}, a novel one-step diffusion model for human body restoration. Specifically, we propose a high-fidelity image embedder (HFIE) as the prompt generator to better guide the model with low-quality human image information, effectively avoiding misleading prompts. Experimental results show that OSDHuman outperforms existing methods in both visual quality and quantitative metrics. The dataset and code will at https://github.com/gobunu/OSDHuman.",
        "tags": [
            "Detection",
            "Diffusion"
        ]
    },
    {
        "id": "246",
        "title": "Visual Attention Never Fades: Selective Progressive Attention ReCalibration for Detailed Image Captioning in Multimodal Large Language Models",
        "author": [
            "Mingi Jung",
            "Saehuyng Lee",
            "Eunji Kim",
            "Sungroh Yoon"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01419",
        "abstract": "Detailed image captioning is essential for tasks like data generation and aiding visually impaired individuals. High-quality captions require a balance between precision and recall, which remains challenging for current multimodal large language models (MLLMs). In this work, we hypothesize that this limitation stems from weakening and increasingly noisy visual attention as responses lengthen. To address this issue, we propose SPARC (Selective Progressive Attention ReCalibration), a training-free method that enhances the contribution of visual tokens during decoding. SPARC is founded on three key observations: (1) increasing the influence of all visual tokens reduces recall; thus, SPARC selectively amplifies visual tokens; (2) as captions lengthen, visual attention becomes noisier, so SPARC identifies critical visual tokens by leveraging attention differences across time steps; (3) as visual attention gradually weakens, SPARC reinforces it to preserve its influence. Our experiments, incorporating both automated and human evaluations, demonstrate that existing methods improve the precision of MLLMs at the cost of recall. In contrast, our proposed method enhances both precision and recall with minimal computational overhead.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "247",
        "title": "Emergent Stack Representations in Modeling Counter Languages Using Transformers",
        "author": [
            "Utkarsh Tiwari",
            "Aviral Gupta",
            "Michael Hahn"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01432",
        "abstract": "Transformer architectures are the backbone of most modern language models, but understanding the inner workings of these models still largely remains an open problem. One way that research in the past has tackled this problem is by isolating the learning capabilities of these architectures by training them over well-understood classes of formal languages. We extend this literature by analyzing models trained over counter languages, which can be modeled using counter variables. We train transformer models on 4 counter languages, and equivalently formulate these languages using stacks, whose depths can be understood as the counter values. We then probe their internal representations for stack depths at each input token to show that these models when trained as next token predictors learn stack-like representations. This brings us closer to understanding the algorithmic details of how transformers learn languages and helps in circuit discovery.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "248",
        "title": "Towards Safer Chatbots: A Framework for Policy Compliance Evaluation of Custom GPTs",
        "author": [
            "David Rodriguez",
            "William Seymour",
            "Jose M. Del Alamo",
            "Jose Such"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01436",
        "abstract": "Large Language Models (LLMs) have gained unprecedented prominence, achieving widespread adoption across diverse domains and integrating deeply into society. The capability to fine-tune general-purpose LLMs, such as Generative Pre-trained Transformers (GPT), for specific tasks has facilitated the emergence of numerous Custom GPTs. These tailored models are increasingly made available through dedicated marketplaces, such as OpenAI's GPT Store. However, their black-box nature introduces significant safety and compliance risks. In this work, we present a scalable framework for the automated evaluation of Custom GPTs against OpenAI's usage policies, which define the permissible behaviors of these systems. Our framework integrates three core components: (1) automated discovery and data collection of models from the GPT store, (2) a red-teaming prompt generator tailored to specific policy categories and the characteristics of each target GPT, and (3) an LLM-as-a-judge technique to analyze each prompt-response pair for potential policy violations.\nWe validate our framework with a manually annotated ground truth, and evaluate it through a large-scale study with 782 Custom GPTs across three categories: Romantic, Cybersecurity, and Academic GPTs. Our manual annotation process achieved an F1 score of 0.975 in identifying policy violations, confirming the reliability of the framework's assessments. The results reveal that 58.7% of the analyzed models exhibit indications of non-compliance, exposing weaknesses in the GPT store's review and approval processes. Furthermore, our findings indicate that a model's popularity does not correlate with compliance, and non-compliance issues largely stem from behaviors inherited from base models rather than user-driven customizations. We believe this approach is extendable to other chatbot platforms and policy domains, improving LLM-based systems safety.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "249",
        "title": "Improved Training Technique for Latent Consistency Models",
        "author": [
            "Quan Dao",
            "Khanh Doan",
            "Di Liu",
            "Trung Le",
            "Dimitris Metaxas"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01441",
        "abstract": "Consistency models are a new family of generative models capable of producing high-quality samples in either a single step or multiple steps. Recently, consistency models have demonstrated impressive performance, achieving results on par with diffusion models in the pixel space. However, the success of scaling consistency training to large-scale datasets, particularly for text-to-image and video generation tasks, is determined by performance in the latent space. In this work, we analyze the statistical differences between pixel and latent spaces, discovering that latent data often contains highly impulsive outliers, which significantly degrade the performance of iCT in the latent space. To address this, we replace Pseudo-Huber losses with Cauchy losses, effectively mitigating the impact of outliers. Additionally, we introduce a diffusion loss at early timesteps and employ optimal transport (OT) coupling to further enhance performance. Lastly, we introduce the adaptive scaling-$c$ scheduler to manage the robust training process and adopt Non-scaling LayerNorm in the architecture to better capture the statistics of the features and reduce outlier impact. With these strategies, we successfully train latent consistency models capable of high-quality sampling with one or two steps, significantly narrowing the performance gap between latent consistency and diffusion models. The implementation is released here: https://github.com/quandao10/sLCT/",
        "tags": [
            "Consistency Models",
            "Diffusion",
            "Text-to-Image",
            "Video Generation"
        ]
    },
    {
        "id": "250",
        "title": "Process Reinforcement through Implicit Rewards",
        "author": [
            "Ganqu Cui",
            "Lifan Yuan",
            "Zefan Wang",
            "Hanbin Wang",
            "Wendi Li",
            "Bingxiang He",
            "Yuchen Fan",
            "Tianyu Yu",
            "Qixin Xu",
            "Weize Chen",
            "Jiarui Yuan",
            "Huayu Chen",
            "Kaiyan Zhang",
            "Xingtai Lv",
            "Shuo Wang",
            "Yuan Yao",
            "Xu Han",
            "Hao Peng",
            "Yu Cheng",
            "Zhiyuan Liu",
            "Maosong Sun",
            "Bowen Zhou",
            "Ning Ding"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01456",
        "abstract": "Dense process rewards have proven a more effective alternative to the sparse outcome-level rewards in the inference-time scaling of large language models (LLMs), particularly in tasks requiring complex multi-step reasoning. While dense rewards also offer an appealing choice for the reinforcement learning (RL) of LLMs since their fine-grained rewards have the potential to address some inherent issues of outcome rewards, such as training efficiency and credit assignment, this potential remains largely unrealized. This can be primarily attributed to the challenges of training process reward models (PRMs) online, where collecting high-quality process labels is prohibitively expensive, making them particularly vulnerable to reward hacking. To address these challenges, we propose PRIME (Process Reinforcement through IMplicit rEwards), which enables online PRM updates using only policy rollouts and outcome labels through implict process rewards. PRIME combines well with various advantage functions and forgoes the dedicated reward model training phrase that existing approaches require, substantially reducing the development overhead. We demonstrate PRIME's effectiveness on competitional math and coding. Starting from Qwen2.5-Math-7B-Base, PRIME achieves a 15.1% average improvement across several key reasoning benchmarks over the SFT model. Notably, our resulting model, Eurus-2-7B-PRIME, surpasses Qwen2.5-Math-7B-Instruct on seven reasoning benchmarks with 10% of its training data.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RL"
        ]
    },
    {
        "id": "251",
        "title": "FALCON: Fine-grained Activation Manipulation by Contrastive Orthogonal Unalignment for Large Language Model",
        "author": [
            "Jinwei Hu",
            "Zhenglin Huang",
            "Xiangyu Yin",
            "Wenjie Ruan",
            "Guangliang Cheng",
            "Yi Dong",
            "Xiaowei Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01472",
        "abstract": "Large language models have been widely applied, but can inadvertently encode sensitive or harmful information, raising significant safety concerns. Machine unlearning has emerged to alleviate this concern; however, existing training-time unlearning approaches, relying on coarse-grained loss combinations, have limitations in precisely separating knowledge and balancing removal effectiveness with model utility. In contrast, we propose Fine-grained Activation manipuLation by Contrastive Orthogonal uNalignment (FALCON), a novel representation-guided unlearning approach that leverages information-theoretic guidance for efficient parameter selection, employs contrastive mechanisms to enhance representation separation, and projects conflict gradients onto orthogonal subspaces to resolve conflicts between forgetting and retention objectives. Extensive experiments demonstrate that FALCON achieves superior unlearning effectiveness while maintaining model utility, exhibiting robust resistance against knowledge recovery attempts.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "252",
        "title": "Generalization Error Analysis for Selective State-Space Models Through the Lens of Attention",
        "author": [
            "Arya Honarpisheh",
            "Mustafa Bozdag",
            "Mario Sznaier",
            "Octavia Camps"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01473",
        "abstract": "State-space models (SSMs) are a new class of foundation models that have emerged as a compelling alternative to Transformers and their attention mechanisms for sequence processing tasks. This paper provides a detailed theoretical analysis of selective SSMs, the core components of the Mamba and Mamba-2 architectures. We leverage the connection between selective SSMs and the self-attention mechanism to highlight the fundamental similarities between these models. Building on this connection, we establish a length independent covering number-based generalization bound for selective SSMs, providing a deeper understanding of their theoretical performance guarantees. We analyze the effects of state matrix stability and input-dependent discretization, shedding light on the critical role played by these factors in the generalization capabilities of selective SSMs. Finally, we empirically demonstrate the sequence length independence of the derived bounds on two tasks.",
        "tags": [
            "Mamba",
            "SSMs",
            "State Space Models"
        ]
    },
    {
        "id": "253",
        "title": "Position: Empowering Time Series Reasoning with Multimodal LLMs",
        "author": [
            "Yaxuan Kong",
            "Yiyuan Yang",
            "Shiyu Wang",
            "Chenghao Liu",
            "Yuxuan Liang",
            "Ming Jin",
            "Stefan Zohren",
            "Dan Pei",
            "Yan Liu",
            "Qingsong Wen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01477",
        "abstract": "Understanding time series data is crucial for multiple real-world applications. While large language models (LLMs) show promise in time series tasks, current approaches often rely on numerical data alone, overlooking the multimodal nature of time-dependent information, such as textual descriptions, visual data, and audio signals. Moreover, these methods underutilize LLMs' reasoning capabilities, limiting the analysis to surface-level interpretations instead of deeper temporal and multimodal reasoning. In this position paper, we argue that multimodal LLMs (MLLMs) can enable more powerful and flexible reasoning for time series analysis, enhancing decision-making and real-world applications. We call on researchers and practitioners to leverage this potential by developing strategies that prioritize trust, interpretability, and robust reasoning in MLLMs. Lastly, we highlight key research directions, including novel reasoning paradigms, architectural innovations, and domain-specific applications, to advance time series reasoning with MLLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "254",
        "title": "Function Approximation Using Analog Building Blocks in Flexible Electronics",
        "author": [
            "Paula Carolina Lozano Duarte",
            "Aradhana Dube",
            "Georgios Zervakis",
            "Mehdi Tahoori",
            "Sani Nassif"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01489",
        "abstract": "Function approximation is crucial in Flexible Electronics (FE), where applications demand efficient computational techniques within strict constraints on size, power, and performance. Devices like wearables and compact sensors are constrained by their limited physical dimensions and energy capacity, making traditional digital function approximation challenging and hardware-demanding. This paper addresses function approximation in FE by proposing a systematic and generic approach using a combination of Analog Building Blocks (ABBs) that perform basic mathematical operations such as addition, multiplication, and squaring. These ABBs serve as the foundation for constructing splines, which are then employed in the creation of Kolmogorov-Arnold Networks (KANs), improving the approximation. The analog realization of KAN offers a promising alternative to digital solutions, providing significant hardware benefits, particularly in terms of area and power consumption. Our design achieves a 125x reduction in area and a 10.59% power saving compared to a digital spline with 8-bit precision. Results also show that the analog design introduces an approximation error of up to 7.58% due to both the design and parasitic elements. Nevertheless, KANs are shown to be a viable candidate for function approximation in FE, with potential for further optimization to address the challenges of error reduction and hardware cost.",
        "tags": [
            "KAN",
            "Kolmogorov-Arnold Networks"
        ]
    },
    {
        "id": "255",
        "title": "The Human-AI Handshake Framework: A Bidirectional Approach to Human-AI Collaboration",
        "author": [
            "Aung Pyae"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01493",
        "abstract": "Human-AI collaboration is evolving from a tool-based perspective to a partnership model where AI systems complement and enhance human capabilities. Traditional approaches often limit AI to a supportive role, missing the potential for reciprocal relationships where both human and AI inputs contribute to shared goals. Although Human-Centered AI (HcAI) frameworks emphasize transparency, ethics, and user experience, they often lack mechanisms for genuine, dynamic collaboration. The \"Human-AI Handshake Model\" addresses this gap by introducing a bi-directional, adaptive framework with five key attributes: information exchange, mutual learning, validation, feedback, and mutual capability augmentation. These attributes foster balanced interaction, enabling AI to act as a responsive partner, evolving with users over time. Human enablers like user experience and trust, alongside AI enablers such as explainability and responsibility, facilitate this collaboration, while shared values of ethics and co-evolution ensure sustainable growth. Distinct from existing frameworks, this model is reflected in tools like GitHub Copilot and ChatGPT, which support bi-directional learning and transparency. Challenges remain, including maintaining ethical standards and ensuring effective user oversight. Future research will explore these challenges, aiming to create a truly collaborative human-AI partnership that leverages the strengths of both to achieve outcomes beyond what either could accomplish alone.",
        "tags": [
            "ChatGPT"
        ]
    },
    {
        "id": "256",
        "title": "TwinMarket: A Scalable Behavioral and SocialSimulation for Financial Markets",
        "author": [
            "Yuzhe Yang",
            "Yifei Zhang",
            "Minghao Wu",
            "Kaidi Zhang",
            "Yunmiao Zhang",
            "Honghai Yu",
            "Yan Hu",
            "Benyou Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01506",
        "abstract": "The study of social emergence has long been a central focus in social science. Traditional modeling approaches, such as rule-based Agent-Based Models (ABMs), struggle to capture the diversity and complexity of human behavior, particularly the irrational factors emphasized in behavioral economics. Recently, large language model (LLM) agents have gained traction as simulation tools for modeling human behavior in social science and role-playing applications. Studies suggest that LLMs can account for cognitive biases, emotional fluctuations, and other non-rational influences, enabling more realistic simulations of socio-economic dynamics. In this work, we introduce TwinMarket, a novel multi-agent framework that leverages LLMs to simulate socio-economic systems. Specifically, we examine how individual behaviors, through interactions and feedback mechanisms, give rise to collective dynamics and emergent phenomena. Through experiments in a simulated stock market environment, we demonstrate how individual actions can trigger group behaviors, leading to emergent outcomes such as financial bubbles and recessions. Our approach provides valuable insights into the complex interplay between individual decision-making and collective socio-economic patterns.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "257",
        "title": "End-to-end Training for Text-to-Image Synthesis using Dual-Text Embeddings",
        "author": [
            "Yeruru Asrar Ahmed",
            "Anurag Mittal"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01507",
        "abstract": "Text-to-Image (T2I) synthesis is a challenging task that requires modeling complex interactions between two modalities ( i.e., text and image). A common framework adopted in recent state-of-the-art approaches to achieving such multimodal interactions is to bootstrap the learning process with pre-trained image-aligned text embeddings trained using contrastive loss. Furthermore, these embeddings are typically trained generically and reused across various synthesis models. In contrast, we explore an approach to learning text embeddings specifically tailored to the T2I synthesis network, trained in an end-to-end fashion. Further, we combine generative and contrastive training and use two embeddings, one optimized to enhance the photo-realism of the generated images, and the other seeking to capture text-to-image alignment. A comprehensive set of experiments on three text-to-image benchmark datasets (Oxford-102, Caltech-UCSD, and MS-COCO) reveal that having two separate embeddings gives better results than using a shared one and that such an approach performs favourably in comparison with methods that use text representations from a pre-trained text encoder trained using a discriminative approach. Finally, we demonstrate that such learned embeddings can be used in other contexts as well, such as text-to-image manipulation.",
        "tags": [
            "Text-to-Image"
        ]
    },
    {
        "id": "258",
        "title": "Hybrid Machine Learning Model for Detecting Bangla Smishing Text Using BERT and Character-Level CNN",
        "author": [
            "Gazi Tanbhir",
            "Md. Farhan Shahriyar",
            "Khandker Shahed",
            "Abdullah Md Raihan Chy",
            "Md Al Adnan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01518",
        "abstract": "Smishing is a social engineering attack using SMS containing malicious content to deceive individuals into disclosing sensitive information or transferring money to cybercriminals. Smishing attacks have surged by 328%, posing a major threat to mobile users, with losses exceeding \\$54.2 million in 2019. Despite its growing prevalence, the issue remains significantly under-addressed. This paper presents a novel hybrid machine learning model for detecting Bangla smishing texts, combining Bidirectional Encoder Representations from Transformers (BERT) with Convolutional Neural Networks (CNNs) for enhanced character-level analysis.\nOur model addresses multi-class classification by distinguishing between Normal, Promotional, and Smishing SMS. Unlike traditional binary classification methods, our approach integrates BERT's contextual embeddings with CNN's character-level features, improving detection accuracy. Enhanced by an attention mechanism, the model effectively prioritizes crucial text segments. Our model achieves 98.47% accuracy, outperforming traditional classifiers, with high precision and recall in Smishing detection, and strong performance across all categories.",
        "tags": [
            "BERT",
            "Detection"
        ]
    },
    {
        "id": "259",
        "title": "BD-Diff: Generative Diffusion Model for Image Deblurring on Unknown Domains with Blur-Decoupled Learning",
        "author": [
            "Junhao Cheng",
            "Wei-Ting Chen",
            "Xi Lu",
            "Ming-Hsuan Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01522",
        "abstract": "Generative diffusion models trained on large-scale datasets have achieved remarkable progress in image synthesis. In favor of their ability to supplement missing details and generate aesthetically pleasing contents, recent works have applied them to image deblurring tasks via training an adapter on blurry-sharp image pairs to provide structural conditions for restoration. However, acquiring substantial amounts of realistic paired data is challenging and costly in real-world scenarios. On the other hand, relying solely on synthetic data often results in overfitting, leading to unsatisfactory performance when confronted with unseen blur patterns. To tackle this issue, we propose BD-Diff, a generative-diffusion-based model designed to enhance deblurring performance on unknown domains by decoupling structural features and blur patterns through joint training on three specially designed tasks. We employ two Q-Formers as structural representations and blur patterns extractors separately. The features extracted by them will be used for the supervised deblurring task on synthetic data and the unsupervised blur-transfer task by leveraging unpaired blurred images from the target domain simultaneously. Furthermore, we introduce a reconstruction task to make the structural features and blur patterns complementary. This blur-decoupled learning process enhances the generalization capabilities of BD-Diff when encountering unknown domain blur patterns. Experiments on real-world datasets demonstrate that BD-Diff outperforms existing state-of-the-art methods in blur removal and structural preservation in various challenging scenarios. The codes will be released in https://github.com/donahowe/BD-Diff",
        "tags": [
            "Deblurring",
            "Diffusion"
        ]
    },
    {
        "id": "260",
        "title": "CondAmbigQA: A Benchmark and Dataset for Conditional Ambiguous Question Answering",
        "author": [
            "Zongxi Li",
            "Yang Li",
            "Haoran Xie",
            "S. Joe Qin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01523",
        "abstract": "Large language models (LLMs) are prone to hallucinations in question-answering (QA) tasks when faced with ambiguous questions. Users often assume that LLMs share their cognitive alignment, a mutual understanding of context, intent, and implicit details, leading them to omit critical information in the queries. However, LLMs generate responses based on assumptions that can misalign with user intent, which may be perceived as hallucinations if they misalign with the user's intent. Therefore, identifying those implicit assumptions is crucial to resolve ambiguities in QA. Prior work, such as AmbigQA, reduces ambiguity in queries via human-annotated clarifications, which is not feasible in real application. Meanwhile, ASQA compiles AmbigQA's short answers into long-form responses but inherits human biases and fails capture explicit logical distinctions that differentiates the answers. We introduce Conditional Ambiguous Question-Answering (CondAmbigQA), a benchmark with 200 ambiguous queries and condition-aware evaluation metrics. Our study pioneers the concept of ``conditions'' in ambiguous QA tasks, where conditions stand for contextual constraints or assumptions that resolve ambiguities. The retrieval-based annotation strategy uses retrieved Wikipedia fragments to identify possible interpretations for a given query as its conditions and annotate the answers through those conditions. Such a strategy minimizes human bias introduced by different knowledge levels among annotators. By fixing retrieval results, CondAmbigQA evaluates how RAG systems leverage conditions to resolve ambiguities. Experiments show that models considering conditions before answering improve performance by $20\\%$, with an additional $5\\%$ gain when conditions are explicitly provided. These results underscore the value of conditional reasoning in QA, offering researchers tools to rigorously evaluate ambiguity resolution.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "261",
        "title": "Efficiently Integrate Large Language Models with Visual Perception: A Survey from the Training Paradigm Perspective",
        "author": [
            "Xiaorui Ma",
            "Haoran Xie",
            "S. Joe Qin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01524",
        "abstract": "The integration of vision-language modalities has been a significant focus in multimodal learning, traditionally relying on Vision-Language Pretrained Models. However, with the advent of Large Language Models (LLMs), there has been a notable shift towards incorporating LLMs with vision modalities. Following this, the training paradigms for incorporating vision modalities into LLMs have evolved. Initially, the approach was to integrate the modalities through pretraining the modality integrator, named Single-stage Tuning. It has since branched out into methods focusing on performance enhancement, denoted as Two-stage Tuning, and those prioritizing parameter efficiency, referred to as Direct Adaptation. However, existing surveys primarily address the latest Vision Large Language Models (VLLMs) with Two-stage Tuning, leaving a gap in understanding the evolution of training paradigms and their unique parameter-efficient considerations. This paper categorizes and reviews 34 VLLMs from top conferences, journals, and highly cited Arxiv papers, focusing on parameter efficiency during adaptation from the training paradigm perspective. We first introduce the architecture of LLMs and parameter-efficient learning methods, followed by a discussion on vision encoders and a comprehensive taxonomy of modality integrators. We then review three training paradigms and their efficiency considerations, summarizing benchmarks in the VLLM field. To gain deeper insights into their effectiveness in parameter efficiency, we compare and discuss the experimental results of representative models, among which the experiment of the Direct Adaptation paradigm is replicated. Providing insights into recent developments and practical uses, this survey is a vital guide for researchers and practitioners navigating the efficient integration of vision modalities into LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "262",
        "title": "Preference Leakage: A Contamination Problem in LLM-as-a-judge",
        "author": [
            "Dawei Li",
            "Renliang Sun",
            "Yue Huang",
            "Ming Zhong",
            "Bohan Jiang",
            "Jiawei Han",
            "Xiangliang Zhang",
            "Wei Wang",
            "Huan Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01534",
        "abstract": "Large Language Models (LLMs) as judges and LLM-based data synthesis have emerged as two fundamental LLM-driven data annotation methods in model development. While their combination significantly enhances the efficiency of model training and evaluation, little attention has been given to the potential contamination brought by this new model development paradigm. In this work, we expose preference leakage, a contamination problem in LLM-as-a-judge caused by the relatedness between the synthetic data generators and LLM-based evaluators. To study this issue, we first define three common relatednesses between data generator LLM and judge LLM: being the same model, having an inheritance relationship, and belonging to the same model family. Through extensive experiments, we empirically confirm the bias of judges towards their related student models caused by preference leakage across multiple LLM baselines and benchmarks. Further analysis suggests that preference leakage is a pervasive issue that is harder to detect compared to previously identified biases in LLM-as-a-judge scenarios. All of these findings imply that preference leakage is a widespread and challenging problem in the area of LLM-as-a-judge. We release all codes and data at: https://github.com/David-Li0406/Preference-Leakage.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "263",
        "title": "VR-Robo: A Real-to-Sim-to-Real Framework for Visual Robot Navigation and Locomotion",
        "author": [
            "Shaoting Zhu",
            "Linzhan Mou",
            "Derun Li",
            "Baijun Ye",
            "Runhan Huang",
            "Hang Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01536",
        "abstract": "Recent success in legged robot locomotion is attributed to the integration of reinforcement learning and physical simulators. However, these policies often encounter challenges when deployed in real-world environments due to sim-to-real gaps, as simulators typically fail to replicate visual realism and complex real-world geometry. Moreover, the lack of realistic visual rendering limits the ability of these policies to support high-level tasks requiring RGB-based perception like ego-centric navigation. This paper presents a Real-to-Sim-to-Real framework that generates photorealistic and physically interactive \"digital twin\" simulation environments for visual navigation and locomotion learning. Our approach leverages 3D Gaussian Splatting (3DGS) based scene reconstruction from multi-view images and integrates these environments into simulations that support ego-centric visual perception and mesh-based physical interactions. To demonstrate its effectiveness, we train a reinforcement learning policy within the simulator to perform a visual goal-tracking task. Extensive experiments show that our framework achieves RGB-only sim-to-real policy transfer. Additionally, our framework facilitates the rapid adaptation of robot policies with effective exploration capability in complex new environments, highlighting its potential for applications in households and factories.",
        "tags": [
            "3D",
            "Gaussian Splatting",
            "Robot"
        ]
    },
    {
        "id": "264",
        "title": "What is a Number, That a Large Language Model May Know It?",
        "author": [
            "Raja Marjieh",
            "Veniamin Veselovsky",
            "Thomas L. Griffiths",
            "Ilia Sucholutsky"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01540",
        "abstract": "Numbers are a basic part of how humans represent and describe the world around them. As a consequence, learning effective representations of numbers is critical for the success of large language models as they become more integrated into everyday decisions. However, these models face a challenge: depending on context, the same sequence of digit tokens, e.g., 911, can be treated as a number or as a string. What kind of representations arise from this duality, and what are its downstream implications? Using a similarity-based prompting technique from cognitive science, we show that LLMs learn representational spaces that blend string-like and numerical representations. In particular, we show that elicited similarity judgments from these models over integer pairs can be captured by a combination of Levenshtein edit distance and numerical Log-Linear distance, suggesting an entangled representation. In a series of experiments we show how this entanglement is reflected in the latent embeddings, how it can be reduced but not entirely eliminated by context, and how it can propagate into a realistic decision scenario. These results shed light on a representational tension in transformer models that must learn what a number is from text input.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "265",
        "title": "VideoRAG: Retrieval-Augmented Generation with Extreme Long-Context Videos",
        "author": [
            "Xubin Ren",
            "Lingrui Xu",
            "Long Xia",
            "Shuaiqiang Wang",
            "Dawei Yin",
            "Chao Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01549",
        "abstract": "Retrieval-Augmented Generation (RAG) has demonstrated remarkable success in enhancing Large Language Models (LLMs) through external knowledge integration, yet its application has primarily focused on textual content, leaving the rich domain of multi-modal video knowledge predominantly unexplored. This paper introduces VideoRAG, the first retrieval-augmented generation framework specifically designed for processing and understanding extremely long-context videos. Our core innovation lies in its dual-channel architecture that seamlessly integrates (i) graph-based textual knowledge grounding for capturing cross-video semantic relationships, and (ii) multi-modal context encoding for efficiently preserving visual features. This novel design empowers VideoRAG to process unlimited-length videos by constructing precise knowledge graphs that span multiple videos while maintaining semantic dependencies through specialized multi-modal retrieval paradigms. Through comprehensive empirical evaluation on our proposed LongerVideos benchmark-comprising over 160 videos totaling 134+ hours across lecture, documentary, and entertainment categories-VideoRAG demonstrates substantial performance compared to existing RAG alternatives and long video understanding methods. The source code of VideoRAG implementation and the benchmark dataset are openly available at: https://github.com/HKUDS/VideoRAG.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "266",
        "title": "Memento No More: Coaching AI Agents to Master Multiple Tasks via Hints Internalization",
        "author": [
            "Minttu Alakuijala",
            "Ya Gao",
            "Georgy Ananov",
            "Samuel Kaski",
            "Pekka Marttinen",
            "Alexander Ilin",
            "Harri Valpola"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01562",
        "abstract": "As the general capabilities of artificial intelligence (AI) agents continue to evolve, their ability to learn to master multiple complex tasks through experience remains a key challenge. Current LLM agents, particularly those based on proprietary language models, typically rely on prompts to incorporate knowledge about the target tasks. This approach does not allow the agent to internalize this information and instead relies on ever-expanding prompts to sustain its functionality in diverse scenarios. This resembles a system of notes used by a person affected by anterograde amnesia, the inability to form new memories. In this paper, we propose a novel method to train AI agents to incorporate knowledge and skills for multiple tasks without the need for either cumbersome note systems or prior high-quality demonstration data. Our approach employs an iterative process where the agent collects new experiences, receives corrective feedback from humans in the form of hints, and integrates this feedback into its weights via a context distillation training procedure. We demonstrate the efficacy of our approach by implementing it in a Llama-3-based agent which, after only a few rounds of feedback, outperforms advanced models GPT-4o and DeepSeek-V3 in a taskset requiring correct sequencing of information retrieval, tool use, and question answering.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLaMA"
        ]
    },
    {
        "id": "267",
        "title": "Massive Values in Self-Attention Modules are the Key to Contextual Knowledge Understanding",
        "author": [
            "Mingyu Jin",
            "Kai Mei",
            "Wujiang Xu",
            "Mingjie Sun",
            "Ruixiang Tang",
            "Mengnan Du",
            "Zirui Liu",
            "Yongfeng Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01563",
        "abstract": "Large language models (LLMs) have achieved remarkable success in contextual knowledge understanding. In this paper, we show that these concentrated massive values consistently emerge in specific regions of attention queries (Q) and keys (K) while not having such patterns in values (V) in various modern transformer-based LLMs (Q, K, and V mean the representations output by the query, key, and value layers respectively). Through extensive experiments, we further demonstrate that these massive values play a critical role in interpreting contextual knowledge (knowledge obtained from the current context window) rather than in retrieving parametric knowledge stored within the model's parameters. Our further investigation of quantization strategies reveals that ignoring these massive values leads to a pronounced drop in performance on tasks requiring rich contextual understanding, aligning with our analysis. Finally, we trace the emergence of concentrated massive values and find that such concentration is caused by Rotary Positional Encoding (RoPE), which has appeared since the first layers. These findings shed new light on how Q and K operate in LLMs and offer practical insights for model design and optimization. The Code is Available at https://github.com/MingyuJ666/Rope_with_LLM.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "268",
        "title": "MeetMap: Real-Time Collaborative Dialogue Mapping with LLMs in Online Meetings",
        "author": [
            "Xinyue Chen",
            "Nathan Yap",
            "Xinyi Lu",
            "Aylin Gunal",
            "Xu Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01564",
        "abstract": "Video meeting platforms display conversations linearly through transcripts or summaries. However, ideas during a meeting do not emerge linearly. We leverage LLMs to create dialogue maps in real time to help people visually structure and connect ideas. Balancing the need to reduce the cognitive load on users during the conversation while giving them sufficient control when using AI, we explore two system variants that encompass different levels of AI assistance. In Human-Map, AI generates summaries of conversations as nodes, and users create dialogue maps with the nodes. In AI-Map, AI produces dialogue maps where users can make edits. We ran a within-subject experiment with ten pairs of users, comparing the two MeetMap variants and a baseline. Users preferred MeetMap over traditional methods for taking notes, which aligned better with their mental models of conversations. Users liked the ease of use for AI-Map due to the low effort demands and appreciated the hands-on opportunity in Human-Map for sense-making.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "269",
        "title": "Scalable Language Models with Posterior Inference of Latent Thought Vectors",
        "author": [
            "Deqian Kong",
            "Minglu Zhao",
            "Dehong Xu",
            "Bo Pang",
            "Shu Wang",
            "Edouardo Honig",
            "Zhangzhang Si",
            "Chuan Li",
            "Jianwen Xie",
            "Sirui Xie",
            "Ying Nian Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01567",
        "abstract": "We propose a novel family of language models, Latent-Thought Language Models (LTMs), which incorporate explicit latent thought vectors that follow an explicit prior model in latent space. These latent thought vectors guide the autoregressive generation of ground tokens through a Transformer decoder. Training employs a dual-rate optimization process within the classical variational Bayes framework: fast learning of local variational parameters for the posterior distribution of latent vectors, and slow learning of global decoder parameters. Empirical studies reveal that LTMs possess additional scaling dimensions beyond traditional LLMs, yielding a structured design space. Higher sample efficiency can be achieved by increasing training compute per token, with further gains possible by trading model size for more inference steps. Designed based on these scaling properties, LTMs demonstrate superior sample and parameter efficiency compared to conventional autoregressive models and discrete diffusion models. They significantly outperform these counterparts in validation perplexity and zero-shot language modeling. Additionally, LTMs exhibit emergent few-shot in-context reasoning capabilities that scale with model and latent size, and achieve competitive performance in conditional and unconditional text generation.",
        "tags": [
            "Diffusion",
            "LLMs",
            "Transformer"
        ]
    },
    {
        "id": "270",
        "title": "MakeAnything: Harnessing Diffusion Transformers for Multi-Domain Procedural Sequence Generation",
        "author": [
            "Yiren Song",
            "Cheng Liu",
            "Mike Zheng Shou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01572",
        "abstract": "A hallmark of human intelligence is the ability to create complex artifacts through structured multi-step processes. Generating procedural tutorials with AI is a longstanding but challenging goal, facing three key obstacles: (1) scarcity of multi-task procedural datasets, (2) maintaining logical continuity and visual consistency between steps, and (3) generalizing across multiple domains. To address these challenges, we propose a multi-domain dataset covering 21 tasks with over 24,000 procedural sequences. Building upon this foundation, we introduce MakeAnything, a framework based on the diffusion transformer (DIT), which leverages fine-tuning to activate the in-context capabilities of DIT for generating consistent procedural sequences. We introduce asymmetric low-rank adaptation (LoRA) for image generation, which balances generalization capabilities and task-specific performance by freezing encoder parameters while adaptively tuning decoder layers. Additionally, our ReCraft model enables image-to-process generation through spatiotemporal consistency constraints, allowing static images to be decomposed into plausible creation sequences. Extensive experiments demonstrate that MakeAnything surpasses existing methods, setting new performance benchmarks for procedural generation tasks.",
        "tags": [
            "DiT",
            "Diffusion",
            "Diffusion Transformer",
            "LoRA",
            "Low-Rank Adaptation",
            "Transformer"
        ]
    },
    {
        "id": "271",
        "title": "Next Steps in LLM-Supported Java Verification",
        "author": [
            "Samuel Teuber",
            "Bernhard Beckert"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01573",
        "abstract": "Recent work has shown that Large Language Models (LLMs) are not only a suitable tool for code generation but also capable of generating annotation-based code specifications. Scaling these methodologies may allow us to deduce provable correctness guarantees for large-scale software systems. In comparison to other LLM tasks, the application field of deductive verification has the notable advantage of providing a rigorous toolset to check LLM-generated solutions. This short paper provides early results on how this rigorous toolset can be used to reliably elicit correct specification annotations from an unreliable LLM oracle.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "272",
        "title": "Robust-LLaVA: On the Effectiveness of Large-Scale Robust Image Encoders for Multi-modal Large Language Models",
        "author": [
            "Hashmat Shadab Malik",
            "Fahad Shamshad",
            "Muzammal Naseer",
            "Karthik Nandakumar",
            "Fahad Khan",
            "Salman Khan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01576",
        "abstract": "Multi-modal Large Language Models (MLLMs) excel in vision-language tasks but remain vulnerable to visual adversarial perturbations that can induce hallucinations, manipulate responses, or bypass safety mechanisms. Existing methods seek to mitigate these risks by applying constrained adversarial fine-tuning to CLIP vision encoders on ImageNet-scale data, ensuring their generalization ability is preserved. However, this limited adversarial training restricts robustness and broader generalization. In this work, we explore an alternative approach of leveraging existing vision classification models that have been adversarially pre-trained on large-scale data. Our analysis reveals two principal contributions: (1) the extensive scale and diversity of adversarial pre-training enables these models to demonstrate superior robustness against diverse adversarial threats, ranging from imperceptible perturbations to advanced jailbreaking attempts, without requiring additional adversarial training, and (2) end-to-end MLLM integration with these robust models facilitates enhanced adaptation of language components to robust visual features, outperforming existing plug-and-play methodologies on complex reasoning tasks. Through systematic evaluation across visual question-answering, image captioning, and jail-break attacks, we demonstrate that MLLMs trained with these robust models achieve superior adversarial robustness while maintaining favorable clean performance. Our framework achieves 2x and 1.5x average robustness gains in captioning and VQA tasks, respectively, and delivers over 10% improvement against jailbreak attacks. Code and pretrained models will be available at https://github.com/HashmatShadab/Robust-LLaVA.",
        "tags": [
            "CLIP",
            "LLaVA",
            "Large Language Models"
        ]
    },
    {
        "id": "273",
        "title": "ReGLA: Refining Gated Linear Attention",
        "author": [
            "Peng Lu",
            "Ivan Kobyzev",
            "Mehdi Rezagholizadeh",
            "Boxing Chen",
            "Philippe Langlais"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01578",
        "abstract": "Recent advancements in Large Language Models (LLMs) have set themselves apart with their exceptional performance in complex language modelling tasks. However, these models are also known for their significant computational and storage requirements, primarily due to the quadratic computation complexity of softmax attention. To mitigate this issue, linear attention has been designed to reduce the quadratic space-time complexity that is inherent in standard transformers. In this work, we embarked on a comprehensive exploration of three key components that substantially impact the performance of the Gated Linear Attention module: feature maps, normalization, and the gating mechanism. We developed a feature mapping function to address some crucial issues that previous suggestions overlooked. Then we offered further rationale for the integration of normalization layers to stabilize the training process. Moreover, we explored the saturation phenomenon of the gating mechanism and augmented it with a refining module. We conducted extensive experiments and showed our architecture outperforms previous Gated Linear Attention mechanisms in extensive tasks including training from scratch and post-linearization with continual pre-training.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "274",
        "title": "PhD Knowledge Not Required: A Reasoning Challenge for Large Language Models",
        "author": [
            "Carolyn Jane Anderson",
            "Joydeep Biswas",
            "Aleksander Boruch-Gruszecki",
            "Federico Cassano",
            "Molly Q Feldman",
            "Arjun Guha",
            "Francesca Lucchetti",
            "Zixuan Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01584",
        "abstract": "Existing benchmarks for frontier models often test specialized, ``PhD-level'' knowledge that is difficult for non-experts to grasp. In contrast, we present a benchmark based on the NPR Sunday Puzzle Challenge that requires only general knowledge. Our benchmark is challenging for both humans and models, however correct solutions are easy to verify, and models' mistakes are easy to spot.\nOur work reveals capability gaps that are not evident in existing benchmarks: OpenAI o1 significantly outperforms other reasoning models that are on par on benchmarks that test specialized knowledge. Furthermore, our analysis of reasoning outputs uncovers new kinds of failures. DeepSeek R1, for instance, often concedes with ``I give up'' before providing an answer that it knows is wrong. R1 can also be remarkably ``uncertain'' in its output and in rare cases, it does not ``finish thinking,'' which suggests the need for an inference-time technique to ``wrap up'' before the context window limit is reached. We also quantify the effectiveness of reasoning longer with R1 and Gemini Thinking to identify the point beyond which more reasoning is unlikely to improve accuracy on our benchmark.",
        "tags": [
            "DeepSeek",
            "Large Language Models"
        ]
    },
    {
        "id": "275",
        "title": "SubTrack your Grad: Gradient Subspace Tracking for Memory and Time Efficient Full-Parameter LLM Training",
        "author": [
            "Sahar Rajabi",
            "Nayeema Nonta",
            "Sirisha Rambhatla"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01586",
        "abstract": "Training Large Language Models (LLMs) demand significant time and computational resources due to their large model sizes and optimizer states. To overcome these challenges, recent methods, such as BAdam, employ partial weight updates to enhance time and memory efficiency, though sometimes at the cost of performance. Others, like GaLore, focus on maintaining performance while optimizing memory usage through full parameter training, but may incur higher time complexity. By leveraging the low-rank structure of the gradient and the Grassmannian geometry, we propose SubTrack-Grad, a subspace tracking-based optimization method that efficiently tracks the evolving gradient subspace by incorporating estimation errors and previously identified subspaces. SubTrack-Grad delivers better or on-par results compared to GaLore, while significantly outperforming BAdam, which, despite being time-efficient, compromises performance. SubTrack-Grad reduces wall-time by up to 20.57% on GLUE tasks (15% average reduction) and up to 65% on SuperGLUE tasks (22% average reduction) compared to GaLore. Notably, for a 3B parameter model, GaLore incurred a substantial 157% increase in wall-time compared to full-rank training, whereas SubTrack-Grad exhibited a 31% increase, representing a 49% reduction in wall-time, while enjoying the same memory reductions as GaLore.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "276",
        "title": "Improving Transformer World Models for Data-Efficient RL",
        "author": [
            "Antoine Dedieu",
            "Joseph Ortiz",
            "Xinghua Lou",
            "Carter Wendelken",
            "Wolfgang Lehrach",
            "J Swaroop Guntupalli",
            "Miguel Lazaro-Gredilla",
            "Kevin Patrick Murphy"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01591",
        "abstract": "We present an approach to model-based RL that achieves a new state of the art performance on the challenging Craftax-classic benchmark, an open-world 2D survival game that requires agents to exhibit a wide range of general abilities -- such as strong generalization, deep exploration, and long-term reasoning. With a series of careful design choices aimed at improving sample efficiency, our MBRL algorithm achieves a reward of 67.4% after only 1M environment steps, significantly outperforming DreamerV3, which achieves 53.2%, and, for the first time, exceeds human performance of 65.0%. Our method starts by constructing a SOTA model-free baseline, using a novel policy architecture that combines CNNs and RNNs. We then add three improvements to the standard MBRL setup: (a) \"Dyna with warmup\", which trains the policy on real and imaginary data, (b) \"nearest neighbor tokenizer\" on image patches, which improves the scheme to create the transformer world model (TWM) inputs, and (c) \"block teacher forcing\", which allows the TWM to reason jointly about the future tokens of the next timestep.",
        "tags": [
            "RL",
            "Transformer"
        ]
    },
    {
        "id": "277",
        "title": "Reinforcement Learning for Long-Horizon Interactive LLM Agents",
        "author": [
            "Kevin Chen",
            "Marco Cusumano-Towner",
            "Brody Huval",
            "Aleksei Petrenko",
            "Jackson Hamburger",
            "Vladlen Koltun",
            "Philipp KrÃ¤henbÃ¼hl"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01600",
        "abstract": "Interactive digital agents (IDAs) leverage APIs of stateful digital environments to perform tasks in response to user requests. While IDAs powered by instruction-tuned large language models (LLMs) can react to feedback from interface invocations in multi-step exchanges, they have not been trained in their respective digital environments. Prior methods accomplish less than half of tasks in sophisticated benchmarks such as AppWorld. We present a reinforcement learning (RL) approach that trains IDAs directly in their target environments. We formalize this training as a partially observable Markov decision process and derive M-PPO, a data- and memory-efficient variant of proximal policy optimization. M-PPO uses no value network and maintains exactly one copy of the underlying LLM in memory, making its implementation straightforward and as memory-efficient as fine-tuning a single LLM. A 32-billion-parameter agent trained with M-PPO in the AppWorld environment outperforms the much larger OpenAI o1 agent by 9 percentage points (15% relative). To our knowledge, this is the first reported application of RL to IDAs that interact with a stateful, multi-domain, multi-app environment via direct API calls. Our analysis sheds light on the effectiveness of RL in this area, showing that the agent learns to consult the API documentation, avoid unwarranted assumptions, minimize confabulation, and recover from setbacks.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RL"
        ]
    },
    {
        "id": "278",
        "title": "Breaking Focus: Contextual Distraction Curse in Large Language Models",
        "author": [
            "Yue Huang",
            "Yanbo Wang",
            "Zixiang Xu",
            "Chujie Gao",
            "Siyuan Wu",
            "Jiayi Ye",
            "Xiuying Chen",
            "Pin-Yu Chen",
            "Xiangliang Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01609",
        "abstract": "Recent advances in Large Language Models (LLMs) have revolutionized generative systems, achieving excellent performance across diverse domains. Although these models perform well in controlled environments, their real-world applications frequently encounter inputs containing both essential and irrelevant details. Our investigation has revealed a critical vulnerability in LLMs, which we term Contextual Distraction Vulnerability (CDV). This phenomenon arises when models fail to maintain consistent performance on questions modified with semantically coherent but irrelevant context. To systematically investigate this vulnerability, we propose an efficient tree-based search methodology to automatically generate CDV examples. Our approach successfully generates CDV examples across four datasets, causing an average performance degradation of approximately 45% in state-of-the-art LLMs. To address this critical issue, we explore various mitigation strategies and find that post-targeted training approaches can effectively enhance model robustness against contextual distractions. Our findings highlight the fundamental nature of CDV as an ability-level challenge rather than a knowledge-level issue since models demonstrate the necessary knowledge by answering correctly in the absence of distractions. This calls the community's attention to address CDV during model development to ensure reliability. The code is available at https://github.com/wyf23187/LLM_CDV.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "279",
        "title": "Self-Improving Transformers Overcome Easy-to-Hard and Length Generalization Challenges",
        "author": [
            "Nayoung Lee",
            "Ziyang Cai",
            "Avi Schwarzschild",
            "Kangwook Lee",
            "Dimitris Papailiopoulos"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01612",
        "abstract": "Large language models often struggle with length generalization and solving complex problem instances beyond their training distribution. We present a self-improvement approach where models iteratively generate and learn from their own solutions, progressively tackling harder problems while maintaining a standard transformer architecture. Across diverse tasks including arithmetic, string manipulation, and maze solving, self-improving enables models to solve problems far beyond their initial training distribution-for instance, generalizing from 10-digit to 100-digit addition without apparent saturation. We observe that in some cases filtering for correct self-generated examples leads to exponential improvements in out-of-distribution performance across training rounds. Additionally, starting from pretrained models significantly accelerates this self-improvement process for several tasks. Our results demonstrate how controlled weak-to-strong curricula can systematically teach a model logical extrapolation without any changes to the positional embeddings, or the model architecture.",
        "tags": [
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "280",
        "title": "Large Language Models Are Human-Like Internally",
        "author": [
            "Tatsuki Kuribayashi",
            "Yohei Oseki",
            "Souhaib Ben Taieb",
            "Kentaro Inui",
            "Timothy Baldwin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01615",
        "abstract": "Recent cognitive modeling studies have reported that larger language models (LMs) exhibit a poorer fit to human reading behavior, leading to claims of their cognitive implausibility. In this paper, we revisit this argument through the lens of mechanistic interpretability and argue that prior conclusions were skewed by an exclusive focus on the final layers of LMs. Our analysis reveals that next-word probabilities derived from internal layers of larger LMs align with human sentence processing data as well as, or better than, those from smaller LMs. This alignment holds consistently across behavioral (self-paced reading times, gaze durations, MAZE task processing times) and neurophysiological (N400 brain potentials) measures, challenging earlier mixed results and suggesting that the cognitive plausibility of larger LMs has been underestimated. Furthermore, we first identify an intriguing relationship between LM layers and human measures: earlier layers correspond more closely with fast gaze durations, while later layers better align with relatively slower signals such as N400 potentials and MAZE processing times. Our work opens new avenues for interdisciplinary research at the intersection of mechanistic interpretability and cognitive modeling.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "281",
        "title": "A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods",
        "author": [
            "Isha Puri",
            "Shivchander Sudalairaj",
            "Guangxuan Xu",
            "Kai Xu",
            "Akash Srivastava"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01618",
        "abstract": "Large language models (LLMs) have achieved significant performance gains via scaling up model sizes and/or data. However, recent evidence suggests diminishing returns from such approaches, motivating scaling the computation spent at inference time. Existing inference-time scaling methods, usually with reward models, cast the task as a search problem, which tends to be vulnerable to reward hacking as a consequence of approximation errors in reward models. In this paper, we instead cast inference-time scaling as a probabilistic inference task and leverage sampling-based techniques to explore the typical set of the state distribution of a state-space model with an approximate likelihood, rather than optimize for its mode directly. We propose a novel inference-time scaling approach by adapting particle-based Monte Carlo methods to this task. Our empirical evaluation demonstrates that our methods have a 4-16x better scaling rate over our deterministic search counterparts on various challenging mathematical reasoning tasks. Using our approach, we show that Qwen2.5-Math-1.5B-Instruct can surpass GPT-4o accuracy in only 4 rollouts, while Qwen2.5-Math-7B-Instruct scales to o1 level accuracy in only 32 rollouts. Our work not only presents an effective method to inference-time scaling, but also connects the rich literature in probabilistic inference with inference-time scaling of LLMs to develop more robust algorithms in future work. Code and further information is available at https://probabilistic-inference-scaling.github.io.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "282",
        "title": "Learning to Generate Unit Tests for Automated Debugging",
        "author": [
            "Archiki Prasad",
            "Elias Stengel-Eskin",
            "Justin Chih-Yao Chen",
            "Zaid Khan",
            "Mohit Bansal"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01619",
        "abstract": "Unit tests (UTs) play an instrumental role in assessing code correctness as well as providing feedback to a large language model (LLM) as it iteratively debugs faulty code, motivating automated test generation. However, we uncover a trade-off between generating unit test inputs that reveal errors when given a faulty code and correctly predicting the unit test output without access to the gold solution. To address this trade-off, we propose UTGen, which teaches LLMs to generate unit test inputs that reveal errors along with their correct expected outputs based on task descriptions and candidate code. We integrate UTGen into UTDebug, a robust debugging pipeline that uses generated tests to help LLMs debug effectively. Since model-generated tests can provide noisy signals (e.g., from incorrectly predicted outputs), UTDebug (i) scales UTGen via test-time compute to improve UT output prediction, and (ii) validates and back-tracks edits based on multiple generated UTs to avoid overfitting. We show that UTGen outperforms UT generation baselines by 7.59% based on a metric measuring the presence of both error-revealing UT inputs and correct UT outputs. When used with UTDebug, we find that feedback from UTGen's unit tests improves pass@1 accuracy of Qwen-2.5 7B on HumanEvalFix and our own harder debugging split of MBPP+ by over 3% and 12.35% (respectively) over other LLM-based UT generation baselines.",
        "tags": [
            "LLMs",
            "Qwen"
        ]
    },
    {
        "id": "283",
        "title": "MFP-VTON: Enhancing Mask-Free Person-to-Person Virtual Try-On via Diffusion Transformer",
        "author": [
            "Le Shen",
            "Yanting Kang",
            "Rong Huang",
            "Zhijie Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01626",
        "abstract": "The garment-to-person virtual try-on (VTON) task, which aims to generate fitting images of a person wearing a reference garment, has made significant strides. However, obtaining a standard garment is often more challenging than using the garment already worn by the person. To improve ease of use, we propose MFP-VTON, a Mask-Free framework for Person-to-Person VTON. Recognizing the scarcity of person-to-person data, we adapt a garment-to-person model and dataset to construct a specialized dataset for this task. Our approach builds upon a pretrained diffusion transformer, leveraging its strong generative capabilities. During mask-free model fine-tuning, we introduce a Focus Attention loss to emphasize the garment of the reference person and the details outside the garment of the target person. Experimental results demonstrate that our model excels in both person-to-person and garment-to-person VTON tasks, generating high-fidelity fitting images.",
        "tags": [
            "Diffusion",
            "Diffusion Transformer",
            "Transformer",
            "Virtual Try-On"
        ]
    },
    {
        "id": "284",
        "title": "Harmonic Loss Trains Interpretable AI Models",
        "author": [
            "David D. Baek",
            "Ziming Liu",
            "Riya Tyagi",
            "Max Tegmark"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01628",
        "abstract": "In this paper, we introduce **harmonic loss** as an alternative to the standard cross-entropy loss for training neural networks and large language models (LLMs). Harmonic loss enables improved interpretability and faster convergence, owing to its scale invariance and finite convergence point by design, which can be interpreted as a class center. We first validate the performance of harmonic models across algorithmic, vision, and language datasets. Through extensive experiments, we demonstrate that models trained with harmonic loss outperform standard models by: (a) enhancing interpretability, (b) requiring less data for generalization, and (c) reducing grokking. Moreover, we compare a GPT-2 model trained with harmonic loss to the standard GPT-2, illustrating that the harmonic model develops more interpretable representations. Looking forward, we believe harmonic loss has the potential to become a valuable tool in domains with limited data availability or in high-stakes applications where interpretability and reliability are paramount, paving the way for more robust and efficient neural network models.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "285",
        "title": "TReMu: Towards Neuro-Symbolic Temporal Reasoning for LLM-Agents with Memory in Multi-Session Dialogues",
        "author": [
            "Yubin Ge",
            "Salvatore Romeo",
            "Jason Cai",
            "Raphael Shu",
            "Monica Sunkara",
            "Yassine Benajiba",
            "Yi Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01630",
        "abstract": "Temporal reasoning in multi-session dialogues presents a significant challenge which has been under-studied in previous temporal reasoning benchmarks. To bridge this gap, we propose a new evaluation task for temporal reasoning in multi-session dialogues and introduce an approach to construct a new benchmark by augmenting dialogues from LoCoMo and creating multi-choice QAs. Furthermore, we present TReMu, a new framework aimed at enhancing the temporal reasoning capabilities of LLM-agents in this context. Specifically, the framework employs \\textit{time-aware memorization} through timeline summarization, generating retrievable memory by summarizing events in each dialogue session with their inferred dates. Additionally, we integrate \\textit{neuro-symbolic temporal reasoning}, where LLMs generate Python code to perform temporal calculations and select answers. Experimental evaluations on popular LLMs demonstrate that our benchmark is challenging, and the proposed framework significantly improves temporal reasoning performance compared to baseline methods, raising from 29.83 on GPT-4o via standard prompting to 77.67 via our approach and highlighting its effectiveness in addressing temporal reasoning in multi-session dialogues.",
        "tags": [
            "GPT",
            "LLMs"
        ]
    },
    {
        "id": "286",
        "title": "Adversarial Reasoning at Jailbreaking Time",
        "author": [
            "Mahdi Sabbaghi",
            "Paul Kassianik",
            "George Pappas",
            "Yaron Singer",
            "Amin Karbasi",
            "Hamed Hassani"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01633",
        "abstract": "As large language models (LLMs) are becoming more capable and widespread, the study of their failure cases is becoming increasingly important. Recent advances in standardizing, measuring, and scaling test-time compute suggest new methodologies for optimizing models to achieve high performance on hard tasks. In this paper, we apply these advances to the task of model jailbreaking: eliciting harmful responses from aligned LLMs. We develop an adversarial reasoning approach to automatic jailbreaking via test-time computation that achieves SOTA attack success rates (ASR) against many aligned LLMs, even the ones that aim to trade inference-time compute for adversarial robustness. Our approach introduces a new paradigm in understanding LLM vulnerabilities, laying the foundation for the development of more robust and trustworthy AI systems.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "287",
        "title": "SliderSpace: Decomposing the Visual Capabilities of Diffusion Models",
        "author": [
            "Rohit Gandikota",
            "Zongze Wu",
            "Richard Zhang",
            "David Bau",
            "Eli Shechtman",
            "Nick Kolkin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01639",
        "abstract": "We present SliderSpace, a framework for automatically decomposing the visual capabilities of diffusion models into controllable and human-understandable directions. Unlike existing control methods that require a user to specify attributes for each edit direction individually, SliderSpace discovers multiple interpretable and diverse directions simultaneously from a single text prompt. Each direction is trained as a low-rank adaptor, enabling compositional control and the discovery of surprising possibilities in the model's latent space. Through extensive experiments on state-of-the-art diffusion models, we demonstrate SliderSpace's effectiveness across three applications: concept decomposition, artistic style exploration, and diversity enhancement. Our quantitative evaluation shows that SliderSpace-discovered directions decompose the visual structure of model's knowledge effectively, offering insights into the latent capabilities encoded within diffusion models. User studies further validate that our method produces more diverse and useful variations compared to baselines. Our code, data and trained weights are available at https://sliderspace.baulab.info",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "288",
        "title": "Normalizing flows for SU($N$) gauge theories employing singular value decomposition",
        "author": [
            "Javad Komijani",
            "Marina K. Marinkovic"
        ],
        "pdf": "https://arxiv.org/pdf/2501.18288",
        "abstract": "We present a progress report on the use of normalizing flows for generating gauge field configurations in pure SU(N) gauge theories. We discuss how the singular value decomposition can be used to construct gauge-invariant quantities, which serve as the building blocks for designing gauge-equivariant transformations of SU(N) gauge links. Using this novel approach, we build representative models for the SU(3) Wilson action on a \\( 4^4 \\) lattice with \\( \\beta = 1 \\). We train these models and provide an analysis of their performance, highlighting the effectiveness of the new technique for gauge-invariant transformations. We also provide a comparison between the efficiency of the proposed algorithm and the spectral flow of Wilson loops.",
        "tags": [
            "Normalizing Flows"
        ]
    },
    {
        "id": "289",
        "title": "AlphaSharpe: LLM-Driven Discovery of Robust Risk-Adjusted Metrics",
        "author": [
            "Kamer Ali Yuksel",
            "Hassan Sawaf"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00029",
        "abstract": "Financial metrics like the Sharpe ratio are pivotal in evaluating investment performance by balancing risk and return. However, traditional metrics often struggle with robustness and generalization, particularly in dynamic and volatile market conditions. This paper introduces AlphaSharpe, a novel framework leveraging large language models (LLMs) to iteratively evolve and optimize financial metrics. AlphaSharpe generates enhanced risk-return metrics that outperform traditional approaches in robustness and correlation with future performance metrics by employing iterative crossover, mutation, and evaluation. Key contributions of this work include: (1) an innovative use of LLMs for generating and refining financial metrics inspired by domain-specific knowledge, (2) a scoring mechanism to ensure the evolved metrics generalize effectively to unseen data, and (3) an empirical demonstration of 3x predictive power for future risk-return forecasting. Experimental results on a real-world dataset highlight the superiority of AlphaSharpe metrics, making them highly relevant for portfolio managers and financial decision-makers. This framework not only addresses the limitations of existing metrics but also showcases the potential of LLMs in advancing financial analytics, paving the way for informed and robust investment strategies.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "290",
        "title": "Segment Anything for Histopathology",
        "author": [
            "Titus Griebel",
            "Anwai Archit",
            "Constantin Pape"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00408",
        "abstract": "Nucleus segmentation is an important analysis task in digital pathology. However, methods for automatic segmentation often struggle with new data from a different distribution, requiring users to manually annotate nuclei and retrain data-specific models. Vision foundation models (VFMs), such as the Segment Anything Model (SAM), offer a more robust alternative for automatic and interactive segmentation. Despite their success in natural images, a foundation model for nucleus segmentation in histopathology is still missing. Initial efforts to adapt SAM have shown some success, but did not yet introduce a comprehensive model for diverse segmentation tasks. To close this gap, we introduce PathoSAM, a VFM for nucleus segmentation, based on training SAM on a diverse dataset. Our extensive experiments show that it is the new state-of-the-art model for automatic and interactive nucleus instance segmentation in histopathology. We also demonstrate how it can be adapted for other segmentation tasks, including semantic nucleus segmentation. For this task, we show that it yields results better than popular methods, while not yet beating the state-of-the-art, CellViT. Our models are open-source and compatible with popular tools for data annotation. We also provide scripts for whole-slide image segmentation. Our code and models are publicly available at https://github.com/computational-cell-analytics/patho-sam.",
        "tags": [
            "SAM",
            "Segment Anything",
            "Segmentation"
        ]
    },
    {
        "id": "291",
        "title": "MarketSenseAI 2.0: Enhancing Stock Analysis through LLM Agents",
        "author": [
            "George Fatouros",
            "Kostas Metaxas",
            "John Soldatos",
            "Manos Karathanassis"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00415",
        "abstract": "MarketSenseAI is a novel framework for holistic stock analysis which leverages Large Language Models (LLMs) to process financial news, historical prices, company fundamentals and the macroeconomic environment to support decision making in stock analysis and selection. In this paper, we present the latest advancements on MarketSenseAI, driven by rapid technological expansion in LLMs. Through a novel architecture combining Retrieval-Augmented Generation and LLM agents, the framework processes SEC filings and earnings calls, while enriching macroeconomic analysis through systematic processing of diverse institutional reports. We demonstrate a significant improvement in fundamental analysis accuracy over the previous version. Empirical evaluation on S\\&P 100 stocks over two years (2023-2024) shows MarketSenseAI achieving cumulative returns of 125.9% compared to the index return of 73.5%, while maintaining comparable risk profiles. Further validation on S\\&P 500 stocks during 2024 demonstrates the framework's scalability, delivering a 33.8% higher Sortino ratio than the market. This work marks a significant advancement in applying LLM technology to financial analysis, offering insights into the robustness of LLM-driven investment strategies.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "292",
        "title": "Sampling Binary Data by Denoising through Score Functions",
        "author": [
            "Francis Bach",
            "Saeed Saremi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00557",
        "abstract": "Gaussian smoothing combined with a probabilistic framework for denoising via the empirical Bayes formalism, i.e., the Tweedie-Miyasawa formula (TMF), are the two key ingredients in the success of score-based generative models in Euclidean spaces. Smoothing holds the key for easing the problem of learning and sampling in high dimensions, denoising is needed for recovering the original signal, and TMF ties these together via the score function of noisy data. In this work, we extend this paradigm to the problem of learning and sampling the distribution of binary data on the Boolean hypercube by adopting Bernoulli noise, instead of Gaussian noise, as a smoothing device. We first derive a TMF-like expression for the optimal denoiser for the Hamming loss, where a score function naturally appears. Sampling noisy binary data is then achieved using a Langevin-like sampler which we theoretically analyze for different noise levels. At high Bernoulli noise levels sampling becomes easy, akin to log-concave sampling in Euclidean spaces. In addition, we extend the sequential multi-measurement sampling of Saremi et al. (2024) to the binary setting where we can bring the \"effective noise\" down by sampling multiple noisy measurements at a fixed noise level, without the need for continuous-time stochastic processes. We validate our formalism and theoretical findings by experiments on synthetic data and binarized images.",
        "tags": [
            "Score-Based Generative"
        ]
    },
    {
        "id": "293",
        "title": "Decision-informed Neural Networks with Large Language Model Integration for Portfolio Optimization",
        "author": [
            "Yoontae Hwang",
            "Yaxuan Kong",
            "Stefan Zohren",
            "Yongjae Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00828",
        "abstract": "This paper addresses the critical disconnect between prediction and decision quality in portfolio optimization by integrating Large Language Models (LLMs) with decision-focused learning. We demonstrate both theoretically and empirically that minimizing the prediction error alone leads to suboptimal portfolio decisions. We aim to exploit the representational power of LLMs for investment decisions. An attention mechanism processes asset relationships, temporal dependencies, and macro variables, which are then directly integrated into a portfolio optimization layer. This enables the model to capture complex market dynamics and align predictions with the decision objectives. Extensive experiments on S\\&P100 and DOW30 datasets show that our model consistently outperforms state-of-the-art deep learning models. In addition, gradient-based analyses show that our model prioritizes the assets most crucial to decision making, thus mitigating the effects of prediction errors on portfolio performance. These findings underscore the value of integrating decision objectives into predictions for more robust and context-aware portfolio management.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "294",
        "title": "HASSLE-free: A unified Framework for Sparse plus Low-Rank Matrix Decomposition for LLMs",
        "author": [
            "Mehdi Makni",
            "Kayhan Behdin",
            "Zheng Xu",
            "Natalia Ponomareva",
            "Rahul Mazumder"
        ],
        "pdf": "https://arxiv.org/pdf/2502.00899",
        "abstract": "The impressive capabilities of large foundation models come at a cost of substantial computing resources to serve them. Compressing these pre-trained models is of practical interest as it can democratize deploying them to the machine learning community at large by lowering the costs associated with inference. A promising compression scheme is to decompose foundation models' dense weights into a sum of sparse plus low-rank matrices. In this paper, we design a unified framework coined HASSLE-free for (semi-structured) sparse plus low-rank matrix decomposition of foundation models. Our framework introduces the local layer-wise reconstruction error objective for this decomposition, we demonstrate that prior work solves a relaxation of this optimization problem; and we provide efficient and scalable methods to minimize the exact introduced optimization problem. HASSLE-free substantially outperforms state-of-the-art methods in terms of the introduced objective and a wide range of LLM evaluation benchmarks. For the Llama3-8B model with a 2:4 sparsity component plus a 64-rank component decomposition, a compression scheme for which recent work shows important inference acceleration on GPUs, HASSLE-free reduces the test perplexity by 12% for the WikiText-2 dataset and reduces the gap (compared to the dense model) of the average of eight popular zero-shot tasks by 15% compared to existing methods.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "295",
        "title": "A generative foundation model for an all-in-one seismic processing framework",
        "author": [
            "Shijun Cheng",
            "Randy Harsuko",
            "Tariq Alkhalifah"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01111",
        "abstract": "Seismic data often face challenges in their utilization due to noise contamination, incomplete acquisition, and limited low-frequency information, which hinder accurate subsurface imaging and interpretation. Traditional processing methods rely heavily on task-specific designs to address these challenges and fail to account for the variability of data. To address these limitations, we present a generative seismic foundation model (GSFM), a unified framework based on generative diffusion models (GDMs), designed to tackle multi-task seismic processing challenges, including denoising, backscattered noise attenuation, interpolation, and low-frequency extrapolation. GSFM leverages a pre-training stage on synthetic data to capture the features of clean, complete, and broadband seismic data distributions and applies an iterative fine-tuning strategy to adapt the model to field data. By adopting a target-oriented diffusion process prediction, GSFM improves computational efficiency without compromising accuracy. Synthetic data tests demonstrate GSFM surpasses benchmarks with equivalent architectures in all tasks and achieves performance comparable to traditional pre-training strategies, even after their fine-tuning. Also, field data tests suggest that our iterative fine-tuning approach addresses the generalization limitations of conventional pre-training and fine-tuning paradigms, delivering significantly enhanced performance across diverse tasks. Furthermore, GSFM's inherent probabilistic nature enables effective uncertainty quantification, offering valuable insights into the reliability of processing results.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "296",
        "title": "Compressed Image Generation with Denoising Diffusion Codebook Models",
        "author": [
            "Guy Ohayon",
            "Hila Manor",
            "Tomer Michaeli",
            "Michael Elad"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01189",
        "abstract": "We present a novel generative approach based on Denoising Diffusion Models (DDMs), which produces high-quality image samples along with their losslessly compressed bit-stream representations. This is obtained by replacing the standard Gaussian noise sampling in the reverse diffusion with a selection of noise samples from pre-defined codebooks of fixed iid Gaussian vectors. Surprisingly, we find that our method, termed Denoising Diffusion Codebook Model (DDCM), retains sample quality and diversity of standard DDMs, even for extremely small codebooks. We leverage DDCM and pick the noises from the codebooks that best match a given image, converting our generative model into a highly effective lossy image codec achieving state-of-the-art perceptual image compression results. More generally, by setting other noise selections rules, we extend our compression method to any conditional image generation task (e.g., image restoration), where the generated images are produced jointly with their condensed bit-stream representations. Our work is accompanied by a mathematical interpretation of the proposed compressed conditional generation schemes, establishing a connection with score-based approximations of posterior samplers for the tasks considered.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "297",
        "title": "One-step full gradient suffices for low-rank fine-tuning, provably and efficiently",
        "author": [
            "Yuanhe Zhang",
            "Fanghui Liu",
            "Yudong Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01235",
        "abstract": "This paper studies how to improve the performance of Low-Rank Adaption (LoRA) as guided by our theoretical analysis. Our first set of theoretical results show that for random initialization and linear models, \\textit{i)} LoRA will align to the certain singular subspace of one-step gradient of full fine-tuning; \\textit{ii)} preconditioners improve convergence in the high-rank case. These insights motivate us to focus on preconditioned LoRA using a specific spectral initialization strategy for aligning with certain subspaces. For both linear and nonlinear models, we prove that alignment and generalization guarantees can be directly achieved at initialization, and the subsequent linear convergence can be also built. Our analysis leads to the \\emph{LoRA-One} algorithm (using \\emph{One}-step gradient and preconditioning), a theoretically grounded algorithm that achieves significant empirical improvement over vanilla LoRA and its variants on several benchmarks. Our theoretical analysis, based on decoupling the learning dynamics and characterizing how spectral initialization contributes to feature learning, may be of independent interest for understanding matrix sensing and deep learning theory. The source code can be found in the https://github.com/YuanheZ/LoRA-One.",
        "tags": [
            "LoRA"
        ]
    },
    {
        "id": "298",
        "title": "Diffusion at Absolute Zero: Langevin Sampling Using Successive Moreau Envelopes",
        "author": [
            "Andreas Habring",
            "Alexander Falk",
            "Thomas Pock"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01358",
        "abstract": "In this article we propose a novel method for sampling from Gibbs distributions of the form $\\pi(x)\\propto\\exp(-U(x))$ with a potential $U(x)$. In particular, inspired by diffusion models we propose to consider a sequence $(\\pi^{t_k})_k$ of approximations of the target density, for which $\\pi^{t_k}\\approx \\pi$ for $k$ small and, on the other hand, $\\pi^{t_k}$ exhibits favorable properties for sampling for $k$ large. This sequence is obtained by replacing parts of the potential $U$ by its Moreau envelopes. Sampling is performed in an Annealed Langevin type procedure, that is, sequentially sampling from $\\pi^{t_k}$ for decreasing $k$, effectively guiding the samples from a simple starting density to the more complex target. In addition to a theoretical analysis we show experimental results supporting the efficacy of the method in terms of increased convergence speed and applicability to multi-modal densities $\\pi$.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "299",
        "title": "Fine-Tuning Discrete Diffusion Models with Policy Gradient Methods",
        "author": [
            "Oussama Zekri",
            "Nicolas BoullÃ©"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01384",
        "abstract": "Discrete diffusion models have recently gained significant attention due to their ability to process complex discrete structures for language modeling. However, fine-tuning these models with policy gradient methods, as is commonly done in Reinforcement Learning from Human Feedback (RLHF), remains a challenging task. We propose an efficient, broadly applicable, and theoretically justified policy gradient algorithm, called Score Entropy Policy Optimization (SEPO), for fine-tuning discrete diffusion models over non-differentiable rewards. Our numerical experiments across several discrete generative tasks demonstrate the scalability and efficiency of our method. Our code is available at https://github.com/ozekri/SEPO",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "300",
        "title": "Gamma/hadron separation in the TAIGA experiment with neural network methods",
        "author": [
            "E. O. Gres",
            "A. P. Kryukov",
            "P. A. Volchugov",
            "J. J. Dubenskaya",
            "D. P. Zhurov",
            "S. P. Polyakov",
            "E. B. Postnikov",
            "A. A. Vlaskina"
        ],
        "pdf": "https://arxiv.org/pdf/2502.01500",
        "abstract": "In this work, the ability of rare VHE gamma ray selection with neural network methods is investigated in the case when cosmic radiation flux strongly prevails (ratio up to {10^4} over the gamma radiation flux from a point source). This ratio is valid for the Crab Nebula in the TeV energy range, since the Crab is a well-studied source for calibration and test of various methods and installations in gamma astronomy. The part of TAIGA experiment which includes three Imaging Atmospheric Cherenkov Telescopes observes this gamma-source too. Cherenkov telescopes obtain images of Extensive Air Showers. Hillas parameters can be used to analyse images in standard processing method, or images can be processed with convolutional neural networks. In this work we would like to describe the main steps and results obtained in the gamma/hadron separation task from the Crab Nebula with neural network methods. The results obtained are compared with standard processing method applied in the TAIGA collaboration and using Hillas parameter cuts. It is demonstrated that a signal was received at the level of higher than 5.5{\\sigma} in 21 hours of Crab Nebula observations after processing the experimental data with the neural network method.",
        "tags": [
            "FLUX"
        ]
    }
]