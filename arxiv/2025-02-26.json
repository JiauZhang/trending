[
    {
        "id": "1",
        "title": "Large Language Models as Realistic Microservice Trace Generators",
        "author": [
            "Donghyun Kim",
            "Sriram Ravula",
            "Taemin Ha",
            "Alexandros G. Dimakis",
            "Daehyeok Kim",
            "Aditya Akella"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17439",
        "abstract": "Computer system workload traces, which record hardware or software events during application execution, are essential for understanding the behavior of complex systems and managing their processing and memory resources. However, obtaining real-world traces can be challenging due to the significant collection overheads in performance and privacy concerns that arise in proprietary systems. As a result, synthetic trace generation is considered a promising alternative to using traces collected in real-world production deployments. This paper proposes to train a large language model (LLM) to generate synthetic workload traces, specifically microservice call graphs. To capture complex and arbitrary hierarchical structures and implicit constraints in such traces, we fine-tune LLMs to generate each layer recursively, making call graph generation a sequence of easier steps. To further enforce learning constraints in traces and generate uncommon situations, we apply additional instruction tuning steps to align our model with the desired trace features. Our evaluation results show that our model can generate diverse realistic traces under various conditions and outperform existing methods in accuracy and validity. We show that our synthetically generated traces can effectively substitute real-world data in optimizing or tuning systems management tasks. We also show that our model can be adapted to perform key downstream trace-related tasks, specifically, predicting key trace features and infilling missing data given partial traces. Codes are available in https://github.com/ldos-project/TraceLLM.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "2",
        "title": "Renaissance of Literate Programming in the Era of LLMs: Enhancing LLM-Based Code Generation in Large-Scale Projects",
        "author": [
            "Wuyang Zhang",
            "Yansong Li",
            "Zeyu Dong",
            "Yu Wu",
            "Yingyao Zhou",
            "Duolei Wang",
            "Songsirou Xing",
            "Chichun Zhou",
            "Da Shen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17441",
        "abstract": "Large Language Models (LLMs) have helped programmers increase efficiency through code generation, comprehension, and repair. However, their application to large-scale projects remains challenging due to complex interdependencies and the extensive size of modern codebases. Although Knuth's concept of Literate Programming (LP) combines code and natural language to convey logic and intent, its potential for enhancing relationships in large projects has not been fully explored. In this study, we introduce the idea of Interoperable LP (ILP), which leverages literate programming principles to enhance the development of both small-scale documents and large-scale projects with LLMs. We investigate how LLMs perform under ILP-style instructions for both document-oriented tasks and entire projects. Recognizing that many researchers rely on well-structured templates to guide LLMs, we propose a concise prompt engineering method to write LP documents so LLMs can better be involved in code generation. We also examine the capacity of various LLMs to generate Scheme and Python code on the RepoBench benchmark, illustrating the advantages of our approach. Our findings indicate that ILP with LLMs can enhance LLM-based code generation in large-scale project development.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "3",
        "title": "Thinking Before Running! Efficient Code Generation with Thorough Exploration and Optimal Refinement",
        "author": [
            "Xiaoqing Zhang",
            "Yuhan Liu",
            "Flood Sung",
            "Xiuying Chen",
            "Rui Yan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17442",
        "abstract": "Code generation is crucial in software engineering for automating the coding process efficiently. While test-time computation methods show promise, they suffer from high latency due to multiple computation rounds. To overcome this, we introduce ThinkCoder, a framework that combines thorough exploration with optimal refinement. The exploration phase diversifies the solution space by searching for potential solutions, followed by a refinement phase that enhances precision. This approach allows us to select the best solution through careful consideration before taking action, avoiding excessive trial and error. To further minimize test-time computation overhead, we introduce preference-driven optimization with Reinforced Self-Training (ReST), which uses exploration trajectories from ThinkCoder to guide LLM's evolution. By learning preferences, this approach improves LLM's exploration efficiency, reducing computational costs while maintaining accuracy. ThinkCoder boosts the performance of multiple base LLMs, excelling on benchmarks like HumanEval and MBPP. Compared to SOTA models, it improves Pass@1 by 1.5\\% over MapCoder with just 21.7\\% of the computation cost. Against AgentCoder, ThinkCoder achieves a 0.6\\% higher Pass@1 after 2 rounds, outperforming AgentCoder's 5 rounds. Additionally, ReST with success trajectories enhances efficiency, allowing models like LLaMA2-7B to achieve competitive results using only 20\\% of the computational resources. These results highlight the framework's effectiveness and scalability.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "4",
        "title": "Studying How Configurations Impact Code Generation in LLMs: the Case of ChatGPT",
        "author": [
            "Benedetta Donato",
            "Leonardo Mariani",
            "Daniela Micucci",
            "Oliviero Riganelli"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17450",
        "abstract": "Leveraging LLMs for code generation is becoming increasingly common, as tools like ChatGPT can suggest method implementations with minimal input, such as a method signature and brief description. Empirical studies further highlight the effectiveness of LLMs in handling such tasks, demonstrating notable performance in code generation scenarios. However, LLMs are inherently non-deterministic, with their output influenced by parameters such as temperature, which regulates the model's level of creativity, and top-p, which controls the choice of the tokens that shall appear in the output. Despite their significance, the role of these parameters is often overlooked. This paper systematically studies the impact of these parameters, as well as the number of prompt repetitions required to account for non-determinism, in the context of 548 Java methods. We observe significantly different performances across different configurations of ChatGPT, with temperature having a marginal impact compared to the more prominent influence of the top-p parameter. Additionally, we show how creativity can enhance code generation tasks. Finally, we provide concrete recommendations for addressing the non-determinism of the model.",
        "tags": [
            "ChatGPT",
            "LLMs"
        ]
    },
    {
        "id": "5",
        "title": "User Intent to Use DeekSeep for Healthcare Purposes and their Trust in the Large Language Model: Multinational Survey Study",
        "author": [
            "Avishek Choudhury",
            "Yeganeh Shahsavar",
            "Hamid Shamszare"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17487",
        "abstract": "Large language models (LLMs) increasingly serve as interactive healthcare resources, yet user acceptance remains underexplored. This study examines how ease of use, perceived usefulness, trust, and risk perception interact to shape intentions to adopt DeepSeek, an emerging LLM-based platform, for healthcare purposes. A cross-sectional survey of 556 participants from India, the United Kingdom, and the United States was conducted to measure perceptions and usage patterns. Structural equation modeling assessed both direct and indirect effects, including potential quadratic relationships. Results revealed that trust plays a pivotal mediating role: ease of use exerts a significant indirect effect on usage intentions through trust, while perceived usefulness contributes to both trust development and direct adoption. By contrast, risk perception negatively affects usage intent, emphasizing the importance of robust data governance and transparency. Notably, significant non-linear paths were observed for ease of use and risk, indicating threshold or plateau effects. The measurement model demonstrated strong reliability and validity, supported by high composite reliabilities, average variance extracted, and discriminant validity measures. These findings extend technology acceptance and health informatics research by illuminating the multifaceted nature of user adoption in sensitive domains. Stakeholders should invest in trust-building strategies, user-centric design, and risk mitigation measures to encourage sustained and safe uptake of LLMs in healthcare. Future work can employ longitudinal designs or examine culture-specific variables to further clarify how user perceptions evolve over time and across different regulatory environments. Such insights are critical for harnessing AI to enhance outcomes.",
        "tags": [
            "DeepSeek",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "6",
        "title": "CoKV: Optimizing KV Cache Allocation via Cooperative Game",
        "author": [
            "Qiheng Sun",
            "Hongwei Zhang",
            "Haocheng Xia",
            "Jiayao Zhang",
            "Jinfei Liu",
            "Kui Ren"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17501",
        "abstract": "Large language models (LLMs) have achieved remarkable success on various aspects of human life. However, one of the major challenges in deploying these models is the substantial memory consumption required to store key-value pairs (KV), which imposes significant resource demands. Recent research has focused on KV cache budget allocation, with several approaches proposing head-level budget distribution by evaluating the importance of individual attention heads. These methods, however, assess the importance of heads independently, overlooking their cooperative contributions within the model, which may result in a deviation from their true impact on model performance. In light of this limitation, we propose CoKV, a novel method that models the cooperation between heads in model inference as a cooperative game. By evaluating the contribution of each head within the cooperative game, CoKV can allocate the cache budget more effectively. Extensive experiments show that CoKV achieves state-of-the-art performance on the LongBench benchmark using LLama-3-8B-Instruct and Mistral-7B models.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "7",
        "title": "C-3DPO: Constrained Controlled Classification for Direct Preference Optimization",
        "author": [
            "Kavosh Asadi",
            "Julien Han",
            "Xingzi Xu",
            "Dominique Perrault-Joncas",
            "Shoham Sabach",
            "Karim Bouyarmane",
            "Mohammad Ghavamzadeh"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17507",
        "abstract": "Direct preference optimization (DPO)-style algorithms have emerged as a promising approach for solving the alignment problem in AI. We present a novel perspective that formulates these algorithms as implicit classification algorithms. This classification framework enables us to recover many variants of DPO-style algorithms by choosing appropriate classification labels and loss functions. We then leverage this classification framework to demonstrate that the underlying problem solved in these algorithms is under-specified, making them susceptible to probability collapse of the winner-loser responses. We address this by proposing a set of constraints designed to control the movement of probability mass between the winner and loser in the reference and target policies. Our resulting algorithm, which we call Constrained Controlled Classification DPO (\\texttt{C-3DPO}), has a meaningful RLHF interpretation. By hedging against probability collapse, \\texttt{C-3DPO} provides practical improvements over vanilla \\texttt{DPO} when aligning several large language models using standard preference datasets.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "8",
        "title": "Recurrent Knowledge Identification and Fusion for Language Model Continual Learning",
        "author": [
            "Yujie Feng",
            "Xujia Wang",
            "Zexin Lu",
            "Shenghong Fu",
            "Guangyuan Shi",
            "Yongxin Xu",
            "Yasha Wang",
            "Philip S. Yu",
            "Xu Chu",
            "Xiao-Ming Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17510",
        "abstract": "Continual learning (CL) is crucial for deploying large language models (LLMs) in dynamic real-world environments without costly retraining. While recent model ensemble and model merging methods guided by parameter importance have gained popularity, they often struggle to balance knowledge transfer and forgetting, mainly due to the reliance on static importance estimates during sequential training. In this paper, we present Recurrent-KIF, a novel CL framework for Recurrent Knowledge Identification and Fusion, which enables dynamic estimation of parameter importance distributions to enhance knowledge transfer. Inspired by human continual learning, Recurrent-KIF employs an inner loop that rapidly adapts to new tasks while identifying important parameters, coupled with an outer loop that globally manages the fusion of new and historical knowledge through redundant knowledge pruning and key knowledge merging. These inner-outer loops iteratively perform multiple rounds of fusion, allowing Recurrent-KIF to leverage intermediate training information and adaptively adjust fusion strategies based on evolving importance distributions. Extensive experiments on two CL benchmarks with various model sizes (from 770M to 13B) demonstrate that Recurrent-KIF effectively mitigates catastrophic forgetting and enhances knowledge transfer.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "9",
        "title": "Int2Int: a framework for mathematics with transformers",
        "author": [
            "FranÃ§ois Charton"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17513",
        "abstract": "This paper documents Int2Int, an open source code base for using transformers on problems of mathematical research, with a focus on number theory and other problems involving integers. Int2Int is a complete PyTorch implementation of a transformer architecture, together with training and evaluation loops, and classes and functions to represent, generate and decode common mathematical objects. Ancillary code for data preparation, and Jupyter Notebooks for visualizing experimental results are also provided. This document presents the main features of Int2Int, serves as its user manual, and provides guidelines on how to extend it. Int2Int is released under the MIT licence, at https://github.com/FacebookResearch/Int2Int.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "10",
        "title": "SAE-V: Interpreting Multimodal Models for Enhanced Alignment",
        "author": [
            "Hantao Lou",
            "Changye Li",
            "Jiaming Ji",
            "Yaodong Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17514",
        "abstract": "With the integration of image modality, the semantic space of multimodal large language models (MLLMs) is more complex than text-only models, making their interpretability more challenging and their alignment less stable, particularly susceptible to low-quality data, which can lead to inconsistencies between modalities, hallucinations, and biased outputs. As a result, developing interpretability methods for MLLMs is crucial for improving alignment quality and efficiency. In text-only LLMs, Sparse Autoencoders (SAEs) have gained attention for their ability to interpret latent representations. However, extending SAEs to multimodal settings presents new challenges due to modality fusion and the difficulty of isolating cross-modal representations. To address these challenges, we introduce SAE-V, a mechanistic interpretability framework that extends the SAE paradigm to MLLMs. By identifying and analyzing interpretable features along with their corresponding data, SAE-V enables fine-grained interpretation of both model behavior and data quality, facilitating a deeper understanding of cross-modal interactions and alignment dynamics. Moreover, by utilizing cross-modal feature weighting, SAE-V provides an intrinsic data filtering mechanism to enhance model alignment without requiring additional models. Specifically, when applied to the alignment process of MLLMs, SAE-V-based data filtering methods could achieve more than 110% performance with less than 50% data. Our results highlight SAE-V's ability to enhance interpretability and alignment in MLLMs, providing insights into their internal mechanisms.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "11",
        "title": "Towards User-level Private Reinforcement Learning with Human Feedback",
        "author": [
            "Jiaming Zhang",
            "Mingxi Lei",
            "Meng Ding",
            "Mengdi Li",
            "Zihang Xiang",
            "Difei Xu",
            "Jinhui Xu",
            "Di Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17515",
        "abstract": "Reinforcement Learning with Human Feedback (RLHF) has emerged as an influential technique, enabling the alignment of large language models (LLMs) with human preferences. Despite the promising potential of RLHF, how to protect user preference privacy has become a crucial issue. Most previous work has focused on using differential privacy (DP) to protect the privacy of individual data. However, they have concentrated primarily on item-level privacy protection and have unsatisfactory performance for user-level privacy, which is more common in RLHF. This study proposes a novel framework, AUP-RLHF, which integrates user-level label DP into RLHF. We first show that the classical random response algorithm, which achieves an acceptable performance in item-level privacy, leads to suboptimal utility when in the user-level settings. We then establish a lower bound for the user-level label DP-RLHF and develop the AUP-RLHF algorithm, which guarantees $(\\varepsilon, \\delta)$ user-level privacy and achieves an improved estimation error. Experimental results show that AUP-RLHF outperforms existing baseline methods in sentiment generation and summarization tasks, achieving a better privacy-utility trade-off.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "12",
        "title": "A Survey on Mechanistic Interpretability for Multi-Modal Foundation Models",
        "author": [
            "Zihao Lin",
            "Samyadeep Basu",
            "Mohammad Beigi",
            "Varun Manjunatha",
            "Ryan A. Rossi",
            "Zichao Wang",
            "Yufan Zhou",
            "Sriram Balasubramanian",
            "Arman Zarei",
            "Keivan Rezaei",
            "Ying Shen",
            "Barry Menglong Yao",
            "Zhiyang Xu",
            "Qin Liu",
            "Yuxiang Zhang",
            "Yan Sun",
            "Shilong Liu",
            "Li Shen",
            "Hongxuan Li",
            "Soheil Feizi",
            "Lifu Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17516",
        "abstract": "The rise of foundation models has transformed machine learning research, prompting efforts to uncover their inner workings and develop more efficient and reliable applications for better control. While significant progress has been made in interpreting Large Language Models (LLMs), multimodal foundation models (MMFMs) - such as contrastive vision-language models, generative vision-language models, and text-to-image models - pose unique interpretability challenges beyond unimodal frameworks. Despite initial studies, a substantial gap remains between the interpretability of LLMs and MMFMs. This survey explores two key aspects: (1) the adaptation of LLM interpretability methods to multimodal models and (2) understanding the mechanistic differences between unimodal language models and crossmodal systems. By systematically reviewing current MMFM analysis techniques, we propose a structured taxonomy of interpretability methods, compare insights across unimodal and multimodal architectures, and highlight critical research gaps.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Text-to-Image"
        ]
    },
    {
        "id": "13",
        "title": "Recent Advances in Large Langauge Model Benchmarks against Data Contamination: From Static to Dynamic Evaluation",
        "author": [
            "Simin Chen",
            "Yiming Chen",
            "Zexin Li",
            "Yifan Jiang",
            "Zhongwei Wan",
            "Yixin He",
            "Dezhi Ran",
            "Tianle Gu",
            "Haizhou Li",
            "Tao Xie",
            "Baishakhi Ray"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17521",
        "abstract": "Data contamination has received increasing attention in the era of large language models (LLMs) due to their reliance on vast Internet-derived training corpora. To mitigate the risk of potential data contamination, LLM benchmarking has undergone a transformation from static to dynamic benchmarking. In this work, we conduct an in-depth analysis of existing static to dynamic benchmarking methods aimed at reducing data contamination risks. We first examine methods that enhance static benchmarks and identify their inherent limitations. We then highlight a critical gap-the lack of standardized criteria for evaluating dynamic benchmarks. Based on this observation, we propose a series of optimal design principles for dynamic benchmarking and analyze the limitations of existing dynamic benchmarks. This survey provides a concise yet comprehensive overview of recent advancements in data contamination research, offering valuable insights and a clear guide for future research efforts. We maintain a GitHub repository to continuously collect both static and dynamic benchmarking methods for LLMs. The repository can be found at this link.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "14",
        "title": "ConvoyLLM: Dynamic Multi-Lane Convoy Control Using LLMs",
        "author": [
            "Liping Lu",
            "Zhican He",
            "Duanfeng Chu",
            "Rukang Wang",
            "Saiqian Peng",
            "Pan Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17529",
        "abstract": "This paper proposes a novel method for multi-lane convoy formation control that uses large language models (LLMs) to tackle coordination challenges in dynamic highway environments. Each connected and autonomous vehicle in the convoy uses a knowledge-driven approach to make real-time adaptive decisions based on various scenarios. Our method enables vehicles to dynamically perform tasks, including obstacle avoidance, convoy joining/leaving, and escort formation switching, all while maintaining the overall convoy structure. We design a Interlaced formation control strategy based on locally dynamic distributed graphs, ensuring the convoy remains stable and flexible. We conduct extensive experiments in the SUMO simulation platform across multiple traffic scenarios, and the results demonstrate that the proposed method is effective, robust, and adaptable to dynamic environments. The code is available at: https://github.com/chuduanfeng/ConvoyLLM.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "15",
        "title": "Laplace-Beltrami Operator for Gaussian Splatting",
        "author": [
            "Hongyu Zhou",
            "Zorah LÃ¤hner"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17531",
        "abstract": "With the rising popularity of 3D Gaussian splatting and the expanse of applications from rendering to 3D reconstruction, there comes also a need for geometry processing applications directly on this new representation. While considering the centers of Gaussians as a point cloud or meshing them is an option that allows to apply existing algorithms, this might ignore information present in the data or be unnecessarily expensive. Additionally, Gaussian splatting tends to contain a large number of outliers which do not affect the rendering quality but need to be handled correctly in order not to produce noisy results in geometry processing applications. In this work, we propose a formulation to compute the Laplace-Beltrami operator, a widely used tool in geometry processing, directly on Gaussian splatting using the Mahalanobis distance. While conceptually similar to a point cloud Laplacian, our experiments show superior accuracy on the point clouds encoded in the Gaussian splatting centers and, additionally, the operator can be used to evaluate the quality of the output during optimization.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "16",
        "title": "The Lottery LLM Hypothesis, Rethinking What Abilities Should LLM Compression Preserve?",
        "author": [
            "Zhenheng Tang",
            "Xiang Liu",
            "Qian Wang",
            "Peijie Dong",
            "Bingsheng He",
            "Xiaowen Chu",
            "Bo Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17535",
        "abstract": "Motivated by reducing the computational and storage costs of LLMs, model compression and KV cache compression have attracted much attention from researchers. However, current methods predominantly emphasize maintaining the performance of compressed LLMs, as measured by perplexity or simple accuracy on tasks of common sense knowledge QA and basic arithmetic reasoning. In this blog, we present a brief review of recent advancements in LLMs related to retrieval-augmented generation, multi-step reasoning, external tools, and computational expressivity, all of which substantially enhance LLM performance. Then, we propose a lottery LLM hypothesis suggesting that for a given LLM and task, there exists a smaller lottery LLM capable of producing the same performance as the original LLM with the assistance of multi-step reasoning and external tools. Based on the review of current progress in LLMs, we discuss and summarize the essential capabilities that the lottery LLM and KV cache compression must possess, which are currently overlooked in existing methods.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "17",
        "title": "PosterSum: A Multimodal Benchmark for Scientific Poster Summarization",
        "author": [
            "Rohit Saxena",
            "Pasquale Minervini",
            "Frank Keller"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17540",
        "abstract": "Generating accurate and concise textual summaries from multimodal documents is challenging, especially when dealing with visually complex content like scientific posters. We introduce PosterSum, a novel benchmark to advance the development of vision-language models that can understand and summarize scientific posters into research paper abstracts. Our dataset contains 16,305 conference posters paired with their corresponding abstracts as summaries. Each poster is provided in image format and presents diverse visual understanding challenges, such as complex layouts, dense text regions, tables, and figures. We benchmark state-of-the-art Multimodal Large Language Models (MLLMs) on PosterSum and demonstrate that they struggle to accurately interpret and summarize scientific posters. We propose Segment & Summarize, a hierarchical method that outperforms current MLLMs on automated metrics, achieving a 3.14% gain in ROUGE-L. This will serve as a starting point for future research on poster summarization.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "18",
        "title": "Dataset Featurization: Uncovering Natural Language Features through Unsupervised Data Reconstruction",
        "author": [
            "Michal Bravansky",
            "Vaclav Kubon",
            "Suhas Hariharan",
            "Robert Kirk"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17541",
        "abstract": "Interpreting data is central to modern research. Large language models (LLMs) show promise in providing such natural language interpretations of data, yet simple feature extraction methods such as prompting often fail to produce accurate and versatile descriptions for diverse datasets and lack control over granularity and scale. To address these limitations, we propose a domain-agnostic method for dataset featurization that provides precise control over the number of features extracted while maintaining compact and descriptive representations comparable to human expert labeling. Our method optimizes the selection of informative binary features by evaluating the ability of an LLM to reconstruct the original data using those features. We demonstrate its effectiveness in dataset modeling tasks and through two case studies: (1) Constructing a feature representation of jailbreak tactics that compactly captures both the effectiveness and diversity of a larger set of human-crafted attacks; and (2) automating the discovery of features that align with human preferences, achieving accuracy and robustness comparable to expert-crafted features. Moreover, we show that the pipeline scales effectively, improving as additional features are sampled, making it suitable for large and diverse datasets.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "19",
        "title": "Towards Conditioning Clinical Text Generation for User Control",
        "author": [
            "Osman Alperen KoraÅ",
            "Rabi Bahnan",
            "Jens Kleesiek",
            "Amin Dada"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17571",
        "abstract": "Deploying natural language generation systems in clinical settings remains challenging despite advances in Large Language Models (LLMs), which continue to exhibit hallucinations and factual inconsistencies, necessitating human oversight. This paper explores automated dataset augmentation using LLMs as human proxies to condition LLMs for clinician control without increasing cognitive workload. On the BioNLP ACL'24 Discharge Me! Shared Task, we achieve new state-of-the-art results with simpler methods than prior submissions through more efficient training, yielding a 9\\% relative improvement without augmented training and up to 34\\% with dataset augmentation. Preliminary human evaluation further supports the effectiveness of our approach, highlighting the potential of augmenting clinical text generation for control to enhance relevance, accuracy, and factual consistency.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "20",
        "title": "Proactive Privacy Amnesia for Large Language Models: Safeguarding PII with Negligible Impact on Model Utility",
        "author": [
            "Martin Kuo",
            "Jingyang Zhang",
            "Jianyi Zhang",
            "Minxue Tang",
            "Louis DiValentin",
            "Aolin Ding",
            "Jingwei Sun",
            "William Chen",
            "Amin Hass",
            "Tianlong Chen",
            "Yiran Chen",
            "Hai Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17591",
        "abstract": "With the rise of large language models (LLMs), increasing research has recognized their risk of leaking personally identifiable information (PII) under malicious attacks. Although efforts have been made to protect PII in LLMs, existing methods struggle to balance privacy protection with maintaining model utility. In this paper, inspired by studies of amnesia in cognitive science, we propose a novel approach, Proactive Privacy Amnesia (PPA), to safeguard PII in LLMs while preserving their utility. This mechanism works by actively identifying and forgetting key memories most closely associated with PII in sequences, followed by a memory implanting using suitable substitute memories to maintain the LLM's functionality. We conduct evaluations across multiple models to protect common PII, such as phone numbers and physical addresses, against prevalent PII-targeted attacks, demonstrating the superiority of our method compared with other existing defensive techniques. The results show that our PPA method completely eliminates the risk of phone number exposure by 100% and significantly reduces the risk of physical address exposure by 9.8% - 87.6%, all while maintaining comparable model utility performance.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "21",
        "title": "Hallucination Detection in LLMs Using Spectral Features of Attention Maps",
        "author": [
            "Jakub Binkowski",
            "Denis Janiak",
            "Albert Sawczyn",
            "Bogdan Gabrys",
            "Tomasz Kajdanowicz"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17598",
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across various tasks but remain prone to hallucinations. Detecting hallucinations is essential for safety-critical applications, and recent methods leverage attention map properties to this end, though their effectiveness remains limited. In this work, we investigate the spectral features of attention maps by interpreting them as adjacency matrices of graph structures. We propose the $\\text{LapEigvals}$ method, which utilises the top-$k$ eigenvalues of the Laplacian matrix derived from the attention maps as an input to hallucination detection probes. Empirical evaluations demonstrate that our approach achieves state-of-the-art hallucination detection performance among attention-based methods. Extensive ablation studies further highlight the robustness and generalisation of $\\text{LapEigvals}$, paving the way for future advancements in the hallucination detection domain.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "22",
        "title": "MEDA: Dynamic KV Cache Allocation for Efficient Multimodal Long-Context Inference",
        "author": [
            "Zhongwei Wan",
            "Hui Shen",
            "Xin Wang",
            "Che Liu",
            "Zheda Mai",
            "Mi Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17599",
        "abstract": "Long-context Multimodal Large Language Models (MLLMs) that incorporate long text-image and text-video modalities, demand substantial resources as their multimodal Key-Value (KV) caches grow with increasing input lengths, challenging inference efficiency. Existing methods for KV cache compression, in both text-only and multimodal LLMs, have neglected attention density variations across layers, thus often adopting uniform or progressive reduction strategies for layer-wise cache allocation. In this work, we propose MEDA, a dynamic layer-wise KV cache allocation method for efficient multimodal long-context inference. As its core, MEDA utilizes cross-modal attention entropy to determine the KV cache size at each MLLMs layer. Given the dynamically allocated KV cache size at each layer, MEDA also employs a KV pair selection scheme to identify which KV pairs to select and a KV pair merging strategy that merges the selected and non-selected ones to preserve information from the entire context. MEDA achieves up to 72% KV cache memory reduction and 2.82 times faster decoding speed, while maintaining or enhancing performance on various multimodal tasks in long-context settings, including multi-images and long-video scenarios. Our code is released at https://github.com/AIoT-MLSys-Lab/MEDA.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "23",
        "title": "Representation Engineering for Large-Language Models: Survey and Research Challenges",
        "author": [
            "Lukasz Bartoszcze",
            "Sarthak Munshi",
            "Bryan Sukidi",
            "Jennifer Yen",
            "Zejia Yang",
            "David Williams-King",
            "Linh Le",
            "Kosi Asuzu",
            "Carsten Maple"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17601",
        "abstract": "Large-language models are capable of completing a variety of tasks, but remain unpredictable and intractable. Representation engineering seeks to resolve this problem through a new approach utilizing samples of contrasting inputs to detect and edit high-level representations of concepts such as honesty, harmfulness or power-seeking. We formalize the goals and methods of representation engineering to present a cohesive picture of work in this emerging discipline. We compare it with alternative approaches, such as mechanistic interpretability, prompt-engineering and fine-tuning. We outline risks such as performance decrease, compute time increases and steerability issues. We present a clear agenda for future research to build predictable, dynamic, safe and personalizable LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "24",
        "title": "Weaving the Cosmos: WASM-Powered Interchain Communication for AI Enabled Smart Contracts",
        "author": [
            "Rabimba Karanjai",
            "Lei Xu",
            "Weidong Shi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17604",
        "abstract": "In this era, significant transformations in industries and tool utilization are driven by AI/Large Language Models (LLMs) and advancements in Machine Learning. There's a growing emphasis on Machine Learning Operations(MLOps) for managing and deploying these AI models. Concurrently, the imperative for richer smart contracts and on-chain computation is escalating. Our paper introduces an innovative framework that integrates blockchain technology, particularly the Cosmos SDK, to facilitate on-chain AI inferences. This system, built on WebAssembly (WASM), enables interchain communication and deployment of WASM modules executing AI inferences across multiple blockchain nodes. We critically assess the framework from feasibility, scalability, and model security, with a special focus on its portability and engine-model agnostic deployment. The capability to support AI on-chain may enhance and expand the scope of smart contracts, and as a result enable new use cases and applications.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "25",
        "title": "PICASO: Permutation-Invariant Context Composition with State Space Models",
        "author": [
            "Tian Yu Liu",
            "Alessandro Achille",
            "Matthew Trager",
            "Aditya Golatkar",
            "Luca Zancato",
            "Stefano Soatto"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17605",
        "abstract": "Providing Large Language Models with relevant contextual knowledge at inference time has been shown to greatly improve the quality of their generations. This is often achieved by prepending informative passages of text, or 'contexts', retrieved from external knowledge bases to their input. However, processing additional contexts online incurs significant computation costs that scale with their length. State Space Models (SSMs) offer a promising solution by allowing a database of contexts to be mapped onto fixed-dimensional states from which to start the generation. A key challenge arises when attempting to leverage information present across multiple contexts, since there is no straightforward way to condition generation on multiple independent states in existing SSMs. To address this, we leverage a simple mathematical relation derived from SSM dynamics to compose multiple states into one that efficiently approximates the effect of concatenating textual contexts. Since the temporal ordering of contexts can often be uninformative, we enforce permutation-invariance by efficiently averaging states obtained via our composition algorithm across all possible context orderings. We evaluate our resulting method on WikiText and MSMARCO in both zero-shot and fine-tuned settings, and show that we can match the strongest performing baseline while enjoying on average 5.4x speedup.",
        "tags": [
            "Large Language Models",
            "SSMs",
            "State Space Models"
        ]
    },
    {
        "id": "26",
        "title": "ELMo-Tune-V2: LLM-Assisted Full-Cycle Auto-Tuning to Optimize LSM-Based Key-Value Stores",
        "author": [
            "Viraj Thakkar",
            "Qi Lin",
            "Kenanya Keandra Adriel Prasetyo",
            "Raden Haryosatyo Wisjnunandono",
            "Achmad Imam Kistijantoro",
            "Reza Fuad Rachmadi",
            "Zhichao Cao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17606",
        "abstract": "Log-Structured Merge-tree-based Key-Value Store (LSM-KVS) is a foundational storage engine serving diverse modern workloads, systems, and applications. To suit varying use cases, LSM-KVS allows a vast configuration space that controls core parameters like compaction, flush, and cache sizes, each consuming a shared pool of CPU, Memory, and Storage resources. Navigating the LSM-KVS configuration space necessitates knowledge of the impact of each configuration on the expected workload and underlying hardware. Beyond expensive and time-intensive human-expert-based tuning, existing LSM-KVS tuning solutions focus on tuning with specific workload expectations while limited to a narrow subset of parameters.\nThis paper introduces ELMo-Tune-V2, a framework that integrates Large Language Models (LLMs) at its foundation to demonstrate the potential of applying modern LLMs in data system optimization problems. ELMo-Tune-V2 leverages the contextual reasoning, cross-domain, and generative capabilities of LLMs to perform 1) self-navigated characterization and modeling of LSM-KVS workloads, 2) automatic tuning across a broad parameter space using cross-domain knowledge, and 3) real-time dynamic configuration adjustments for LSM-KVS. ELMo-Tune-V2 integrates three innovations: LLM-based workload synthesis for adaptive benchmark generation, feedback-driven iterative fine-tuning for configuration refinement, and real-time tuning to handle evolving workloads. Through detailed evaluation using RocksDB under several real-world applications across diverse scenarios, ELMo-Tune-V2 achieves performance improvements up to ~14X our YCSB benchmarks compared against default RocksDB configurations, and our end-to-end tests with upper-level applications, NebulaGraph and Kvrocks, demonstrate performance gains of 34% and 26%, respectively.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "27",
        "title": "Synthetic Text Generation for Training Large Language Models via Gradient Matching",
        "author": [
            "Dang Nguyen",
            "Zeman Li",
            "Mohammadhossein Bateni",
            "Vahab Mirrokni",
            "Meisam Razaviyayn",
            "Baharan Mirzasoleiman"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17607",
        "abstract": "Synthetic data has the potential to improve the performance, training efficiency, and privacy of real training examples. Nevertheless, existing approaches for synthetic text generation are mostly heuristics and cannot generate human-readable text without compromising the privacy of real data or provide performance guarantees for training Large Language Models (LLMs). In this work, we propose the first theoretically rigorous approach for generating synthetic human-readable text that guarantees the convergence and performance of LLMs during fine-tuning on a target task. To do so, we leverage Alternating Direction Method of Multipliers (ADMM) that iteratively optimizes the embeddings of synthetic examples to match the gradient of the target training or validation data, and maps them to a sequence of text tokens with low perplexity. In doing so, the generated synthetic text can guarantee convergence of the model to a close neighborhood of the solution obtained by fine-tuning on real data. Experiments on various classification tasks confirm the effectiveness of our proposed approach.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "28",
        "title": "Evaluating the Effect of Retrieval Augmentation on Social Biases",
        "author": [
            "Tianhui Zhang",
            "Yi Zhou",
            "Danushka Bollegala"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17611",
        "abstract": "Retrieval Augmented Generation (RAG) has gained popularity as a method for conveniently incorporating novel facts that were not seen during the pre-training stage in Large Language Model (LLM)-based Natural Language Generation (NLG) systems. However, LLMs are known to encode significant levels of unfair social biases. The modulation of these biases by RAG in NLG systems is not well understood. In this paper, we systematically study the relationship between the different components of a RAG system and the social biases presented in the text generated across three languages (i.e. English, Japanese and Chinese) and four social bias types (i.e. gender, race, age and religion). Specifically, using the Bias Question Answering (BBQ) benchmark datasets, we evaluate the social biases in RAG responses from document collections with varying levels of stereotypical biases, employing multiple LLMs used as generators. We find that the biases in document collections are often amplified in the generated responses, even when the generating LLM exhibits a low-level of bias. Our findings raise concerns about the use of RAG as a technique for injecting novel facts into NLG systems and call for careful evaluation of potential social biases in RAG applications before their real-world deployment.",
        "tags": [
            "LLMs",
            "RAG"
        ]
    },
    {
        "id": "29",
        "title": "Preconditioned normal equations for solving discretised partial differential equations",
        "author": [
            "Lorenzo Lazzarino",
            "Yuji Nakatsukasa",
            "Umberto Zerbinati"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17626",
        "abstract": "This paper explores preconditioning the normal equation for non-symmetric square linear systems arising from PDE discretization, focusing on methods like CGNE and LSQR. The concept of ``normal'' preconditioning is introduced and a strategy to construct preconditioners studying the associated ``normal'' PDE is presented. Numerical experiments on convection-diffusion problems demonstrate the effectiveness of this approach in achieving fast and stable convergence.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "30",
        "title": "Towards Robust Legal Reasoning: Harnessing Logical LLMs in Law",
        "author": [
            "Manuj Kant",
            "Sareh Nabi",
            "Manav Kant",
            "Roland Scharrer",
            "Megan Ma",
            "Marzieh Nabi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17638",
        "abstract": "Legal services rely heavily on text processing. While large language models (LLMs) show promise, their application in legal contexts demands higher accuracy, repeatability, and transparency. Logic programs, by encoding legal concepts as structured rules and facts, offer reliable automation, but require sophisticated text extraction. We propose a neuro-symbolic approach that integrates LLMs' natural language understanding with logic-based reasoning to address these limitations.\nAs a legal document case study, we applied neuro-symbolic AI to coverage-related queries in insurance contracts using both closed and open-source LLMs. While LLMs have improved in legal reasoning, they still lack the accuracy and consistency required for complex contract analysis. In our analysis, we tested three methodologies to evaluate whether a specific claim is covered under a contract: a vanilla LLM, an unguided approach that leverages LLMs to encode both the contract and the claim, and a guided approach that uses a framework for the LLM to encode the contract. We demonstrated the promising capabilities of LLM + Logic in the guided approach.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "31",
        "title": "CalibRefine: Deep Learning-Based Online Automatic Targetless LiDAR-Camera Calibration with Iterative and Attention-Driven Post-Refinement",
        "author": [
            "Lei Chenga",
            "Lihao Guoa",
            "Tianya Zhangb",
            "Tam Bangb",
            "Austin Harrisb",
            "Mustafa Hajijc",
            "Mina Sartipib",
            "Siyang Cao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17648",
        "abstract": "Accurate multi-sensor calibration is essential for deploying robust perception systems in applications such as autonomous driving, robotics, and intelligent transportation. Existing LiDAR-camera calibration methods often rely on manually placed targets, preliminary parameter estimates, or intensive data preprocessing, limiting their scalability and adaptability in real-world settings. In this work, we propose a fully automatic, targetless, and online calibration framework, CalibRefine, which directly processes raw LiDAR point clouds and camera images. Our approach is divided into four stages: (1) a Common Feature Discriminator that trains on automatically detected objects--using relative positions, appearance embeddings, and semantic classes--to generate reliable LiDAR-camera correspondences, (2) a coarse homography-based calibration, (3) an iterative refinement to incrementally improve alignment as additional data frames become available, and (4) an attention-based refinement that addresses non-planar distortions by leveraging a Vision Transformer and cross-attention mechanisms. Through extensive experiments on two urban traffic datasets, we show that CalibRefine delivers high-precision calibration results with minimal human involvement, outperforming state-of-the-art targetless methods and remaining competitive with, or surpassing, manually tuned baselines. Our findings highlight how robust object-level feature matching, together with iterative and self-supervised attention-based adjustments, enables consistent sensor fusion in complex, real-world conditions without requiring ground-truth calibration matrices or elaborate data preprocessing.",
        "tags": [
            "Robotics",
            "Transformer"
        ]
    },
    {
        "id": "32",
        "title": "Towards Typologically Aware Rescoring to Mitigate Unfaithfulness in Lower-Resource Languages",
        "author": [
            "Tsan Tsai Chan",
            "Xin Tong",
            "Thi Thu Uyen Hoang",
            "Barbare Tepnadze",
            "Wojciech Stempniak"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17664",
        "abstract": "Multilingual large language models (LLMs) are known to more frequently generate non-faithful output in resource-constrained languages (Guerreiro et al., 2023 - https://arxiv.org/abs/2303.16104), potentially because these typologically diverse languages are underrepresented in their training data. To mitigate unfaithfulness in such settings, we propose using computationally light auxiliary models to rescore the outputs of larger architectures. As proof of the feasibility of such an approach, we show that monolingual 4-layer BERT models pretrained from scratch on less than 700 MB of data without fine-tuning are able to identify faithful summaries with a mean accuracy of 88.33% in three genetically unrelated languages that differ in their morphological complexity - Vietnamese, Polish and Georgian. The same hyperparameter combination moreover generalises well to three other tasks, suggesting applications for rescoring beyond improving faithfulness. In order to inform typologically aware model selection, we also investigate how morphological complexity interacts with regularisation, model depth and training objectives, ultimately demonstrating that morphologically complex languages are more likely to benefit from dropout, while across languages downstream performance is enhanced most by shallow architectures as well as training using the standard BERT objectives.",
        "tags": [
            "BERT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "33",
        "title": "From Perceptions to Decisions: Wildfire Evacuation Decision Prediction with Behavioral Theory-informed LLMs",
        "author": [
            "Ruxiao Chen",
            "Chenguang Wang",
            "Yuran Sun",
            "Xilei Zhao",
            "Susu Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17701",
        "abstract": "Evacuation decision prediction is critical for efficient and effective wildfire response by helping emergency management anticipate traffic congestion and bottlenecks, allocate resources, and minimize negative impacts. Traditional statistical methods for evacuation decision prediction fail to capture the complex and diverse behavioral logic of different individuals. In this work, for the first time, we introduce FLARE, short for facilitating LLM for advanced reasoning on wildfire evacuation decision prediction, a Large Language Model (LLM)-based framework that integrates behavioral theories and models to streamline the Chain-of-Thought (CoT) reasoning and subsequently integrate with memory-based Reinforcement Learning (RL) module to provide accurate evacuation decision prediction and understanding. Our proposed method addresses the limitations of using existing LLMs for evacuation behavioral predictions, such as limited survey data, mismatching with behavioral theory, conflicting individual preferences, implicit and complex mental states, and intractable mental state-behavior mapping. Experiments on three post-wildfire survey datasets show an average of 20.47% performance improvement over traditional theory-informed behavioral models, with strong cross-event generalizability. Our complete code is publicly available at https://github.com/SusuXu-s-Lab/FLARE",
        "tags": [
            "LLMs",
            "RL"
        ]
    },
    {
        "id": "34",
        "title": "Contrastive Visual Data Augmentation",
        "author": [
            "Yu Zhou",
            "Bingxuan Li",
            "Mohan Tang",
            "Xiaomeng Jin",
            "Te-Lin Wu",
            "Kuan-Hao Huang",
            "Heng Ji",
            "Kai-Wei Chang",
            "Nanyun Peng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17709",
        "abstract": "Large multimodal models (LMMs) often struggle to recognize novel concepts, as they rely on pre-trained knowledge and have limited ability to capture subtle visual details. Domain-specific knowledge gaps in training also make them prone to confusing visually similar, commonly misrepresented, or low-resource concepts. To help LMMs better align nuanced visual features with language, improving their ability to recognize and reason about novel or rare concepts, we propose a Contrastive visual Data Augmentation (CoDA) strategy. CoDA extracts key contrastive textual and visual features of target concepts against the known concepts they are misrecognized as, and then uses multimodal generative models to produce targeted synthetic data. Automatic filtering of extracted features and augmented images is implemented to guarantee their quality, as verified by human annotators. We show the effectiveness and efficiency of CoDA on low-resource concept and diverse scene recognition datasets including INaturalist and SUN. We additionally collect NovelSpecies, a benchmark dataset consisting of newly discovered animal species that are guaranteed to be unseen by LMMs. LLaVA-1.6 1-shot updating results on these three datasets show CoDA significantly improves SOTA visual data augmentation strategies by 12.3% (NovelSpecies), 5.1% (SUN), and 6.0% (iNat) absolute gains in accuracy.",
        "tags": [
            "LLaVA"
        ]
    },
    {
        "id": "35",
        "title": "Mind the Gesture: Evaluating AI Sensitivity to Culturally Offensive Non-Verbal Gestures",
        "author": [
            "Akhila Yerukola",
            "Saadia Gabriel",
            "Nanyun Peng",
            "Maarten Sap"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17710",
        "abstract": "Gestures are an integral part of non-verbal communication, with meanings that vary across cultures, and misinterpretations that can have serious social and diplomatic consequences. As AI systems become more integrated into global applications, ensuring they do not inadvertently perpetuate cultural offenses is critical. To this end, we introduce Multi-Cultural Set of Inappropriate Gestures and Nonverbal Signs (MC-SIGNS), a dataset of 288 gesture-country pairs annotated for offensiveness, cultural significance, and contextual factors across 25 gestures and 85 countries. Through systematic evaluation using MC-SIGNS, we uncover critical limitations: text-to-image (T2I) systems exhibit strong US-centric biases, performing better at detecting offensive gestures in US contexts than in non-US ones; large language models (LLMs) tend to over-flag gestures as offensive; and vision-language models (VLMs) default to US-based interpretations when responding to universal concepts like wishing someone luck, frequently suggesting culturally inappropriate gestures. These findings highlight the urgent need for culturally-aware AI safety mechanisms to ensure equitable global deployment of AI technologies.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Text-to-Image"
        ]
    },
    {
        "id": "36",
        "title": "Spontaneous Giving and Calculated Greed in Language Models",
        "author": [
            "Yuxuan Li",
            "Hirokazu Shirado"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17720",
        "abstract": "Large language models, when trained with reinforcement learning, demonstrate advanced problem-solving capabilities through reasoning techniques like chain of thoughts and reflection. However, it is unclear how these reasoning capabilities extend to social intelligence. In this study, we investigate how reasoning influences model outcomes in social dilemmas. First, we examine the effects of chain-of-thought and reflection techniques in a public goods game. We then extend our analysis to six economic games on cooperation and punishment, comparing off-the-shelf non-reasoning and reasoning models. We find that reasoning models reduce cooperation and norm enforcement, prioritizing individual rationality. Consequently, groups with more reasoning models exhibit less cooperation and lower gains through repeated interactions. These behaviors parallel human tendencies of \"spontaneous giving and calculated greed.\" Our results suggest the need for AI architectures that incorporate social intelligence alongside reasoning capabilities to ensure that AI supports, rather than disrupts, human cooperative intuition.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "37",
        "title": "Aligning Compound AI Systems via System-level DPO",
        "author": [
            "Xiangwen Wang",
            "Yibo Jacky Zhang",
            "Zhoujie Ding",
            "Katherine Tsai",
            "Sanmi Koyejo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17721",
        "abstract": "Compound AI systems, comprising multiple interacting components such as LLM agents and external tools, demonstrate state-of-the-art results across diverse tasks. It is hence crucial to align components within the system to produce consistent results that match human expectations. However, conventional alignment methods, such as Direct Preference Optimization (DPO), are not directly applicable to compound AI systems. These challenges include the non-differentiable interactions between components, making end-to-end gradient optimization infeasible. Additionally, system-level preferences cannot be directly translated into component-level preferences, further complicating alignment. We address the issues by formulating compound AI systems as Directed Acyclic Graphs (DAGs), capturing the connections between agents and the data generation processes. We propose a system-level DPO (SysDPO) to jointly align compound systems by adapting the DPO to operate on these DAGs. We study the joint alignment of an LLM and a diffusion model to demonstrate the effectiveness of our approach. Our exploration provides insights into the alignment of compound AI systems and lays a foundation for future advancements.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "38",
        "title": "LLM Inference Acceleration via Efficient Operation Fusion",
        "author": [
            "Mahsa Salmani",
            "Ilya Soloveychik"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17728",
        "abstract": "The rapid development of the Transformer-based Large Language Models (LLMs) in recent years has been closely linked to their ever-growing and already enormous sizes. Many LLMs contain hundreds of billions of parameters and require dedicated hardware resources for training and inference. One of the key challenges inherent to the Transformer architecture is the requirement to support numerous non-linear transformations that involves normalization. For instance, each decoder block typically contains at least one Softmax operation and two Layernorms. The computation of the corresponding normalization scaling factors becomes a major bottleneck as it requires spatial collective operations. In other words, when it comes to the computation of denominators for Softmax and Layernorm, all vector elements must be aggregated into a single location, requiring significant communication. These collective operations slow down inference on Transformers by approximately 20%, defeating the whole purpose of distributed in-memory compute. In this work, we propose an extremely efficient technique that can completely hide the overhead caused by such collective operations. Note that each Softmax and Layernorm operation is typically followed by a linear layer. Since non-linear and linear operations are performed on different hardware engines, they can be easily parallelized once the algebra allows such commutation. By leveraging the inherent properties of linear operations, we can defer the normalization of the preceding Softmax and Layernorm until after the linear layer is computed. Now we can compute the collective scaling factors concurrently with the matrix multiplication and completely hide the latency of the former behind the latter. Such parallelization preserves the numerical accuracy while significantly improving the hardware utilization and reducing the overall latency.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "39",
        "title": "Detection of LLM-Paraphrased Code and Identification of the Responsible LLM Using Coding Style Features",
        "author": [
            "Shinwoo Park",
            "Hyundong Jin",
            "Jeong-won Cha",
            "Yo-Sub Han"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17749",
        "abstract": "Recent progress in large language models (LLMs) for code generation has raised serious concerns about intellectual property protection. Malicious users can exploit LLMs to produce paraphrased versions of proprietary code that closely resemble the original. While the potential for LLM-assisted code paraphrasing continues to grow, research on detecting it remains limited, underscoring an urgent need for detection system. We respond to this need by proposing two tasks. The first task is to detect whether code generated by an LLM is a paraphrased version of original human-written code. The second task is to identify which LLM is used to paraphrase the original code. For these tasks, we construct a dataset LPcode consisting of pairs of human-written code and LLM-paraphrased code using various LLMs.\nWe statistically confirm significant differences in the coding styles of human-written and LLM-paraphrased code, particularly in terms of naming consistency, code structure, and readability. Based on these findings, we develop LPcodedec, a detection method that identifies paraphrase relationships between human-written and LLM-generated code, and discover which LLM is used for the paraphrasing. LPcodedec outperforms the best baselines in two tasks, improving F1 scores by 2.64% and 15.17% while achieving speedups of 1,343x and 213x, respectively.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "40",
        "title": "Design and implementation of a distributed security threat detection system integrating federated learning and multimodal LLM",
        "author": [
            "Yuqing Wang",
            "Xiao Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17763",
        "abstract": "Traditional security protection methods struggle to address sophisticated attack vectors in large-scale distributed systems, particularly when balancing detection accuracy with data privacy concerns. This paper presents a novel distributed security threat detection system that integrates federated learning with multimodal large language models (LLMs). Our system leverages federated learning to ensure data privacy while employing multimodal LLMs to process heterogeneous data sources including network traffic, system logs, images, and sensor data. Experimental evaluation on a 10TB distributed dataset demonstrates that our approach achieves 96.4% detection accuracy, outperforming traditional baseline models by 4.1 percentage points. The system reduces both false positive and false negative rates by 1.8 and 2.4 percentage points respectively. Performance analysis shows that our system maintains efficient processing capabilities in distributed environments, requiring 180 seconds for model training and 3.8 seconds for threat detection across the distributed network. These results demonstrate significant improvements in detection accuracy and computational efficiency while preserving data privacy, suggesting strong potential for real-world deployment in large-scale security systems.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "41",
        "title": "DeepSeek vs. ChatGPT: A Comparative Study for Scientific Computing and Scientific Machine Learning Tasks",
        "author": [
            "Qile Jiang",
            "Zhiwei Gao",
            "George Em Karniadakis"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17764",
        "abstract": "Large Language Models (LLMs) have emerged as powerful tools for tackling a wide range of problems, including those in scientific computing, particularly in solving partial differential equations (PDEs). However, different models exhibit distinct strengths and preferences, resulting in varying levels of performance. In this paper, we compare the capabilities of the most advanced LLMs--ChatGPT and DeepSeek--along with their reasoning-optimized versions in addressing computational challenges. Specifically, we evaluate their proficiency in solving traditional numerical problems in scientific computing as well as leveraging scientific machine learning techniques for PDE-based problems. We designed all our experiments so that a non-trivial decision is required, e.g. defining the proper space of input functions for neural operator learning. Our findings reveal that the latest model, ChatGPT o3-mini-high, usually delivers the most accurate results while also responding significantly faster than its reasoning counterpart, DeepSeek R1. This enhanced speed and accuracy make ChatGPT o3-mini-high a more practical and efficient choice for diverse computational tasks at this juncture.",
        "tags": [
            "ChatGPT",
            "DeepSeek",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "42",
        "title": "Improving Transformer Based Line Segment Detection with Matched Predicting and Re-ranking",
        "author": [
            "Xin Tong",
            "Shi Peng",
            "Baojie Tian",
            "Yufei Guo",
            "Xuhui Huang",
            "Zhe Ma"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17766",
        "abstract": "Classical Transformer-based line segment detection methods have delivered impressive results. However, we observe that some accurately detected line segments are assigned low confidence scores during prediction, causing them to be ranked lower and potentially suppressed. Additionally, these models often require prolonged training periods to achieve strong performance, largely due to the necessity of bipartite matching. In this paper, we introduce RANK-LETR, a novel Transformer-based line segment detection method. Our approach leverages learnable geometric information to refine the ranking of predicted line segments by enhancing the confidence scores of high-quality predictions in a posterior verification step. We also propose a new line segment proposal method, wherein the feature point nearest to the centroid of the line segment directly predicts the location, significantly improving training efficiency and stability. Moreover, we introduce a line segment ranking loss to stabilize rankings during training, thereby enhancing the generalization capability of the model. Experimental results demonstrate that our method outperforms other Transformer-based and CNN-based approaches in prediction accuracy while requiring fewer training epochs than previous Transformer-based models.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "43",
        "title": "FoREST: Frame of Reference Evaluation in Spatial Reasoning Tasks",
        "author": [
            "Tanawan Premsri",
            "Parisa Kordjamshidi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17775",
        "abstract": "Spatial reasoning is a fundamental aspect of human intelligence. One key concept in spatial cognition is the Frame of Reference (FoR), which identifies the perspective of spatial expressions. Despite its significance, FoR has received limited attention in AI models that need spatial intelligence. There is a lack of dedicated benchmarks and in-depth evaluation of large language models (LLMs) in this area. To address this issue, we introduce the Frame of Reference Evaluation in Spatial Reasoning Tasks (FoREST) benchmark, designed to assess FoR comprehension in LLMs. We evaluate LLMs on answering questions that require FoR comprehension and layout generation in text-to-image models using FoREST. Our results reveal a notable performance gap across different FoR classes in various LLMs, affecting their ability to generate accurate layouts for text-to-image generation. This highlights critical shortcomings in FoR comprehension. To improve FoR understanding, we propose Spatial-Guided prompting, which improves LLMs ability to extract essential spatial concepts. Our proposed method improves overall performance across spatial reasoning tasks.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Text-to-Image"
        ]
    },
    {
        "id": "44",
        "title": "Tip of the Tongue Query Elicitation for Simulated Evaluation",
        "author": [
            "Yifan He",
            "To Eun Kim",
            "Fernando Diaz",
            "Jaime Arguello",
            "Bhaskar Mitra"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17776",
        "abstract": "Tip-of-the-tongue (TOT) search occurs when a user struggles to recall a specific identifier, such as a document title. While common, existing search systems often fail to effectively support TOT scenarios. Research on TOT retrieval is further constrained by the challenge of collecting queries, as current approaches rely heavily on community question-answering (CQA) websites, leading to labor-intensive evaluation and domain bias. To overcome these limitations, we introduce two methods for eliciting TOT queries - leveraging large language models (LLMs) and human participants - to facilitate simulated evaluations of TOT retrieval systems. Our LLM-based TOT user simulator generates synthetic TOT queries at scale, achieving high correlations with how CQA-based TOT queries rank TOT retrieval systems when tested in the Movie domain. Additionally, these synthetic queries exhibit high linguistic similarity to CQA-derived queries. For human-elicited queries, we developed an interface that uses visual stimuli to place participants in a TOT state, enabling the collection of natural queries. In the Movie domain, system rank correlation and linguistic similarity analyses confirm that human-elicited queries are both effective and closely resemble CQA-based queries. These approaches reduce reliance on CQA-based data collection while expanding coverage to underrepresented domains, such as Landmark and Person. LLM-elicited queries for the Movie, Landmark, and Person domains have been released as test queries in the TREC 2024 TOT track, with human-elicited queries scheduled for inclusion in the TREC 2025 TOT track. Additionally, we provide source code for synthetic query generation and the human query collection interface, along with curated visual stimuli used for eliciting TOT queries.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "45",
        "title": "MuCoS: Efficient Drug-Target Prediction through Multi-Context-Aware Sampling",
        "author": [
            "Haji Gul",
            "Abdul Gani Haji Naim",
            "Ajaz A. Bhat"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17784",
        "abstract": "Drug-target interactions are critical for understanding biological processes and advancing drug discovery. However, traditional methods such as ComplEx-SE, TransE, and DistMult struggle with unseen relationships and negative triplets, which limits their effectiveness in drug-target prediction. To address these challenges, we propose Multi-Context-Aware Sampling (MuCoS), an efficient and positively accurate method for drug-target prediction. MuCoS reduces computational complexity by prioritizing neighbors of higher density to capture informative structural patterns. These optimized neighborhood representations are integrated with BERT, enabling contextualized embeddings for accurate prediction of missing relationships or tail entities. MuCoS avoids the need for negative triplet sampling, reducing computation while improving performance over unseen entities and relations. Experiments on the KEGG50k biomedical dataset show that MuCoS improved over existing models by 13\\% on MRR, 7\\% on Hits@1, 4\\% on Hits@3, and 18\\% on Hits@10 for the general relationship, and by 6\\% on MRR, 1\\% on Hits@1, 3\\% on Hits@3, and 12\\% on Hits@10 for prediction of drug-target relationship.",
        "tags": [
            "BERT"
        ]
    },
    {
        "id": "46",
        "title": "Exploring the Potential of Large Language Models for Estimating the Reading Comprehension Question Difficulty",
        "author": [
            "Yoshee Jain",
            "John Hollander",
            "Amber He",
            "Sunny Tang",
            "Liang Zhang",
            "John Sabatini"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17785",
        "abstract": "Reading comprehension is a key for individual success, yet the assessment of question difficulty remains challenging due to the extensive human annotation and large-scale testing required by traditional methods such as linguistic analysis and Item Response Theory (IRT). While these robust approaches provide valuable insights, their scalability is limited. There is potential for Large Language Models (LLMs) to automate question difficulty estimation; however, this area remains underexplored. Our study investigates the effectiveness of LLMs, specifically OpenAI's GPT-4o and o1, in estimating the difficulty of reading comprehension questions using the Study Aid and Reading Assessment (SARA) dataset. We evaluated both the accuracy of the models in answering comprehension questions and their ability to classify difficulty levels as defined by IRT. The results indicate that, while the models yield difficulty estimates that align meaningfully with derived IRT parameters, there are notable differences in their sensitivity to extreme item characteristics. These findings suggest that LLMs can serve as the scalable method for automated difficulty assessment, particularly in dynamic interactions between learners and Adaptive Instructional Systems (AIS), bridging the gap between traditional psychometric techniques and modern AIS for reading comprehension and paving the way for more adaptive and personalized educational assessments.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "47",
        "title": "AIR: Complex Instruction Generation via Automatic Iterative Refinement",
        "author": [
            "Wei Liu",
            "Yancheng He",
            "Hui Huang",
            "Chengwei Hu",
            "Jiaheng Liu",
            "Shilong Li",
            "Wenbo Su",
            "Bo Zheng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17787",
        "abstract": "With the development of large language models, their ability to follow simple instructions has significantly improved. However, adhering to complex instructions remains a major challenge. Current approaches to generating complex instructions are often irrelevant to the current instruction requirements or suffer from limited scalability and diversity. Moreover, methods such as back-translation, while effective for simple instruction generation, fail to leverage the rich contents and structures in large web corpora. In this paper, we propose a novel automatic iterative refinement framework to generate complex instructions with constraints, which not only better reflects the requirements of real scenarios but also significantly enhances LLMs' ability to follow complex instructions. The AIR framework consists of two stages: (1)Generate an initial instruction from a document; (2)Iteratively refine instructions with LLM-as-judge guidance by comparing the model's output with the document to incorporate valuable constraints. Finally, we construct the AIR-10K dataset with 10K complex instructions and demonstrate that instructions generated with our approach significantly improve the model's ability to follow complex instructions, outperforming existing methods for instruction generation.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "48",
        "title": "Synthia: Novel Concept Design with Affordance Composition",
        "author": [
            "Xiaomeng Jin",
            "Hyeonjeong Ha",
            "Jeonghwan Kim",
            "Jiateng Liu",
            "Zhenhailong Wang",
            "Khanh Duy Nguyen",
            "Ansel Blume",
            "Nanyun Peng",
            "Kai-wei Chang",
            "Heng Ji"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17793",
        "abstract": "Text-to-image (T2I) models enable rapid concept design, making them widely used in AI-driven design. While recent studies focus on generating semantic and stylistic variations of given design concepts, functional coherence--the integration of multiple affordances into a single coherent concept--remains largely overlooked. In this paper, we introduce SYNTHIA, a framework for generating novel, functionally coherent designs based on desired affordances. Our approach leverages a hierarchical concept ontology that decomposes concepts into parts and affordances, serving as a crucial building block for functionally coherent design. We also develop a curriculum learning scheme based on our ontology that contrastively fine-tunes T2I models to progressively learn affordance composition while maintaining visual novelty. To elaborate, we (i) gradually increase affordance distance, guiding models from basic concept-affordance association to complex affordance compositions that integrate parts of distinct affordances into a single, coherent form, and (ii) enforce visual novelty by employing contrastive objectives to push learned representations away from existing concepts. Experimental results show that SYNTHIA outperforms state-of-the-art T2I models, demonstrating absolute gains of 25.1% and 14.7% for novelty and functional coherence in human evaluation, respectively.",
        "tags": [
            "Text-to-Image"
        ]
    },
    {
        "id": "49",
        "title": "LAM: Large Avatar Model for One-shot Animatable Gaussian Head",
        "author": [
            "Yisheng He",
            "Xiaodong Gu",
            "Xiaodan Ye",
            "Chao Xu",
            "Zhengyi Zhao",
            "Yuan Dong",
            "Weihao Yuan",
            "Zilong Dong",
            "Liefeng Bo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17796",
        "abstract": "We present LAM, an innovative Large Avatar Model for animatable Gaussian head reconstruction from a single image. Unlike previous methods that require extensive training on captured video sequences or rely on auxiliary neural networks for animation and rendering during inference, our approach generates Gaussian heads that are immediately animatable and renderable. Specifically, LAM creates an animatable Gaussian head in a single forward pass, enabling reenactment and rendering without additional networks or post-processing steps. This capability allows for seamless integration into existing rendering pipelines, ensuring real-time animation and rendering across a wide range of platforms, including mobile phones. The centerpiece of our framework is the canonical Gaussian attributes generator, which utilizes FLAME canonical points as queries. These points interact with multi-scale image features through a Transformer to accurately predict Gaussian attributes in the canonical space. The reconstructed canonical Gaussian avatar can then be animated utilizing standard linear blend skinning (LBS) with corrective blendshapes as the FLAME model did and rendered in real-time on various platforms. Our experimental results demonstrate that LAM outperforms state-of-the-art methods on existing benchmarks.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "50",
        "title": "Your Language Model May Think Too Rigidly: Achieving Reasoning Consistency with Symmetry-Enhanced Training",
        "author": [
            "Yihang Yao",
            "Zhepeng Cen",
            "Miao Li",
            "William Han",
            "Yuyou Zhang",
            "Emerson Liu",
            "Zuxin Liu",
            "Chuang Gan",
            "Ding Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17800",
        "abstract": "Large Language Models (LLMs) have demonstrated strong reasoning capabilities across various tasks. However, even minor variations in query phrasing, despite preserving the underlying semantic meaning, can significantly affect their performance. To address this, we focus on enhancing LLMs' awareness of symmetry in query variations and propose syMmetry-ENhanceD (MEND) Data Augmentation, a data-centric approach that improves the model's ability to extract useful information from context. Unlike existing methods that emphasize reasoning chain augmentation, our approach improves model robustness at the knowledge extraction stage through query augmentations, enabling more data-efficient training and stronger generalization to Out-of-Distribution (OOD) settings. Extensive experiments on both logical and arithmetic reasoning tasks show that MEND enhances reasoning performance across diverse query variations, providing new insight into improving LLM robustness through structured dataset curation.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "51",
        "title": "DocPuzzle: A Process-Aware Benchmark for Evaluating Realistic Long-Context Reasoning Capabilities",
        "author": [
            "Tianyi Zhuang",
            "Chuqiao Kuang",
            "Xiaoguang Li",
            "Yihua Teng",
            "Jihao Wu",
            "Yasheng Wang",
            "Lifeng Shang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17807",
        "abstract": "We present DocPuzzle, a rigorously constructed benchmark for evaluating long-context reasoning capabilities in large language models (LLMs). This benchmark comprises 100 expert-level QA problems requiring multi-step reasoning over long real-world documents. To ensure the task quality and complexity, we implement a human-AI collaborative annotation-validation pipeline. DocPuzzle introduces an innovative evaluation framework that mitigates guessing bias through checklist-guided process analysis, establishing new standards for assessing reasoning capacities in LLMs. Our evaluation results show that: 1)Advanced slow-thinking reasoning models like o1-preview(69.7%) and DeepSeek-R1(66.3%) significantly outperform best general instruct models like Claude 3.5 Sonnet(57.7%); 2)Distilled reasoning models like DeepSeek-R1-Distill-Qwen-32B(41.3%) falls far behind the teacher model, suggesting challenges to maintain the generalization of reasoning capabilities relying solely on distillation.",
        "tags": [
            "DeepSeek",
            "LLMs",
            "Large Language Models",
            "Qwen"
        ]
    },
    {
        "id": "52",
        "title": "URO-Bench: A Comprehensive Benchmark for End-to-End Spoken Dialogue Models",
        "author": [
            "Ruiqi Yan",
            "Xiquan Li",
            "Wenxi Chen",
            "Zhikang Niu",
            "Chen Yang",
            "Ziyang Ma",
            "Kai Yu",
            "Xie Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17810",
        "abstract": "In recent years, with advances in large language models (LLMs), end-to-end spoken dialogue models (SDMs) have made significant strides. Compared to text-based LLMs, the evaluation of SDMs needs to take speech-related aspects into account, such as paralinguistic information and speech quality. However, there is still a lack of comprehensive evaluations for SDMs in speech-to-speech (S2S) scenarios. To address this gap, we propose URO-Bench, an extensive benchmark for SDMs. Notably, URO-Bench is the first S2S benchmark that covers evaluations about multilingualism, multi-round dialogues, and paralinguistics. Our benchmark is divided into two difficulty levels: basic track and pro track, consisting of 16 and 20 datasets respectively, evaluating the model's abilities in Understanding, Reasoning, and Oral conversation. Evaluations on our proposed benchmark reveal that current open-source SDMs perform rather well in daily QA tasks, but lag behind their backbone LLMs in terms of instruction-following ability and also suffer from catastrophic forgetting. Their performance in advanced evaluations of paralinguistic information and audio understanding remains subpar, highlighting the need for further research in this direction. We hope that URO-Bench can effectively facilitate the development of spoken dialogue models by providing a multifaceted evaluation of existing models and helping to track progress in this area.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "53",
        "title": "Predicting Through Generation: Why Generation Is Better for Prediction",
        "author": [
            "Md Kowsher",
            "Nusrat Jahan Prottasha",
            "Prakash Bhat",
            "Chun-Nam Yu",
            "Mojtaba Soltanalian",
            "Ivan Garibay",
            "Ozlem Garibay",
            "Chen Chen",
            "Niloofar Yousefi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17817",
        "abstract": "This paper argues that generating output tokens is more effective than using pooled representations for prediction tasks because token-level generation retains more mutual information. Since LLMs are trained on massive text corpora using next-token prediction, generation aligns naturally with their learned behavior. Using the Data Processing Inequality (DPI), we provide both theoretical and empirical evidence supporting this claim. However, autoregressive models face two key challenges when used for prediction: (1) exposure bias, where the model sees ground truth tokens during training but relies on its own predictions during inference, leading to errors, and (2) format mismatch, where discrete tokens do not always align with the tasks required output structure. To address these challenges, we introduce PredGen(Predicting Through Generating), an end to end framework that (i) uses scheduled sampling to reduce exposure bias, and (ii) introduces a task adapter to convert the generated tokens into structured outputs. Additionally, we introduce Writer-Director Alignment Loss (WDAL), which ensures consistency between token generation and final task predictions, improving both text coherence and numerical accuracy. We evaluate PredGen on multiple classification and regression benchmarks. Our results show that PredGen consistently outperforms standard baselines, demonstrating its effectiveness in structured prediction tasks.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "54",
        "title": "A General Framework to Enhance Fine-tuning-based LLM Unlearning",
        "author": [
            "Jie Ren",
            "Zhenwei Dai",
            "Xianfeng Tang",
            "Hui Liu",
            "Jingying Zeng",
            "Zhen Li",
            "Rahul Goutam",
            "Suhang Wang",
            "Yue Xing",
            "Qi He",
            "Hui Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17823",
        "abstract": "Unlearning has been proposed to remove copyrighted and privacy-sensitive data from Large Language Models (LLMs). Existing approaches primarily rely on fine-tuning-based methods, which can be categorized into gradient ascent-based (GA-based) and suppression-based methods. However, they often degrade model utility (the ability to respond to normal prompts). In this work, we aim to develop a general framework that enhances the utility of fine-tuning-based unlearning methods. To achieve this goal, we first investigate the common property between GA-based and suppression-based methods. We unveil that GA-based methods unlearn by distinguishing the target data (i.e., the data to be removed) and suppressing related generations, which is essentially the same strategy employed by suppression-based methods. Inspired by this finding, we introduce Gated Representation UNlearning (GRUN) which has two components: a soft gate function for distinguishing target data and a suppression module using Representation Fine-tuning (ReFT) to adjust representations rather than model parameters. Experiments show that GRUN significantly improves the unlearning and utility. Meanwhile, it is general for fine-tuning-based methods, efficient and promising for sequential unlearning.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "55",
        "title": "MM-PoisonRAG: Disrupting Multimodal RAG with Local and Global Poisoning Attacks",
        "author": [
            "Hyeonjeong Ha",
            "Qiusi Zhan",
            "Jeonghwan Kim",
            "Dimitrios Bralios",
            "Saikrishna Sanniboina",
            "Nanyun Peng",
            "Kai-wei Chang",
            "Daniel Kang",
            "Heng Ji"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17832",
        "abstract": "Multimodal large language models (MLLMs) equipped with Retrieval Augmented Generation (RAG) leverage both their rich parametric knowledge and the dynamic, external knowledge to excel in tasks such as Question Answering. While RAG enhances MLLMs by grounding responses in query-relevant external knowledge, this reliance poses a critical yet underexplored safety risk: knowledge poisoning attacks, where misinformation or irrelevant knowledge is intentionally injected into external knowledge bases to manipulate model outputs to be incorrect and even harmful. To expose such vulnerabilities in multimodal RAG, we propose MM-PoisonRAG, a novel knowledge poisoning attack framework with two attack strategies: Localized Poisoning Attack (LPA), which injects query-specific misinformation in both text and images for targeted manipulation, and Globalized Poisoning Attack (GPA) to provide false guidance during MLLM generation to elicit nonsensical responses across all queries. We evaluate our attacks across multiple tasks, models, and access settings, demonstrating that LPA successfully manipulates the MLLM to generate attacker-controlled answers, with a success rate of up to 56% on MultiModalQA. Moreover, GPA completely disrupts model generation to 0% accuracy with just a single irrelevant knowledge injection. Our results highlight the urgent need for robust defenses against knowledge poisoning to safeguard multimodal RAG frameworks.",
        "tags": [
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "56",
        "title": "Say Less, Mean More: Leveraging Pragmatics in Retrieval-Augmented Generation",
        "author": [
            "Haris Riaz",
            "Ellen Riloff",
            "Mihai Surdeanu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17839",
        "abstract": "We propose a simple, unsupervised method that injects pragmatic principles in retrieval-augmented generation (RAG) frameworks such as Dense Passage Retrieval~\\cite{karpukhin2020densepassageretrievalopendomain} to enhance the utility of retrieved contexts. Our approach first identifies which sentences in a pool of documents retrieved by RAG are most relevant to the question at hand, cover all the topics addressed in the input question and no more, and then highlights these sentences within their context, before they are provided to the LLM, without truncating or altering the context in any other way. We show that this simple idea brings consistent improvements in experiments on three question answering tasks (ARC-Challenge, PubHealth and PopQA) using five different LLMs. It notably enhances relative accuracy by up to 19.7\\% on PubHealth and 10\\% on ARC-Challenge compared to a conventional RAG system.",
        "tags": [
            "LLMs",
            "RAG"
        ]
    },
    {
        "id": "57",
        "title": "A Combinatorial Identities Benchmark for Theorem Proving via Automated Theorem Generation",
        "author": [
            "Beibei Xiong",
            "Hangyu Lv",
            "Haojia Shan",
            "Jianlin Wang",
            "Zhengfeng Yang",
            "Lihong Zhi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17840",
        "abstract": "Large language models (LLMs) have significantly advanced formal theorem proving, yet the scarcity of high-quality training data constrains their capabilities in complex mathematical domains. Combinatorics, a cornerstone of mathematics, provides essential tools for analyzing discrete structures and solving optimization problems. However, its inherent complexity makes it particularly challenging for automated theorem proving (ATP) for combinatorial identities. To address this, we manually construct LeanComb, combinatorial identities benchmark in Lean, which is, to our knowledge, the first formalized theorem proving benchmark built for combinatorial identities. We develop an Automated Theorem Generator for Combinatorial Identities, ATG4CI, which combines candidate tactics suggested by a self-improving large language model with a Reinforcement Learning Tree Search approach for tactic prediction. By utilizing ATG4CI, we generate a LeanComb-Enhanced dataset comprising 260K combinatorial identities theorems, each with a complete formal proof in Lean, and experimental evaluations demonstrate that models trained on this dataset can generate more effective tactics, thereby improving success rates in automated theorem proving for combinatorial identities.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "58",
        "title": "Task-Driven Semantic Quantization and Imitation Learning for Goal-Oriented Communications",
        "author": [
            "Yu-Chieh Chao",
            "Yubei Chen",
            "Weiwei Wang",
            "Achintha Wijesinghe",
            "Suchinthaka Wanninayaka",
            "Songyang Zhang",
            "Zhi Ding"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17842",
        "abstract": "Semantic communication marks a new paradigm shift from bit-wise data transmission to semantic information delivery for the purpose of bandwidth reduction. To more effectively carry out specialized downstream tasks at the receiver end, it is crucial to define the most critical semantic message in the data based on the task or goal-oriented features. In this work, we propose a novel goal-oriented communication (GO-COM) framework, namely Goal-Oriented Semantic Variational Autoencoder (GOS-VAE), by focusing on the extraction of the semantics vital to the downstream tasks. Specifically, we adopt a Vector Quantized Variational Autoencoder (VQ-VAE) to compress media data at the transmitter side. Instead of targeting the pixel-wise image data reconstruction, we measure the quality-of-service at the receiver end based on a pre-defined task-incentivized model. Moreover, to capture the relevant semantic features in the data reconstruction, imitation learning is adopted to measure the data regeneration quality in terms of goal-oriented semantics. Our experimental results demonstrate the power of imitation learning in characterizing goal-oriented semantics and bandwidth efficiency of our proposed GOS-VAE.",
        "tags": [
            "VAE"
        ]
    },
    {
        "id": "59",
        "title": "Automatic Vehicle Detection using DETR: A Transformer-Based Approach for Navigating Treacherous Roads",
        "author": [
            "Istiaq Ahmed Fahad",
            "Abdullah Ibne Hanif Arean",
            "Nazmus Sakib Ahmed",
            "Mahmudul Hasan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17843",
        "abstract": "Automatic Vehicle Detection (AVD) in diverse driving environments presents unique challenges due to varying lighting conditions, road types, and vehicle types. Traditional methods, such as YOLO and Faster R-CNN, often struggle to cope with these complexities. As computer vision evolves, combining Convolutional Neural Networks (CNNs) with Transformer-based approaches offers promising opportunities for improving detection accuracy and efficiency. This study is the first to experiment with Detection Transformer (DETR) for automatic vehicle detection in complex and varied settings. We employ a Collaborative Hybrid Assignments Training scheme, Co-DETR, to enhance feature learning and attention mechanisms in DETR. By leveraging versatile label assignment strategies and introducing multiple parallel auxiliary heads, we provide more effective supervision during training and extract positive coordinates to boost training efficiency. Through extensive experiments on DETR variants and YOLO models, conducted using the BadODD dataset, we demonstrate the advantages of our approach. Our method achieves superior results, and improved accuracy in diverse conditions, making it practical for real-world deployment. This work significantly advances autonomous navigation technology and opens new research avenues in object detection for autonomous vehicles. By integrating the strengths of CNNs and Transformers, we highlight the potential of DETR for robust and efficient vehicle detection in challenging driving environments.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "60",
        "title": "LR${}^{2}$Bench: Evaluating Long-chain Reflective Reasoning Capabilities of Large Language Models via Constraint Satisfaction Problems",
        "author": [
            "Jianghao Chen",
            "Zhenlin Wei",
            "Zhenjiang Ren",
            "Ziyong Li",
            "Jiajun Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17848",
        "abstract": "Recent progress in o1-like models has significantly enhanced the reasoning abilities of Large Language Models (LLMs), empowering them to tackle increasingly complex tasks through reflection capabilities, such as making assumptions, backtracking, and self-refinement. However, effectively evaluating such reflection capabilities remains challenging due to the lack of appropriate benchmarks. To bridge this gap, we introduce LR${}^{2}$Bench, a novel benchmark designed to evaluate the Long-chain Reflective Reasoning capabilities of LLMs. LR${}^{2}$Bench comprises 850 samples across six Constraint Satisfaction Problems (CSPs) where reflective reasoning is crucial for deriving solutions that meet all given constraints. Each type of task focuses on distinct constraint patterns, such as knowledge-based, logical, and spatial constraints, providing a comprehensive evaluation of diverse problem-solving scenarios. We conduct extensive evaluation on both conventional models and o1-like models. Our experimental results reveal that even the most advanced reasoning-specific models, such as DeepSeek-R1 and OpenAI o1-preview, struggle with tasks in LR${}^{2}$Bench, achieving an average Exact Match score of only 20.0% and 23.6%, respectively. These findings underscore the significant room for improvement in the reflective reasoning capabilities of current LLMs. The leaderboard of our benchmark is available at https://huggingface.co/spaces/UltraRonin/LR2Bench",
        "tags": [
            "DeepSeek",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "61",
        "title": "SYNTHEMPATHY: A Scalable Empathy Corpus Generated Using LLMs Without Any Crowdsourcing",
        "author": [
            "Run Chen",
            "Jun Shin",
            "Julia Hirschberg"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17857",
        "abstract": "Previous research has shown that humans are more receptive towards language models that that exhibit empathetic behavior. While empathy is essential for developing helpful dialogue agents, very few large corpora containing empathetic dialogues are available for fine-tune LLMs. The few existing corpora have largely relied on crowdsourcing to simulate empathetic conversations, a process that is expensive, time-consuming, and not scalable to larger datasets. We propose a data generation framework for developing SYNTHEMPATHY, a large corpus containing 105k empathetic responses to real-life situations compiled through LLM generation. A base Mistral 7B model fine-tuned on our SYNTHEMPATHY corpus exhibits an increase in the average empathy score.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "62",
        "title": "UniGS: Unified Language-Image-3D Pretraining with Gaussian Splatting",
        "author": [
            "Haoyuan Li",
            "Yanpeng Zhou",
            "Tao Tang",
            "Jifei Song",
            "Yihan Zeng",
            "Michael Kampffmeyer",
            "Hang Xu",
            "Xiaodan Liang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17860",
        "abstract": "Recent advancements in multi-modal 3D pre-training methods have shown promising efficacy in learning joint representations of text, images, and point clouds. However, adopting point clouds as 3D representation fails to fully capture the intricacies of the 3D world and exhibits a noticeable gap between the discrete points and the dense 2D pixels of images. To tackle this issue, we propose UniGS, integrating 3D Gaussian Splatting (3DGS) into multi-modal pre-training to enhance the 3D representation. We first rely on the 3DGS representation to model the 3D world as a collection of 3D Gaussians with color and opacity, incorporating all the information of the 3D scene while establishing a strong connection with 2D images. Then, to achieve Language-Image-3D pertaining, UniGS starts with a pre-trained vision-language model to establish a shared visual and textual space through extensive real-world image-text pairs. Subsequently, UniGS employs a 3D encoder to align the optimized 3DGS with the Language-Image representations to learn unified multi-modal representations. To facilitate the extraction of global explicit 3D features by the 3D encoder and achieve better cross-modal alignment, we additionally introduce a novel Gaussian-Aware Guidance module that guides the learning of fine-grained representations of the 3D domain. Through extensive experiments across the Objaverse, ABO, MVImgNet and SUN RGBD datasets with zero-shot classification, text-driven retrieval and open-world understanding tasks, we demonstrate the effectiveness of UniGS in learning a more general and stronger aligned multi-modal representation. Specifically, UniGS achieves leading results across different 3D tasks with remarkable improvements over previous SOTA, Uni3D, including on zero-shot classification (+9.36%), text-driven retrieval (+4.3%) and open-world understanding (+7.92%).",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "63",
        "title": "HRR: Hierarchical Retrospection Refinement for Generated Image Detection",
        "author": [
            "Peipei Yuan",
            "Zijing Xie",
            "Shuo Ye",
            "Hong Chen",
            "Yulong Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17862",
        "abstract": "Generative artificial intelligence holds significant potential for abuse, and generative image detection has become a key focus of research. However, existing methods primarily focused on detecting a specific generative model and emphasizing the localization of synthetic regions, while neglecting the interference caused by image size and style on model learning. Our goal is to reach a fundamental conclusion: Is the image real or generated? To this end, we propose a diffusion model-based generative image detection framework termed Hierarchical Retrospection Refinement~(HRR). It designs a multi-scale style retrospection module that encourages the model to generate detailed and realistic multi-scale representations, while alleviating the learning biases introduced by dataset styles and generative models. Additionally, based on the principle of correntropy sparse additive machine, a feature refinement module is designed to reduce the impact of redundant features on learning and capture the intrinsic structure and patterns of the data, thereby improving the model's generalization ability. Extensive experiments demonstrate the HRR framework consistently delivers significant performance improvements, outperforming state-of-the-art methods in generated image detection task.",
        "tags": [
            "Detection",
            "Diffusion"
        ]
    },
    {
        "id": "64",
        "title": "ASurvey: Spatiotemporal Consistency in Video Generation",
        "author": [
            "Zhiyu Yin",
            "Kehai Chen",
            "Xuefeng Bai",
            "Ruili Jiang",
            "Juntao Li",
            "Hongdong Li",
            "Jin Liu",
            "Yang Xiang",
            "Jun Yu",
            "Min Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17863",
        "abstract": "Video generation, by leveraging a dynamic visual generation method, pushes the boundaries of Artificial Intelligence Generated Content (AIGC). Video generation presents unique challenges beyond static image generation, requiring both high-quality individual frames and temporal coherence to maintain consistency across the spatiotemporal sequence. Recent works have aimed at addressing the spatiotemporal consistency issue in video generation, while few literature review has been organized from this perspective. This gap hinders a deeper understanding of the underlying mechanisms for high-quality video generation. In this survey, we systematically review the recent advances in video generation, covering five key aspects: foundation models, information representations, generation schemes, post-processing techniques, and evaluation metrics. We particularly focus on their contributions to maintaining spatiotemporal consistency. Finally, we discuss the future directions and challenges in this field, hoping to inspire further efforts to advance the development of video generation.",
        "tags": [
            "Video Generation"
        ]
    },
    {
        "id": "65",
        "title": "EEGM2: An Efficient Mamba-2-Based Self-Supervised Framework for Long-Sequence EEG Modeling",
        "author": [
            "Jiazhen Hong",
            "Geoffrey Mackellar",
            "Soheila Ghane"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17873",
        "abstract": "Deep learning has achieved significant progress in the development of electroencephalogram (EEG) foundation models, with Transformer-based architectures excelling at capturing long-range dependencies. However, their quadratic computational complexity presents challenges in memory efficiency, training, and inference speed, limiting their scalability and generalizability as a foundation model. In this paper, we propose EEGM2, a self-supervised framework based on structured state space duality (SSD) that overcomes these limitations. EEGM2 introduces three key innovations: (1) a reconstruction-based framework that captures both local and global EEG features through Mamba-2 structured state space models, (2) a spatiotemporal-aware loss function that enhances robustness to noise and preserves spectral information, and (3) a multi-branch receptive field input embedding strategy that improves cross-subject generalization and stability for EEG sequences of varying lengths. In comparison to traditional pretraining methods, on raw EEG or latent representation spaces, EEGM2 shows superior performance on long-sequence tasks, where conventional models struggle. Our experimental results on six EEG datasets validate that EEGM2 not only achieves state-of-the-art cross-domain accuracy but also reduces computational overhead, making it a more efficient solution for deployment on resource-constrained BCI devices.",
        "tags": [
            "Mamba",
            "State Space Models",
            "Transformer"
        ]
    },
    {
        "id": "66",
        "title": "Towards Enhanced Immersion and Agency for LLM-based Interactive Drama",
        "author": [
            "Hongqiu Wu",
            "Weiqi Wu",
            "Tianyang Xu",
            "Jiameng Zhang",
            "Hai Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17878",
        "abstract": "LLM-based Interactive Drama is a novel AI-based dialogue scenario, where the user (i.e. the player) plays the role of a character in the story, has conversations with characters played by LLM agents, and experiences an unfolding story. This paper begins with understanding interactive drama from two aspects: Immersion, the player's feeling of being present in the story, and Agency, the player's ability to influence the story world. Both are crucial to creating an enjoyable interactive experience, while they have been underexplored in previous work. To enhance these two aspects, we first propose Playwriting-guided Generation, a novel method that helps LLMs craft dramatic stories with substantially improved structures and narrative quality. Additionally, we introduce Plot-based Reflection for LLM agents to refine their reactions to align with the player's intentions. Our evaluation relies on human judgment to assess the gains of our methods in terms of immersion and agency.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "67",
        "title": "VVRec: Reconstruction Attacks on DL-based Volumetric Video Upstreaming via Latent Diffusion Model with Gamma Distribution",
        "author": [
            "Rui Lu",
            "Bihai Zhang",
            "Dan Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17880",
        "abstract": "With the popularity of 3D volumetric video applications, such as Autonomous Driving, Virtual Reality, and Mixed Reality, current developers have turned to deep learning for compressing volumetric video frames, i.e., point clouds for video upstreaming. The latest deep learning-based solutions offer higher efficiency, lower distortion, and better hardware support compared to traditional ones like MPEG and JPEG. However, privacy threats arise, especially reconstruction attacks targeting to recover the original input point cloud from the intermediate results. In this paper, we design VVRec, to the best of our knowledge, which is the first targeting DL-based Volumetric Video Reconstruction attack scheme. VVRec demonstrates the ability to reconstruct high-quality point clouds from intercepted transmission intermediate results using four well-trained neural network modules we design. Leveraging the latest latent diffusion models with Gamma distribution and a refinement algorithm, VVRec excels in reconstruction quality, color recovery, and surpasses existing defenses. We evaluate VVRec using three volumetric video datasets. The results demonstrate that VVRec achieves 64.70dB reconstruction accuracy, with an impressive 46.39% reduction of distortion over baselines.",
        "tags": [
            "3D",
            "Diffusion"
        ]
    },
    {
        "id": "68",
        "title": "Science Across Languages: Assessing LLM Multilingual Translation of Scientific Papers",
        "author": [
            "Hannah Calzi Kleidermacher",
            "James Zou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17882",
        "abstract": "Scientific research is inherently global. However, the vast majority of academic journals are published exclusively in English, creating barriers for non-native-English-speaking researchers. In this study, we leverage large language models (LLMs) to translate published scientific articles while preserving their native JATS XML formatting, thereby developing a practical, automated approach for implementation by academic journals. Using our approach, we translate articles across multiple scientific disciplines into 28 languages. To evaluate translation accuracy, we introduce a novel question-and-answer (QA) benchmarking method, in which an LLM generates comprehension-based questions from the original text and then answers them based on the translated text. Our benchmark results show an average performance of 95.9%, showing that the key scientific details are accurately conveyed. In a user study, we translate the scientific papers of 15 researchers into their native languages, finding that the authors consistently found the translations to accurately capture the original information in their articles. Interestingly, a third of the authors found many technical terms \"overtranslated,\" expressing a preference to keep terminology more familiar in English untranslated. Finally, we demonstrate how in-context learning techniques can be used to align translations with domain-specific preferences such as mitigating overtranslation, highlighting the adaptability and utility of LLM-driven scientific translation. The code and translated articles are available at https://hankleid.github.io/ProjectMundo.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "69",
        "title": "RankCoT: Refining Knowledge for Retrieval-Augmented Generation through Ranking Chain-of-Thoughts",
        "author": [
            "Mingyan Wu",
            "Zhenghao Liu",
            "Yukun Yan",
            "Xinze Li",
            "Shi Yu",
            "Zheni Zeng",
            "Yu Gu",
            "Ge Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17888",
        "abstract": "Retrieval-Augmented Generation (RAG) enhances the performance of Large Language Models (LLMs) by incorporating external knowledge. However, LLMs still encounter challenges in effectively utilizing the knowledge from retrieved documents, often being misled by irrelevant or noisy information. To address this issue, we introduce RankCoT, a knowledge refinement method that incorporates reranking signals in generating CoT-based summarization for knowledge refinement based on given query and all retrieval documents. During training, RankCoT prompts the LLM to generate Chain-of-Thought (CoT) candidates based on the query and individual documents. It then fine-tunes the LLM to directly reproduce the best CoT from these candidate outputs based on all retrieved documents, which requires LLM to filter out irrelevant documents during generating CoT-style summarization. Additionally, RankCoT incorporates a self-reflection mechanism that further refines the CoT outputs, resulting in higher-quality training data. Our experiments demonstrate the effectiveness of RankCoT, showing its superior performance over other knowledge refinement models. Further analysis reveals that RankCoT can provide shorter but effective refinement results, enabling the generator to produce more accurate answers. All code and data are available at https://github.com/NEUIR/RankCoT.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "70",
        "title": "Sample-efficient diffusion-based control of complex nonlinear systems",
        "author": [
            "Hongyi Chen",
            "Jingtao Ding",
            "Jianhai Shu",
            "Xinchun Yu",
            "Xiaojun Liang",
            "Yong Li",
            "Xiao-Ping Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17893",
        "abstract": "Complex nonlinear system control faces challenges in achieving sample-efficient, reliable performance. While diffusion-based methods have demonstrated advantages over classical and reinforcement learning approaches in long-term control performance, they are limited by sample efficiency. This paper presents SEDC (Sample-Efficient Diffusion-based Control), a novel diffusion-based control framework addressing three core challenges: high-dimensional state-action spaces, nonlinear system dynamics, and the gap between non-optimal training data and near-optimal control solutions. Through three innovations - Decoupled State Diffusion, Dual-Mode Decomposition, and Guided Self-finetuning - SEDC achieves 39.5\\%-49.4\\% better control accuracy than baselines while using only 10\\% of the training samples, as validated across three complex nonlinear dynamic systems. Our approach represents a significant advancement in sample-efficient control of complex nonlinear systems. The implementation of the code can be found at https://anonymous.4open.science/r/DIFOCON-C019.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "71",
        "title": "VeriPlan: Integrating Formal Verification and LLMs into End-User Planning",
        "author": [
            "Christine Lee",
            "David Porfirio",
            "Xinyu Jessica Wang",
            "Kevin Zhao",
            "Bilge Mutlu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17898",
        "abstract": "Automated planning is traditionally the domain of experts, utilized in fields like manufacturing and healthcare with the aid of expert planning tools. Recent advancements in LLMs have made planning more accessible to everyday users due to their potential to assist users with complex planning tasks. However, LLMs face several application challenges within end-user planning, including consistency, accuracy, and user trust issues. This paper introduces VeriPlan, a system that applies formal verification techniques, specifically model checking, to enhance the reliability and flexibility of LLMs for end-user planning. In addition to the LLM planner, VeriPlan includes three additional core features -- a rule translator, flexibility sliders, and a model checker -- that engage users in the verification process. Through a user study (n=12), we evaluate VeriPlan, demonstrating improvements in the perceived quality, usability, and user satisfaction of LLMs. Our work shows the effective integration of formal verification and user-control features with LLMs for end-user planning tasks.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "72",
        "title": "Towards Sustainable Web Agents: A Plea for Transparency and Dedicated Metrics for Energy Consumption",
        "author": [
            "Lars Krupp",
            "Daniel GeiÃler",
            "Paul Lukowicz",
            "Jakob Karolus"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17903",
        "abstract": "Improvements in the area of large language models have shifted towards the construction of models capable of using external tools and interpreting their outputs. These so-called web agents have the ability to interact autonomously with the internet. This allows them to become powerful daily assistants handling time-consuming, repetitive tasks while supporting users in their daily activities. While web agent research is thriving, the sustainability aspect of this research direction remains largely unexplored. We provide an initial exploration of the energy and CO2 cost associated with web agents. Our results show how different philosophies in web agent creation can severely impact the associated expended energy. We highlight lacking transparency regarding the disclosure of model parameters and processes used for some web agents as a limiting factor when estimating energy consumption. As such, our work advocates a change in thinking when evaluating web agents, warranting dedicated metrics for energy consumption and sustainability.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "73",
        "title": "Scaling LLM Pre-training with Vocabulary Curriculum",
        "author": [
            "Fangyuan Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17910",
        "abstract": "Modern language models rely on static vocabularies, fixed before pretraining, in contrast to the adaptive vocabulary acquisition observed in human language learning. To bridge this gap, we introduce vocabulary curriculum learning, an approach that improves pretraining efficiency with log-linear scaling gains relative to vocabulary size. Our method alternates between entropy-guided vocabulary expansion and model optimization, enabling models to learn transferable representations across diverse tokenization granularities. This approach naturally gives rise to an optimal computation allocation pattern: longer tokens capture predictable content, while shorter tokens focus on more complex, harder-to-predict contexts. Experiments on small-scale GPT models demonstrate improved scaling efficiency, reinforcing the effectiveness of dynamic tokenization. We release our code to support further research and plan to extend our experiments to larger models and diverse domains.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "74",
        "title": "Enhancing Speech Quality through the Integration of BGRU and Transformer Architectures",
        "author": [
            "Souliman Alghnam",
            "Mohammad Alhussien",
            "Khaled Shaheen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17911",
        "abstract": "Speech enhancement plays an essential role in improving the quality of speech signals in noisy environments. This paper investigates the efficacy of integrating Bidirectional Gated Recurrent Units (BGRU) and Transformer models for speech enhancement tasks. Through a comprehensive experimental evaluation, our study demonstrates the superiority of this hybrid architecture over traditional methods and standalone models. The combined BGRU-Transformer framework excels in capturing temporal dependencies and learning complex signal patterns, leading to enhanced noise reduction and improved speech quality. Results show significant performance gains compared to existing approaches, highlighting the potential of this integrated model in real-world applications. The seamless integration of BGRU and Transformer architectures not only enhances system robustness but also opens the road for advanced speech processing techniques. This research contributes to the ongoing efforts in speech enhancement technology and sets a solid foundation for future investigations into optimizing model architectures, exploring many application scenarios, and advancing the field of speech processing in noisy environments.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "75",
        "title": "C-LoRA: Continual Low-Rank Adaptation for Pre-trained Models",
        "author": [
            "Xin Zhang",
            "Liang Bai",
            "Xian Yang",
            "Jiye Liang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17920",
        "abstract": "Low-Rank Adaptation (LoRA) is an efficient fine-tuning method that has been extensively applied in areas such as natural language processing and computer vision. Existing LoRA fine-tuning approaches excel in static environments but struggle in dynamic learning due to reliance on multiple adapter modules, increasing overhead and complicating inference. We propose Continual Low-Rank Adaptation (C-LoRA), a novel extension of LoRA for continual learning. C-LoRA uses a learnable routing matrix to dynamically manage parameter updates across tasks, ensuring efficient reuse of learned subspaces while enforcing orthogonality to minimize interference and forgetting. Unlike existing approaches that require separate adapters for each task, C-LoRA enables a integrated approach for task adaptation, achieving both scalability and parameter efficiency in sequential learning scenarios. C-LoRA achieves state-of-the-art accuracy and parameter efficiency on benchmarks while providing theoretical insights into its routing matrix's role in retaining and transferring knowledge, establishing a scalable framework for continual learning.",
        "tags": [
            "LoRA",
            "Low-Rank Adaptation"
        ]
    },
    {
        "id": "76",
        "title": "FACT-AUDIT: An Adaptive Multi-Agent Framework for Dynamic Fact-Checking Evaluation of Large Language Models",
        "author": [
            "Hongzhan Lin",
            "Yang Deng",
            "Yuxuan Gu",
            "Wenxuan Zhang",
            "Jing Ma",
            "See-Kiong Ng",
            "Tat-Seng Chua"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17924",
        "abstract": "Large Language Models (LLMs) have significantly advanced the fact-checking studies. However, existing automated fact-checking evaluation methods rely on static datasets and classification metrics, which fail to automatically evaluate the justification production and uncover the nuanced limitations of LLMs in fact-checking. In this work, we introduce FACT-AUDIT, an agent-driven framework that adaptively and dynamically assesses LLMs' fact-checking capabilities. Leveraging importance sampling principles and multi-agent collaboration, FACT-AUDIT generates adaptive and scalable datasets, performs iterative model-centric evaluations, and updates assessments based on model-specific responses. By incorporating justification production alongside verdict prediction, this framework provides a comprehensive and evolving audit of LLMs' factual reasoning capabilities, to investigate their trustworthiness. Extensive experiments demonstrate that FACT-AUDIT effectively differentiates among state-of-the-art LLMs, providing valuable insights into model strengths and limitations in model-centric fact-checking analysis.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "77",
        "title": "LeanProgress: Guiding Search for Neural Theorem Proving via Proof Progress Prediction",
        "author": [
            "Suozhi Huang",
            "Peiyang Song",
            "Robert Joseph George",
            "Anima Anandkumar"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17925",
        "abstract": "Mathematical reasoning remains a significant challenge for Large Language Models (LLMs) due to hallucinations. When combined with formal proof assistants like Lean, these hallucinations can be eliminated through rigorous verification, making theorem proving reliable. However, even with formal verification, LLMs still struggle with long proofs and complex mathematical formalizations. While Lean with LLMs offers valuable assistance with retrieving lemmas, generating tactics, or even complete proofs, it lacks a crucial capability: providing a sense of proof progress. This limitation particularly impacts the overall development efficiency in large formalization projects. We introduce LeanProgress, a method that predicts the progress in the proof. Training and evaluating our models made on a large corpus of Lean proofs from Lean Workbook Plus and Mathlib4 and how many steps remain to complete it, we employ data preprocessing and balancing techniques to handle the skewed distribution of proof lengths. Our experiments show that LeanProgress achieves an overall prediction accuracy of 75.1\\% in predicting the amount of progress and, hence, the remaining number of steps. When integrated into a best-first search framework using Reprover, our method shows a 3.8\\% improvement on Mathlib4 compared to baseline performances of 41.2\\%, particularly for longer proofs. These results demonstrate how proof progress prediction can enhance both automated and interactive theorem proving, enabling users to make more informed decisions about proof strategies.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "78",
        "title": "Advantage-Guided Distillation for Preference Alignment in Small Language Models",
        "author": [
            "Shiping Gao",
            "Fanqi Wan",
            "Jiajian Guo",
            "Xiaojun Quan",
            "Qifan Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17927",
        "abstract": "Alignment techniques enable Large Language Models (LLMs) to generate outputs that align with human preferences and play a crucial role in their effectiveness. However, their impact often diminishes when applied to Small Language Models (SLMs), likely due to the limited capacity of these models. Instead of directly applying existing alignment techniques to SLMs, we propose to utilize a well-aligned teacher LLM to guide the alignment process for these models, thereby facilitating the transfer of the teacher's knowledge of human preferences to the student model. To achieve this, we first explore a straightforward approach, Dual-Constrained Knowledge Distillation (DCKD), that employs knowledge distillation with two KL-divergence constraints from the aligned teacher to the unaligned student. To further enhance the student's ability to distinguish between preferred and dispreferred responses, we then propose Advantage-Guided Distillation for Preference Alignment (ADPA), which leverages an advantage function from the aligned teacher to deliver more nuanced, distribution-level reward signals for the student's alignment. Our experimental results show that these two approaches appreciably improve the alignment of SLMs and narrow the performance gap with larger counterparts. Among them, ADPA demonstrates superior performance and achieves even greater effectiveness when integrated with DCKD. Our code is available at https://github.com/SLIT-AI/ADPA.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "79",
        "title": "Structure-prior Informed Diffusion Model for Graph Source Localization with Limited Data",
        "author": [
            "Hongyi Chen",
            "Jingtao Ding",
            "Xiaojun Liang",
            "Yong Li",
            "Xiao-Ping Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17928",
        "abstract": "The source localization problem in graph information propagation is crucial for managing various network disruptions, from misinformation spread to infrastructure failures. While recent deep generative approaches have shown promise in this domain, their effectiveness is limited by the scarcity of real-world propagation data. This paper introduces SIDSL (\\textbf{S}tructure-prior \\textbf{I}nformed \\textbf{D}iffusion model for \\textbf{S}ource \\textbf{L}ocalization), a novel framework that addresses three key challenges in limited-data scenarios: unknown propagation patterns, complex topology-propagation relationships, and class imbalance between source and non-source nodes. SIDSL incorporates topology-aware priors through graph label propagation and employs a propagation-enhanced conditional denoiser with a GNN-parameterized label propagation module (GNN-LP). Additionally, we propose a structure-prior biased denoising scheme that initializes from structure-based source estimations rather than random noise, effectively countering class imbalance issues. Experimental results across four real-world datasets demonstrate SIDSL's superior performance, achieving 7.5-13.3% improvements in F1 scores compared to state-of-the-art methods. Notably, when pretrained with simulation data of synthetic patterns, SIDSL maintains robust performance with only 10% of training data, surpassing baselines by more than 18.8%. These results highlight SIDSL's effectiveness in real-world applications where labeled data is scarce.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "80",
        "title": "Optimal Brain Apoptosis",
        "author": [
            "Mingyuan Sun",
            "Zheng Fang",
            "Jiaxu Wang",
            "Junjie Jiang",
            "Delei Kong",
            "Chenming Hu",
            "Yuetong Fang",
            "Renjing Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17941",
        "abstract": "The increasing complexity and parameter count of Convolutional Neural Networks (CNNs) and Transformers pose challenges in terms of computational efficiency and resource demands. Pruning has been identified as an effective strategy to address these challenges by removing redundant elements such as neurons, channels, or connections, thereby enhancing computational efficiency without heavily compromising performance. This paper builds on the foundational work of Optimal Brain Damage (OBD) by advancing the methodology of parameter importance estimation using the Hessian matrix. Unlike previous approaches that rely on approximations, we introduce Optimal Brain Apoptosis (OBA), a novel pruning method that calculates the Hessian-vector product value directly for each parameter. By decomposing the Hessian matrix across network layers and identifying conditions under which inter-layer Hessian submatrices are non-zero, we propose a highly efficient technique for computing the second-order Taylor expansion of parameters. This approach allows for a more precise pruning process, particularly in the context of CNNs and Transformers, as validated in our experiments including VGG19, ResNet32, ResNet50, and ViT-B/16 on CIFAR10, CIFAR100 and Imagenet datasets. Our code is available at https://github.com/NEU-REAL/OBA.",
        "tags": [
            "ViT"
        ]
    },
    {
        "id": "81",
        "title": "CaseGen: A Benchmark for Multi-Stage Legal Case Documents Generation",
        "author": [
            "Haitao Li",
            "Jiaying Ye",
            "Yiran Hu",
            "Jia Chen",
            "Qingyao Ai",
            "Yueyue Wu",
            "Junjie Chen",
            "Yifan Chen",
            "Cheng Luo",
            "Quan Zhou",
            "Yiqun Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17943",
        "abstract": "Legal case documents play a critical role in judicial proceedings. As the number of cases continues to rise, the reliance on manual drafting of legal case documents is facing increasing pressure and challenges. The development of large language models (LLMs) offers a promising solution for automating document generation. However, existing benchmarks fail to fully capture the complexities involved in drafting legal case documents in real-world scenarios. To address this gap, we introduce CaseGen, the benchmark for multi-stage legal case documents generation in the Chinese legal domain. CaseGen is based on 500 real case samples annotated by legal experts and covers seven essential case sections. It supports four key tasks: drafting defense statements, writing trial facts, composing legal reasoning, and generating judgment results. To the best of our knowledge, CaseGen is the first benchmark designed to evaluate LLMs in the context of legal case document generation. To ensure an accurate and comprehensive evaluation, we design the LLM-as-a-judge evaluation framework and validate its effectiveness through human annotations. We evaluate several widely used general-domain LLMs and legal-specific LLMs, highlighting their limitations in case document generation and pinpointing areas for potential improvement. This work marks a step toward a more effective framework for automating legal case documents drafting, paving the way for the reliable application of AI in the legal field. The dataset and code are publicly available at https://github.com/CSHaitao/CaseGen.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "82",
        "title": "Assessing Large Language Models in Agentic Multilingual National Bias",
        "author": [
            "Qianying Liu",
            "Katrina Qiyao Wang",
            "Fei Cheng",
            "Sadao Kurohashi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17945",
        "abstract": "Large Language Models have garnered significant attention for their capabilities in multilingual natural language processing, while studies on risks associated with cross biases are limited to immediate context preferences. Cross-language disparities in reasoning-based recommendations remain largely unexplored, with a lack of even descriptive analysis. This study is the first to address this gap. We test LLM's applicability and capability in providing personalized advice across three key scenarios: university applications, travel, and relocation. We investigate multilingual bias in state-of-the-art LLMs by analyzing their responses to decision-making tasks across multiple languages. We quantify bias in model-generated scores and assess the impact of demographic factors and reasoning strategies (e.g., Chain-of-Thought prompting) on bias patterns. Our findings reveal that local language bias is prevalent across different tasks, with GPT-4 and Sonnet reducing bias for English-speaking countries compared to GPT-3.5 but failing to achieve robust multilingual alignment, highlighting broader implications for multilingual AI agents and applications such as education.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "83",
        "title": "InVDriver: Intra-Instance Aware Vectorized Query-Based Autonomous Driving Transformer",
        "author": [
            "Bo Zhang",
            "Heye Huang",
            "Chunyang Liu",
            "Yaqin Zhang",
            "Zhenhua Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17949",
        "abstract": "End-to-end autonomous driving with its holistic optimization capabilities, has gained increasing traction in academia and industry. Vectorized representations, which preserve instance-level topological information while reducing computational overhead, have emerged as a promising paradigm. While existing vectorized query-based frameworks often overlook the inherent spatial correlations among intra-instance points, resulting in geometrically inconsistent outputs (e.g., fragmented HD map elements or oscillatory trajectories). To address these limitations, we propose InVDriver, a novel vectorized query-based system that systematically models intra-instance spatial dependencies through masked self-attention layers, thereby enhancing planning accuracy and trajectory smoothness. Across all core modules, i.e., perception, prediction, and planning, InVDriver incorporates masked self-attention mechanisms that restrict attention to intra-instance point interactions, enabling coordinated refinement of structural elements while suppressing irrelevant inter-instance noise. Experimental results on the nuScenes benchmark demonstrate that InVDriver achieves state-of-the-art performance, surpassing prior methods in both accuracy and safety, while maintaining high computational efficiency. Our work validates that explicit modeling of intra-instance geometric coherence is critical for advancing vectorized autonomous driving systems, bridging the gap between theoretical advantages of end-to-end frameworks and practical deployment requirements.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "84",
        "title": "Towards Better Understanding of Program-of-Thought Reasoning in Cross-Lingual and Multilingual Environments",
        "author": [
            "Patomporn Payoungkhamdee",
            "Pume Tuchinda",
            "Jinheon Baek",
            "Samuel Cahyawijaya",
            "Can Udomcharoenchaikit",
            "Potsawee Manakul",
            "Peerat Limkonchotiwat",
            "Ekapol Chuangsuwanich",
            "Sarana Nutanong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17956",
        "abstract": "Multi-step reasoning is essential for large language models (LLMs), yet multilingual performance remains challenging. While Chain-of-Thought (CoT) prompting improves reasoning, it struggles with non-English languages due to the entanglement of reasoning and execution. Program-of-Thought (PoT) prompting separates reasoning from execution, offering a promising alternative but shifting the challenge to generating programs from non-English questions. We propose a framework to evaluate PoT by separating multilingual reasoning from code execution to examine (i) the impact of fine-tuning on question-reasoning alignment and (ii) how reasoning quality affects answer correctness. Our findings demonstrate that PoT fine-tuning substantially enhances multilingual reasoning, outperforming CoT fine-tuned models. We further demonstrate a strong correlation between reasoning quality (measured through code quality) and answer accuracy, highlighting its potential as a test-time performance improvement heuristic.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "85",
        "title": "LLM Knows Geometry Better than Algebra: Numerical Understanding of LLM-Based Agents in A Trading Arena",
        "author": [
            "Tianmi Ma",
            "Jiawei Du",
            "Wenxin Huang",
            "Wenjie Wang",
            "Liang Xie",
            "Xian Zhong",
            "Joey Tianyi Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17967",
        "abstract": "Recent advancements in large language models (LLMs) have significantly improved performance in natural language processing tasks. However, their ability to generalize to dynamic, unseen tasks, particularly in numerical reasoning, remains a challenge. Existing benchmarks mainly evaluate LLMs on problems with predefined optimal solutions, which may not align with real-world scenarios where clear answers are absent. To bridge this gap, we design the Agent Trading Arena, a virtual numerical game simulating complex economic systems through zero-sum games, where agents invest in stock portfolios. Our experiments reveal that LLMs, including GPT-4o, struggle with algebraic reasoning when dealing with plain-text stock data, often focusing on local details rather than global trends. In contrast, LLMs perform significantly better with geometric reasoning when presented with visual data, such as scatter plots or K-line charts, suggesting that visual representations enhance numerical reasoning. This capability is further improved by incorporating the reflection module, which aids in the analysis and interpretation of complex data. We validate our findings on NASDAQ Stock dataset, where LLMs demonstrate stronger reasoning with visual data compared to text. Our code and data are publicly available at https://github.com/wekjsdvnm/Agent-Trading-Arena.git.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "86",
        "title": "Unveiling the Key Factors for Distilling Chain-of-Thought Reasoning",
        "author": [
            "Xinghao Chen",
            "Zhijing Sun",
            "Wenjin Guo",
            "Miaoran Zhang",
            "Yanjun Chen",
            "Yirong Sun",
            "Hui Su",
            "Yijie Pan",
            "Dietrich Klakow",
            "Wenjie Li",
            "Xiaoyu Shen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18001",
        "abstract": "Large Language Models (LLMs) excel in reasoning tasks through Chain-of-Thought (CoT) prompting. However, CoT prompting greatly increases computational demands, which has prompted growing interest in distilling CoT capabilities into Small Language Models (SLMs). This study systematically examines the factors influencing CoT distillation, including the choice of granularity, format and teacher model. Through experiments involving four teacher models and seven student models across seven mathematical and commonsense reasoning datasets, we uncover three key findings: (1) Unlike LLMs, SLMs exhibit a non-monotonic relationship with granularity, with stronger models benefiting from finer-grained reasoning and weaker models performing better with simpler CoT supervision; (2) CoT format significantly impacts LLMs but has minimal effect on SLMs, likely due to their reliance on supervised fine-tuning rather than pretraining preferences; (3) Stronger teacher models do NOT always produce better student models, as diversity and complexity in CoT supervision can outweigh accuracy alone. These findings emphasize the need to tailor CoT strategies to specific student model, offering actionable insights for optimizing CoT distillation in SLMs. The code and datasets are available at https://github.com/EIT-NLP/Distilling-CoT-Reasoning.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "87",
        "title": "NotaGen: Advancing Musicality in Symbolic Music Generation with Large Language Model Training Paradigms",
        "author": [
            "Yashan Wang",
            "Shangda Wu",
            "Jianhuai Hu",
            "Xingjian Du",
            "Yueqi Peng",
            "Yongxin Huang",
            "Shuai Fan",
            "Xiaobing Li",
            "Feng Yu",
            "Maosong Sun"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18008",
        "abstract": "We introduce NotaGen, a symbolic music generation model aiming to explore the potential of producing high-quality classical sheet music. Inspired by the success of Large Language Models (LLMs), NotaGen adopts pre-training, fine-tuning, and reinforcement learning paradigms (henceforth referred to as the LLM training paradigms). It is pre-trained on 1.6M pieces of music, and then fine-tuned on approximately 9K high-quality classical compositions conditioned on \"period-composer-instrumentation\" prompts. For reinforcement learning, we propose the CLaMP-DPO method, which further enhances generation quality and controllability without requiring human annotations or predefined rewards. Our experiments demonstrate the efficacy of CLaMP-DPO in symbolic music generation models with different architectures and encoding schemes. Furthermore, subjective A/B tests show that NotaGen outperforms baseline models against human compositions, greatly advancing musical aesthetics in symbolic music http://generation.The project homepage is https://electricalexis.github.io/notagen-demo.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "88",
        "title": "Verdict: A Library for Scaling Judge-Time Compute",
        "author": [
            "Nimit Kalra",
            "Leonard Tang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18018",
        "abstract": "The use of LLMs as automated judges (\"LLM-as-a-judge\") is now widespread, yet standard judges suffer from a multitude of reliability issues. To address these challenges, we introduce Verdict, an open-source library for scaling judge-time compute to enhance the accuracy, reliability, and interpretability of automated evaluators. Verdict leverages the composition of modular reasoning units -- such as verification, debate, and aggregation -- and increased inference-time compute to improve LLM judge quality. Across a variety of challenging tasks such as content moderation, fact-checking, and hallucination detection, Verdict judges achieve state-of-the-art (SOTA) or near-SOTA performance, surpassing orders-of-magnitude larger fine-tuned judges, prompted judges, and reasoning models. Ultimately, we hope Verdict serves as a useful framework for researchers and practitioners building scalable, interpretable, and reliable LLM-based evaluators.",
        "tags": [
            "Detection",
            "LLMs"
        ]
    },
    {
        "id": "89",
        "title": "AfroXLMR-Comet: Multilingual Knowledge Distillation with Attention Matching for Low-Resource languages",
        "author": [
            "Joshua Sakthivel Raju",
            "Sanjay S",
            "Jaskaran Singh Walia",
            "Srinivas Raghav",
            "Vukosi Marivate"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18020",
        "abstract": "Language model compression through knowledge distillation has emerged as a promising approach for deploying large language models in resource-constrained environments. However, existing methods often struggle to maintain performance when distilling multilingual models, especially for low-resource languages. In this paper, we present a novel hybrid distillation approach that combines traditional knowledge distillation with a simplified attention matching mechanism, specifically designed for multilingual contexts. Our method introduces an extremely compact student model architecture, significantly smaller than conventional multilingual models. We evaluate our approach on five African languages: Kinyarwanda, Swahili, Hausa, Igbo, and Yoruba. The distilled student model; AfroXLMR-Comet successfully captures both the output distribution and internal attention patterns of a larger teacher model (AfroXLMR-Large) while reducing the model size by over 85%. Experimental results demonstrate that our hybrid approach achieves competitive performance compared to the teacher model, maintaining an accuracy within 85% of the original model's performance while requiring substantially fewer computational resources. Our work provides a practical framework for deploying efficient multilingual models in resource-constrained environments, particularly benefiting applications involving African languages.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "90",
        "title": "Detecting Knowledge Boundary of Vision Large Language Models by Sampling-Based Inference",
        "author": [
            "Zhuo Chen",
            "Xinyu Wang",
            "Yong Jiang",
            "Zhen Zhang",
            "Xinyu Geng",
            "Pengjun Xie",
            "Fei Huang",
            "Kewei Tu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18023",
        "abstract": "Despite the advancements made in Visual Large Language Models (VLLMs), like text Large Language Models (LLMs), they have limitations in addressing questions that require real-time information or are knowledge-intensive. Indiscriminately adopting Retrieval Augmented Generation (RAG) techniques is an effective yet expensive way to enable models to answer queries beyond their knowledge scopes. To mitigate the dependence on retrieval and simultaneously maintain, or even improve, the performance benefits provided by retrieval, we propose a method to detect the knowledge boundary of VLLMs, allowing for more efficient use of techniques like RAG. Specifically, we propose a method with two variants that fine-tunes a VLLM on an automatically constructed dataset for boundary identification. Experimental results on various types of Visual Question Answering datasets show that our method successfully depicts a VLLM's knowledge boundary based on which we are able to reduce indiscriminate retrieval while maintaining or improving the performance. In addition, we show that the knowledge boundary identified by our method for one VLLM can be used as a surrogate boundary for other VLLMs. Code will be released at https://github.com/Chord-Chen-30/VLLM-KnowledgeBoundary",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "91",
        "title": "Harnessing Multiple Large Language Models: A Survey on LLM Ensemble",
        "author": [
            "Zhijun Chen",
            "Jingzheng Li",
            "Pengpeng Chen",
            "Zhuoran Li",
            "Kai Sun",
            "Yuankai Luo",
            "Qianren Mao",
            "Dingqi Yang",
            "Hailong Sun",
            "Philip S. Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18036",
        "abstract": "LLM Ensemble -- which involves the comprehensive use of multiple large language models (LLMs), each aimed at handling user queries during downstream inference, to benefit from their individual strengths -- has gained substantial attention recently. The widespread availability of LLMs, coupled with their varying strengths and out-of-the-box usability, has profoundly advanced the field of LLM Ensemble. This paper presents the first systematic review of recent developments in LLM Ensemble. First, we introduce our taxonomy of LLM Ensemble and discuss several related research problems. Then, we provide a more in-depth classification of the methods under the broad categories of \"ensemble-before-inference, ensemble-during-inference, ensemble-after-inference\", and review all relevant methods. Finally, we introduce related benchmarks and applications, summarize existing studies, and suggest several future research directions. A curated list of papers on LLM Ensemble is available at https://github.com/junchenzhi/Awesome-LLM-Ensemble.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "92",
        "title": "OpenFly: A Versatile Toolchain and Large-scale Benchmark for Aerial Vision-Language Navigation",
        "author": [
            "Yunpeng Gao",
            "Chenhui Li",
            "Zhongrui You",
            "Junli Liu",
            "Zhen Li",
            "Pengan Chen",
            "Qizhi Chen",
            "Zhonghan Tang",
            "Liansheng Wang",
            "Penghui Yang",
            "Yiwen Tang",
            "Yuhang Tang",
            "Shuai Liang",
            "Songyi Zhu",
            "Ziqin Xiong",
            "Yifei Su",
            "Xinyi Ye",
            "Jianan Li",
            "Yan Ding",
            "Dong Wang",
            "Zhigang Wang",
            "Bin Zhao",
            "Xuelong Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18041",
        "abstract": "Vision-Language Navigation (VLN) aims to guide agents through an environment by leveraging both language instructions and visual cues, playing a pivotal role in embodied AI. Indoor VLN has been extensively studied, whereas outdoor aerial VLN remains underexplored. The potential reason is that outdoor aerial view encompasses vast areas, making data collection more challenging, which results in a lack of benchmarks. To address this problem, we propose OpenFly, a platform comprising a versatile toolchain and large-scale benchmark for aerial VLN. Firstly, we develop a highly automated toolchain for data collection, enabling automatic point cloud acquisition, scene semantic segmentation, flight trajectory creation, and instruction generation. Secondly, based on the toolchain, we construct a large-scale aerial VLN dataset with 100k trajectories, covering diverse heights and lengths across 18 scenes. The corresponding visual data are generated using various rendering engines and advanced techniques, including Unreal Engine, GTA V, Google Earth, and 3D Gaussian Splatting (3D GS). All data exhibit high visual quality. Particularly, 3D GS supports real-to-sim rendering, further enhancing the realism of the dataset. Thirdly, we propose OpenFly-Agent, a keyframe-aware VLN model, which takes language instructions, current observations, and historical keyframes as input, and outputs flight actions directly. Extensive analyses and experiments are conducted, showcasing the superiority of our OpenFly platform and OpenFly-Agent. The toolchain, dataset, and codes will be open-sourced.",
        "tags": [
            "3D",
            "Gaussian Splatting",
            "Segmentation"
        ]
    },
    {
        "id": "93",
        "title": "S-Graphs 2.0 -- A Hierarchical-Semantic Optimization and Loop Closure for SLAM",
        "author": [
            "Hriday Bavle",
            "Jose Luis Sanchez-Lopez",
            "Muhammad Shaheer",
            "Javier Civera",
            "Holger Voos"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18044",
        "abstract": "Works based on localization and mapping do not exploit the inherent semantic-relational information from the environment for faster and efficient management and optimization of the robot poses and its map elements, often leading to pose and map inaccuracies and computational inefficiencies in large scale environments. 3D scene graph representations which distributes the environment in an hierarchical manner can be exploited to enhance the management/optimization of underlying robot poses and its map.\nIn this direction, we present our work Situational Graphs 2.0, which leverages the hierarchical structure of indoor scenes for efficient data management and optimization. Our algorithm begins by constructing a situational graph that organizes the environment into four layers: Keyframes, Walls, Rooms, and Floors. Our first novelty lies in the front-end which includes a floor detection module capable of identifying stairways and assigning a floor-level semantic-relations to the underlying layers. This floor-level semantic enables a floor-based loop closure strategy, rejecting false-positive loop closures in visually similar areas on different floors. Our second novelty is in exploiting the hierarchy for an improved optimization. It consists of: (1) local optimization, optimizing a window of recent keyframes and their connected components, (2) floor-global optimization, which focuses only on keyframes and their connections within the current floor during loop closures, and (3) room-local optimization, marginalizing redundant keyframes that share observations within the room.\nWe validate our algorithm extensively in different real multi-floor environments. Our approach can demonstrate state-of-art-art results in large scale multi-floor environments creating hierarchical maps while bounding the computational complexity where several baseline works fail to execute efficiently.",
        "tags": [
            "3D",
            "Detection",
            "Robot",
            "SLAM"
        ]
    },
    {
        "id": "94",
        "title": "HEROS-GAN: Honed-Energy Regularized and Optimal Supervised GAN for Enhancing Accuracy and Range of Low-Cost Accelerometers",
        "author": [
            "Yifeng Wang",
            "Yi Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18064",
        "abstract": "Low-cost accelerometers play a crucial role in modern society due to their advantages of small size, ease of integration, wearability, and mass production, making them widely applicable in automotive systems, aerospace, and wearable technology. However, this widely used sensor suffers from severe accuracy and range limitations. To this end, we propose a honed-energy regularized and optimal supervised GAN (HEROS-GAN), which transforms low-cost sensor signals into high-cost equivalents, thereby overcoming the precision and range limitations of low-cost accelerometers. Due to the lack of frame-level paired low-cost and high-cost signals for training, we propose an Optimal Transport Supervision (OTS), which leverages optimal transport theory to explore potential consistency between unpaired data, thereby maximizing supervisory information. Moreover, we propose a Modulated Laplace Energy (MLE), which injects appropriate energy into the generator to encourage it to break range limitations, enhance local changes, and enrich signal details. Given the absence of a dedicated dataset, we specifically establish a Low-cost Accelerometer Signal Enhancement Dataset (LASED) containing tens of thousands of samples, which is the first dataset serving to improve the accuracy and range of accelerometers and is released in Github. Experimental results demonstrate that a GAN combined with either OTS or MLE alone can surpass the previous signal enhancement SOTA methods by an order of magnitude. Integrating both OTS and MLE, the HEROS-GAN achieves remarkable results, which doubles the accelerometer range while reducing signal noise by two orders of magnitude, establishing a benchmark in the accelerometer signal processing.",
        "tags": [
            "GAN"
        ]
    },
    {
        "id": "95",
        "title": "MRBTP: Efficient Multi-Robot Behavior Tree Planning and Collaboration",
        "author": [
            "Yishuai Cai",
            "Xinglin Chen",
            "Zhongxuan Cai",
            "Yunxin Mao",
            "Minglong Li",
            "Wenjing Yang",
            "Ji Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18072",
        "abstract": "Multi-robot task planning and collaboration are critical challenges in robotics. While Behavior Trees (BTs) have been established as a popular control architecture and are plannable for a single robot, the development of effective multi-robot BT planning algorithms remains challenging due to the complexity of coordinating diverse action spaces. We propose the Multi-Robot Behavior Tree Planning (MRBTP) algorithm, with theoretical guarantees of both soundness and completeness. MRBTP features cross-tree expansion to coordinate heterogeneous actions across different BTs to achieve the team's goal. For homogeneous actions, we retain backup structures among BTs to ensure robustness and prevent redundant execution through intention sharing. While MRBTP is capable of generating BTs for both homogeneous and heterogeneous robot teams, its efficiency can be further improved. We then propose an optional plugin for MRBTP when Large Language Models (LLMs) are available to reason goal-related actions for each robot. These relevant actions can be pre-planned to form long-horizon subtrees, significantly enhancing the planning speed and collaboration efficiency of MRBTP. We evaluate our algorithm in warehouse management and everyday service scenarios. Results demonstrate MRBTP's robustness and execution efficiency under varying settings, as well as the ability of the pre-trained LLM to generate effective task-specific subtrees for MRBTP.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Robot",
            "Robotics"
        ]
    },
    {
        "id": "96",
        "title": "Examining the Threat Landscape: Foundation Models and Model Stealing",
        "author": [
            "Ankita Raj",
            "Deepankar Varma",
            "Chetan Arora"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18077",
        "abstract": "Foundation models (FMs) for computer vision learn rich and robust representations, enabling their adaptation to task/domain-specific deployments with little to no fine-tuning. However, we posit that the very same strength can make applications based on FMs vulnerable to model stealing attacks. Through empirical analysis, we reveal that models fine-tuned from FMs harbor heightened susceptibility to model stealing, compared to conventional vision architectures like ResNets. We hypothesize that this behavior is due to the comprehensive encoding of visual patterns and features learned by FMs during pre-training, which are accessible to both the attacker and the victim. We report that an attacker is able to obtain 94.28% agreement (matched predictions with victim) for a Vision Transformer based victim model (ViT-L/16) trained on CIFAR-10 dataset, compared to only 73.20% agreement for a ResNet-18 victim, when using ViT-L/16 as the thief model. We arguably show, for the first time, that utilizing FMs for downstream tasks may not be the best choice for deployment in commercial APIs due to their susceptibility to model theft. We thereby alert model owners towards the associated security risks, and highlight the need for robust security measures to safeguard such models against theft. Code is available at https://github.com/rajankita/foundation_model_stealing.",
        "tags": [
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "97",
        "title": "Towards Thinking-Optimal Scaling of Test-Time Compute for LLM Reasoning",
        "author": [
            "Wenkai Yang",
            "Shuming Ma",
            "Yankai Lin",
            "Furu Wei"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18080",
        "abstract": "Recent studies have shown that making a model spend more time thinking through longer Chain of Thoughts (CoTs) enables it to gain significant improvements in complex reasoning tasks. While current researches continue to explore the benefits of increasing test-time compute by extending the CoT lengths of Large Language Models (LLMs), we are concerned about a potential issue hidden behind the current pursuit of test-time scaling: Would excessively scaling the CoT length actually bring adverse effects to a model's reasoning performance? Our explorations on mathematical reasoning tasks reveal an unexpected finding that scaling with longer CoTs can indeed impair the reasoning performance of LLMs in certain domains. Moreover, we discover that there exists an optimal scaled length distribution that differs across different domains. Based on these insights, we propose a Thinking-Optimal Scaling strategy. Our method first uses a small set of seed data with varying response length distributions to teach the model to adopt different reasoning efforts for deep thinking. Then, the model selects its shortest correct response under different reasoning efforts on additional problems for self-improvement. Our self-improved models built upon Qwen2.5-32B-Instruct outperform other distillation-based 32B o1-like models across various math benchmarks, and achieve performance on par with QwQ-32B-Preview.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "98",
        "title": "A Fusion Model for Art Style and Author Recognition Based on Convolutional Neural Networks and Transformers",
        "author": [
            "Zhenyu Wang",
            "Heng Song"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18083",
        "abstract": "The recognition of art styles and authors is crucial in areas like cultural heritage protection, art market analysis, and historical research. With the advancement of deep learning, Convolutional Neural Networks (CNNs) and Transformer models have become key tools for image classification. While CNNs excel in local feature extraction, they struggle with global context, and Transformers are strong in capturing global dependencies but weak in fine-grained local details. To address these challenges, this paper proposes a fusion model combining CNNs and Transformers for art style and author recognition. The model first extracts local features using CNNs, then captures global context with a Transformer, followed by a feature fusion mechanism to enhance classification accuracy. Experiments on Chinese and oil painting datasets show the fusion model outperforms individual CNN and Transformer models, improving classification accuracy by 9.7% and 7.1%, respectively, and increasing F1 scores by 0.06 and 0.05. The results demonstrate the model's effectiveness and potential for future improvements, such as multimodal integration and architecture optimization.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "99",
        "title": "Stackelberg Game Preference Optimization for Data-Efficient Alignment of Language Models",
        "author": [
            "Xu Chu",
            "Zhixin Zhang",
            "Tianyu Jia",
            "Yujie Jin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18099",
        "abstract": "Aligning language models with human preferences is critical for real-world deployment, but existing methods often require large amounts of high-quality human annotations. Aiming at a data-efficient alignment method, we propose Stackelberg Game Preference Optimization (SGPO), a framework that models alignment as a two-player Stackelberg game, where a policy (leader) optimizes against a worst-case preference distribution (follower) within an $\\epsilon$-Wasserstein ball, ensuring robustness to (self-)annotation noise and distribution shifts. SGPO guarantees $O(\\epsilon)$-bounded regret, unlike Direct Preference Optimization (DPO), which suffers from linear regret growth in the distribution mismatch. We instantiate SGPO with the Stackelberg Self-Annotated Preference Optimization (SSAPO) algorithm, which iteratively self-annotates preferences and adversarially reweights synthetic annotated preferences. Using only 2K seed preferences, from the UltraFeedback dataset, i.e., 1/30 of human labels in the dataset, our method achieves 35.82% GPT-4 win-rate with Mistral-7B and 40.12% with Llama3-8B-Instruct within three rounds of SSAPO.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "100",
        "title": "Detecting Offensive Memes with Social Biases in Singapore Context Using Multimodal Large Language Models",
        "author": [
            "Cao Yuxuan",
            "Wu Jiayang",
            "Alistair Cheong Liang Chuen",
            "Bryan Shan Guanrong",
            "Theodore Lee Chong Jen",
            "Sherman Chann Zhi Shen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18101",
        "abstract": "Traditional online content moderation systems struggle to classify modern multimodal means of communication, such as memes, a highly nuanced and information-dense medium. This task is especially hard in a culturally diverse society like Singapore, where low-resource languages are used and extensive knowledge on local context is needed to interpret online content. We curate a large collection of 112K memes labeled by GPT-4V for fine-tuning a VLM to classify offensive memes in Singapore context. We show the effectiveness of fine-tuned VLMs on our dataset, and propose a pipeline containing OCR, translation and a 7-billion parameter-class VLM. Our solutions reach 80.62% accuracy and 0.8192 AUROC on a held-out test set, and can greatly aid human in moderating online contents. The dataset, code, and model weights will be open-sourced at https://github.com/aliencaocao/vlm-for-memes-aisg.",
        "tags": [
            "GPT",
            "Large Language Models"
        ]
    },
    {
        "id": "101",
        "title": "Bayesian Optimization for Controlled Image Editing via LLMs",
        "author": [
            "Chengkun Cai",
            "Haoliang Liu",
            "Xu Zhao",
            "Zhongyu Jiang",
            "Tianfang Zhang",
            "Zongkai Wu",
            "Jenq-Neng Hwang",
            "Serge Belongie",
            "Lei Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18116",
        "abstract": "In the rapidly evolving field of image generation, achieving precise control over generated content and maintaining semantic consistency remain significant limitations, particularly concerning grounding techniques and the necessity for model fine-tuning. To address these challenges, we propose BayesGenie, an off-the-shelf approach that integrates Large Language Models (LLMs) with Bayesian Optimization to facilitate precise and user-friendly image editing. Our method enables users to modify images through natural language descriptions without manual area marking, while preserving the original image's semantic integrity. Unlike existing techniques that require extensive pre-training or fine-tuning, our approach demonstrates remarkable adaptability across various LLMs through its model-agnostic design. BayesGenie employs an adapted Bayesian optimization strategy to automatically refine the inference process parameters, achieving high-precision image editing with minimal user intervention. Through extensive experiments across diverse scenarios, we demonstrate that our framework significantly outperforms existing methods in both editing accuracy and semantic preservation, as validated using different LLMs including Claude3 and GPT-4.",
        "tags": [
            "GPT",
            "Image Editing",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "102",
        "title": "Personalized Federated Learning for Egocentric Video Gaze Estimation with Comprehensive Parameter Frezzing",
        "author": [
            "Yuhu Feng",
            "Keisuke Maeda",
            "Takahiro Ogawa",
            "Miki Haseyama"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18123",
        "abstract": "Egocentric video gaze estimation requires models to capture individual gaze patterns while adapting to diverse user data. Our approach leverages a transformer-based architecture, integrating it into a PFL framework where only the most significant parameters, those exhibiting the highest rate of change during training, are selected and frozen for personalization in client models. Through extensive experimentation on the EGTEA Gaze+ and Ego4D datasets, we demonstrate that FedCPF significantly outperforms previously reported federated learning methods, achieving superior recall, precision, and F1-score. These results confirm the effectiveness of our comprehensive parameters freezing strategy in enhancing model personalization, making FedCPF a promising approach for tasks requiring both adaptability and accuracy in federated learning settings.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "103",
        "title": "HyperG: Hypergraph-Enhanced LLMs for Structured Knowledge",
        "author": [
            "Sirui Huang",
            "Hanqian Li",
            "Yanggan Gu",
            "Xuming Hu",
            "Qing Li",
            "Guandong Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18125",
        "abstract": "Given that substantial amounts of domain-specific knowledge are stored in structured formats, such as web data organized through HTML, Large Language Models (LLMs) are expected to fully comprehend this structured information to broaden their applications in various real-world downstream tasks. Current approaches for applying LLMs to structured data fall into two main categories: serialization-based and operation-based methods. Both approaches, whether relying on serialization or using SQL-like operations as an intermediary, encounter difficulties in fully capturing structural relationships and effectively handling sparse data. To address these unique characteristics of structured data, we propose HyperG, a hypergraph-based generation framework aimed at enhancing LLMs' ability to process structured knowledge. Specifically, HyperG first augment sparse data with contextual information, leveraging the generative power of LLMs, and incorporate a prompt-attentive hypergraph learning (PHL) network to encode both the augmented information and the intricate structural relationships within the data. To validate the effectiveness and generalization of HyperG, we conduct extensive experiments across two different downstream tasks requiring structured knowledge.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "104",
        "title": "SpargeAttn: Accurate Sparse Attention Accelerating Any Model Inference",
        "author": [
            "Jintao Zhang",
            "Chendong Xiang",
            "Haofeng Huang",
            "Jia Wei",
            "Haocheng Xi",
            "Jun Zhu",
            "Jianfei Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18137",
        "abstract": "An efficient attention implementation is essential for large models due to its quadratic time complexity. Fortunately, attention commonly exhibits sparsity, i.e., many values in the attention map are near zero, allowing for the omission of corresponding computations. Many studies have utilized the sparse pattern to accelerate attention. However, most existing works focus on optimizing attention within specific models by exploiting certain sparse patterns of the attention map. A universal sparse attention that guarantees both the speedup and end-to-end performance of diverse models remains elusive. In this paper, we propose SpargeAttn, a universal sparse and quantized attention for any model. Our method uses a two-stage online filter: in the first stage, we rapidly and accurately predict the attention map, enabling the skip of some matrix multiplications in attention. In the second stage, we design an online softmax-aware filter that incurs no extra overhead and further skips some matrix multiplications. Experiments show that our method significantly accelerates diverse models, including language, image, and video generation, without sacrificing end-to-end metrics. The codes are available at https://github.com/thu-ml/SpargeAttn.",
        "tags": [
            "Video Generation"
        ]
    },
    {
        "id": "105",
        "title": "Large Language Model Driven Agents for Simulating Echo Chamber Formation",
        "author": [
            "Chenhao Gu",
            "Ling Luo",
            "Zainab Razia Zaidi",
            "Shanika Karunasekera"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18138",
        "abstract": "The rise of echo chambers on social media platforms has heightened concerns about polarization and the reinforcement of existing beliefs. Traditional approaches for simulating echo chamber formation have often relied on predefined rules and numerical simulations, which, while insightful, may lack the nuance needed to capture complex, real-world interactions. In this paper, we present a novel framework that leverages large language models (LLMs) as generative agents to simulate echo chamber dynamics within social networks. The novelty of our approach is that it incorporates both opinion updates and network rewiring behaviors driven by LLMs, allowing for a context-aware and semantically rich simulation of social interactions. Additionally, we utilize real-world Twitter (now X) data to benchmark the LLM-based simulation against actual social media behaviors, providing insights into the accuracy and realism of the generated opinion trends. Our results demonstrate the efficacy of LLMs in modeling echo chamber formation, capturing both structural and semantic dimensions of opinion clustering. %This work contributes to a deeper understanding of social influence dynamics and offers a new tool for studying polarization in online communities.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "106",
        "title": "LevelRAG: Enhancing Retrieval-Augmented Generation with Multi-hop Logic Planning over Rewriting Augmented Searchers",
        "author": [
            "Zhuocheng Zhang",
            "Yang Feng",
            "Min Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18139",
        "abstract": "Retrieval-Augmented Generation (RAG) is a crucial method for mitigating hallucinations in Large Language Models (LLMs) and integrating external knowledge into their responses. Existing RAG methods typically employ query rewriting to clarify the user intent and manage multi-hop logic, while using hybrid retrieval to expand search scope. However, the tight coupling of query rewriting to the dense retriever limits its compatibility with hybrid retrieval, impeding further RAG performance improvements. To address this challenge, we introduce a high-level searcher that decomposes complex queries into atomic queries, independent of any retriever-specific optimizations. Additionally, to harness the strengths of sparse retrievers for precise keyword retrieval, we have developed a new sparse searcher that employs Lucene syntax to enhance retrieval http://accuracy.Alongside web and dense searchers, these components seamlessly collaborate within our proposed method, \\textbf{LevelRAG}. In LevelRAG, the high-level searcher orchestrates the retrieval logic, while the low-level searchers (sparse, web, and dense) refine the queries for optimal retrieval. This approach enhances both the completeness and accuracy of the retrieval process, overcoming challenges associated with current query rewriting techniques in hybrid retrieval scenarios. Empirical experiments conducted on five datasets, encompassing both single-hop and multi-hop question answering tasks, demonstrate the superior performance of LevelRAG compared to existing RAG methods. Notably, LevelRAG outperforms the state-of-the-art proprietary model, GPT4o, underscoring its effectiveness and potential impact on the RAG field.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "107",
        "title": "Actively Inferring Optimal Measurement Sequences",
        "author": [
            "Catherine F. Higham",
            "Paul Henderson",
            "Roderick Murray-Smith"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18142",
        "abstract": "Measurement of a physical quantity such as light intensity is an integral part of many reconstruction and decision scenarios but can be costly in terms of acquisition time, invasion of or damage to the environment and storage. Data minimisation and compliance with data protection laws is also an important consideration. Where there are a range of measurements that can be made, some may be more informative and compliant with the overall measurement objective than others. We develop an active sequential inference algorithm that uses the low dimensional representational latent space from a variational autoencoder (VAE) to choose which measurement to make next. Our aim is to recover high dimensional data by making as few measurements as possible. We adapt the VAE encoder to map partial data measurements on to the latent space of the complete data. The algorithm draws samples from this latent space and uses the VAE decoder to generate data conditional on the partial measurements. Estimated measurements are made on the generated data and fed back through the partial VAE encoder to the latent space where they can be evaluated prior to making a measurement. Starting from no measurements and a normal prior on the latent space, we consider alternative strategies for choosing the next measurement and updating the predictive posterior prior for the next step. The algorithm is illustrated using the Fashion MNIST dataset and a novel convolutional Hadamard pattern measurement basis. We see that useful patterns are chosen within 10 steps, leading to the convergence of the guiding generative images. Compared with using stochastic variational inference to infer the parameters of the posterior distribution for each generated data point individually, the partial VAE framework can efficiently process batches of generated data and obtains superior results with minimal measurements.",
        "tags": [
            "VAE"
        ]
    },
    {
        "id": "108",
        "title": "Carbon and Silicon, Coexist or Compete? A Survey on Human-AI Interactions in Agent-based Modeling and Simulation",
        "author": [
            "Ziyue Lin",
            "Siqi Shen",
            "Zichen Cheng",
            "Cheok Lam Lai",
            "Siming Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18145",
        "abstract": "Recent interest in human-AI interactions in agent-based modeling and simulation (ABMS) has grown rapidly due to the widespread utilization of large language models (LLMs). ABMS is an intelligent approach that simulates autonomous agents' behaviors within a defined environment to research emergent phenomena. Integrating LLMs into ABMS enables natural language interaction between humans and models. Meanwhile, it introduces new challenges that rely on human interaction to address. Human involvement can assist ABMS in adapting to flexible and complex research demands. However, systematic reviews of interactions that examine how humans and AI interact in ABMS are lacking. In this paper, we investigate existing works and propose a novel taxonomy to categorize the interactions derived from them. Specifically, human users refer to researchers who utilize ABMS tools to conduct their studies in our survey. We decompose interactions into five dimensions: the goals that users want to achieve (Why), the phases that users are involved (When), the components of the system (What), the roles of users (Who), and the means of interactions (How). Our analysis summarizes the findings that reveal existing interaction patterns. They provide researchers who develop interactions with comprehensive guidance on how humans and AI interact. We further discuss the unexplored interactions and suggest future research directions.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "109",
        "title": "Jacobian Sparse Autoencoders: Sparsify Computations, Not Just Activations",
        "author": [
            "Lucy Farnik",
            "Tim Lawson",
            "Conor Houghton",
            "Laurence Aitchison"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18147",
        "abstract": "Sparse autoencoders (SAEs) have been successfully used to discover sparse and human-interpretable representations of the latent activations of LLMs. However, we would ultimately like to understand the computations performed by LLMs and not just their representations. The extent to which SAEs can help us understand computations is unclear because they are not designed to \"sparsify\" computations in any sense, only latent activations. To solve this, we propose Jacobian SAEs (JSAEs), which yield not only sparsity in the input and output activations of a given model component but also sparsity in the computation (formally, the Jacobian) connecting them. With a naÃ¯ve implementation, the Jacobians in LLMs would be computationally intractable due to their size. One key technical contribution is thus finding an efficient way of computing Jacobians in this setup. We find that JSAEs extract a relatively large degree of computational sparsity while preserving downstream LLM performance approximately as well as traditional SAEs. We also show that Jacobians are a reasonable proxy for computational sparsity because MLPs are approximately linear when rewritten in the JSAE basis. Lastly, we show that JSAEs achieve a greater degree of computational sparsity on pre-trained LLMs than on the equivalent randomized LLM. This shows that the sparsity of the computational graph appears to be a property that LLMs learn through training, and suggests that JSAEs might be more suitable for understanding learned transformer computations than standard SAEs.",
        "tags": [
            "LLMs",
            "Transformer"
        ]
    },
    {
        "id": "110",
        "title": "NusaAksara: A Multimodal and Multilingual Benchmark for Preserving Indonesian Indigenous Scripts",
        "author": [
            "Muhammad Farid Adilazuarda",
            "Musa Izzanardi Wijanarko",
            "Lucky Susanto",
            "Khumaisa Nur'aini",
            "Derry Wijaya",
            "Alham Fikri Aji"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18148",
        "abstract": "Indonesia is rich in languages and scripts. However, most NLP progress has been made using romanized text. In this paper, we present NusaAksara, a novel public benchmark for Indonesian languages that includes their original scripts. Our benchmark covers both text and image modalities and encompasses diverse tasks such as image segmentation, OCR, transliteration, translation, and language identification. Our data is constructed by human experts through rigorous steps. NusaAksara covers 8 scripts across 7 languages, including low-resource languages not commonly seen in NLP benchmarks. Although unsupported by Unicode, the Lampung script is included in this dataset. We benchmark our data across several models, from LLMs and VLMs such as GPT-4o, Llama 3.2, and Aya 23 to task-specific systems such as PP-OCR and LangID, and show that most NLP technologies cannot handle Indonesia's local scripts, with many achieving near-zero performance.",
        "tags": [
            "GPT",
            "LLMs",
            "LLaMA",
            "Segmentation"
        ]
    },
    {
        "id": "111",
        "title": "Joint Reconstruction of Spatially-Coherent and Realistic Clothed Humans and Objects from a Single Image",
        "author": [
            "Ayushi Dutta",
            "Marco Pesavento",
            "Marco Volino",
            "Adrian Hilton",
            "Armin Mustafa"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18150",
        "abstract": "Recent advances in human shape learning have focused on achieving accurate human reconstruction from single-view images. However, in the real world, humans share space with other objects. Reconstructing images with humans and objects is challenging due to the occlusions and lack of 3D spatial awareness, which leads to depth ambiguity in the reconstruction. Existing methods in monocular human-object reconstruction fail to capture intricate details of clothed human bodies and object surfaces due to their template-based nature. In this paper, we jointly reconstruct clothed humans and objects in a spatially coherent manner from single-view images, while addressing human-object occlusions. A novel attention-based neural implicit model is proposed that leverages image pixel alignment to retrieve high-quality details, and incorporates semantic features extracted from the human-object pose to enable 3D spatial awareness. A generative diffusion model is used to handle human-object occlusions. For training and evaluation, we introduce a synthetic dataset with rendered scenes of inter-occluded 3D human scans and diverse objects. Extensive evaluation on both synthetic and real datasets demonstrates the superior quality of proposed human-object reconstructions over competitive methods.",
        "tags": [
            "3D",
            "Diffusion"
        ]
    },
    {
        "id": "112",
        "title": "Can LLMs Explain Themselves Counterfactually?",
        "author": [
            "Zahra Dehghanighobadi",
            "Asja Fischer",
            "Muhammad Bilal Zafar"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18156",
        "abstract": "Explanations are an important tool for gaining insights into the behavior of ML models, calibrating user trust and ensuring regulatory compliance. Past few years have seen a flurry of post-hoc methods for generating model explanations, many of which involve computing model gradients or solving specially designed optimization problems. However, owing to the remarkable reasoning abilities of Large Language Model (LLMs), self-explanation, that is, prompting the model to explain its outputs has recently emerged as a new paradigm. In this work, we study a specific type of self-explanations, self-generated counterfactual explanations (SCEs). We design tests for measuring the efficacy of LLMs in generating SCEs. Analysis over various LLM families, model sizes, temperature settings, and datasets reveals that LLMs sometimes struggle to generate SCEs. Even when they do, their prediction often does not agree with their own counterfactual reasoning.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "113",
        "title": "SECURA: Sigmoid-Enhanced CUR Decomposition with Uninterrupted Retention and Low-Rank Adaptation in Large Language Models",
        "author": [
            "Zhang Yuxuan",
            "Li Ruizhe"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18168",
        "abstract": "With the rapid development of large language models (LLMs), fully fine-tuning (FT) these models has become increasingly impractical due to the high computational demands. Additionally, FT can lead to catastrophic forgetting. As an alternative, Low-Rank Adaptation (LoRA) has been proposed, which fine-tunes only a small subset of parameters, achieving similar performance to FT while significantly reducing resource requirements. However, since LoRA inherits FT's design, the issue of catastrophic forgetting remains.\nTo address these challenges, we propose SECURA: Sigmoid-Enhanced CUR Decomposition LoRA, a novel parameter-efficient fine-tuning (PEFT) variant that mitigates catastrophic forgetting while improving fine-tuning performance. Our method introduces a new normalization technique, SigNorm, to enhance parameter retention and overall performance.\nSECURA has been evaluated on a variety of tasks, including mathematical problem-solving (GSM8K), challenging question-answering (CNNDM), translation (NewsDE), and complex multiple-choice reasoning (LogiQA). Experimental results show that SECURA achieves an average fine-tuning improvement of 3.59% across four multiple-choice question (MCQ) tasks and a 2.51% improvement across five question-answering (QA) tasks on models such as Gemma2 2b, Qwen2 1.5b, Qwen 2 7b, Llama3 8b, and Llama3.1 8b, compared to DoRA. Moreover, SECURA demonstrates superior knowledge retention capabilities, maintaining more than 70% accuracy on basic LLM knowledge across 16 continual learning tests, outperforming Experience Replay (ER), Sequential Learning (SEQ), EWC, I-LoRA, and CUR-LoRA.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "LoRA",
            "Low-Rank Adaptation",
            "Qwen"
        ]
    },
    {
        "id": "114",
        "title": "CLIPure: Purification in Latent Space via CLIP for Adversarially Robust Zero-Shot Classification",
        "author": [
            "Mingkun Zhang",
            "Keping Bi",
            "Wei Chen",
            "Jiafeng Guo",
            "Xueqi Cheng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18176",
        "abstract": "In this paper, we aim to build an adversarially robust zero-shot image classifier. We ground our work on CLIP, a vision-language pre-trained encoder model that can perform zero-shot classification by matching an image with text prompts ``a photo of a <class-name>.''. Purification is the path we choose since it does not require adversarial training on specific attack types and thus can cope with any foreseen attacks. We then formulate purification risk as the KL divergence between the joint distributions of the purification process of denoising the adversarial samples and the attack process of adding perturbations to benign samples, through bidirectional Stochastic Differential Equations (SDEs). The final derived results inspire us to explore purification in the multi-modal latent space of CLIP. We propose two variants for our CLIPure approach: CLIPure-Diff which models the likelihood of images' latent vectors with the DiffusionPrior module in DaLLE-2 (modeling the generation process of CLIP's latent vectors), and CLIPure-Cos which models the likelihood with the cosine similarity between the embeddings of an image and ``a photo of a.''. As far as we know, CLIPure is the first purification method in multi-modal latent space and CLIPure-Cos is the first purification method that is not based on generative models, which substantially improves defense efficiency. We conducted extensive experiments on CIFAR-10, ImageNet, and 13 datasets that previous CLIP-based defense methods used for evaluating zero-shot classification robustness. Results show that CLIPure boosts the SOTA robustness by a large margin, e.g., from 71.7% to 91.1% on CIFAR10, from 59.6% to 72.6% on ImageNet, and 108% relative improvements of average robustness on the 13 datasets over previous SOTA. The code is available at https://github.com/TMLResearchGroup-CAS/CLIPure.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "115",
        "title": "Problem Solved? Information Extraction Design Space for Layout-Rich Documents using LLMs",
        "author": [
            "Gaye Colakoglu",
            "GÃ¼rkan Solmaz",
            "Jonathan FÃ¼rst"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18179",
        "abstract": "This paper defines and explores the design space for information extraction (IE) from layout-rich documents using large language models (LLMs). The three core challenges of layout-aware IE with LLMs are 1) data structuring, 2) model engagement, and 3) output refinement. Our study delves into the sub-problems within these core challenges, such as input representation, chunking, prompting, and selection of LLMs and multimodal models. It examines the outcomes of different design choices through a new layout-aware IE test suite, benchmarking against the state-of-art (SoA) model LayoutLMv3. The results show that the configuration from one-factor-at-a-time (OFAT) trial achieves near-optimal results with 14.1 points F1-score gain from the baseline model, while full factorial exploration yields only a slightly higher 15.1 points gain at around 36x greater token usage. We demonstrate that well-configured general-purpose LLMs can match the performance of specialized models, providing a cost-effective alternative. Our test-suite is freely available at https://github.com/gayecolakoglu/LayIE-LLM.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "116",
        "title": "ChatMotion: A Multimodal Multi-Agent for Human Motion Analysis",
        "author": [
            "Li Lei",
            "Jia Sen",
            "Wang Jianhao",
            "An Zhaochong",
            "Li Jiaang",
            "Hwang Jenq-Neng",
            "Belongie Serge"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18180",
        "abstract": "Advancements in Multimodal Large Language Models (MLLMs) have improved human motion understanding. However, these models remain constrained by their \"instruct-only\" nature, lacking interactivity and adaptability for diverse analytical perspectives. To address these challenges, we introduce ChatMotion, a multimodal multi-agent framework for human motion analysis. ChatMotion dynamically interprets user intent, decomposes complex tasks into meta-tasks, and activates specialized function modules for motion comprehension. It integrates multiple specialized modules, such as the MotionCore, to analyze human motion from various perspectives. Extensive experiments demonstrate ChatMotion's precision, adaptability, and user engagement for human motion understanding.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "117",
        "title": "Multi-Perspective Data Augmentation for Few-shot Object Detection",
        "author": [
            "Anh-Khoa Nguyen Vu",
            "Quoc-Truong Truong",
            "Vinh-Tiep Nguyen",
            "Thanh Duc Ngo",
            "Thanh-Toan Do",
            "Tam V. Nguyen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18195",
        "abstract": "Recent few-shot object detection (FSOD) methods have focused on augmenting synthetic samples for novel classes, show promising results to the rise of diffusion models. However, the diversity of such datasets is often limited in representativeness because they lack awareness of typical and hard samples, especially in the context of foreground and background relationships. To tackle this issue, we propose a Multi-Perspective Data Augmentation (MPAD) framework. In terms of foreground-foreground relationships, we propose in-context learning for object synthesis (ICOS) with bounding box adjustments to enhance the detail and spatial information of synthetic samples. Inspired by the large margin principle, support samples play a vital role in defining class boundaries. Therefore, we design a Harmonic Prompt Aggregation Scheduler (HPAS) to mix prompt embeddings at each time step of the generation process in diffusion models, producing hard novel samples. For foreground-background relationships, we introduce a Background Proposal method (BAP) to sample typical and hard backgrounds. Extensive experiments on multiple FSOD benchmarks demonstrate the effectiveness of our approach. Our framework significantly outperforms traditional methods, achieving an average increase of $17.5\\%$ in nAP50 over the baseline on PASCAL VOC. Code is available at https://github.com/nvakhoa/MPAD.",
        "tags": [
            "Detection",
            "Diffusion"
        ]
    },
    {
        "id": "118",
        "title": "Training Consistency Models with Variational Noise Coupling",
        "author": [
            "Gianluigi Silvestri",
            "Luca Ambrogioni",
            "Chieh-Hsin Lai",
            "Yuhta Takida",
            "Yuki Mitsufuji"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18197",
        "abstract": "Consistency Training (CT) has recently emerged as a promising alternative to diffusion models, achieving competitive performance in image generation tasks. However, non-distillation consistency training often suffers from high variance and instability, and analyzing and improving its training dynamics is an active area of research. In this work, we propose a novel CT training approach based on the Flow Matching framework. Our main contribution is a trained noise-coupling scheme inspired by the architecture of Variational Autoencoders (VAE). By training a data-dependent noise emission model implemented as an encoder architecture, our method can indirectly learn the geometry of the noise-to-data mapping, which is instead fixed by the choice of the forward process in classical CT. Empirical results across diverse image datasets show significant generative improvements, with our model outperforming baselines and achieving the state-of-the-art (SoTA) non-distillation CT FID on CIFAR-10, and attaining FID on par with SoTA on ImageNet at $64 \\times 64$ resolution in 2-step generation. Our code is available at https://github.com/sony/vct .",
        "tags": [
            "Consistency Models",
            "Diffusion",
            "Flow Matching",
            "VAE"
        ]
    },
    {
        "id": "119",
        "title": "Intersubjective Model of AI-mediated Communication: Augmenting Human-Human Text Chat through LLM-based Adaptive Agent Pair",
        "author": [
            "Shutaro Aoyama",
            "Rintaro Chujo",
            "Ari Hautasaari",
            "Takeshi Naemura"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18201",
        "abstract": "The growing prevalence of Large Language Models (LLMs) is reshaping online text-based communication; a transformation that is extensively studied as AI-mediated communication. However, much of the existing research remains bound by traditional communication models, where messages are created and transmitted directly between humans despite LLMs being able to play a more active role in transforming messages. In this work, we propose the Intersubjective Model of AI-mediated Communication, an alternative communication model that leverages LLM-based adaptive agents to augment human-human communication. Unlike traditional communication models that focus on the accurate transmission of information, the Intersubjective Model allows for communication to be designed in an adaptive and customizable way to create alternative interactions by dynamically shaping messages in real time and facilitating shared understanding between the human participants. In this paper, we have developed a prototype text chat system based on the Intersubjective Model to describe the potential of this model, as well as the design space it affords.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "120",
        "title": "Grandes modelos de lenguaje: de la predicciÃ³n de palabras a la comprensiÃ³n?",
        "author": [
            "Carlos GÃ³mez-RodrÃ­guez"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18205",
        "abstract": "Large language models, such as the well-known ChatGPT, have brought about an unexpected revolution in the field of artificial intelligence. On the one hand, they have numerous practical applications and enormous potential still to be explored. On the other hand, they are also the subject of debate from scientific, philosophical, and social perspectives: there are doubts about the exact mechanisms of their functioning and their actual capacity for language comprehension, and their applications raise ethical dilemmas. In this chapter, we describe how this technology has been developed and the fundamentals of its operation, allowing us to better understand its capabilities and limitations and to introduce some of the main debates surrounding its development and use.\n--\nLos grandes modelos de lenguaje, como el conocido ChatGPT, han supuesto una inesperada revoluciÃ³n en el Ã¡mbito de la inteligencia artificial. Por un lado, cuentan con multitud de aplicaciones prÃ¡cticas y un enorme potencial todavÃ­a por explorar. Por otro lado, son tambiÃ©n objeto de debate, tanto desde el punto de vista cientÃ­fico y filosÃ³fico como social: hay dudas sobre los mecanismos exactos de su funcionamiento y su capacidad real de comprensiÃ³n del lenguaje, y sus aplicaciones plantean dilemas Ã©ticos. En este capÃ­tulo describimos cÃ³mo se ha llegado a esta tecnologÃ­a y los fundamentos de su funcionamiento, permitiÃ©ndonos asÃ­ comprender mejor sus capacidades y limitaciones e introducir algunos de los principales debates que rodean su desarrollo y uso.",
        "tags": [
            "ChatGPT",
            "Large Language Models"
        ]
    },
    {
        "id": "121",
        "title": "A Normal Variance Mixture Model for Robust Kalman Filtering",
        "author": [
            "Michael J. Walsh"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18206",
        "abstract": "The Kalman filter is ubiquitous for state space models because of its desirable statistical properties, ease of implementation, and generally good performance. However, it can perform poorly in the presence of outliers, or measurements with noise variances much greater than those assumed by the filter. An algorithm that is similar to the Kalman filter but robust to outliers is derived in this report. This algorithm -- called the normal variance mixture filter (NVMF) -- replaces the Gaussian distribution for the noise in the Kalman filter measurement model with a normal variance mixture distribution that admits heavier tails. Choice of the mixing density determines the complexity and performance of the NVMF. When the mixing density is the Dirac delta function, the NVMF is equivalent to the Kalman filter. Choice of an inverse gamma mixing density leads to closed-form recursions for the state estimate and its error covariance matrix that are robust to outliers. The NVMF is compared to the benchmark probabilistic data association filter (PDAF), as well as two other robust filters from the recent literature, for a simulated example. While all four robust filters outperform the Kalman filter when outliers are present, the NVMF provides the most consistent performance across all simulations.",
        "tags": [
            "State Space Models"
        ]
    },
    {
        "id": "122",
        "title": "LAG: LLM agents for Leaderboard Auto Generation on Demanding",
        "author": [
            "Jian Wu",
            "Jiayu Zhang",
            "Dongyuan Li",
            "Linyi Yang",
            "Aoxiao Zhong",
            "Renhe Jiang",
            "Qingsong Wen",
            "Yue Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18209",
        "abstract": "This paper introduces Leaderboard Auto Generation (LAG), a novel and well-organized framework for automatic generation of leaderboards on a given research topic in rapidly evolving fields like Artificial Intelligence (AI). Faced with a large number of AI papers updated daily, it becomes difficult for researchers to track every paper's proposed methods, experimental results, and settings, prompting the need for efficient automatic leaderboard construction. While large language models (LLMs) offer promise in automating this process, challenges such as multi-document summarization, leaderboard generation, and experiment fair comparison still remain under exploration. LAG solves these challenges through a systematic approach that involves the paper collection, experiment results extraction and integration, leaderboard generation, and quality evaluation. Our contributions include a comprehensive solution to the leaderboard construction problem, a reliable evaluation method, and experimental results showing the high quality of leaderboards.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "123",
        "title": "From ChatGPT to DeepSeek: Can LLMs Simulate Humanity?",
        "author": [
            "Qian Wang",
            "Zhenheng Tang",
            "Bingsheng He"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18210",
        "abstract": "Simulation powered by Large Language Models (LLMs) has become a promising method for exploring complex human social behaviors. However, the application of LLMs in simulations presents significant challenges, particularly regarding their capacity to accurately replicate the complexities of human behaviors and societal dynamics, as evidenced by recent studies highlighting discrepancies between simulated and real-world interactions. We rethink LLM-based simulations by emphasizing both their limitations and the necessities for advancing LLM simulations. By critically examining these challenges, we aim to offer actionable insights and strategies for enhancing the applicability of LLM simulations in human society in the future.",
        "tags": [
            "ChatGPT",
            "DeepSeek",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "124",
        "title": "Learning Structure-Supporting Dependencies via Keypoint Interactive Transformer for General Mammal Pose Estimation",
        "author": [
            "Tianyang Xu",
            "Jiyong Rao",
            "Xiaoning Song",
            "Zhenhua Feng",
            "Xiao-Jun Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18214",
        "abstract": "General mammal pose estimation is an important and challenging task in computer vision, which is essential for understanding mammal behaviour in real-world applications. However, existing studies are at their preliminary research stage, which focus on addressing the problem for only a few specific mammal species. In principle, from specific to general mammal pose estimation, the biggest issue is how to address the huge appearance and pose variances for different species. We argue that given appearance context, instance-level prior and the structural relation among keypoints can serve as complementary evidence. To this end, we propose a Keypoint Interactive Transformer (KIT) to learn instance-level structure-supporting dependencies for general mammal pose estimation. Specifically, our KITPose consists of two coupled components. The first component is to extract keypoint features and generate body part prompts. The features are supervised by a dedicated generalised heatmap regression loss (GHRL). Instead of introducing external visual/text prompts, we devise keypoints clustering to generate body part biases, aligning them with image context to generate corresponding instance-level prompts. Second, we propose a novel interactive transformer that takes feature slices as input tokens without performing spatial splitting. In addition, to enhance the capability of the KIT model, we design an adaptive weight strategy to address the imbalance issue among different keypoints.",
        "tags": [
            "Pose Estimation",
            "Transformer"
        ]
    },
    {
        "id": "125",
        "title": "Synthesizing Consistent Novel Views via 3D Epipolar Attention without Re-Training",
        "author": [
            "Botao Ye",
            "Sifei Liu",
            "Xueting Li",
            "Marc Pollefeys",
            "Ming-Hsuan Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18219",
        "abstract": "Large diffusion models demonstrate remarkable zero-shot capabilities in novel view synthesis from a single image. However, these models often face challenges in maintaining consistency across novel and reference views. A crucial factor leading to this issue is the limited utilization of contextual information from reference views. Specifically, when there is an overlap in the viewing frustum between two views, it is essential to ensure that the corresponding regions maintain consistency in both geometry and appearance. This observation leads to a simple yet effective approach, where we propose to use epipolar geometry to locate and retrieve overlapping information from the input view. This information is then incorporated into the generation of target views, eliminating the need for training or fine-tuning, as the process requires no learnable parameters. Furthermore, to enhance the overall consistency of generated views, we extend the utilization of epipolar attention to a multi-view setting, allowing retrieval of overlapping information from the input view and other target views. Qualitative and quantitative experimental results demonstrate the effectiveness of our method in significantly improving the consistency of synthesized views without the need for any fine-tuning. Moreover, This enhancement also boosts the performance of downstream applications such as 3D reconstruction. The code is available at https://github.com/botaoye/ConsisSyn.",
        "tags": [
            "3D",
            "Diffusion"
        ]
    },
    {
        "id": "126",
        "title": "Debt Collection Negotiations with Large Language Models: An Evaluation System and Optimizing Decision Making with Multi-Agent",
        "author": [
            "Xiaofeng Wang",
            "Zhixin Zhang",
            "Jinguang Zheng",
            "Yiming Ai",
            "Rui Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18228",
        "abstract": "Debt collection negotiations (DCN) are vital for managing non-performing loans (NPLs) and reducing creditor losses. Traditional methods are labor-intensive, while large language models (LLMs) offer promising automation potential. However, prior systems lacked dynamic negotiation and real-time decision-making capabilities. This paper explores LLMs in automating DCN and proposes a novel evaluation framework with 13 metrics across 4 aspects. Our experiments reveal that LLMs tend to over-concede compared to human negotiators. To address this, we propose the Multi-Agent Debt Negotiation (MADeN) framework, incorporating planning and judging modules to improve decision rationality. We also apply post-training techniques, including DPO with rejection sampling, to optimize performance. Our studies provide valuable insights for practitioners and researchers seeking to enhance efficiency and outcomes in this domain.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "127",
        "title": "Unveiling and Causalizing CoT: A Causal Pespective",
        "author": [
            "Jiarun Fu",
            "Lizhong Ding",
            "Hao Li",
            "Pengqi Li",
            "Qiuning Wei",
            "Xu Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18239",
        "abstract": "Although Chain-of-Thought (CoT) has achieved remarkable success in enhancing the reasoning ability of large language models (LLMs), the mechanism of CoT remains a ``black box''. Even if the correct answers can frequently be obtained, existing CoTs struggle to make the reasoning understandable to human. In this paper, we unveil and causalize CoT from a causal perspective to ensure both correctness and understandability of all reasoning steps (to the best of our knowledge, the first such). We model causality of CoT via structural causal models (SCM) to unveil the reasoning mechanism of CoT. To measure the causality of CoT, we define the CoT Average Causal Effect (CACE) to test the causal relations between steps. For those steps without causality (wrong or unintelligible steps), we design a role-playing causal query algorithm to causalize these steps, resulting a causalized CoT with all steps correct and understandable. Experimental results on both open-source and closed-source LLMs demonstrate that the causal errors commonly in steps are effectively corrected and the reasoning ability of LLMs is significantly improved.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "128",
        "title": "Beyond In-Distribution Success: Scaling Curves of CoT Granularity for Language Model Generalization",
        "author": [
            "Ru Wang",
            "Wei Huang",
            "Selena Song",
            "Haoyu Zhang",
            "Yusuke Iwasawa",
            "Yutaka Matsuo",
            "Jiaxian Guo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18273",
        "abstract": "Generalization to novel compound tasks under distribution shift is important for deploying transformer-based language models (LMs). This work investigates Chain-of-Thought (CoT) reasoning as a means to enhance OOD generalization. Through controlled experiments across several compound tasks, we reveal three key insights: (1) While QA-trained models achieve near-perfect in-distribution accuracy, their OOD performance degrades catastrophically, even with 10000k+ training examples; (2) the granularity of CoT data strongly correlates with generalization performance; finer-grained CoT data leads to better generalization; (3) CoT exhibits remarkable sample efficiency, matching QA performance with much less (even 80%) data.\nTheoretically, we demonstrate that compound tasks inherently permit shortcuts in Q-A data that misalign with true reasoning principles, while CoT forces internalization of valid dependency structures, and thus can achieve better generalization. Further, we show that transformer positional embeddings can amplify generalization by emphasizing subtask condition recurrence in long CoT sequences. Our combined theoretical and empirical analysis provides compelling evidence for CoT reasoning as a crucial training paradigm for enabling LM generalization under real-world distributional shifts for compound tasks.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "129",
        "title": "Self-Adjust Softmax",
        "author": [
            "Chuanyang Zheng",
            "Yihang Gao",
            "Guoxuan Chen",
            "Han Shi",
            "Jing Xiong",
            "Xiaozhe Ren",
            "Chao Huang",
            "Xin Jiang",
            "Zhenguo Li",
            "Yu Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18277",
        "abstract": "The softmax function is crucial in Transformer attention, which normalizes each row of the attention scores with summation to one, achieving superior performances over other alternative functions. However, the softmax function can face a gradient vanishing issue when some elements of the attention scores approach extreme values, such as probabilities close to one or zero. In this paper, we propose Self-Adjust Softmax (SA-Softmax) to address this issue by modifying $softmax(x)$ to $x \\cdot softmax(x)$ and its normalized variant $\\frac{(x - min(x_{\\min},0))}{max(0,x_{max})-min(x_{min},0)} \\cdot softmax(x)$. We theoretically show that SA-Softmax provides enhanced gradient properties compared to the vanilla softmax function. Moreover, SA-Softmax Attention can be seamlessly integrated into existing Transformer models to their attention mechanisms with minor adjustments. We conducted experiments to evaluate the empirical performance of Transformer models using SA-Softmax compared to the vanilla softmax function. These experiments, involving models with up to 2.7 billion parameters, are conducted across diverse datasets, language tasks, and positional encoding methods.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "130",
        "title": "Better Aligned with Survey Respondents or Training Data? Unveiling Political Leanings of LLMs on U.S. Supreme Court Cases",
        "author": [
            "Shanshan Xu",
            "T.Y.S.S Santosh",
            "Yanai Elazar",
            "Quirin Vogel",
            "Barbara Plank",
            "Matthias Grabmair"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18282",
        "abstract": "The increased adoption of Large Language Models (LLMs) and their potential to shape public opinion have sparked interest in assessing these models' political leanings. Building on previous research that compared LLMs and human opinions and observed political bias in system responses, we take a step further to investigate the underlying causes of such biases by empirically examining how the values and biases embedded in training corpora shape model outputs. Specifically, we propose a method to quantitatively evaluate political leanings embedded in the large pretraining corpora. Subsequently we investigate to whom are the LLMs' political leanings more aligned with, their pretrainig corpora or the surveyed human opinions. As a case study, we focus on probing the political leanings of LLMs in 32 U.S. Supreme Court cases, addressing contentious topics such as abortion and voting rights. Our findings reveal that LLMs strongly reflect the political leanings in their training data, and no strong correlation is observed with their alignment to human opinions as expressed in surveys. These results underscore the importance of responsible curation of training data and the need for robust evaluation metrics to ensure LLMs' alignment with human-centered values.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "131",
        "title": "AMPO: Active Multi-Preference Optimization",
        "author": [
            "Taneesh Gupta",
            "Rahul Madhavan",
            "Xuchao Zhang",
            "Chetan Bansal",
            "Saravan Rajmohan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18293",
        "abstract": "Multi-preference optimization enriches language-model alignment beyond pairwise preferences by contrasting entire sets of helpful and undesired responses, thereby enabling richer training signals for large language models. During self-play alignment, these models often produce numerous candidate answers per query, rendering it computationally infeasible to include all responses in the training objective. In this work, we propose $\\textit{Active Multi-Preference Optimization}$ (AMPO), a novel approach that combines on-policy generation, a multi-preference group-contrastive loss, and active subset selection. Specifically, we score and embed large candidate pools of responses and then select a small, yet informative, subset that covers reward extremes and distinct semantic clusters for preference optimization. Our contrastive training scheme is capable of identifying not only the best and worst answers but also subtle, underexplored modes that are crucial for robust alignment. Theoretically, we provide guarantees for expected reward maximization using our active selection method, and empirically, AMPO achieves state-of-the-art results on $\\textit{AlpacaEval}$ using Llama 8B.",
        "tags": [
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "132",
        "title": "DeepCircuitX: A Comprehensive Repository-Level Dataset for RTL Code Understanding, Generation, and PPA Analysis",
        "author": [
            "Zeju Li",
            "Changran Xu",
            "Zhengyuan Shi",
            "Zedong Peng",
            "Yi Liu",
            "Yunhao Zhou",
            "Lingfeng Zhou",
            "Chengyu Ma",
            "Jianyuan Zhong",
            "Xi Wang",
            "Jieru Zhao",
            "Zhufei Chu",
            "Xiaoyan Yang",
            "Qiang Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18297",
        "abstract": "This paper introduces DeepCircuitX, a comprehensive repository-level dataset designed to advance RTL (Register Transfer Level) code understanding, generation, and power-performance-area (PPA) analysis. Unlike existing datasets that are limited to either file-level RTL code or physical layout data, DeepCircuitX provides a holistic, multilevel resource that spans repository, file, module, and block-level RTL code. This structure enables more nuanced training and evaluation of large language models (LLMs) for RTL-specific tasks. DeepCircuitX is enriched with Chain of Thought (CoT) annotations, offering detailed descriptions of functionality and structure at multiple levels. These annotations enhance its utility for a wide range of tasks, including RTL code understanding, generation, and completion. Additionally, the dataset includes synthesized netlists and PPA metrics, facilitating early-stage design exploration and enabling accurate PPA prediction directly from RTL code. We demonstrate the dataset's effectiveness on various LLMs finetuned with our dataset and confirm the quality with human evaluations. Our results highlight DeepCircuitX as a critical resource for advancing RTL-focused machine learning applications in hardware design http://automation.Our data is available at https://zeju.gitbook.io/lcm-team.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "133",
        "title": "LDGen: Enhancing Text-to-Image Synthesis via Large Language Model-Driven Language Representation",
        "author": [
            "Pengzhi Li",
            "Pengfei Yu",
            "Zide Liu",
            "Wei He",
            "Xuhao Pan",
            "Xudong Rao",
            "Tao Wei",
            "Wei Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18302",
        "abstract": "In this paper, we introduce LDGen, a novel method for integrating large language models (LLMs) into existing text-to-image diffusion models while minimizing computational demands. Traditional text encoders, such as CLIP and T5, exhibit limitations in multilingual processing, hindering image generation across diverse languages. We address these challenges by leveraging the advanced capabilities of LLMs. Our approach employs a language representation strategy that applies hierarchical caption optimization and human instruction techniques to derive precise semantic information,. Subsequently, we incorporate a lightweight adapter and a cross-modal refiner to facilitate efficient feature alignment and interaction between LLMs and image features. LDGen reduces training time and enables zero-shot multilingual image generation. Experimental results indicate that our method surpasses baseline models in both prompt adherence and image aesthetic quality, while seamlessly supporting multiple languages. Project page: https://zrealli.github.io/LDGen.",
        "tags": [
            "CLIP",
            "Diffusion",
            "LLMs",
            "Large Language Models",
            "Text-to-Image"
        ]
    },
    {
        "id": "134",
        "title": "RefuteBench 2.0 -- Agentic Benchmark for Dynamic Evaluation of LLM Responses to Refutation Instruction",
        "author": [
            "Jianhao Yan",
            "Yun Luo",
            "Yue Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18308",
        "abstract": "In the multi-turn interaction schema, large language models (LLMs) can leverage user feedback to enhance the quality and relevance of their responses. However, evaluating an LLM's ability to incorporate user refutation feedback is crucial yet challenging. In this study, we introduce RefuteBench 2.0, which significantly extends the original RefuteBench by incorporating LLM agents as refuters and evaluators, which allows for flexible and comprehensive assessment.\nWe design both transient and persistent refutation instructions with different validity periods. Meta-evaluation shows that the LLM-based refuter could generate more human-like refutations and the evaluators could assign scores with high correlation with humans. Experimental results of various LLMs show that current models could effectively satisfy the refutation but fail to memorize the refutation information. Interestingly, we also observe that the performance of the initial task decreases as the refutations increase. Analysis of the attention scores further shows a potential weakness of current LLMs: they struggle to retain and correctly use previous information during long context dialogues. https://github.com/ElliottYan/RefuteBench-2.0",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "135",
        "title": "GCDance: Genre-Controlled 3D Full Body Dance Generation Driven By Music",
        "author": [
            "Xinran Liu",
            "Xu Dong",
            "Diptesh Kanojia",
            "Wenwu Wang",
            "Zhenhua Feng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18309",
        "abstract": "Generating high-quality full-body dance sequences from music is a challenging task as it requires strict adherence to genre-specific choreography. Moreover, the generated sequences must be both physically realistic and precisely synchronized with the beats and rhythm of the music. To overcome these challenges, we propose GCDance, a classifier-free diffusion framework for generating genre-specific dance motions conditioned on both music and textual prompts. Specifically, our approach extracts music features by combining high-level pre-trained music foundation model features with hand-crafted features for multi-granularity feature fusion. To achieve genre controllability, we leverage CLIP to efficiently embed genre-based textual prompt representations at each time step within our dance generation pipeline. Our GCDance framework can generate diverse dance styles from the same piece of music while ensuring coherence with the rhythm and melody of the music. Extensive experimental results obtained on the FineDance dataset demonstrate that GCDance significantly outperforms the existing state-of-the-art approaches, which also achieve competitive results on the AIST++ dataset. Our ablation and inference time analysis demonstrate that GCDance provides an effective solution for high-quality music-driven dance generation.",
        "tags": [
            "3D",
            "CLIP",
            "Diffusion"
        ]
    },
    {
        "id": "136",
        "title": "WiCkeD: A Simple Method to Make Multiple Choice Benchmarks More Challenging",
        "author": [
            "Ahmed Elhady",
            "Eneko Agirre",
            "Mikel Artetxe"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18316",
        "abstract": "We introduce WiCkeD, a simple method to increase the complexity of existing multiple-choice benchmarks by randomly replacing a choice with \"None of the above\", a method often used in educational tests. We show that WiCkeD can be automatically applied to any existing benchmark, making it more challenging. We apply WiCkeD to 6 popular benchmarks and use it to evaluate 18 open-weight LLMs. The performance of the models drops 12.1 points on average with respect to the original versions of the datasets. When using chain-of-thought on 3 MMLU datasets, the performance drop for the WiCkeD variant is similar to the one observed when using the LLMs directly, showing that WiCkeD is also challenging for models with enhanced reasoning abilities. WiCkeD also uncovers that some models are more sensitive to the extra reasoning required, providing additional information with respect to the original benchmarks. We relase our code and data at https://github.com/ahmedselhady/wicked-benchmarks.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "137",
        "title": "Mapping of Subjective Accounts into Interpreted Clusters (MOSAIC): Topic Modelling and LLM applied to Stroboscopic Phenomenology",
        "author": [
            "Romy BeautÃ©",
            "David J. Schwartzman",
            "Guillaume Dumas",
            "Jennifer Crook",
            "Fiona Macpherson",
            "Adam B. Barrett",
            "Anil K. Seth"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18318",
        "abstract": "Stroboscopic light stimulation (SLS) on closed eyes typically induces simple visual hallucinations (VHs), characterised by vivid, geometric and colourful patterns. A dataset of 862 sentences, extracted from 422 open subjective reports, was recently compiled as part of the Dreamachine programme (Collective Act, 2022), an immersive multisensory experience that combines SLS and spatial sound in a collective setting. Although open reports extend the range of reportable phenomenology, their analysis presents significant challenges, particularly in systematically identifying patterns. To address this challenge, we implemented a data-driven approach leveraging Large Language Models and Topic Modelling to uncover and interpret latent experiential topics directly from the Dreamachine's text-based reports. Our analysis confirmed the presence of simple VHs typically documented in scientific studies of SLS, while also revealing experiences of altered states of consciousness and complex hallucinations. Building on these findings, our computational approach expands the systematic study of subjective experience by enabling data-driven analyses of open-ended phenomenological reports, capturing experiences not readily identified through standard questionnaires. By revealing rich and multifaceted aspects of experiences, our study broadens our understanding of stroboscopically-induced phenomena while highlighting the potential of Natural Language Processing and Large Language Models in the emerging field of computational (neuro)phenomenology. More generally, this approach provides a practically applicable methodology for uncovering subtle hidden patterns of subjective experience across diverse research domains.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "138",
        "title": "Pretraining Frequency Predicts Compositional Generalization of CLIP on Real-World Tasks",
        "author": [
            "ThaddÃ¤us Wiedemer",
            "Yash Sharma",
            "Ameya Prabhu",
            "Matthias Bethge",
            "Wieland Brendel"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18326",
        "abstract": "We investigate the success conditions for compositional generalization of CLIP models on real-world data through performance prediction. Prior work shows that CLIP requires exponentially more pretraining data for linear performance gains on individual concepts. This sample-inefficient scaling could be mitigated if CLIP systematically understood new inputs as compositions of learned components, allowing rare observation to be mapped to common concepts. To explore CLIP's compositional generalization ability, we filter retrieval corpora for samples with object combinations not present in the pretraining corpus. We show that CLIP's performance on these samples can be accurately predicted from the pretraining frequencies of individual objects. Our findings demonstrate that CLIP learns to disentangle objects observed in its pretraining data and can recompose them straightforwardly. Additionally, we are the first to show how this ability scales with pretraining data. For data curation in practice, our results suggest that balancing object occurrences improves generalization, which should benefit CLIP's efficiency and accuracy without scaling data volume.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "139",
        "title": "Correlating and Predicting Human Evaluations of Language Models from Natural Language Processing Benchmarks",
        "author": [
            "Rylan Schaeffer",
            "Punit Singh Koura",
            "Binh Tang",
            "Ranjan Subramanian",
            "Aaditya K Singh",
            "Todor Mihaylov",
            "Prajjwal Bhargava",
            "Lovish Madaan",
            "Niladri S. Chatterji",
            "Vedanuj Goswami",
            "Sergey Edunov",
            "Dieuwke Hupkes",
            "Sanmi Koyejo",
            "Sharan Narang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18339",
        "abstract": "The explosion of high-performing conversational language models (LMs) has spurred a shift from classic natural language processing (NLP) benchmarks to expensive, time-consuming and noisy human evaluations - yet the relationship between these two evaluation strategies remains hazy. In this paper, we conduct a large-scale study of four Chat Llama 2 models, comparing their performance on 160 standard NLP benchmarks (e.g., MMLU, ARC, BIG-Bench Hard) against extensive human preferences on more than 11k single-turn and 2k multi-turn dialogues from over 2k human annotators. Our findings are striking: most NLP benchmarks strongly correlate with human evaluations, suggesting that cheaper, automated metrics can serve as surprisingly reliable predictors of human preferences. Three human evaluations, such as adversarial dishonesty and safety, are anticorrelated with NLP benchmarks, while two are uncorrelated. Moreover, through overparameterized linear regressions, we show that NLP scores can accurately predict human evaluations across different model scales, offering a path to reduce costly human annotation without sacrificing rigor. Overall, our results affirm the continued value of classic benchmarks and illuminate how to harness them to anticipate real-world user satisfaction - pointing to how NLP benchmarks can be leveraged to meet evaluation needs of our new era of conversational AI.",
        "tags": [
            "LLaMA"
        ]
    },
    {
        "id": "140",
        "title": "BRIDO: Bringing Democratic Order to Abstractive Summarization",
        "author": [
            "Junhyun Lee",
            "Harshith Goka",
            "Hyeonmok Ko"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18342",
        "abstract": "Hallucination refers to the inaccurate, irrelevant, and inconsistent text generated from large language models (LLMs). While the LLMs have shown great promise in a variety of tasks, the issue of hallucination still remains a major challenge for many practical uses. In this paper, we tackle the issue of hallucination in abstract text summarization by mitigating exposure bias. Existing models targeted for exposure bias mitigation, namely BRIO, aim for better summarization quality in the ROUGE score. We propose a model that uses a similar exposure bias mitigation strategy but with a goal that is aligned with less hallucination. We conjecture that among a group of candidate outputs, ones with hallucinations will comprise the minority of the whole group. That is, candidates with less similarity with others will have a higher chance of containing hallucinated content. Our method uses this aspect and utilizes contrastive learning, incentivizing candidates with high inter-candidate ROUGE scores. We performed experiments on the XSum and CNN/DM summarization datasets, and our method showed 6.25% and 3.82% improvement, respectively, on the consistency G-Eval score over BRIO.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "141",
        "title": "WebGames: Challenging General-Purpose Web-Browsing AI Agents",
        "author": [
            "George Thomas",
            "Alex J. Chan",
            "Jikun Kang",
            "Wenqi Wu",
            "Filippos Christianos",
            "Fraser Greenlee",
            "Andy Toulis",
            "Marvin Purtorab"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18356",
        "abstract": "We introduce WebGames, a comprehensive benchmark suite designed to evaluate general-purpose web-browsing AI agents through a collection of 50+ interactive challenges. These challenges are specifically crafted to be straightforward for humans while systematically testing the limitations of current AI systems across fundamental browser interactions, advanced input processing, cognitive tasks, workflow automation, and interactive entertainment. Our framework eliminates external dependencies through a hermetic testing environment, ensuring reproducible evaluation with verifiable ground-truth solutions. We evaluate leading vision-language models including GPT-4o, Claude Computer-Use, Gemini-1.5-Pro, and Qwen2-VL against human performance. Results reveal a substantial capability gap, with the best AI system achieving only 43.1% success rate compared to human performance of 95.7%, highlighting fundamental limitations in current AI systems' ability to handle common web interaction patterns that humans find intuitive. The benchmark is publicly available at http://webgames.convergence.ai, offering a lightweight, client-side implementation that facilitates rapid evaluation cycles. Through its modular architecture and standardized challenge specifications, WebGames provides a robust foundation for measuring progress in development of more capable web-browsing agents.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "142",
        "title": "Which Contributions Deserve Credit? Perceptions of Attribution in Human-AI Co-Creation",
        "author": [
            "Jessica He",
            "Stephanie Houde",
            "Justin D. Weisz"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18357",
        "abstract": "AI systems powered by large language models can act as capable assistants for writing and editing. In these tasks, the AI system acts as a co-creative partner, making novel contributions to an artifact-under-creation alongside its human partner(s). One question that arises in these scenarios is the extent to which AI should be credited for its contributions. We examined knowledge workers' views of attribution through a survey study (N=155) and found that they assigned different levels of credit across different contribution types, amounts, and initiative. Compared to a human partner, we observed a consistent pattern in which AI was assigned less credit for equivalent contributions. Participants felt that disclosing AI involvement was important and used a variety of criteria to make attribution judgments, including the quality of contributions, personal values, and technology considerations. Our results motivate and inform new approaches for crediting AI contributions to co-created work.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "143",
        "title": "Responsible AI Agents",
        "author": [
            "Deven R. Desai",
            "Mark O. Riedl"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18359",
        "abstract": "Thanks to advances in large language models, a new type of software agent, the artificial intelligence (AI) agent, has entered the marketplace. Companies such as OpenAI, Google, Microsoft, and Salesforce promise their AI Agents will go from generating passive text to executing tasks. Instead of a travel itinerary, an AI Agent would book all aspects of your trip. Instead of generating text or images for social media post, an AI Agent would post the content across a host of social media outlets. The potential power of AI Agents has fueled legal scholars' fears that AI Agents will enable rogue commerce, human manipulation, rampant defamation, and intellectual property harms. These scholars are calling for regulation before AI Agents cause havoc.\nThis Article addresses the concerns around AI Agents head on. It shows that core aspects of how one piece of software interacts with another creates ways to discipline AI Agents so that rogue, undesired actions are unlikely, perhaps more so than rules designed to govern human agents. It also develops a way to leverage the computer-science approach to value-alignment to improve a user's ability to take action to prevent or correct AI Agent operations. That approach offers and added benefit of helping AI Agents align with norms around user-AI Agent interactions. These practices will enable desired economic outcomes and mitigate perceived risks. The Article also argues that no matter how much AI Agents seem like human agents, they need not, and should not, be given legal personhood status. In short, humans are responsible for AI Agents' actions, and this Article provides a guide for how humans can build and maintain responsible AI Agents.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "144",
        "title": "ART: Anonymous Region Transformer for Variable Multi-Layer Transparent Image Generation",
        "author": [
            "Yifan Pu",
            "Yiming Zhao",
            "Zhicong Tang",
            "Ruihong Yin",
            "Haoxing Ye",
            "Yuhui Yuan",
            "Dong Chen",
            "Jianmin Bao",
            "Sirui Zhang",
            "Yanbin Wang",
            "Lin Liang",
            "Lijuan Wang",
            "Ji Li",
            "Xiu Li",
            "Zhouhui Lian",
            "Gao Huang",
            "Baining Guo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18364",
        "abstract": "Multi-layer image generation is a fundamental task that enables users to isolate, select, and edit specific image layers, thereby revolutionizing interactions with generative models. In this paper, we introduce the Anonymous Region Transformer (ART), which facilitates the direct generation of variable multi-layer transparent images based on a global text prompt and an anonymous region layout. Inspired by Schema theory suggests that knowledge is organized in frameworks (schemas) that enable people to interpret and learn from new information by linking it to prior knowledge.}, this anonymous region layout allows the generative model to autonomously determine which set of visual tokens should align with which text tokens, which is in contrast to the previously dominant semantic layout for the image generation task. In addition, the layer-wise region crop mechanism, which only selects the visual tokens belonging to each anonymous region, significantly reduces attention computation costs and enables the efficient generation of images with numerous distinct layers (e.g., 50+). When compared to the full attention approach, our method is over 12 times faster and exhibits fewer layer conflicts. Furthermore, we propose a high-quality multi-layer transparent image autoencoder that supports the direct encoding and decoding of the transparency of variable multi-layer images in a joint manner. By enabling precise control and scalable layer generation, ART establishes a new paradigm for interactive content creation.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "145",
        "title": "MindMem: Multimodal for Predicting Advertisement Memorability Using LLMs and Deep Learning",
        "author": [
            "Sepehr Asgarian",
            "Qayam Jetha",
            "Jouhyun Jeon"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18371",
        "abstract": "In the competitive landscape of advertising, success hinges on effectively navigating and leveraging complex interactions among consumers, advertisers, and advertisement platforms. These multifaceted interactions compel advertisers to optimize strategies for modeling consumer behavior, enhancing brand recall, and tailoring advertisement content. To address these challenges, we present MindMem, a multimodal predictive model for advertisement memorability. By integrating textual, visual, and auditory data, MindMem achieves state-of-the-art performance, with a Spearman's correlation coefficient of 0.631 on the LAMBDA and 0.731 on the Memento10K dataset, consistently surpassing existing methods. Furthermore, our analysis identified key factors influencing advertisement memorability, such as video pacing, scene complexity, and emotional resonance. Expanding on this, we introduced MindMem-ReAd (MindMem-Driven Re-generated Advertisement), which employs Large Language Model-based simulations to optimize advertisement content and placement, resulting in up to a 74.12% improvement in advertisement memorability. Our results highlight the transformative potential of Artificial Intelligence in advertising, offering advertisers a robust tool to drive engagement, enhance competitiveness, and maximize impact in a rapidly evolving market.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "146",
        "title": "Mechanistic PDE Networks for Discovery of Governing Equations",
        "author": [
            "Adeel Pervez",
            "Efstratios Gavves",
            "Francesco Locatello"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18377",
        "abstract": "We present Mechanistic PDE Networks -- a model for discovery of governing partial differential equations from data. Mechanistic PDE Networks represent spatiotemporal data as space-time dependent linear partial differential equations in neural network hidden representations. The represented PDEs are then solved and decoded for specific tasks. The learned PDE representations naturally express the spatiotemporal dynamics in data in neural network hidden space, enabling increased power for dynamical modeling. Solving the PDE representations in a compute and memory-efficient way, however, is a significant challenge. We develop a native, GPU-capable, parallel, sparse, and differentiable multigrid solver specialized for linear partial differential equations that acts as a module in Mechanistic PDE Networks. Leveraging the PDE solver, we propose a discovery architecture that can discover nonlinear PDEs in complex settings while also being robust to noise. We validate PDE discovery on a number of PDEs, including reaction-diffusion and Navier-Stokes equations.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "147",
        "title": "How Far are LLMs from Real Search? A Comprehensive Study on Efficiency, Completeness, and Inherent Capabilities",
        "author": [
            "Minhua Lin",
            "Hui Liu",
            "Xianfeng Tang",
            "Jingying Zeng",
            "Zhenwei Dai",
            "Chen Luo",
            "Zheng Li",
            "Xiang Zhang",
            "Qi He",
            "Suhang Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18387",
        "abstract": "Search plays a fundamental role in problem-solving across various domains, with most real-world decision-making problems being solvable through systematic search. Drawing inspiration from recent discussions on search and learning, we systematically explore the complementary relationship between search and Large Language Models (LLMs) from three perspectives. First, we analyze how learning can enhance search efficiency and propose Search via Learning (SeaL), a framework that leverages LLMs for effective and efficient search. Second, we further extend SeaL to SeaL-C to ensure rigorous completeness during search. Our evaluation across three real-world planning tasks demonstrates that SeaL achieves near-perfect accuracy while reducing search spaces by up to 99.1% compared to traditional approaches. Finally, we explore how far LLMs are from real search by investigating whether they can develop search capabilities independently. Our analysis reveals that while current LLMs struggle with efficient search in complex problems, incorporating systematic search strategies significantly enhances their problem-solving capabilities. These findings not only validate the effectiveness of our approach but also highlight the need for improving LLMs' search abilities for real-world applications.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "148",
        "title": "Monte Carlo Temperature: a robust sampling strategy for LLM's uncertainty quantification methods",
        "author": [
            "Nicola Cecere",
            "Andrea Bacciu",
            "Ignacio FernÃ¡ndez TobÃ­as",
            "Amin Mantrach"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18389",
        "abstract": "Uncertainty quantification (UQ) in Large Language Models (LLMs) is essential for their safe and reliable deployment, particularly in critical applications where incorrect outputs can have serious consequences. Current UQ methods typically rely on querying the model multiple times using non-zero temperature sampling to generate diverse outputs for uncertainty estimation. However, the impact of selecting a given temperature parameter is understudied, and our analysis reveals that temperature plays a fundamental role in the quality of uncertainty estimates. The conventional approach of identifying optimal temperature values requires expensive hyperparameter optimization (HPO) that must be repeated for each new model-dataset combination. We propose Monte Carlo Temperature (MCT), a robust sampling strategy that eliminates the need for temperature calibration. Our analysis reveals that: 1) MCT provides more robust uncertainty estimates across a wide range of temperatures, 2) MCT improves the performance of UQ methods by replacing fixed-temperature strategies that do not rely on HPO, and 3) MCT achieves statistical parity with oracle temperatures, which represent the ideal outcome of a well-tuned but computationally expensive HPO process. These findings demonstrate that effective UQ can be achieved without the computational burden of temperature parameter calibration.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "149",
        "title": "Enhancing DNA Foundation Models to Address Masking Inefficiencies",
        "author": [
            "Monireh Safari",
            "Pablo Millan Arias",
            "Scott C. Lowe",
            "Lila Kari",
            "Angel X. Chang",
            "Graham W. Taylor"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18405",
        "abstract": "Masked language modelling (MLM) as a pretraining objective has been widely adopted in genomic sequence modelling. While pretrained models can successfully serve as encoders for various downstream tasks, the distribution shift between pretraining and inference detrimentally impacts performance, as the pretraining task is to map [MASK] tokens to predictions, yet the [MASK] is absent during downstream applications. This means the encoder does not prioritize its encodings of non-[MASK] tokens, and expends parameters and compute on work only relevant to the MLM task, despite this being irrelevant at deployment time. In this work, we propose a modified encoder-decoder architecture based on the masked autoencoder framework, designed to address this inefficiency within a BERT-based transformer. We empirically show that the resulting mismatch is particularly detrimental in genomic pipelines where models are often used for feature extraction without fine-tuning. We evaluate our approach on the BIOSCAN-5M dataset, comprising over 2 million unique DNA barcodes. We achieve substantial performance gains in both closed-world and open-world classification tasks when compared against causal models and bidirectional architectures pretrained with MLM tasks.",
        "tags": [
            "BERT",
            "Transformer"
        ]
    },
    {
        "id": "150",
        "title": "AgentRM: Enhancing Agent Generalization with Reward Modeling",
        "author": [
            "Yu Xia",
            "Jingru Fan",
            "Weize Chen",
            "Siyu Yan",
            "Xin Cong",
            "Zhong Zhang",
            "Yaxi Lu",
            "Yankai Lin",
            "Zhiyuan Liu",
            "Maosong Sun"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18407",
        "abstract": "Existing LLM-based agents have achieved strong performance on held-in tasks, but their generalizability to unseen tasks remains poor. Hence, some recent work focus on fine-tuning the policy model with more diverse tasks to improve the generalizability. In this work, we find that finetuning a reward model to guide the policy model is more robust than directly finetuning the policy model. Based on this finding, we propose AgentRM, a generalizable reward model, to guide the policy model for effective test-time search. We comprehensively investigate three approaches to construct the reward model, including explicit reward modeling, implicit reward modeling and LLM-as-a-judge. We then use AgentRM to guide the answer generation with Best-of-N sampling and step-level beam search. On four types of nine agent tasks, AgentRM enhances the base policy model by $8.8$ points on average, surpassing the top general agent by $4.0$. Moreover, it demonstrates weak-to-strong generalization, yielding greater improvement of $12.6$ on LLaMA-3-70B policy model. As for the specializability, AgentRM can also boost a finetuned policy model and outperform the top specialized agent by $11.4$ on three held-in tasks. Further analysis verifies its effectiveness in test-time scaling. Codes will be released to facilitate the research in this area.",
        "tags": [
            "LLaMA"
        ]
    },
    {
        "id": "151",
        "title": "TSKANMixer: Kolmogorov-Arnold Networks with MLP-Mixer Model for Time Series Forecasting",
        "author": [
            "Young-Chae Hong",
            "Bei Xiao",
            "Yangho Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18410",
        "abstract": "Time series forecasting has long been a focus of research across diverse fields, including economics, energy, healthcare, and traffic management. Recent works have introduced innovative architectures for time series models, such as the Time-Series Mixer (TSMixer), which leverages multi-layer perceptrons (MLPs) to enhance prediction accuracy by effectively capturing both spatial and temporal dependencies within the data. In this paper, we investigate the capabilities of the Kolmogorov-Arnold Networks (KANs) for time-series forecasting by modifying TSMixer with a KAN layer (TSKANMixer). Experimental results demonstrate that TSKANMixer tends to improve prediction accuracy over the original TSMixer across multiple datasets, ranking among the top-performing models compared to other time series approaches. Our results show that the KANs are promising alternatives to improve the performance of time series forecasting by replacing or extending traditional MLPs.",
        "tags": [
            "KAN",
            "Kolmogorov-Arnold Networks"
        ]
    },
    {
        "id": "152",
        "title": "OmniAlign-V: Towards Enhanced Alignment of MLLMs with Human Preference",
        "author": [
            "Xiangyu Zhao",
            "Shengyuan Ding",
            "Zicheng Zhang",
            "Haian Huang",
            "Maosong Cao",
            "Weiyun Wang",
            "Jiaqi Wang",
            "Xinyu Fang",
            "Wenhai Wang",
            "Guangtao Zhai",
            "Haodong Duan",
            "Hua Yang",
            "Kai Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18411",
        "abstract": "Recent advancements in open-source multi-modal large language models (MLLMs) have primarily focused on enhancing foundational capabilities, leaving a significant gap in human preference alignment. This paper introduces OmniAlign-V, a comprehensive dataset of 200K high-quality training samples featuring diverse images, complex questions, and varied response formats to improve MLLMs' alignment with human preferences. We also present MM-AlignBench, a human-annotated benchmark specifically designed to evaluate MLLMs' alignment with human values. Experimental results show that finetuning MLLMs with OmniAlign-V, using Supervised Fine-Tuning (SFT) or Direct Preference Optimization (DPO), significantly enhances human preference alignment while maintaining or enhancing performance on standard VQA benchmarks, preserving their fundamental capabilities. Our datasets, benchmark, code and checkpoints have been released at https://github.com/PhoenixZ810/OmniAlign-V.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "153",
        "title": "Comparative Analysis of MDL-VAE vs. Standard VAE on 202 Years of Gynecological Data",
        "author": [
            "Paula Santos"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18412",
        "abstract": "This study presents a comparative evaluation of a Variational Autoencoder (VAE) enhanced with Minimum Description Length (MDL) regularization against a Standard Autoencoder for reconstructing high-dimensional gynecological data. The MDL-VAE exhibits significantly lower reconstruction errors (MSE, MAE, RMSE) and more structured latent representations, driven by effective KL divergence regularization. Statistical analyses confirm these performance improvements are significant. Furthermore, the MDL-VAE shows consistent training and validation losses and achieves efficient inference times, underscoring its robustness and practical viability. Our findings suggest that incorporating MDL principles into VAE architectures can substantially improve data reconstruction and generalization, making it a promising approach for advanced applications in healthcare data modeling and analysis.",
        "tags": [
            "VAE"
        ]
    },
    {
        "id": "154",
        "title": "When Benchmarks Talk: Re-Evaluating Code LLMs with Interactive Feedback",
        "author": [
            "Jane Pan",
            "Ryan Shar",
            "Jacob Pfau",
            "Ameet Talwalkar",
            "He He",
            "Valerie Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18413",
        "abstract": "Programming is a fundamentally interactive process, yet coding assistants are often evaluated using static benchmarks that fail to measure how well models collaborate with users. We introduce an interactive evaluation pipeline to examine how LLMs incorporate different types of feedback in a collaborative setting. Specifically, we perturb static coding benchmarks so that the code model must interact with a simulated user to retrieve key information about the problem. We find that interaction significantly affects model performance, as the relative rankings of 10 models across 3 datasets often vary between static and interactive settings, despite models being fairly robust to feedback that contains errors. We also observe that even when different feedback types are equally effective with respect to performance, they can impact model behaviors such as (1) how models respond to higher- vs. lower-quality feedback and (2) whether models prioritize aesthetic vs. functional edits. Our work aims to \"re-evaluate\" model coding capabilities through an interactive lens toward bridging the gap between existing evaluations and real-world usage.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "155",
        "title": "Rank1: Test-Time Compute for Reranking in Information Retrieval",
        "author": [
            "Orion Weller",
            "Kathryn Ricci",
            "Eugene Yang",
            "Andrew Yates",
            "Dawn Lawrie",
            "Benjamin Van Durme"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18418",
        "abstract": "We introduce Rank1, the first reranking model trained to take advantage of test-time compute. Rank1 demonstrates the applicability within retrieval of using a reasoning language model (i.e. OpenAI's o1, Deepseek's R1, etc.) for distillation in order to rapidly improve the performance of a smaller model. We gather and open-source a dataset of more than 600,000 examples of R1 reasoning traces from queries and passages in MS MARCO. Models trained on this dataset show: (1) state-of-the-art performance on advanced reasoning and instruction following datasets; (2) work remarkably well out of distribution due to the ability to respond to user-input prompts; and (3) have explainable reasoning chains that can be given to users or RAG-based systems. Further, we demonstrate that quantized versions of these models retain strong performance while using less compute/memory. Overall, Rank1 shows that test-time compute allows for a fundamentally new type of explainable and performant reranker model for search.",
        "tags": [
            "DeepSeek",
            "RAG"
        ]
    },
    {
        "id": "156",
        "title": "Is OpenAlex Suitable for Research Quality Evaluation and Which Citation Indicator is Best?",
        "author": [
            "Mike Thelwall",
            "Xiaorui Jiang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18427",
        "abstract": "This article compares (1) citation analysis with OpenAlex and Scopus, testing their citation counts, document type/coverage and subject classifications and (2) three citation-based indicators: raw counts, (field and year) Normalised Citation Scores (NCS) and Normalised Log-transformed Citation Scores (NLCS). Methods (1&2): The indicators calculated from 28.6 million articles were compared through 8,704 correlations on two gold standards for 97,816 UK Research Excellence Framework (REF) 2021 articles. The primary gold standard is ChatGPT scores, and the secondary is the average REF2021 expert review score for the department submitting the article. Results: (1) OpenAlex provides better citation counts than Scopus and its inclusive document classification/scope does not seem to cause substantial field normalisation problems. The broadest OpenAlex classification scheme provides the best indicators. (2) Counterintuitively, raw citation counts are at least as good as nearly all field normalised indicators, and better for single years, and NCS is better than NLCS. (1&2) There are substantial field differences. Thus, (1) OpenAlex is suitable for citation analysis in most fields and (2) the major citation-based indicators seem to work counterintuitively compared to quality judgements. Field normalisation seems ineffective because more cited fields tend to produce higher quality work, affecting interdisciplinary research or within-field topic differences.",
        "tags": [
            "ChatGPT"
        ]
    },
    {
        "id": "157",
        "title": "TextGames: Learning to Self-Play Text-Based Puzzle Games via Language Model Reasoning",
        "author": [
            "Frederikus Hudi",
            "Genta Indra Winata",
            "Ruochen Zhang",
            "Alham Fikri Aji"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18431",
        "abstract": "Reasoning is a fundamental capability of large language models (LLMs), enabling them to comprehend, analyze, and solve complex problems. In this paper, we introduce TextGames, an innovative benchmark specifically crafted to assess LLMs through demanding text-based games that require advanced skills in pattern recognition, spatial awareness, arithmetic, and logical reasoning. Our analysis probes LLMs' performance in both single-turn and multi-turn reasoning, and their abilities in leveraging feedback to correct subsequent answers through self-reflection. Our findings reveal that, although LLMs exhibit proficiency in addressing most easy and medium-level problems, they face significant challenges with more difficult tasks. In contrast, humans are capable of solving all tasks when given sufficient time. Moreover, we observe that LLMs show improved performance in multi-turn predictions through self-reflection, yet they still struggle with sequencing, counting, and following complex rules consistently. Additionally, models optimized for reasoning outperform pre-trained LLMs that prioritize instruction following, highlighting the crucial role of reasoning skills in addressing highly complex problems.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "158",
        "title": "ToMCAT: Theory-of-Mind for Cooperative Agents in Teams via Multiagent Diffusion Policies",
        "author": [
            "Pedro Sequeira",
            "Vidyasagar Sadhu",
            "Melinda Gervasio"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18438",
        "abstract": "In this paper we present ToMCAT (Theory-of-Mind for Cooperative Agents in Teams), a new framework for generating ToM-conditioned trajectories. It combines a meta-learning mechanism, that performs ToM reasoning over teammates' underlying goals and future behavior, with a multiagent denoising-diffusion model, that generates plans for an agent and its teammates conditioned on both the agent's goals and its teammates' characteristics, as computed via ToM. We implemented an online planning system that dynamically samples new trajectories (replans) from the diffusion model whenever it detects a divergence between a previously generated plan and the current state of the world. We conducted several experiments using ToMCAT in a simulated cooking domain. Our results highlight the importance of the dynamic replanning mechanism in reducing the usage of resources without sacrificing team performance. We also show that recent observations about the world and teammates' behavior collected by an agent over the course of an episode combined with ToM inferences are crucial to generate team-aware plans for dynamic adaptation to teammates, especially when no prior information is provided about them.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "159",
        "title": "MAPoRL: Multi-Agent Post-Co-Training for Collaborative Large Language Models with Reinforcement Learning",
        "author": [
            "Chanwoo Park",
            "Seungju Han",
            "Xingzhi Guo",
            "Asuman Ozdaglar",
            "Kaiqing Zhang",
            "Joo-Kyung Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18439",
        "abstract": "Leveraging multiple large language models (LLMs) to build collaborative multi-agentic workflows has demonstrated significant potential. However, most previous studies focus on prompting the out-of-the-box LLMs, relying on their innate capability for collaboration, which may not improve LLMs' performance as shown recently. In this paper, we introduce a new post-training paradigm MAPoRL (Multi-Agent Post-co-training for collaborative LLMs with Reinforcement Learning), to explicitly elicit the collaborative behaviors and further unleash the power of multi-agentic LLM frameworks. In MAPoRL, multiple LLMs first generate their own responses independently and engage in a multi-turn discussion to collaboratively improve the final answer. In the end, a MAPoRL verifier evaluates both the answer and the discussion, by assigning a score that verifies the correctness of the answer, while adding incentives to encourage corrective and persuasive discussions. The score serves as the co-training reward, and is then maximized through multi-agent RL. Unlike existing LLM post-training paradigms, MAPoRL advocates the co-training of multiple LLMs together using RL for better generalization. Accompanied by analytical insights, our experiments demonstrate that training individual LLMs alone is insufficient to induce effective collaboration. In contrast, multi-agent co-training can boost the collaboration performance across benchmarks, with generalization to unseen domains.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RL"
        ]
    },
    {
        "id": "160",
        "title": "SWE-RL: Advancing LLM Reasoning via Reinforcement Learning on Open Software Evolution",
        "author": [
            "Yuxiang Wei",
            "Olivier Duchenne",
            "Jade Copet",
            "Quentin Carbonneaux",
            "Lingming Zhang",
            "Daniel Fried",
            "Gabriel Synnaeve",
            "Rishabh Singh",
            "Sida I. Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18449",
        "abstract": "The recent DeepSeek-R1 release has demonstrated the immense potential of reinforcement learning (RL) in enhancing the general reasoning capabilities of large language models (LLMs). While DeepSeek-R1 and other follow-up work primarily focus on applying RL to competitive coding and math problems, this paper introduces SWE-RL, the first approach to scale RL-based LLM reasoning for real-world software engineering. Leveraging a lightweight rule-based reward (e.g., the similarity score between ground-truth and LLM-generated solutions), SWE-RL enables LLMs to autonomously recover a developer's reasoning processes and solutions by learning from extensive open-source software evolution data -- the record of a software's entire lifecycle, including its code snapshots, code changes, and events such as issues and pull requests. Trained on top of Llama 3, our resulting reasoning model, Llama3-SWE-RL-70B, achieves a 41.0% solve rate on SWE-bench Verified -- a human-verified collection of real-world GitHub issues. To our knowledge, this is the best performance reported for medium-sized (<100B) LLMs to date, even comparable to leading proprietary LLMs like GPT-4o. Surprisingly, despite performing RL solely on software evolution data, Llama3-SWE-RL has even emerged with generalized reasoning skills. For example, it shows improved results on five out-of-domain tasks, namely, function coding, library use, code reasoning, mathematics, and general language understanding, whereas a supervised-finetuning baseline even leads to performance degradation on average. Overall, SWE-RL opens up a new direction to improve the reasoning capabilities of LLMs through reinforcement learning on massive software engineering data.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLMs",
            "LLaMA",
            "Large Language Models",
            "RL"
        ]
    },
    {
        "id": "161",
        "title": "FRIDA to the Rescue! Analyzing Synthetic Data Effectiveness in Object-Based Common Sense Reasoning for Disaster Response",
        "author": [
            "Mollie Shichman",
            "Claire Bonial",
            "Austin Blodgett",
            "Taylor Hudson",
            "Francis Ferraro",
            "Rachel Rudinger"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18452",
        "abstract": "Large Language Models (LLMs) have the potential for substantial common sense reasoning. However, these capabilities are often emergent in larger models. This means smaller models that can be run locally are less helpful and capable with respect to certain reasoning tasks. To meet our problem space requirements, we fine-tune smaller LLMs to disaster domains, as these domains involve complex and low-frequency physical common sense knowledge. We introduce a pipeline to create Field Ready Instruction Decoding Agent (FRIDA) models, where domain experts and linguists combine their knowledge to make high-quality seed data that is used to generate synthetic data for fine-tuning. We create a set of 130 seed instructions for synthetic generation, a synthetic dataset of 25000 instructions, and 119 evaluation instructions relating to both general and earthquake-specific object affordances. We fine-tune several LLaMa and Mistral instruction-tuned models and find that FRIDA models outperform their base models at a variety of sizes. We then run an ablation study to understand which kinds of synthetic data most affect performance and find that training physical state and object function common sense knowledge alone improves over FRIDA models trained on all data. We conclude that the FRIDA pipeline is capable of instilling general common sense, but needs to be augmented with information retrieval for specific domain knowledge.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "162",
        "title": "Evaluating the Effectiveness of Small Language Models in Detecting Refactoring Bugs",
        "author": [
            "Rohit Gheyi",
            "Marcio Ribeiro",
            "Jonhnanthan Oliveira"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18454",
        "abstract": "Popular IDEs frequently contain bugs in their refactoring implementations. Ensuring that a transformation preserves a program's behavior is a complex task. Traditional detection methods rely on predefined preconditions for each refactoring type, limiting their scalability and adaptability to new transformations. These methods often require extensive static and dynamic analyses, which are computationally expensive, time-consuming, and may still fail to detect certain refactoring bugs. This study evaluates the effectiveness of Small Language Models (SLMs) in detecting two types of refactoring bugs in Java and Python: (i) transformations that introduce errors or behavioral changes (Type I) and (ii) transformations unnecessarily blocked by IDEs despite being valid (Type II). We assess whether Llama 3.2 3B, Mistral 7B, Gemma 2 9B, DeepSeek-R1 14B, Phi-4 14B, o1-mini, and o3-mini-high can accurately detect 100 refactoring bugs reported in widely used Java and Python IDEs, such as Eclipse and NetBeans. The study covers 16 refactoring types and employs zero-shot prompting on consumer-grade hardware to evaluate the models' ability to reason about refactoring correctness without explicit prior training. The proprietary o3-mini-high model achieved the highest detection rate, identifying 84.3% of Type I bugs. The open-source Phi-4 14B performed comparably well, demonstrating strong effectiveness across both bug types. However, o3-mini-high struggled with Type II bugs, correctly identifying and applying valid but blocked transformations in only 40% of cases. The findings highlight the potential of SLMs for efficiently detecting refactoring bugs, particularly in verifying behavioral changes. Additionally, SLMs offer a more adaptable solution capable of generalizing across different refactoring types and programming languages, addressing key limitations of traditional approaches.",
        "tags": [
            "DeepSeek",
            "Detection",
            "LLaMA"
        ]
    },
    {
        "id": "163",
        "title": "LLM-Based Design Pattern Detection",
        "author": [
            "Christian Schindler",
            "Andreas Rausch"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18458",
        "abstract": "Detecting design pattern instances in unfamiliar codebases remains a challenging yet essential task for improving software quality and maintainability. Traditional static analysis tools often struggle with the complexity, variability, and lack of explicit annotations that characterize real-world pattern implementations. In this paper, we present a novel approach leveraging Large Language Models to automatically identify design pattern instances across diverse codebases. Our method focuses on recognizing the roles classes play within the pattern instances. By providing clearer insights into software structure and intent, this research aims to support developers, improve comprehension, and streamline tasks such as refactoring, maintenance, and adherence to best practices.",
        "tags": [
            "Detection",
            "Large Language Models"
        ]
    },
    {
        "id": "164",
        "title": "DRAMA: Diverse Augmentation from Large Language Models to Smaller Dense Retrievers",
        "author": [
            "Xueguang Ma",
            "Xi Victoria Lin",
            "Barlas Oguz",
            "Jimmy Lin",
            "Wen-tau Yih",
            "Xilun Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18460",
        "abstract": "Large language models (LLMs) have demonstrated strong effectiveness and robustness while fine-tuned as dense retrievers. However, their large parameter size brings significant inference time computational challenges, including high encoding costs for large-scale corpora and increased query latency, limiting their practical deployment. While smaller retrievers offer better efficiency, they often fail to generalize effectively with limited supervised fine-tuning data. In this work, we introduce DRAMA, a training framework that leverages LLMs to train smaller generalizable dense retrievers. In particular, we adopt pruned LLMs as the backbone and train on diverse LLM-augmented data in a single-stage contrastive learning setup. Experiments show that DRAMA offers better multilingual and long-context capabilities than traditional encoder-based retrievers, and achieves strong performance across multiple tasks and languages. These highlight the potential of connecting the training of smaller retrievers with the growing advancements in LLMs, bridging the gap between efficiency and generalization.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "165",
        "title": "K-LoRA: Unlocking Training-Free Fusion of Any Subject and Style LoRAs",
        "author": [
            "Ziheng Ouyang",
            "Zhen Li",
            "Qibin Hou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18461",
        "abstract": "Recent studies have explored combining different LoRAs to jointly generate learned style and content. However, existing methods either fail to effectively preserve both the original subject and style simultaneously or require additional training. In this paper, we argue that the intrinsic properties of LoRA can effectively guide diffusion models in merging learned subject and style. Building on this insight, we propose K-LoRA, a simple yet effective training-free LoRA fusion approach. In each attention layer, K-LoRA compares the Top-K elements in each LoRA to be fused, determining which LoRA to select for optimal fusion. This selection mechanism ensures that the most representative features of both subject and style are retained during the fusion process, effectively balancing their contributions. Experimental results demonstrate that the proposed method effectively integrates the subject and style information learned by the original LoRAs, outperforming state-of-the-art training-based approaches in both qualitative and quantitative results.",
        "tags": [
            "Diffusion",
            "LoRA"
        ]
    },
    {
        "id": "166",
        "title": "MoEMba: A Mamba-based Mixture of Experts for High-Density EMG-based Hand Gesture Recognition",
        "author": [
            "Mehran Shabanpour",
            "Kasra Rad",
            "Sadaf Khademi",
            "Arash Mohammadi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17457",
        "abstract": "High-Density surface Electromyography (HDsEMG) has emerged as a pivotal resource for Human-Computer Interaction (HCI), offering direct insights into muscle activities and motion intentions. However, a significant challenge in practical implementations of HD-sEMG-based models is the low accuracy of inter-session and inter-subject classification. Variability between sessions can reach up to 40% due to the inherent temporal variability of HD-sEMG signals. Targeting this challenge, the paper introduces the MoEMba framework, a novel approach leveraging Selective StateSpace Models (SSMs) to enhance HD-sEMG-based gesture recognition. The MoEMba framework captures temporal dependencies and cross-channel interactions through channel attention techniques. Furthermore, wavelet feature modulation is integrated to capture multi-scale temporal and spatial relations, improving signal representation. Experimental results on the CapgMyo HD-sEMG dataset demonstrate that MoEMba achieves a balanced accuracy of 56.9%, outperforming its state-of-the-art counterparts. The proposed framework's robustness to session-to-session variability and its efficient handling of high-dimensional multivariate time series data highlight its potential for advancing HD-sEMG-powered HCI systems.",
        "tags": [
            "Mamba",
            "SSMs"
        ]
    },
    {
        "id": "167",
        "title": "CSSSTN: A Class-sensitive Subject-to-subject Semantic Style Transfer Network for EEG Classification in RSVP Tasks",
        "author": [
            "Ziyue Yang",
            "Chengrui Chen",
            "Yong Peng",
            "Qiong Chen",
            "Wanzeng Kong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17468",
        "abstract": "The Rapid Serial Visual Presentation (RSVP) paradigm represents a promising application of electroencephalography (EEG) in Brain-Computer Interface (BCI) systems. However, cross-subject variability remains a critical challenge, particularly for BCI-illiterate users who struggle to effectively interact with these systems. To address this issue, we propose the Class-Sensitive Subject-to-Subject Semantic Style Transfer Network (CSSSTN), which incorporates a class-sensitive approach to align feature distributions between golden subjects (BCI experts) and target (BCI-illiterate) users on a class-by-class basis. Building on the SSSTN framework, CSSSTN incorporates three key components: (1) subject-specific classifier training, (2) a unique style loss to transfer class-discriminative features while preserving semantic information through a modified content loss, and (3) an ensemble approach to integrate predictions from both source and target domains. We evaluated CSSSTN using both a publicly available dataset and a self-collected dataset. Experimental results demonstrate that CSSSTN outperforms state-of-the-art methods, achieving mean balanced accuracy improvements of 6.4\\% on the Tsinghua dataset and 3.5\\% on the HDU dataset, with notable benefits for BCI-illiterate users. Ablation studies confirm the effectiveness of each component, particularly the class-sensitive transfer and the use of lower-layer features, which enhance transfer performance and mitigate negative transfer. Additionally, CSSSTN achieves competitive results with minimal target data, reducing calibration time and effort. These findings highlight the practical potential of CSSSTN for real-world BCI applications, offering a robust and scalable solution to improve the performance of BCI-illiterate users while minimizing reliance on extensive training data. Our code is available at https://github.com/ziyuey/CSSSTN.",
        "tags": [
            "Style Transfer"
        ]
    },
    {
        "id": "168",
        "title": "MC2SleepNet: Multi-modal Cross-masking with Contrastive Learning for Sleep Stage Classification",
        "author": [
            "Younghoon Na"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17470",
        "abstract": "Sleep profoundly affects our health, and sleep deficiency or disorders can cause physical and mental problems. % Despite significant findings from previous studies, challenges persist in optimizing deep learning models, especially in multi-modal learning for high-accuracy sleep stage classification. Our research introduces MC2SleepNet (Multi-modal Cross-masking with Contrastive learning for Sleep stage classification Network). It aims to facilitate the effective collaboration between Convolutional Neural Networks (CNNs) and Transformer architectures for multi-modal training with the help of contrastive learning and cross-masking. % Raw single channel EEG signals and corresponding spectrogram data provide differently characterized modalities for multi-modal learning. Our MC2SleepNet has achieved state-of-the-art performance with an accuracy of both 84.6% on the SleepEDF-78 and 88.6% accuracy on the Sleep Heart Health Study (SHHS). These results demonstrate the effective generalization of our proposed network across both small and large datasets.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "169",
        "title": "Frequency-Aware Masked Autoencoders for Human Activity Recognition using Accelerometers",
        "author": [
            "Niels R. Lorenzen",
            "Poul J. Jennum",
            "Emmanuel Mignot",
            "Andreas Brink-Kjaer"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17477",
        "abstract": "Wearable accelerometers are widely used for continuous monitoring of physical activity. Supervised machine learning and deep learning algorithms have long been used to extract meaningful activity information from raw accelerometry data, but progress has been hampered by the limited amount of publicly available labeled data. Exploiting large unlabeled datasets using self-supervised pretraining is a relatively new and underexplored approach in the field of human activity recognition (HAR). We used a time-series transformer masked autoencoder (MAE) approach to self-supervised pretraining and propose a novel spectrogram-based loss function named the log-scale mean magnitude (LMM) loss. We compared MAE models pretrained with LMM to one trained with the mean squared error (MSE) loss. We leveraged the large unlabeled UK Biobank accelerometry dataset (n = 109k) for pretraining and evaluated downstream HAR performance using linear classifier in a smaller labelled dataset. We found that pretraining with the LMM loss improved performance compared to a model pretrained with the MSE loss, with balanced accuracies of 0.848 and 0.709, respectively. Further analysis revealed that better convergence of the LMM loss, but not the MSE loss significantly correlated with improved downstream performance (r=-0.61, p=0.04) for balanced accuracy). Finally, we compared our MAE models to the state-of-the-art for HAR, also pretrained on the UK Biobank accelerometry data. Our LMM-pretrained models performed better when finetuned using a linear classifier and performed comparably when finetuned using an LSTM classifier, while MSE-pretrained models consistently underperformed. Our findings demonstrate that the LMM loss is a robust and effective method for pretraining MAE models on accelerometer data for HAR. Future work should explore optimizing loss function combinations and extending our approach to other tasks.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "170",
        "title": "Toward Foundational Model for Sleep Analysis Using a Multimodal Hybrid Self-Supervised Learning Framework",
        "author": [
            "Cheol-Hui Lee",
            "Hakseung Kim",
            "Byung C. Yoon",
            "Dong-Joo Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17481",
        "abstract": "Sleep is essential for maintaining human health and quality of life. Analyzing physiological signals during sleep is critical in assessing sleep quality and diagnosing sleep disorders. However, manual diagnoses by clinicians are time-intensive and subjective. Despite advances in deep learning that have enhanced automation, these approaches remain heavily dependent on large-scale labeled datasets. This study introduces SynthSleepNet, a multimodal hybrid self-supervised learning framework designed for analyzing polysomnography (PSG) data. SynthSleepNet effectively integrates masked prediction and contrastive learning to leverage complementary features across multiple modalities, including electroencephalogram (EEG), electrooculography (EOG), electromyography (EMG), and electrocardiogram (ECG). This approach enables the model to learn highly expressive representations of PSG data. Furthermore, a temporal context module based on Mamba was developed to efficiently capture contextual information across signals. SynthSleepNet achieved superior performance compared to state-of-the-art methods across three downstream tasks: sleep-stage classification, apnea detection, and hypopnea detection, with accuracies of 89.89%, 99.75%, and 89.60%, respectively. The model demonstrated robust performance in a semi-supervised learning environment with limited labels, achieving accuracies of 87.98%, 99.37%, and 77.52% in the same tasks. These results underscore the potential of the model as a foundational tool for the comprehensive analysis of PSG data. SynthSleepNet demonstrates comprehensively superior performance across multiple downstream tasks compared to other methodologies, making it expected to set a new standard for sleep disorder monitoring and diagnostic systems.",
        "tags": [
            "Detection",
            "Mamba"
        ]
    },
    {
        "id": "171",
        "title": "ConSense: Continually Sensing Human Activity with WiFi via Growing and Picking",
        "author": [
            "Rong Li",
            "Tao Deng",
            "Siwei Feng",
            "Mingjie Sun",
            "Juncheng Jia"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17483",
        "abstract": "WiFi-based human activity recognition (HAR) holds significant application potential across various fields. To handle dynamic environments where new activities are continuously introduced, WiFi-based HAR systems must adapt by learning new concepts without forgetting previously learned ones. Furthermore, retaining knowledge from old activities by storing historical exemplar is impractical for WiFi-based HAR due to privacy concerns and limited storage capacity of edge devices. In this work, we propose ConSense, a lightweight and fast-adapted exemplar-free class incremental learning framework for WiFi-based HAR. The framework leverages the transformer architecture and involves dynamic model expansion and selective retraining to preserve previously learned knowledge while integrating new information. Specifically, during incremental sessions, small-scale trainable parameters that are trained specifically on the data of each task are added in the multi-head self-attention layer. In addition, a selective retraining strategy that dynamically adjusts the weights in multilayer perceptron based on the performance stability of neurons across tasks is used. Rather than training the entire model, the proposed strategies of dynamic model expansion and selective retraining reduce the overall computational load while balancing stability on previous tasks and plasticity on new tasks. Evaluation results on three public WiFi datasets demonstrate that ConSense not only outperforms several competitive approaches but also requires fewer parameters, highlighting its practical utility in class-incremental scenarios for HAR.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "172",
        "title": "Multimodal Sleep Stage and Sleep Apnea Classification Using Vision Transformer: A Multitask Explainable Learning Approach",
        "author": [
            "Kianoosh Kazemi",
            "Iman Azimi",
            "Michelle Khine",
            "Rami N. Khayat",
            "Amir M. Rahmani",
            "Pasi Liljeberg"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17486",
        "abstract": "Sleep is an essential component of human physiology, contributing significantly to overall health and quality of life. Accurate sleep staging and disorder detection are crucial for assessing sleep quality. Studies in the literature have proposed PSG-based approaches and machine-learning methods utilizing single-modality signals. However, existing methods often lack multimodal, multilabel frameworks and address sleep stages and disorders classification separately. In this paper, we propose a 1D-Vision Transformer for simultaneous classification of sleep stages and sleep disorders. Our method exploits the sleep disorders' correlation with specific sleep stage patterns and performs a simultaneous identification of a sleep stage and sleep disorder. The model is trained and tested using multimodal-multilabel sensory data (including photoplethysmogram, respiratory flow, and respiratory effort signals). The proposed method shows an overall accuracy (cohen's Kappa) of 78% (0.66) for five-stage sleep classification and 74% (0.58) for sleep apnea classification. Moreover, we analyzed the encoder attention weights to clarify our models' predictions and investigate the influence different features have on the models' outputs. The result shows that identified patterns, such as respiratory troughs and peaks, make a higher contribution to the final classification process.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "173",
        "title": "Attention-based UAV Trajectory Optimization for Wireless Power Transfer-assisted IoT Systems",
        "author": [
            "Li Dong",
            "Feibo Jiang",
            "Yubo Peng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17517",
        "abstract": "Unmanned Aerial Vehicles (UAVs) in Wireless Power Transfer (WPT)-assisted Internet of Things (IoT) systems face the following challenges: limited resources and suboptimal trajectory planning. Reinforcement learning-based trajectory planning schemes face issues of low search efficiency and learning instability when optimizing large-scale systems. To address these issues, we present an Attention-based UAV Trajectory Optimization (AUTO) framework based on the graph transformer, which consists of an Attention Trajectory Optimization Model (ATOM) and a Trajectory lEarNing Method based on Actor-critic (TENMA). In ATOM, a graph encoder is used to calculate the self-attention characteristics of all IoTDs, and a trajectory decoder is developed to optimize the number and trajectories of UAVs. TENMA then trains the ATOM using an improved Actor-Critic method, in which the real reward of the system is applied as the baseline to reduce variances in the critic network. This method is suitable for high-quality and large-scale multi-UAV trajectory planning. Finally, we develop numerous experiments, including a hardware experiment in the field case, to verify the feasibility and efficiency of the AUTO framework.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "174",
        "title": "From Euler to AI: Unifying Formulas for Mathematical Constants",
        "author": [
            "Tomer Raz",
            "Michael Shalyt",
            "Elyasheev Leibtag",
            "Rotem Kalisch",
            "Yaron Hadad",
            "Ido Kaminer"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17533",
        "abstract": "The constant $\\pi$ has fascinated scholars for centuries, inspiring the derivation of countless formulas rooted in profound mathematical insight. This abundance of formulas raises a question: Are they interconnected, and can a unifying structure explain their relationships?\nWe propose a systematic methodology for discovering and proving formula equivalences, leveraging modern large language models, large-scale data processing, and novel mathematical algorithms. Analyzing 457,145 arXiv papers, over a third of the validated formulas for $\\pi$ were proven to be derivable from a single mathematical object - including formulas by Euler, Gauss, Lord Brouncker, and newer ones from algorithmic discoveries by the Ramanujan Machine.\nOur approach extends to other constants, such as $e$, $\\zeta(3)$, and Catalan's constant, proving its broad applicability. This work represents a step toward the automatic unification of mathematical knowledge, laying a foundation for AI-driven discoveries of connections across scientific domains.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "175",
        "title": "CLEP-GAN: An Innovative Approach to Subject-Independent ECG Reconstruction from PPG Signals",
        "author": [
            "Xiaoyan Li",
            "Shixin Xu",
            "Faisal Habib",
            "Neda Aminnejad",
            "Arvind Gupta",
            "Huaxiong Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17536",
        "abstract": "This study addresses the challenge of reconstructing unseen ECG signals from PPG signals, a critical task for non-invasive cardiac monitoring. While numerous public ECG-PPG datasets are available, they lack the diversity seen in image datasets, and data collection processes often introduce noise, complicating ECG reconstruction from PPG even with advanced machine learning models. To tackle these challenges, we first introduce a novel synthetic ECG-PPG data generation technique using an ODE model to enhance training diversity. Next, we develop a novel subject-independent PPG-to-ECG reconstruction model that integrates contrastive learning, adversarial learning, and attention gating, achieving results comparable to or even surpassing existing approaches for unseen ECG reconstruction. Finally, we examine factors such as sex and age that impact reconstruction accuracy, emphasizing the importance of considering demographic diversity during model training and dataset augmentation.",
        "tags": [
            "GAN",
            "ODE"
        ]
    },
    {
        "id": "176",
        "title": "Theory-guided Pseudo-spectral Full Waveform Inversion via Deep Neural Networks",
        "author": [
            "Christopher Zerafa",
            "Pauline Galea",
            "Cristiana Sebu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17624",
        "abstract": "Full-Waveform Inversion seeks to achieve a high-resolution model of the subsurface through the application of multi-variate optimization to the seismic inverse problem. Although now a mature technology, FWI has limitations related to the choice of the appropriate solver for the forward problem in challenging environments requiring complex assumptions, and very wide angle and multi-azimuth data necessary for full reconstruction are often not available.\nDeep Learning techniques have emerged as excellent optimization frameworks. Data-driven methods do not impose a wave propagation model and are not exposed to modelling errors. On the contrary, deterministic models are governed by the laws of physics.\nSeismic FWI has recently started to be investigated as a Deep Learning framework. Focus has been on the time-domain, while the pseudo-spectral domain has not been yet explored. However, classical FWI experienced major breakthroughs when pseudo-spectral approaches were employed. This work addresses the lacuna that exists in incorporating the pseudo-spectral approach within Deep Learning. This has been done by re-formulating the pseudo-spectral FWI problem as a Deep Learning algorithm for a theory-driven pseudo-spectral approach. A novel Recurrent Neural Network framework is proposed. This is qualitatively assessed on synthetic data, applied to a two-dimensional Marmousi dataset and evaluated against deterministic and time-based approaches.\nPseudo-spectral theory-guided FWI using RNN was shown to be more accurate than classical FWI with only 0.05 error tolerance and 1.45\\% relative percent-age error. Indeed, this provides more stable convergence, able to identify faults better and has more low frequency content than classical FWI. Moreover, RNN was more suited than classical FWI at edge detection in the shallow and deep sections due to cleaner receiver residuals.",
        "tags": [
            "Detection",
            "RNN"
        ]
    },
    {
        "id": "177",
        "title": "StatLLM: A Dataset for Evaluating the Performance of Large Language Models in Statistical Analysis",
        "author": [
            "Xinyi Song",
            "Lina Lee",
            "Kexin Xie",
            "Xueying Liu",
            "Xinwei Deng",
            "Yili Hong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17657",
        "abstract": "The coding capabilities of large language models (LLMs) have opened up new opportunities for automatic statistical analysis in machine learning and data science. However, before their widespread adoption, it is crucial to assess the accuracy of code generated by LLMs. A major challenge in this evaluation lies in the absence of a benchmark dataset for statistical code (e.g., SAS and R). To fill in this gap, this paper introduces StatLLM, an open-source dataset for evaluating the performance of LLMs in statistical analysis. The StatLLM dataset comprises three key components: statistical analysis tasks, LLM-generated SAS code, and human evaluation scores. The first component includes statistical analysis tasks spanning a variety of analyses and datasets, providing problem descriptions, dataset details, and human-verified SAS code. The second component features SAS code generated by ChatGPT 3.5, ChatGPT 4.0, and Llama 3.1 for those tasks. The third component contains evaluation scores from human experts in assessing the correctness, effectiveness, readability, executability, and output accuracy of the LLM-generated code. We also illustrate the unique potential of the established benchmark dataset for (1) evaluating and enhancing natural language processing metrics, (2) assessing and improving LLM performance in statistical coding, and (3) developing and testing of next-generation statistical software - advancements that are crucial for data science and machine learning research.",
        "tags": [
            "ChatGPT",
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "178",
        "title": "A Fokker-Planck-Based Loss Function that Bridges Dynamics with Density Estimation",
        "author": [
            "Zhixin Lu",
            "Åukasz KuÅmierz",
            "Stefan Mihalas"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17690",
        "abstract": "We have derived a novel loss function from the Fokker-Planck equation that links dynamical system models with their probability density functions, demonstrating its utility in model identification and density estimation. In the first application, we show that this loss function can enable the extraction of dynamical parameters from non-temporal datasets, including timestamp-free measurements from steady non-equilibrium systems such as noisy Lorenz systems and gene regulatory networks. In the second application, when coupled with a density estimator, this loss facilitates density estimation when the dynamic equations are known. For density estimation, we propose a density estimator that integrates a Gaussian Mixture Model with a normalizing flow model. It simultaneously estimates normalized density, energy, and score functions from both empirical data and dynamics. It is compatible with a variety of data-based training methodologies, including maximum likelihood and score matching. It features a latent space akin to a modern Hopfield network, where the inherent Hopfield energy effectively assigns low densities to sparsely populated data regions, addressing common challenges in neural density estimators. Additionally, this Hopfield-like energy enables direct and rapid data manipulation through the Concave-Convex Procedure (CCCP) rule, facilitating tasks such as denoising and clustering. Our work demonstrates a principled framework for leveraging the complex interdependencies between dynamics and density estimation, as illustrated through synthetic examples that clarify the underlying theoretical intuitions.",
        "tags": [
            "Score Matching"
        ]
    },
    {
        "id": "179",
        "title": "Uncertainty Quantification for LLM-Based Survey Simulations",
        "author": [
            "Chengpiao Huang",
            "Yuhang Wu",
            "Kaizheng Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17773",
        "abstract": "We investigate the reliable use of simulated survey responses from large language models (LLMs) through the lens of uncertainty quantification. Our approach converts synthetic data into confidence sets for population parameters of human responses, addressing the distribution shift between the simulated and real populations. A key innovation lies in determining the optimal number of simulated responses: too many produce overly narrow confidence sets with poor coverage, while too few yield excessively loose estimates. To resolve this, our method adaptively selects the simulation sample size, ensuring valid average-case coverage guarantees. It is broadly applicable to any LLM, irrespective of its fidelity, and any procedure for constructing confidence sets. Additionally, the selected sample size quantifies the degree of misalignment between the LLM and the target human population. We illustrate our method on real datasets and LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "180",
        "title": "An Overview of Large Language Models for Statisticians",
        "author": [
            "Wenlong Ji",
            "Weizhe Yuan",
            "Emily Getzen",
            "Kyunghyun Cho",
            "Michael I. Jordan",
            "Song Mei",
            "Jason E Weston",
            "Weijie J. Su",
            "Jing Xu",
            "Linjun Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17814",
        "abstract": "Large Language Models (LLMs) have emerged as transformative tools in artificial intelligence (AI), exhibiting remarkable capabilities across diverse tasks such as text generation, reasoning, and decision-making. While their success has primarily been driven by advances in computational power and deep learning architectures, emerging problems -- in areas such as uncertainty quantification, decision-making, causal inference, and distribution shift -- require a deeper engagement with the field of statistics. This paper explores potential areas where statisticians can make important contributions to the development of LLMs, particularly those that aim to engender trustworthiness and transparency for human users. Thus, we focus on issues such as uncertainty quantification, interpretability, fairness, privacy, watermarking and model adaptation. We also consider possible roles for LLMs in statistical analysis. By bridging AI and statistics, we aim to foster a deeper collaboration that advances both the theoretical foundations and practical applications of LLMs, ultimately shaping their role in addressing complex societal challenges.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "181",
        "title": "3D Anatomical Structure-guided Deep Learning for Accurate Diffusion Microstructure Imaging",
        "author": [
            "Xinrui Ma",
            "Jian Cheng",
            "Wenxin Fan",
            "Ruoyou Wu",
            "Yongquan Ye",
            "Shanshan Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.17933",
        "abstract": "Diffusion magnetic resonance imaging (dMRI) is a crucial non-invasive technique for exploring the microstructure of the living human brain. Traditional hand-crafted and model-based tissue microstructure reconstruction methods often require extensive diffusion gradient sampling, which can be time-consuming and limits the clinical applicability of tissue microstructure information. Recent advances in deep learning have shown promise in microstructure estimation; however, accurately estimating tissue microstructure from clinically feasible dMRI scans remains challenging without appropriate constraints. This paper introduces a novel framework that achieves high-fidelity and rapid diffusion microstructure imaging by simultaneously leveraging anatomical information from macro-level priors and mutual information across parameters. This approach enhances time efficiency while maintaining accuracy in microstructure estimation. Experimental results demonstrate that our method outperforms four state-of-the-art techniques, achieving a peak signal-to-noise ratio (PSNR) of 30.51$\\pm$0.58 and a structural similarity index measure (SSIM) of 0.97$\\pm$0.004 in estimating parametric maps of multiple diffusion models. Notably, our method achieves a 15$\\times$ acceleration compared to the dense sampling approach, which typically utilizes 270 diffusion gradients.",
        "tags": [
            "3D",
            "Diffusion"
        ]
    },
    {
        "id": "182",
        "title": "Recurrent Neural Networks for Dynamic VWAP Execution: Adaptive Trading Strategies with Temporal Kolmogorov-Arnold Networks",
        "author": [
            "Remi Genet"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18177",
        "abstract": "The execution of Volume Weighted Average Price (VWAP) orders remains a critical challenge in modern financial markets, particularly as trading volumes and market complexity continue to increase. In my previous work https://arxiv.org/abs/2502.13722, I introduced a novel deep learning approach that demonstrated significant improvements over traditional VWAP execution methods by directly optimizing the execution problem rather than relying on volume curve predictions. However, that model was static because it employed the fully linear approach described in https://arxiv.org/abs/2410.21448, which is not designed for dynamic adjustment. This paper extends that foundation by developing a dynamic neural VWAP framework that adapts to evolving market conditions in real time. We introduce two key innovations: first, the integration of recurrent neural networks to capture complex temporal dependencies in market dynamics, and second, a sophisticated dynamic adjustment mechanism that continuously optimizes execution decisions based on market feedback. The empirical analysis, conducted across five major cryptocurrency markets, demonstrates that this dynamic approach achieves substantial improvements over both traditional methods and our previous static implementation, with execution performance gains of 10 to 15% in liquid markets and consistent outperformance across varying conditions. These results suggest that adaptive neural architectures can effectively address the challenges of modern VWAP execution while maintaining computational efficiency suitable for practical deployment.",
        "tags": [
            "Kolmogorov-Arnold Networks"
        ]
    },
    {
        "id": "183",
        "title": "Near-Optimal Approximations for Bayesian Inference in Function Space",
        "author": [
            "Veit Wild",
            "James Wu",
            "Dino Sejdinovic",
            "Jeremias Knoblauch"
        ],
        "pdf": "https://arxiv.org/pdf/2502.18279",
        "abstract": "We propose a scalable inference algorithm for Bayes posteriors defined on a reproducing kernel Hilbert space (RKHS). Given a likelihood function and a Gaussian random element representing the prior, the corresponding Bayes posterior measure $\\Pi_{\\text{B}}$ can be obtained as the stationary distribution of an RKHS-valued Langevin diffusion. We approximate the infinite-dimensional Langevin diffusion via a projection onto the first $M$ components of the Kosambi-Karhunen-LoÃ¨ve expansion. Exploiting the thus obtained approximate posterior for these $M$ components, we perform inference for $\\Pi_{\\text{B}}$ by relying on the law of total probability and a sufficiency assumption. The resulting method scales as $O(M^3+JM^2)$, where $J$ is the number of samples produced from the posterior measure $\\Pi_{\\text{B}}$. Interestingly, the algorithm recovers the posterior arising from the sparse variational Gaussian process (SVGP) (see Titsias, 2009) as a special case, owed to the fact that the sufficiency assumption underlies both methods. However, whereas the SVGP is parametrically constrained to be a Gaussian process, our method is based on a non-parametric variational family $\\mathcal{P}(\\mathbb{R}^M)$ consisting of all probability measures on $\\mathbb{R}^M$. As a result, our method is provably close to the optimal $M$-dimensional variational approximation of the Bayes posterior $\\Pi_{\\text{B}}$ in $\\mathcal{P}(\\mathbb{R}^M)$ for convex and Lipschitz continuous negative log likelihoods, and coincides with SVGP for the special case of a Gaussian error likelihood.",
        "tags": [
            "Diffusion"
        ]
    }
]