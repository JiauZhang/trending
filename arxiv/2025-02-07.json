[
    {
        "id": "1",
        "title": "AI Governance in the Context of the EU AI Act: A Bibliometric and Literature Review Approach",
        "author": [
            "Byeong-Je Kim",
            "Seunghoo Jeong",
            "Bong-Kyung Cho",
            "Ji-Bum Chung"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03468",
        "abstract": "The rapid advancement of artificial intelligence (AI) has brought about significant societal changes, necessitating robust AI governance frameworks. This study analyzed the research trends in AI governance within the framework of the EU AI Act. This study conducted a bibliometric analysis to examine the publications indexed in the Web of Science database. Our findings reveal that research on AI governance, particularly concerning AI systems regulated by the EU AI Act, remains relatively limited compared to the broader AI research landscape. Nonetheless, a growing interdisciplinary interest in AI governance is evident, with notable contributions from multi-disciplinary journals and open-access publications. Dominant research themes include ethical considerations, privacy concerns, and the growing impact of generative AI, such as ChatGPT. Notably, education, healthcare, and worker management are prominent application domains. Keyword network analysis highlights education, ethics, and ChatGPT as central keywords, underscoring the importance of these areas in current AI governance research. Subsequently, a comprehensive literature review was undertaken based on the bibliometric analysis findings to identify research trends, challenges, and insights within the categories of the EU AI Act. The findings provide valuable insights for researchers and policymakers, informing future research directions and contributing to developing comprehensive AI governance frameworks beyond the EU AI Act.",
        "tags": [
            "ChatGPT"
        ]
    },
    {
        "id": "2",
        "title": "Powering LLM Regulation through Data: Bridging the Gap from Compute Thresholds to Customer Experiences",
        "author": [
            "Wesley Pasfield"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03472",
        "abstract": "The rapid advancement of Large Language Models (LLMs) has created a critical gap in consumer protection due to the lack of standardized certification processes for LLM-powered Artificial Intelligence (AI) systems. This paper argues that current regulatory approaches, which focus on compute-level thresholds and generalized model evaluations, are insufficient to ensure the safety and effectiveness of specific LLM-based user experiences. We propose a shift towards a certification process centered on actual user-facing experiences and the curation of high-quality datasets for evaluation. This approach offers several benefits: it drives consumer confidence in AI system performance, enables businesses to demonstrate the credibility of their products, and allows regulators to focus on direct consumer protection. The paper outlines a potential certification workflow, emphasizing the importance of domain-specific datasets and expert evaluation. By repositioning data as the strategic center of regulatory efforts, this framework aims to address the challenges posed by the probabilistic nature of AI systems and the rapid pace of technological advancement. This shift in regulatory focus has the potential to foster innovation while ensuring responsible AI development, ultimately benefiting consumers, businesses, and government entities alike.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "3",
        "title": "Artificial Intelligence and Legal Analysis: Implications for Legal Education and the Profession",
        "author": [
            "Lee Peoples"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03487",
        "abstract": "This article reports the results of a study examining the ability of legal and non-legal Large Language Models to perform legal analysis using the Issue-Rule-Application-Conclusion framework. LLMs were tested on legal reasoning tasks involving rule analysis and analogical reasoning. The results show that LLMs can conduct basic IRAC analysis, but are limited by brief responses lacking detail, an inability to commit to answers, false confidence, and hallucinations. The study compares legal and nonlegal LLMs, identifies shortcomings, and explores traits that may hinder their ability to think like a lawyer. It also discusses the implications for legal education and practice, highlighting the need for critical thinking skills in future lawyers and the potential pitfalls of overreliance on artificial intelligence AI resulting in a loss of logic, reasoning, and critical thinking skills.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "4",
        "title": "Examining Two Hop Reasoning Through Information Content Scaling",
        "author": [
            "David Johnston",
            "Nora Belrose"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03490",
        "abstract": "Prior work has found that transformers have an inconsistent ability to learn to answer latent two-hop questions -- questions of the form \"Who is Bob's mother's boss?\" We study why this is the case by examining how transformers' capacity to learn datasets of two-hop questions and answers (two-hop QA) scales with their size, motivated by prior work on transformer knowledge capacity for simple factual memorization. We find that capacity scaling and generalization both support the hypothesis that latent two-hop QA requires transformers to learn each fact twice, while two-hop QA with chain of thought does not. We also show that with appropriate dataset parameters, it is possible to \"trap\" very small models in a regime where they memorize answers to two-hop questions independently, even though they would perform better if they could learn to answer them with function composition. Our findings show that measurement of capacity scaling can complement existing interpretability methods, though there are challenges in using it for this purpose.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "5",
        "title": "Teaching Language Models to Critique via Reinforcement Learning",
        "author": [
            "Zhihui Xie",
            "Jie chen",
            "Liyu Chen",
            "Weichao Mao",
            "Jingjing Xu",
            "Lingpeng Kong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03492",
        "abstract": "Teaching large language models (LLMs) to critique and refine their outputs is crucial for building systems that can iteratively improve, yet it is fundamentally limited by the ability to provide accurate judgments and actionable suggestions. In this work, we study LLM critics for code generation and propose $\\texttt{CTRL}$, a framework for $\\texttt{C}$ritic $\\texttt{T}$raining via $\\texttt{R}$einforcement $\\texttt{L}$earning, which trains a critic model to generate feedback that maximizes correction performance for a fixed generator model without human supervision. Our results demonstrate that critics trained with $\\texttt{CTRL}$ significantly enhance pass rates and mitigate compounding errors across both base and stronger generator models. Furthermore, we show that these critic models act as accurate generative reward models and enable test-time scaling through iterative critique-revision, achieving up to 106.1% relative improvements across challenging code generation benchmarks.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "6",
        "title": "An Empirical Exploration of ChatGPT's Ability to Support Problem Formulation Tasks for Mission Engineering and a Documentation of its Performance Variability",
        "author": [
            "Max Ofsa",
            "Taylan G. Topcu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03511",
        "abstract": "Systems engineering (SE) is evolving with the availability of generative artificial intelligence (AI) and the demand for a systems-of-systems perspective, formalized under the purview of mission engineering (ME) in the US Department of Defense. Formulating ME problems is challenging because they are open-ended exercises that involve translation of ill-defined problems into well-defined ones that are amenable for engineering development. It remains to be seen to which extent AI could assist problem formulation objectives. To that end, this paper explores the quality and consistency of multi-purpose Large Language Models (LLM) in supporting ME problem formulation tasks, specifically focusing on stakeholder identification. We identify a relevant reference problem, a NASA space mission design challenge, and document ChatGPT-3.5's ability to perform stakeholder identification tasks. We execute multiple parallel attempts and qualitatively evaluate LLM outputs, focusing on both their quality and variability. Our findings portray a nuanced picture. We find that the LLM performs well in identifying human-focused stakeholders but poorly in recognizing external systems and environmental factors, despite explicit efforts to account for these. Additionally, LLMs struggle with preserving the desired level of abstraction and exhibit a tendency to produce solution specific outputs that are inappropriate for problem formulation. More importantly, we document great variability among parallel threads, highlighting that LLM outputs should be used with caution, ideally by adopting a stochastic view of their abilities. Overall, our findings suggest that, while ChatGPT could reduce some expert workload, its lack of consistency and domain understanding may limit its reliability for problem formulation tasks.",
        "tags": [
            "ChatGPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "7",
        "title": "YINYANG-ALIGN: Benchmarking Contradictory Objectives and Proposing Multi-Objective Optimization based DPO for Text-to-Image Alignment",
        "author": [
            "Amitava Das",
            "Yaswanth Narsupalli",
            "Gurpreet Singh",
            "Vinija Jain",
            "Vasu Sharma",
            "Suranjana Trivedy",
            "Aman Chadha",
            "Amit Sheth"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03512",
        "abstract": "Precise alignment in Text-to-Image (T2I) systems is crucial to ensure that generated visuals not only accurately encapsulate user intents but also conform to stringent ethical and aesthetic benchmarks. Incidents like the Google Gemini fiasco, where misaligned outputs triggered significant public backlash, underscore the critical need for robust alignment mechanisms. In contrast, Large Language Models (LLMs) have achieved notable success in alignment. Building on these advancements, researchers are eager to apply similar alignment techniques, such as Direct Preference Optimization (DPO), to T2I systems to enhance image generation fidelity and reliability.\nWe present YinYangAlign, an advanced benchmarking framework that systematically quantifies the alignment fidelity of T2I systems, addressing six fundamental and inherently contradictory design objectives. Each pair represents fundamental tensions in image generation, such as balancing adherence to user prompts with creative modifications or maintaining diversity alongside visual coherence. YinYangAlign includes detailed axiom datasets featuring human prompts, aligned (chosen) responses, misaligned (rejected) AI-generated outputs, and explanations of the underlying contradictions.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Text-to-Image"
        ]
    },
    {
        "id": "8",
        "title": "Kronecker Mask and Interpretive Prompts are Language-Action Video Learners",
        "author": [
            "Jingyi Yang",
            "Zitong Yu",
            "Xiuming Ni",
            "Jia He",
            "Hui Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03549",
        "abstract": "Contrastive language-image pretraining (CLIP) has significantly advanced image-based vision learning. A pressing topic subsequently arises: how can we effectively adapt CLIP to the video domain? Recent studies have focused on adjusting either the textual or visual branch of CLIP for action recognition. However, we argue that adaptations of both branches are crucial. In this paper, we propose \\textbf{CLAVER}: a \\textbf{C}ontrastive \\textbf{L}anguage-\\textbf{A}ction \\textbf{V}ideo Learn\\textbf{er}, designed to shift CLIP's focus from the alignment of static visual objects and concrete nouns to the alignment of dynamic action behaviors and abstract verbs. Specifically, we introduce a novel Kronecker mask attention for temporal modeling. Our tailored Kronecker mask offers three benefits 1) it expands the temporal receptive field for each token, 2) it serves as an effective spatiotemporal heterogeneity inductive bias, mitigating the issue of spatiotemporal homogenization, and 3) it can be seamlessly plugged into transformer-based models. Regarding the textual branch, we leverage large language models to generate diverse, sentence-level and semantically rich interpretive prompts of actions, which shift the model's focus towards the verb comprehension. Extensive experiments on various benchmarks and learning scenarios demonstrate the superiority and generality of our approach. The code will be available soon.",
        "tags": [
            "CLIP",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "9",
        "title": "CLIP Behaves like a Bag-of-Words Model Cross-modally but not Uni-modally",
        "author": [
            "Darina Koishigarina",
            "Arnas Uselis",
            "Seong Joon Oh"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03566",
        "abstract": "CLIP (Contrastive Language-Image Pretraining) has become a popular choice for various downstream tasks. However, recent studies have questioned its ability to represent compositional concepts effectively. These works suggest that CLIP often acts like a bag-of-words (BoW) model, interpreting images and text as sets of individual concepts without grasping the structural relationships. In particular, CLIP struggles to correctly bind attributes to their corresponding objects when multiple objects are present in an image or text. In this work, we investigate why CLIP exhibits this BoW-like behavior. We find that the correct attribute-object binding information is already present in individual text and image modalities. Instead, the issue lies in the cross-modal alignment, which relies on cosine similarity. To address this, we propose Linear Attribute Binding CLIP or LABCLIP. It applies a linear transformation to text embeddings before computing cosine similarity. This approach significantly improves CLIP's ability to bind attributes to correct objects, thereby enhancing its compositional understanding.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "10",
        "title": "Code Simulation as a Proxy for High-order Tasks in Large Language Models",
        "author": [
            "Emanuele La Malfa",
            "Christoph Weinhuber",
            "Orazio Torre",
            "Fangru Lin",
            "X. Angelo Huang",
            "Samuele Marro",
            "Anthony Cohn",
            "Nigel Shadbolt",
            "Michael Wooldridge"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03568",
        "abstract": "Many reasoning, planning, and problem-solving tasks share an intrinsic algorithmic nature: correctly simulating each step is a sufficient condition to solve them correctly. We collect pairs of naturalistic and synthetic reasoning tasks to assess the capabilities of Large Language Models (LLM). While naturalistic tasks often require careful human handcrafting, we show that synthetic data is, in many cases, a good proxy that is much easier to collect at scale. We leverage common constructs in programming as the counterpart of the building blocks of naturalistic reasoning tasks, such as straight-line programs, code that contains critical paths, and approximate and redundant instructions. We further assess the capabilities of LLMs on sorting problems and repeated operations via sorting algorithms and nested loops. Our synthetic datasets further reveal that while the most powerful LLMs exhibit relatively strong execution capabilities, the process is fragile: it is negatively affected by memorisation and seems to rely heavily on pattern recognition. Our contribution builds upon synthetically testing the reasoning capabilities of LLMs as a scalable complement to handcrafted human-annotated problems.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "11",
        "title": "Chartist: Task-driven Eye Movement Control for Chart Reading",
        "author": [
            "Danqing Shi",
            "Yao Wang",
            "Yunpeng Bai",
            "Andreas Bulling",
            "Antti Oulasvirta"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03575",
        "abstract": "To design data visualizations that are easy to comprehend, we need to understand how people with different interests read them. Computational models of predicting scanpaths on charts could complement empirical studies by offering estimates of user performance inexpensively; however, previous models have been limited to gaze patterns and overlooked the effects of tasks. Here, we contribute Chartist, a computational model that simulates how users move their eyes to extract information from the chart in order to perform analysis tasks, including value retrieval, filtering, and finding extremes. The novel contribution lies in a two-level hierarchical control architecture. At the high level, the model uses LLMs to comprehend the information gained so far and applies this representation to select a goal for the lower-level controllers, which, in turn, move the eyes in accordance with a sampling policy learned via reinforcement learning. The model is capable of predicting human-like task-driven scanpaths across various tasks. It can be applied in fields such as explainable AI, visualization design evaluation, and optimization. While it displays limitations in terms of generalizability and accuracy, it takes modeling in a promising direction, toward understanding human behaviors in interacting with charts.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "12",
        "title": "A Mixed-Methods Evaluation of LLM-Based Chatbots for Menopause",
        "author": [
            "Roshini Deva",
            "Manvi S",
            "Jasmine Zhou",
            "Elizabeth Britton Chahine",
            "Agena Davenport-Nicholson",
            "Nadi Nina Kaonga",
            "Selen Bozkurt",
            "Azra Ismail"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03579",
        "abstract": "The integration of Large Language Models (LLMs) into healthcare settings has gained significant attention, particularly for question-answering tasks. Given the high-stakes nature of healthcare, it is essential to ensure that LLM-generated content is accurate and reliable to prevent adverse outcomes. However, the development of robust evaluation metrics and methodologies remains a matter of much debate. We examine the performance of publicly available LLM-based chatbots for menopause-related queries, using a mixed-methods approach to evaluate safety, consensus, objectivity, reproducibility, and explainability. Our findings highlight the promise and limitations of traditional evaluation metrics for sensitive health topics. We propose the need for customized and ethically grounded evaluation frameworks to assess LLMs to advance safe and effective use in healthcare.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "13",
        "title": "Bilevel ZOFO: Bridging Parameter-Efficient and Zeroth-Order Techniques for Efficient LLM Fine-Tuning and Meta-Training",
        "author": [
            "Reza Shirkavand",
            "Qi He",
            "Peiran Yu",
            "Heng Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03604",
        "abstract": "Fine-tuning pre-trained Large Language Models (LLMs) for downstream tasks using First-Order (FO) optimizers presents significant computational challenges. Parameter-Efficient Fine-Tuning(PEFT) methods have been proposed to address these challenges by freezing most model parameters and training only a small subset. While PEFT is efficient, it may not outperform full fine-tuning when high task-specific performance is required. Zeroth-Order (ZO) methods offer an alternative for fine-tuning the entire pre-trained model by approximating gradients using only the forward pass, thus eliminating the computational burden of back-propagation in first-order methods. However, when implementing ZO methods, a hard prompt is crucial, and relying on simple, fixed hard prompts may not be optimal. In this paper, we propose a bilevel optimization framework that complements ZO methods with PEFT to mitigate sensitivity to hard prompts while efficiently and effectively fine-tuning LLMs. Our Bilevel ZOFO (Zeroth-Order-First-Order) method employs a double-loop optimization strategy, where only the gradient of the PEFT model and the forward pass of the base model are required. We provide convergence guarantees for Bilevel ZOFO. Empirically, we demonstrate that Bilevel ZOFO outperforms both PEFT and ZO methods in single-task settings while maintaining similar memory efficiency. Additionally, we show its strong potential for multitask learning. Compared to current first-order meta-training algorithms for multitask learning, our method has significantly lower computational demands while maintaining or improving performance.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "14",
        "title": "Accelerating OTA Circuit Design: Transistor Sizing Based on a Transformer Model and Precomputed Lookup Tables",
        "author": [
            "Subhadip Ghosh",
            "Endalk Y. Gebru",
            "Chandramouli V. Kashyap",
            "Ramesh Harjani",
            "Sachin S. Sapatnekar"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03605",
        "abstract": "Device sizing is crucial for meeting performance specifications in operational transconductance amplifiers (OTAs), and this work proposes an automated sizing framework based on a transformer model. The approach first leverages the driving-point signal flow graph (DP-SFG) to map an OTA circuit and its specifications into transformer-friendly sequential data. A specialized tokenization approach is applied to the sequential data to expedite the training of the transformer on a diverse range of OTA topologies, under multiple specifications. Under specific performance constraints, the trained transformer model is used to accurately predict DP-SFG parameters in the inference phase. The predicted DP-SFG parameters are then translated to transistor sizes using a precomputed look-up table-based approach inspired by the gm/Id methodology. In contrast to previous conventional or machine-learning-based methods, the proposed framework achieves significant improvements in both speed and computational efficiency by reducing the need for expensive SPICE simulations within the optimization loop; instead, almost all SPICE simulations are confined to the one-time training phase. The method is validated on a variety of unseen specifications, and the sizing solution demonstrates over 90% success in meeting specifications with just one SPICE simulation for validation, and 100% success with 3-5 additional SPICE simulations.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "15",
        "title": "Simultaneous Multi-Robot Motion Planning with Projected Diffusion Models",
        "author": [
            "Jinhao Liang",
            "Jacob K Christopher",
            "Sven Koenig",
            "Ferdinando Fioretto"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03607",
        "abstract": "Recent advances in diffusion models hold significant potential in robotics, enabling the generation of diverse and smooth trajectories directly from raw representations of the environment. Despite this promise, applying diffusion models to motion planning remains challenging due to their difficulty in enforcing critical constraints, such as collision avoidance and kinematic feasibility. These limitations become even more pronounced in Multi-Robot Motion Planning (MRMP), where multiple robots must coordinate in shared spaces. To address this challenge, this work proposes Simultaneous MRMP Diffusion (SMD), a novel approach integrating constrained optimization into the diffusion sampling process to produce collision-free, kinematically feasible trajectories. Additionally, the paper introduces a comprehensive MRMP benchmark to evaluate trajectory planning algorithms across scenarios with varying robot densities, obstacle complexities, and motion constraints. Experimental results show SMD consistently outperforms classical and learning-based motion planners, achieving higher success rates and efficiency in complex multi-robot environments.",
        "tags": [
            "Diffusion",
            "Robot",
            "Robotics"
        ]
    },
    {
        "id": "16",
        "title": "Resource-Efficient & Effective Code Summarization",
        "author": [
            "Saima Afrin",
            "Joseph Call",
            "Khai-Nguyen Nguyen",
            "Oscar Chaparro",
            "Antonio Mastropaolo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03617",
        "abstract": "Code Language Models (CLMs) have demonstrated high effectiveness in automating software engineering tasks such as bug fixing, code generation, and code documentation. This progress has been driven by the scaling of large models, ranging from millions to trillions of parameters (e.g., GPT-4). However, as models grow in scale, sustainability concerns emerge, as they are extremely resource-intensive, highlighting the need for efficient, environmentally conscious solutions. GreenAI techniques, such as QLoRA (Quantized Low-Rank Adaptation), offer a promising path for dealing with large models' sustainability as they enable resource-efficient model fine-tuning. Previous research has shown the effectiveness of QLoRA in code-related tasks, particularly those involving natural language inputs and code as the target output (NL-to-Code), such as code generation. However, no studies have explored its application to tasks that are fundamentally similar to NL-to-Code (natural language to code) but operate in the opposite direction, such as code summarization. This leaves a gap in understanding how well QLoRA can generalize to Code-to-NL tasks, which are equally important for supporting developers in understanding and maintaining code. To address this gap, we investigate the extent to which QLoRA's capabilities in NL-to-Code tasks can be leveraged and transferred to code summarization, one representative Code-to-NL task. Our study evaluates two state-of-the-art CLMs (CodeLlama and DeepSeek-Coder) across two programming languages: Python and Java. Our research tasked models with generating descriptions for Python and Java code methods. The results align with prior findings on QLoRA for source code generation, showing that QLoRA enables efficient fine-tuning of CLMs for code summarization.",
        "tags": [
            "DeepSeek",
            "GPT",
            "Low-Rank Adaptation"
        ]
    },
    {
        "id": "17",
        "title": "The Logical Implication Steering Method for Conditional Interventions on Transformer Generation",
        "author": [
            "Damjan Kalajdzievski"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03618",
        "abstract": "The field of mechanistic interpretability in pre-trained transformer models has demonstrated substantial evidence supporting the ''linear representation hypothesis'', which is the idea that high level concepts are encoded as vectors in the space of activations of a model. Studies also show that model generation behavior can be steered toward a given concept by adding the concept's vector to the corresponding activations. We show how to leverage these properties to build a form of logical implication into models, enabling transparent and interpretable adjustments that induce a chosen generation behavior in response to the presence of any given concept. Our method, Logical Implication Model Steering (LIMS), unlocks new hand engineered reasoning capabilities by integrating neuro-symbolic logic into pre-trained transformer models.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "18",
        "title": "DynVFX: Augmenting Real Videos with Dynamic Content",
        "author": [
            "Danah Yatim",
            "Rafail Fridman",
            "Omer Bar-Tal",
            "Tali Dekel"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03621",
        "abstract": "We present a method for augmenting real-world videos with newly generated dynamic content. Given an input video and a simple user-provided text instruction describing the desired content, our method synthesizes dynamic objects or complex scene effects that naturally interact with the existing scene over time. The position, appearance, and motion of the new content are seamlessly integrated into the original footage while accounting for camera motion, occlusions, and interactions with other dynamic objects in the scene, resulting in a cohesive and realistic output video. We achieve this via a zero-shot, training-free framework that harnesses a pre-trained text-to-video diffusion transformer to synthesize the new content and a pre-trained Vision Language Model to envision the augmented scene in detail. Specifically, we introduce a novel inference-based method that manipulates features within the attention mechanism, enabling accurate localization and seamless integration of the new content while preserving the integrity of the original scene. Our method is fully automated, requiring only a simple user instruction. We demonstrate its effectiveness on a wide range of edits applied to real-world videos, encompassing diverse objects and scenarios involving both camera and object motion.",
        "tags": [
            "Diffusion",
            "Diffusion Transformer",
            "Text-to-Video",
            "Transformer"
        ]
    },
    {
        "id": "19",
        "title": "AdaPhish: AI-Powered Adaptive Defense and Education Resource Against Deceptive Emails",
        "author": [
            "Rei Meguro",
            "Ng S. T. Chong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03622",
        "abstract": "Phishing attacks remain a significant threat in the digital age, yet organizations lack effective methods to tackle phishing attacks without leaking sensitive information. Phish bowl initiatives are a vital part of cybersecurity efforts against these attacks. However, traditional phish bowls require manual anonymization and are often limited to internal use. To overcome these limitations, we introduce AdaPhish, an AI-powered phish bowl platform that automatically anonymizes and analyzes phishing emails using large language models (LLMs) and vector databases. AdaPhish achieves real-time detection and adaptation to new phishing tactics while enabling long-term tracking of phishing trends. Through automated reporting, adaptive analysis, and real-time alerts, AdaPhish presents a scalable, collaborative solution for phishing detection and cybersecurity education.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "20",
        "title": "REALEDIT: Reddit Edits As a Large-scale Empirical Dataset for Image Transformations",
        "author": [
            "Peter Sushko",
            "Ayana Bharadwaj",
            "Zhi Yang Lim",
            "Vasily Ilin",
            "Ben Caffee",
            "Dongping Chen",
            "Mohammadreza Salehi",
            "Cheng-Yu Hsieh",
            "Ranjay Krishna"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03629",
        "abstract": "Existing image editing models struggle to meet real-world demands. Despite excelling in academic benchmarks, they have yet to be widely adopted for real user needs. Datasets that power these models use artificial edits, lacking the scale and ecological validity necessary to address the true diversity of user requests. We introduce REALEDIT, a large-scale image editing dataset with authentic user requests and human-made edits sourced from Reddit. REALEDIT includes a test set of 9300 examples to evaluate models on real user requests. Our results show that existing models fall short on these tasks, highlighting the need for realistic training data. To address this, we introduce 48K training examples and train our REALEDIT model, achieving substantial gains - outperforming competitors by up to 165 Elo points in human judgment and 92 percent relative improvement on the automated VIEScore metric. We deploy our model on Reddit, testing it on new requests, and receive positive feedback. Beyond image editing, we explore REALEDIT's potential in detecting edited images by partnering with a deepfake detection non-profit. Finetuning their model on REALEDIT data improves its F1-score by 14 percentage points, underscoring the dataset's value for broad applications.",
        "tags": [
            "Detection",
            "Image Editing"
        ]
    },
    {
        "id": "21",
        "title": "Towards Physical Understanding in Video Generation: A 3D Point Regularization Approach",
        "author": [
            "Yunuo Chen",
            "Junli Cao",
            "Anil Kag",
            "Vidit Goel",
            "Sergei Korolev",
            "Chenfanfu Jiang",
            "Sergey Tulyakov",
            "Jian Ren"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03639",
        "abstract": "We present a novel video generation framework that integrates 3-dimensional geometry and dynamic awareness. To achieve this, we augment 2D videos with 3D point trajectories and align them in pixel space. The resulting 3D-aware video dataset, PointVid, is then used to fine-tune a latent diffusion model, enabling it to track 2D objects with 3D Cartesian coordinates. Building on this, we regularize the shape and motion of objects in the video to eliminate undesired artifacts, \\eg, nonphysical deformation. Consequently, we enhance the quality of generated RGB videos and alleviate common issues like object morphing, which are prevalent in current video models due to a lack of shape awareness. With our 3D augmentation and regularization, our model is capable of handling contact-rich scenarios such as task-oriented videos. These videos involve complex interactions of solids, where 3D information is essential for perceiving deformation and contact. Furthermore, our model improves the overall quality of video generation by promoting the 3D consistency of moving objects and reducing abrupt changes in shape and motion.",
        "tags": [
            "3D",
            "Diffusion",
            "Video Generation"
        ]
    },
    {
        "id": "22",
        "title": "Context-Preserving Gradient Modulation for Large Language Models: A Novel Approach to Semantic Consistency in Long-Form Text Generation",
        "author": [
            "Nirola Kobanov",
            "Edmund Weatherstone",
            "Zachary Vanderpoel",
            "Orlando Wetherby"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03643",
        "abstract": "Maintaining semantic consistency over extended text sequences remains a fundamental challenge in long-form text generation, where conventional training methodologies often struggle to prevent contextual drift and coherence degradation. A novel gradient modulation approach is introduced, designed to adjust parameter updates dynamically in response to contextual relevance, ensuring that generated text remains aligned with prior discourse. By integrating a modulation function that selectively amplifies or attenuates gradients based on learned contextual dependencies, the proposed method enhances the stability of model-generated narratives without imposing significant computational overhead. Comparative evaluations against baseline models reveal improvements in coherence, contextual retention, and long-range dependency tracking, demonstrating the effectiveness of modifying the learning process at the gradient level. The results indicate that sentence structure variability and lexical diversity benefit from this approach, mitigating repetitive phrasing and improving adaptability across diverse linguistic contexts. Statistical validation of coherence metrics further substantiates the observed enhancements, with a significant reduction in inconsistencies emerging as a direct consequence of the modulation mechanism. Computational efficiency assessments confirm that the framework achieves these gains without requiring substantial modifications to the underlying architecture, ensuring compatibility with existing optimization workflows.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "23",
        "title": "MNE: overparametrized neural evolution with applications to diffusion processes and sampling",
        "author": [
            "Michael Lindsey"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03645",
        "abstract": "We propose a framework for solving evolution equations within parametric function classes, especially ones that are specified by neural networks. We call this framework the minimal neural evolution (MNE) because it is motivated by the goal of seeking the smallest instantaneous change in the neural network parameters that is compatible with exact solution of the evolution equation at a set of evolving collocation points. Formally, the MNE is quite similar to the recently introduced Neural Galerkin framework, but a difference in perspective motivates an alternative sketching procedure that effectively reduces the linear systems solved within the integrator to a size that is interpretable as an effective rank of the evolving neural tangent kernel, while maintaining a smooth evolution equation for the neural network parameters. We focus specifically on the application of this framework to diffusion processes, where the score function allows us to define intuitive dynamics for the collocation points. These can in turn be propagated jointly with the neural network parameters using a high-order adaptive integrator. In particular, we demonstrate how the Ornstein-Uhlenbeck diffusion process can be used for the task of sampling from a probability distribution given a formula for the density but no training data. This framework extends naturally to allow for conditional sampling and marginalization, and we show how to systematically remove the sampling bias due to parametric approximation error. We validate the efficiency, systematic improvability, and scalability of our approach on illustrative examples in low and high spatial dimensions.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "24",
        "title": "Looking for the Inner Music: Probing LLMs' Understanding of Literary Style",
        "author": [
            "Rebecca M. M. Hicke",
            "David Mimno"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03647",
        "abstract": "Recent work has demonstrated that language models can be trained to identify the author of much shorter literary passages than has been thought feasible for traditional stylometry. We replicate these results for authorship and extend them to a new dataset measuring novel genre. We find that LLMs are able to distinguish authorship and genre, but they do so in different ways. Some models seem to rely more on memorization, while others benefit more from training to learn author/genre characteristics. We then use three methods to probe one high-performing LLM for features that define style. These include direct syntactic ablations to input text as well as two methods that look at model internals. We find that authorial style is easier to define than genre-level style and is more impacted by minor syntactic decisions and contextual word usage. However, some traits like pronoun usage and word order prove significant for defining both kinds of literary style.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "25",
        "title": "Gompertz Linear Units: Leveraging Asymmetry for Enhanced Learning Dynamics",
        "author": [
            "Indrashis Das",
            "Mahmoud Safari",
            "Steven Adriaensen",
            "Frank Hutter"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03654",
        "abstract": "Activation functions are fundamental elements of deep learning architectures as they significantly influence training dynamics. ReLU, while widely used, is prone to the dying neuron problem, which has been mitigated by variants such as LeakyReLU, PReLU, and ELU that better handle negative neuron outputs. Recently, self-gated activations like GELU and Swish have emerged as state-of-the-art alternatives, leveraging their smoothness to ensure stable gradient flow and prevent neuron inactivity. In this work, we introduce the Gompertz Linear Unit (GoLU), a novel self-gated activation function defined as $\\mathrm{GoLU}(x) = x \\, \\mathrm{Gompertz}(x)$, where $\\mathrm{Gompertz}(x) = e^{-e^{-x}}$. The GoLU activation leverages the asymmetry in the Gompertz function to reduce variance in the latent space more effectively compared to GELU and Swish, while preserving robust gradient flow. Extensive experiments across diverse tasks, including Image Classification, Language Modeling, Semantic Segmentation, Object Detection, Instance Segmentation, and Diffusion, highlight GoLU's superior performance relative to state-of-the-art activation functions, establishing GoLU as a robust alternative to existing activation functions.",
        "tags": [
            "Detection",
            "Diffusion",
            "Segmentation"
        ]
    },
    {
        "id": "26",
        "title": "Advancing Reasoning in Large Language Models: Promising Methods and Approaches",
        "author": [
            "Avinash Patil"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03671",
        "abstract": "Large Language Models (LLMs) have succeeded remarkably in various natural language processing (NLP) tasks, yet their reasoning capabilities remain a fundamental challenge. While LLMs exhibit impressive fluency and factual recall, their ability to perform complex reasoning-spanning logical deduction, mathematical problem-solving, commonsense inference, and multi-step reasoning-often falls short of human expectations. This survey provides a comprehensive review of emerging techniques enhancing reasoning in LLMs. We categorize existing methods into key approaches, including prompting strategies (e.g., Chain-of-Thought reasoning, Self-Consistency, and Tree-of-Thought reasoning), architectural innovations (e.g., retrieval-augmented models, modular reasoning networks, and neuro-symbolic integration), and learning paradigms (e.g., fine-tuning with reasoning-specific datasets, reinforcement learning, and self-supervised reasoning objectives). Additionally, we explore evaluation frameworks used to assess reasoning in LLMs and highlight open challenges, such as hallucinations, robustness, and reasoning generalization across diverse tasks. By synthesizing recent advancements, this survey aims to provide insights into promising directions for future research and practical applications of reasoning-augmented LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "27",
        "title": "Reflection-Window Decoding: Text Generation with Selective Refinement",
        "author": [
            "Zeyu Tang",
            "Zhenhao Chen",
            "Loka Li",
            "Xiangchen Song",
            "Yunlong Deng",
            "Yifan Shen",
            "Guangyi Chen",
            "Peter Spirtes",
            "Kun Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03678",
        "abstract": "The autoregressive decoding for text generation in large language models (LLMs), while widely used, is inherently suboptimal due to the lack of a built-in mechanism to perform refinement and/or correction of the generated content. In this paper, we consider optimality in terms of the joint probability over the generated response, when jointly considering all tokens at the same time. We theoretically characterize the potential deviation of the autoregressively generated response from its globally optimal counterpart that is of the same length. Our analysis suggests that we need to be cautious when noticeable uncertainty arises during text generation, which may signal the sub-optimality of the generation history. To address the pitfall of autoregressive decoding for text generation, we propose an approach that incorporates a sliding reflection window and a pausing criterion, such that refinement and generation can be carried out interchangeably as the decoding proceeds. Our selective refinement framework strikes a balance between efficiency and optimality, and our extensive experimental results demonstrate the effectiveness of our approach.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "28",
        "title": "Controlled LLM Decoding via Discrete Auto-regressive Biasing",
        "author": [
            "Patrick Pynadath",
            "Ruqi Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03685",
        "abstract": "Controlled text generation allows for enforcing user-defined constraints on large language model outputs, an increasingly important field as LLMs become more prevalent in everyday life. One common approach uses energy-based decoding, which defines a target distribution through an energy function that combines multiple constraints into a weighted average. However, these methods often struggle to balance fluency with constraint satisfaction, even with extensive tuning of the energy function's coefficients. In this paper, we identify that this suboptimal balance arises from sampling in continuous space rather than the natural discrete space of text tokens. To address this, we propose Discrete Auto-regressive Biasing, a controlled decoding algorithm that leverages gradients while operating entirely in the discrete text domain. Specifically, we introduce a new formulation for controlled text generation by defining a joint distribution over the generated sequence and an auxiliary bias sequence. To efficiently sample from this joint distribution, we propose a Langevin-within-Gibbs sampling algorithm using gradient-based discrete MCMC. Our method significantly improves constraint satisfaction while maintaining comparable or better fluency, all with even lower computational costs. We demonstrate the advantages of our controlled decoding method on sentiment control, language detoxification, and keyword-guided generation.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "29",
        "title": "Variational Control for Guidance in Diffusion Models",
        "author": [
            "Kushagra Pandey",
            "Farrin Marouf Sofian",
            "Felix Draxler",
            "Theofanis Karaletsos",
            "Stephan Mandt"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03686",
        "abstract": "Diffusion models exhibit excellent sample quality, but existing guidance methods often require additional model training or are limited to specific tasks. We revisit guidance in diffusion models from the perspective of variational inference and control, introducing Diffusion Trajectory Matching (DTM) that enables guiding pretrained diffusion trajectories to satisfy a terminal cost. DTM unifies a broad class of guidance methods and enables novel instantiations. We introduce a new method within this framework that achieves state-of-the-art results on several linear and (blind) non-linear inverse problems without requiring additional model training or modifications. For instance, in ImageNet non-linear deblurring, our model achieves an FID score of 34.31, significantly improving over the best pretrained-method baseline (FID 78.07). We will make the code available in a future update.",
        "tags": [
            "Deblurring",
            "Diffusion"
        ]
    },
    {
        "id": "30",
        "title": "A Comparison of DeepSeek and Other LLMs",
        "author": [
            "Tianchen Gao",
            "Jiashun Jin",
            "Zheng Tracy Ke",
            "Gabriel Moryoussef"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03688",
        "abstract": "Recently, DeepSeek has been the focus of attention in and beyond the AI community. An interesting problem is how DeepSeek compares to other large language models (LLMs). There are many tasks an LLM can do, and in this paper, we use the task of predicting an outcome using a short text for comparison. We consider two settings, an authorship classification setting and a citation classification setting. In the first one, the goal is to determine whether a short text is written by human or AI. In the second one, the goal is to classify a citation to one of four types using the textual content. For each experiment, we compare DeepSeek with $4$ popular LLMs: Claude, Gemini, GPT, and Llama.\nWe find that, in terms of classification accuracy, DeepSeek outperforms Gemini, GPT, and Llama in most cases, but underperforms Claude. We also find that DeepSeek is comparably slower than others but with a low cost to use, while Claude is much more expensive than all the others. Finally, we find that in terms of similarity, the output of DeepSeek is most similar to those of Gemini and Claude (and among all $5$ LLMs, Claude and Gemini have the most similar outputs).\nIn this paper, we also present a fully-labeled dataset collected by ourselves, and propose a recipe where we can use the LLMs and a recent data set, MADStat, to generate new data sets. The datasets in our paper can be used as benchmarks for future study on LLMs.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "31",
        "title": "DocMIA: Document-Level Membership Inference Attacks against DocVQA Models",
        "author": [
            "Khanh Nguyen",
            "Raouf Kerkouche",
            "Mario Fritz",
            "Dimosthenis Karatzas"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03692",
        "abstract": "Document Visual Question Answering (DocVQA) has introduced a new paradigm for end-to-end document understanding, and quickly became one of the standard benchmarks for multimodal LLMs. Automating document processing workflows, driven by DocVQA models, presents significant potential for many business sectors. However, documents tend to contain highly sensitive information, raising concerns about privacy risks associated with training such DocVQA models. One significant privacy vulnerability, exploited by the membership inference attack, is the possibility for an adversary to determine if a particular record was part of the model's training data. In this paper, we introduce two novel membership inference attacks tailored specifically to DocVQA models. These attacks are designed for two different adversarial scenarios: a white-box setting, where the attacker has full access to the model architecture and parameters, and a black-box setting, where only the model's outputs are available. Notably, our attacks assume the adversary lacks access to auxiliary datasets, which is more realistic in practice but also more challenging. Our unsupervised methods outperform existing state-of-the-art membership inference attacks across a variety of DocVQA models and datasets, demonstrating their effectiveness and highlighting the privacy risks in this domain.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "32",
        "title": "LLM Alignment as Retriever Optimization: An Information Retrieval Perspective",
        "author": [
            "Bowen Jin",
            "Jinsung Yoon",
            "Zhen Qin",
            "Ziqi Wang",
            "Wei Xiong",
            "Yu Meng",
            "Jiawei Han",
            "Sercan O. Arik"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03699",
        "abstract": "Large Language Models (LLMs) have revolutionized artificial intelligence with capabilities in reasoning, coding, and communication, driving innovation across industries. Their true potential depends on effective alignment to ensure correct, trustworthy and ethical behavior, addressing challenges like misinformation, hallucinations, bias and misuse. While existing Reinforcement Learning (RL)-based alignment methods are notoriously complex, direct optimization approaches offer a simpler alternative. In this work, we introduce a novel direct optimization approach for LLM alignment by drawing on established Information Retrieval (IR) principles. We present a systematic framework that bridges LLM alignment and IR methodologies, mapping LLM generation and reward models to IR's retriever-reranker paradigm. Building on this foundation, we propose LLM Alignment as Retriever Preference Optimization (LarPO), a new alignment method that enhances overall alignment quality. Extensive experiments validate LarPO's effectiveness with 38.9 % and 13.7 % averaged improvement on AlpacaEval2 and MixEval-Hard respectively. Our work opens new avenues for advancing LLM alignment by integrating IR foundations, offering a promising direction for future research.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RL"
        ]
    },
    {
        "id": "33",
        "title": "Aggregate and conquer: detecting and steering LLM concepts by combining nonlinear predictors over multiple layers",
        "author": [
            "Daniel Beaglehole",
            "Adityanarayanan Radhakrishnan",
            "Enric Boix-AdserÃ ",
            "Mikhail Belkin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03708",
        "abstract": "A trained Large Language Model (LLM) contains much of human knowledge. Yet, it is difficult to gauge the extent or accuracy of that knowledge, as LLMs do not always ``know what they know'' and may even be actively misleading. In this work, we give a general method for detecting semantic concepts in the internal activations of LLMs. Furthermore, we show that our methodology can be easily adapted to steer LLMs toward desirable outputs. Our innovations are the following: (1) we use a nonlinear feature learning method to identify important linear directions for predicting concepts from each layer; (2) we aggregate features across layers to build powerful concept detectors and steering mechanisms. We showcase the power of our approach by attaining state-of-the-art results for detecting hallucinations, harmfulness, toxicity, and untruthful content on seven benchmarks. We highlight the generality of our approach by steering LLMs towards new concepts that, to the best of our knowledge, have not been previously considered in the literature, including: semantic disambiguation, human languages, programming languages, hallucinated responses, science subjects, poetic/Shakespearean English, and even multiple concepts simultaneously. Moreover, our method can steer concepts with numerical attributes such as product reviews. We provide our code (including a simple API for our methods) at https://github.com/dmbeaglehole/neural_controllers .",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "34",
        "title": "MultiQ&A: An Analysis in Measuring Robustness via Automated Crowdsourcing of Question Perturbations and Answers",
        "author": [
            "Nicole Cho",
            "William Watson"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03711",
        "abstract": "One critical challenge in the institutional adoption journey of Large Language Models (LLMs) stems from their propensity to hallucinate in generated responses. To address this, we propose MultiQ&A, a systematic approach for evaluating the robustness and consistency of LLM-generated answers. We demonstrate MultiQ&A's ability to crowdsource question perturbations and their respective answers through independent LLM agents at scale. Our experiments culminated in the examination of 1.9 million question perturbations and 2.3 million answers. Furthermore, MultiQ&A shows that ensembled LLMs, such as gpt-3.5-turbo, remain relatively robust and consistent under perturbations. MultiQ&A provides clarity in the response generation space, offering an effective method for inspecting disagreements and variability. Therefore, our system offers a potential framework for institutional LLM adoption with the ability to measure confidence, consistency, and the quantification of hallucinations.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "35",
        "title": "Efficiently Generating Expressive Quadruped Behaviors via Language-Guided Preference Learning",
        "author": [
            "Jaden Clark",
            "Joey Hejna",
            "Dorsa Sadigh"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03717",
        "abstract": "Expressive robotic behavior is essential for the widespread acceptance of robots in social environments. Recent advancements in learned legged locomotion controllers have enabled more dynamic and versatile robot behaviors. However, determining the optimal behavior for interactions with different users across varied scenarios remains a challenge. Current methods either rely on natural language input, which is efficient but low-resolution, or learn from human preferences, which, although high-resolution, is sample inefficient. This paper introduces a novel approach that leverages priors generated by pre-trained LLMs alongside the precision of preference learning. Our method, termed Language-Guided Preference Learning (LGPL), uses LLMs to generate initial behavior samples, which are then refined through preference-based feedback to learn behaviors that closely align with human expectations. Our core insight is that LLMs can guide the sampling process for preference learning, leading to a substantial improvement in sample efficiency. We demonstrate that LGPL can quickly learn accurate and expressive behaviors with as few as four queries, outperforming both purely language-parameterized models and traditional preference learning approaches. Website with videos: https://lgpl-gaits.github.io/",
        "tags": [
            "LLMs",
            "Robot"
        ]
    },
    {
        "id": "36",
        "title": "MD-BERT: Action Recognition in Dark Videos via Dynamic Multi-Stream Fusion and Temporal Modeling",
        "author": [
            "Sharana Dharshikgan Suresh Dass",
            "Hrishav Bakul Barua",
            "Ganesh Krishnasamy",
            "Raveendran Paramesran",
            "Raphael C.-W. Phan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03724",
        "abstract": "Action recognition in dark, low-light (under-exposed) or noisy videos is a challenging task due to visibility degradation, which can hinder critical spatiotemporal details. This paper proposes MD-BERT, a novel multi-stream approach that integrates complementary pre-processing techniques such as gamma correction and histogram equalization alongside raw dark frames to address these challenges. We introduce the Dynamic Feature Fusion (DFF) module, extending existing attentional fusion methods to a three-stream setting, thereby capturing fine-grained and global contextual information across different brightness and contrast enhancements. The fused spatiotemporal features are then processed by a BERT-based temporal model, which leverages its bidirectional self-attention to effectively capture long-range dependencies and contextual relationships across frames. Extensive experiments on the ARID V1.0 and ARID V1.5 dark video datasets show that MD-BERT outperforms existing methods, establishing a new state-of-the-art performance. Ablation studies further highlight the individual contributions of each input stream and the effectiveness of the proposed DFF and BERT modules. The official website of this work is available at: https://github.com/HrishavBakulBarua/DarkBERT",
        "tags": [
            "BERT"
        ]
    },
    {
        "id": "37",
        "title": "DICE: Distilling Classifier-Free Guidance into Text Embeddings",
        "author": [
            "Zhenyu Zhou",
            "Defang Chen",
            "Can Wang",
            "Chun Chen",
            "Siwei Lyu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03726",
        "abstract": "Text-to-image diffusion models are capable of generating high-quality images, but these images often fail to align closely with the given text prompts. Classifier-free guidance (CFG) is a popular and effective technique for improving text-image alignment in the generative process. However, using CFG introduces significant computational overhead and deviates from the established theoretical foundations of diffusion models. In this paper, we present DIstilling CFG by enhancing text Embeddings (DICE), a novel approach that removes the reliance on CFG in the generative process while maintaining the benefits it provides. DICE distills a CFG-based text-to-image diffusion model into a CFG-free version by refining text embeddings to replicate CFG-based directions. In this way, we avoid the computational and theoretical drawbacks of CFG, enabling high-quality, well-aligned image generation at a fast sampling speed. Extensive experiments on multiple Stable Diffusion v1.5 variants, SDXL and PixArt-$\\alpha$ demonstrate the effectiveness of our method. Furthermore, DICE supports negative prompts for image editing to improve image quality further. Code will be available soon.",
        "tags": [
            "Diffusion",
            "Image Editing",
            "SDXL",
            "Text-to-Image"
        ]
    },
    {
        "id": "38",
        "title": "Scaling Laws in Patchification: An Image Is Worth 50,176 Tokens And More",
        "author": [
            "Feng Wang",
            "Yaodong Yu",
            "Guoyizhe Wei",
            "Wei Shao",
            "Yuyin Zhou",
            "Alan Yuille",
            "Cihang Xie"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03738",
        "abstract": "Since the introduction of Vision Transformer (ViT), patchification has long been regarded as a de facto image tokenization approach for plain visual architectures. By compressing the spatial size of images, this approach can effectively shorten the token sequence and reduce the computational cost of ViT-like plain architectures. In this work, we aim to thoroughly examine the information loss caused by this patchification-based compressive encoding paradigm and how it affects visual understanding. We conduct extensive patch size scaling experiments and excitedly observe an intriguing scaling law in patchification: the models can consistently benefit from decreased patch sizes and attain improved predictive performance, until it reaches the minimum patch size of 1x1, i.e., pixel tokenization. This conclusion is broadly applicable across different vision tasks, various input scales, and diverse architectures such as ViT and the recent Mamba models. Moreover, as a by-product, we discover that with smaller patches, task-specific decoder heads become less critical for dense prediction. In the experiments, we successfully scale up the visual sequence to an exceptional length of 50,176 tokens, achieving a competitive test accuracy of 84.6% with a base-sized model on the ImageNet-1k benchmark. We hope this study can provide insights and theoretical foundations for future works of building non-compressive vision models. Code is available at https://github.com/wangf3014/Patch_Scaling.",
        "tags": [
            "Mamba",
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "39",
        "title": "Multiple Invertible and Partial-Equivariant Function for Latent Vector Transformation to Enhance Disentanglement in VAEs",
        "author": [
            "Hee-Jun Jung",
            "Jaehyoung Jeong",
            "Kangil Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03740",
        "abstract": "Disentanglement learning is a core issue for understanding and re-using trained information in Variational AutoEncoder (VAE), and effective inductive bias has been reported as a key factor. However, the actual implementation of such bias is still vague. In this paper, we propose a novel method, called Multiple Invertible and partial-equivariant transformation (MIPE-transformation), to inject inductive bias by 1) guaranteeing the invertibility of latent-to-latent vector transformation while preserving a certain portion of equivariance of input-to-latent vector transformation, called Invertible and partial-equivariant transformation (IPE-transformation), 2) extending the form of prior and posterior in VAE frameworks to an unrestricted form through a learnable conversion to an approximated exponential family, called Exponential Family conversion (EF-conversion), and 3) integrating multiple units of IPE-transformation and EF-conversion, and their training. In experiments on 3D Cars, 3D Shapes, and dSprites datasets, MIPE-transformation improves the disentanglement performance of state-of-the-art VAEs.",
        "tags": [
            "3D",
            "VAE"
        ]
    },
    {
        "id": "40",
        "title": "Rethinking the Residual Distribution of Locate-then-Editing Methods in Model Editing",
        "author": [
            "Xiaopeng Li",
            "Shanwen Wang",
            "Shasha Li",
            "Shezheng Song",
            "Bin Ji",
            "Jun Ma",
            "Jie Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03748",
        "abstract": "Model editing is a powerful technique for updating the knowledge of Large Language Models (LLMs). Locate-then-edit methods are a popular class of approaches that first identify the critical layers storing knowledge, then compute the residual of the last critical layer based on the edited knowledge, and finally perform multi-layer updates using a least-squares solution by evenly distributing the residual from the first critical layer to the last. Although these methods achieve promising results, they have been shown to degrade the original knowledge of LLMs. We argue that residual distribution leads to this issue. To explore this, we conduct a comprehensive analysis of residual distribution in locate-then-edit methods from both empirical and theoretical perspectives, revealing that residual distribution introduces editing errors, leading to inaccurate edits. To address this issue, we propose the Boundary Layer UpdatE (BLUE) strategy to enhance locate-then-edit methods. Sequential batch editing experiments on three LLMs and two datasets demonstrate that BLUE not only delivers an average performance improvement of 35.59\\%, significantly advancing the state of the art in model editing, but also enhances the preservation of LLMs' general capabilities. Our code is available at https://github.com/xpq-tech/BLUE.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "41",
        "title": "Systolic Sparse Tensor Slices: FPGA Building Blocks for Sparse and Dense AI Acceleration",
        "author": [
            "Endri Taka",
            "Ning-Chi Huang",
            "Chi-Chih Chang",
            "Kai-Chiang Wu",
            "Aman Arora",
            "Diana Marculescu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03763",
        "abstract": "FPGA architectures have recently been enhanced to meet the substantial computational demands of modern deep neural networks (DNNs). To this end, both FPGA vendors and academic researchers have proposed in-fabric blocks that perform efficient tensor computations. However, these blocks are primarily optimized for dense computation, while most DNNs exhibit sparsity. To address this limitation, we propose incorporating structured sparsity support into FPGA architectures. We architect 2D systolic in-fabric blocks, named systolic sparse tensor (SST) slices, that support multiple degrees of sparsity to efficiently accelerate a wide variety of DNNs. SSTs support dense operation, 2:4 (50%) and 1:4 (75%) sparsity, as well as a new 1:3 (66.7%) sparsity level to further increase flexibility. When demonstrating on general matrix multiplication (GEMM) accelerators, which are the heart of most current DNN accelerators, our sparse SST-based designs attain up to 5x higher FPGA frequency and 10.9x lower area, compared to traditional FPGAs. Moreover, evaluation of the proposed SSTs on state-of-the-art sparse ViT and CNN models exhibits up to 3.52x speedup with minimal area increase of up to 13.3%, compared to dense in-fabric acceleration.",
        "tags": [
            "ViT"
        ]
    },
    {
        "id": "42",
        "title": "Hierarchical Contextual Manifold Alignment for Structuring Latent Representations in Large Language Models",
        "author": [
            "Meiquan Dong",
            "Haoran Liu",
            "Yan Huang",
            "Zixuan Feng",
            "Jianhong Tang",
            "Ruoxi Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03766",
        "abstract": "The organization of latent token representations plays a crucial role in determining the stability, generalization, and contextual consistency of language models, yet conventional approaches to embedding refinement often rely on parameter modifications that introduce additional computational overhead. A hierarchical alignment method was introduced to restructure token embeddings without altering core model weights, ensuring that representational distributions maintained coherence across different linguistic contexts. Experimental evaluations demonstrated improvements in rare token retrieval, adversarial robustness, and long-range dependency tracking, highlighting the advantages of hierarchical structuring in mitigating inconsistencies in latent space organization. The comparative analysis against conventional fine-tuning and embedding perturbation methods revealed that hierarchical restructuring maintained computational efficiency while achieving measurable gains in representation quality. Structural refinements introduced through the alignment process resulted in improved contextual stability across varied linguistic tasks, reducing inconsistencies in token proximity relationships and enhancing interpretability in language generation. A detailed computational assessment confirmed that the realignment process introduced minimal inference overhead, ensuring that representational improvements did not compromise model efficiency. The findings reinforced the broader significance of structured representation learning, illustrating that hierarchical embedding modifications could serve as an effective strategy for refining latent space distributions while preserving pre-learned semantic associations.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "43",
        "title": "GistVis: Automatic Generation of Word-scale Visualizations from Data-rich Documents",
        "author": [
            "Ruishi Zou",
            "Yinqi Tang",
            "Jingzhu Chen",
            "Siyu Lu",
            "Yan Lu",
            "Yingfan Yang",
            "Chen Ye"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03784",
        "abstract": "Data-rich documents are ubiquitous in various applications, yet they often rely solely on textual descriptions to convey data insights. Prior research primarily focused on providing visualization-centric augmentation to data-rich documents. However, few have explored using automatically generated word-scale visualizations to enhance the document-centric reading process. As an exploratory step, we propose GistVis, an automatic pipeline that extracts and visualizes data insight from text descriptions. GistVis decomposes the generation process into four modules: Discoverer, Annotator, Extractor, and Visualizer, with the first three modules utilizing the capabilities of large language models and the fourth using visualization design knowledge. Technical evaluation including a comparative study on Discoverer and an ablation study on Annotator reveals decent performance of GistVis. Meanwhile, the user study (N=12) showed that GistVis could generate satisfactory word-scale visualizations, indicating its effectiveness in facilitating users' understanding of data-rich documents (+5.6% accuracy) while significantly reducing their mental demand (p=0.016) and perceived effort (p=0.033).",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "44",
        "title": "Iterate to Accelerate: A Unified Framework for Iterative Reasoning and Feedback Convergence",
        "author": [
            "Jacob Fein-Ashley"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03787",
        "abstract": "We introduce a unified framework for iterative reasoning that leverages non-Euclidean geometry via Bregman divergences, higher-order operator averaging, and adaptive feedback mechanisms. Our analysis establishes that, under mild smoothness and contractivity assumptions, a generalized update scheme not only unifies classical methods such as mirror descent and dynamic programming but also captures modern chain-of-thought reasoning processes in large language models. In particular, we prove that our accelerated iterative update achieves an $O(1/t^2)$ convergence rate in the absence of persistent perturbations, and we further demonstrate that feedback (iterative) architectures are necessary to approximate certain fixed-point functions efficiently. These theoretical insights bridge classical acceleration techniques with contemporary applications in neural computation and optimization.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "45",
        "title": "Frontend Diffusion: Empowering Self-Representation of Junior Researchers and Designers Through Agentic Workflows",
        "author": [
            "Zijian Ding",
            "Qinshi Zhang",
            "Mohan Chi",
            "Ziyi Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03788",
        "abstract": "With the continuous development of generative AI's logical reasoning abilities, AI's growing code-generation potential poses challenges for both technical and creative professionals. But how can these advances be directed toward empowering junior researchers and designers who often require additional help to build and express their professional and personal identities? We present Frontend Diffusion, a multi-stage agentic system, transforms user-drawn layouts and textual prompts into refined website code, thereby supporting self-representation goals. A user study with 13 junior researchers and designers shows AI as a human capability enhancer rather than a replacement, and highlights the importance of bidirectional human-AI alignment. We then discuss future work such as leveraging AI for career development and fostering bidirectional human-AI alignment on the intent level.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "46",
        "title": "It's All in The [MASK]: Simple Instruction-Tuning Enables BERT-like Masked Language Models As Generative Classifiers",
        "author": [
            "Benjamin ClaviÃ©",
            "Nathan Cooper",
            "Benjamin Warner"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03793",
        "abstract": "While encoder-only models such as BERT and ModernBERT are ubiquitous in real-world NLP applications, their conventional reliance on task-specific classification heads can limit their applicability compared to decoder-based large language models (LLMs). In this work, we introduce ModernBERT-Large-Instruct, a 0.4B-parameter encoder model that leverages its masked language modelling (MLM) head for generative classification. Our approach employs an intentionally simple training loop and inference mechanism that requires no heavy pre-processing, heavily engineered prompting, or architectural modifications. ModernBERT-Large-Instruct exhibits strong zero-shot performance on both classification and knowledge-based tasks, outperforming similarly sized LLMs on MMLU and achieving 93% of Llama3-1B's MMLU performance with 60% less parameters. We also demonstrate that, when fine-tuned, the generative approach using the MLM head matches or even surpasses traditional classification-head methods across diverse NLU http://tasks.This capability emerges specifically in models trained on contemporary, diverse data mixes, with models trained on lower volume, less-diverse data yielding considerably weaker performance. Although preliminary, these results demonstrate the potential of using the original generative masked language modelling head over traditional task-specific heads for downstream tasks. Our work suggests that further exploration into this area is warranted, highlighting many avenues for future improvements.",
        "tags": [
            "BERT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "47",
        "title": "Enhancing Hallucination Detection through Noise Injection",
        "author": [
            "Litian Liu",
            "Reza Pourreza",
            "Sunny Panchal",
            "Apratim Bhattacharyya",
            "Yao Qin",
            "Roland Memisevic"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03799",
        "abstract": "Large Language Models (LLMs) are prone to generating plausible yet incorrect responses, known as hallucinations. Effectively detecting hallucinations is therefore crucial for the safe deployment of LLMs. Recent research has linked hallucinations to model uncertainty, suggesting that hallucinations can be detected by measuring dispersion over answer distributions obtained from a set of samples drawn from a model. While drawing from the distribution over tokens defined by the model is a natural way to obtain samples, in this work, we argue that it is sub-optimal for the purpose of detecting hallucinations. We show that detection can be improved significantly by taking into account model uncertainty in the Bayesian sense. To this end, we propose a very simple and efficient approach that perturbs an appropriate subset of model parameters, or equivalently hidden unit activations, during sampling. We demonstrate its effectiveness across a wide range of datasets and model architectures.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "48",
        "title": "Understanding and Supporting Formal Email Exchange by Answering AI-Generated Questions",
        "author": [
            "Yusuke Miura",
            "Chi-Lan Yang",
            "Masaki Kuribayashi",
            "Keigo Matsumoto",
            "Hideaki Kuzuoka",
            "Shigeo Morishima"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03804",
        "abstract": "Replying to formal emails is time-consuming and cognitively demanding, as it requires polite phrasing and ensuring an adequate response to the sender's demands. Although systems with Large Language Models (LLM) were designed to simplify the email replying process, users still needed to provide detailed prompts to obtain the expected output. Therefore, we proposed and evaluated an LLM-powered question-and-answer (QA)-based approach for users to reply to emails by answering a set of simple and short questions generated from the incoming email. We developed a prototype system, ResQ, and conducted controlled and field experiments with 12 and 8 participants. Our results demonstrated that QA-based approach improves the efficiency of replying to emails and reduces workload while maintaining email quality compared to a conventional prompt-based approach that requires users to craft appropriate prompts to obtain email drafts. We discuss how QA-based approach influences the email reply process and interpersonal relationship dynamics, as well as the opportunities and challenges associated with using a QA-based approach in AI-mediated communication.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "49",
        "title": "Identify Critical KV Cache in LLM Inference from an Output Perturbation Perspective",
        "author": [
            "Yuan Feng",
            "Junlin Lv",
            "Yukun Cao",
            "Xike Xie",
            "S Kevin Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03805",
        "abstract": "Large language models have revolutionized natural language processing but face significant challenges of high storage and runtime costs, due to the transformer architecture's reliance on self-attention, particularly the large Key-Value (KV) cache for long-sequence inference. Recent efforts to reduce KV cache size by pruning less critical entries based on attention weights remain empirical and lack formal grounding. This paper presents a formal study on identifying critical KV cache entries by analyzing attention output perturbation. Our analysis reveals that, beyond attention weights, the value states within KV entries and pretrained parameter matrices are also crucial. Based on this, we propose a perturbation-constrained selection algorithm that optimizes the worst-case output perturbation to identify critical entries. Evaluations on the Needle-in-a-Haystack test and Longbench benchmark show our algorithm enhances state-of-the-art cache eviction methods. Further empirical analysis confirms that our algorithm achieves lower output perturbations in over 92% attention heads in Llama model, thereby providing a significant improvement over existing methods.",
        "tags": [
            "LLaMA",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "50",
        "title": "DeblurDiff: Real-World Image Deblurring with Generative Diffusion Models",
        "author": [
            "Lingshun Kong",
            "Jiawei Zhang",
            "Dongqing Zou",
            "Jimmy Ren",
            "Xiaohe Wu",
            "Jiangxin Dong",
            "Jinshan Pan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03810",
        "abstract": "Diffusion models have achieved significant progress in image generation. The pre-trained Stable Diffusion (SD) models are helpful for image deblurring by providing clear image priors. However, directly using a blurry image or pre-deblurred one as a conditional control for SD will either hinder accurate structure extraction or make the results overly dependent on the deblurring network. In this work, we propose a Latent Kernel Prediction Network (LKPN) to achieve robust real-world image deblurring. Specifically, we co-train the LKPN in latent space with conditional diffusion. The LKPN learns a spatially variant kernel to guide the restoration of sharp images in the latent space. By applying element-wise adaptive convolution (EAC), the learned kernel is utilized to adaptively process the input feature, effectively preserving the structural information of the input. This process thereby more effectively guides the generative process of Stable Diffusion (SD), enhancing both the deblurring efficacy and the quality of detail reconstruction. Moreover, the results at each diffusion step are utilized to iteratively estimate the kernels in LKPN to better restore the sharp latent by EAC. This iterative refinement enhances the accuracy and robustness of the deblurring process. Extensive experimental results demonstrate that the proposed method outperforms state-of-the-art image deblurring methods on both benchmark and real-world images.",
        "tags": [
            "Deblurring",
            "Diffusion"
        ]
    },
    {
        "id": "51",
        "title": "Large Language Models for Multi-Robot Systems: A Survey",
        "author": [
            "Peihan Li",
            "Zijian An",
            "Shams Abrar",
            "Lifeng Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03814",
        "abstract": "The rapid advancement of Large Language Models (LLMs) has opened new possibilities in Multi-Robot Systems (MRS), enabling enhanced communication, task planning, and human-robot interaction. Unlike traditional single-robot and multi-agent systems, MRS poses unique challenges, including coordination, scalability, and real-world adaptability. This survey provides the first comprehensive exploration of LLM integration into MRS. It systematically categorizes their applications across high-level task allocation, mid-level motion planning, low-level action generation, and human intervention. We highlight key applications in diverse domains, such as household robotics, construction, formation control, target tracking, and robot games, showcasing the versatility and transformative potential of LLMs in MRS. Furthermore, we examine the challenges that limit adapting LLMs in MRS, including mathematical reasoning limitations, hallucination, latency issues, and the need for robust benchmarking systems. Finally, we outline opportunities for future research, emphasizing advancements in fine-tuning, reasoning techniques, and task-specific models. This survey aims to guide researchers in the intelligence and real-world deployment of MRS powered by LLMs. Based on the fast-evolving nature of research in the field, we keep updating the papers in the open-source Github repository.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Robot",
            "Robotics"
        ]
    },
    {
        "id": "52",
        "title": "PsyPlay: Personality-Infused Role-Playing Conversational Agents",
        "author": [
            "Tao Yang",
            "Yuhua Zhu",
            "Xiaojun Quan",
            "Cong Liu",
            "Qifan Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03821",
        "abstract": "The current research on Role-Playing Conversational Agents (RPCAs) with Large Language Models (LLMs) primarily focuses on imitating specific speaking styles and utilizing character backgrounds, neglecting the depiction of deeper personality traits.~In this study, we introduce personality-infused role-playing for LLM agents, which encourages agents to accurately portray their designated personality traits during dialogues. We then propose PsyPlay, a dialogue generation framework that facilitates the expression of rich personalities among multiple LLM agents. Specifically, PsyPlay enables agents to assume roles with distinct personality traits and engage in discussions centered around specific topics, consistently exhibiting their designated personality traits throughout the interactions. Validation on generated dialogue data demonstrates that PsyPlay can accurately portray the intended personality traits, achieving an overall success rate of 80.31% on GPT-3.5. Notably, we observe that LLMs aligned with positive values are more successful in portraying positive personality roles compared to negative ones. Moreover, we construct a dialogue corpus for personality-infused role-playing, called PsyPlay-Bench. The corpus, which consists of 4745 instances of correctly portrayed dialogues using PsyPlay, aims to further facilitate research in personalized role-playing and dialogue personality detection.",
        "tags": [
            "Detection",
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "53",
        "title": "Dynamic Rank Adjustment in Diffusion Policies for Efficient and Flexible Training",
        "author": [
            "Xiatao Sun",
            "Shuo Yang",
            "Yinxing Chen",
            "Francis Fan",
            "Yiyan",
            "Liang",
            "Daniel Rakita"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03822",
        "abstract": "Diffusion policies trained via offline behavioral cloning have recently gained traction in robotic motion generation. While effective, these policies typically require a large number of trainable parameters. This model size affords powerful representations but also incurs high computational cost during training. Ideally, it would be beneficial to dynamically adjust the trainable portion as needed, balancing representational power with computational efficiency. For example, while overparameterization enables diffusion policies to capture complex robotic behaviors via offline behavioral cloning, the increased computational demand makes online interactive imitation learning impractical due to longer training time. To address this challenge, we present a framework, called DRIFT, that uses the Singular Value Decomposition to enable dynamic rank adjustment during diffusion policy training. We implement and demonstrate the benefits of this framework in DRIFT-DAgger, an imitation learning algorithm that can seamlessly slide between an offline bootstrapping phase and an online interactive phase. We perform extensive experiments to better understand the proposed framework, and demonstrate that DRIFT-DAgger achieves improved sample efficiency and faster training with minimal impact on model performance.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "54",
        "title": "Syntriever: How to Train Your Retriever with Synthetic Data from LLMs",
        "author": [
            "Minsang Kim",
            "Seungjun Baek"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03824",
        "abstract": "LLMs have boosted progress in many AI applications. Recently, there were attempts to distill the vast knowledge of LLMs into information retrieval systems. Those distillation methods mostly use output probabilities of LLMs which are unavailable in the latest black-box LLMs. We propose Syntriever, a training framework for retrievers using synthetic data from black-box LLMs. Syntriever consists of two stages. Firstly in the distillation stage, we synthesize relevant and plausibly irrelevant passages and augmented queries using chain-of-thoughts for the given queries. LLM is asked to self-verify the synthetic data for possible hallucinations, after which retrievers are trained with a loss designed to cluster the embeddings of relevant passages. Secondly in the alignment stage, we align the retriever with the preferences of LLMs. We propose a preference modeling called partial Plackett-Luce ranking to learn LLM preferences with regularization which prevents the model from deviating excessively from that trained in the distillation stage. Experiments show that Syntriever achieves state-of-the-art performances on benchmark datasets from various domains in nDCG@$K$. The code is available at \\href{https://github.com/kmswin1/Syntriever}{https://github.com/kmswin1/Syntriever}.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "55",
        "title": "FairT2I: Mitigating Social Bias in Text-to-Image Generation via Large Language Model-Assisted Detection and Attribute Rebalancing",
        "author": [
            "Jinya Sakurai",
            "Issei Sato"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03826",
        "abstract": "The proliferation of Text-to-Image (T2I) models has revolutionized content creation, providing powerful tools for diverse applications ranging from artistic expression to educational material development and marketing. Despite these technological advancements, significant ethical concerns arise from these models' reliance on large-scale datasets that often contain inherent societal biases. These biases are further amplified when AI-generated content is included in training data, potentially reinforcing and perpetuating stereotypes in the generated outputs. In this paper, we introduce FairT2I, a novel framework that harnesses large language models to detect and mitigate social biases in T2I generation. Our framework comprises two key components: (1) an LLM-based bias detection module that identifies potential social biases in generated images based on text prompts, and (2) an attribute rebalancing module that fine-tunes sensitive attributes within the T2I model to mitigate identified biases. Our extensive experiments across various T2I models and datasets show that FairT2I can significantly reduce bias while maintaining high-quality image generation. We conducted both qualitative user studies and quantitative non-parametric analyses in the generated image feature space, building upon the occupational dataset introduced in the Stable Bias study. Our results show that FairT2I successfully mitigates social biases and enhances the diversity of sensitive attributes in generated images. We further demonstrate, using the P2 dataset, that our framework can detect subtle biases that are challenging for human observers to perceive, extending beyond occupation-related prompts. On the basis of these findings, we introduce a new benchmark dataset for evaluating bias in T2I models.",
        "tags": [
            "Detection",
            "Large Language Models",
            "Text-to-Image"
        ]
    },
    {
        "id": "56",
        "title": "FE-UNet: Frequency Domain Enhanced U-Net with Segment Anything Capability for Versatile Image Segmentation",
        "author": [
            "Guohao Huo",
            "Ruiting Dai",
            "Ling Shao",
            "Hao Tang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03829",
        "abstract": "Image segmentation is a critical task in visual understanding. Convolutional Neural Networks (CNNs) are predisposed to capture high-frequency features in images, while Transformers exhibit a contrasting focus on low-frequency features. In this paper, we experimentally quantify the contrast sensitivity function of CNNs and compare it with that of the human visual system, informed by the seminal experiments of Mannos and Sakrison. Leveraging these insights, we propose the Wavelet-Guided Spectral Pooling Module (WSPM) to enhance and balance image features across the frequency domain. To further emulate the human visual system, we introduce the Frequency Domain Enhanced Receptive Field Block (FE-RFB), which integrates WSPM to extract enriched features from the frequency domain. Building on these innovations, we develop FE-UNet, a model that utilizes SAM2 as its backbone and incorporates Hiera-Large as a pre-trained block, designed to enhance generalization capabilities while ensuring high segmentation accuracy. Experimental results demonstrate that FE-UNet achieves state-of-the-art performance in diverse tasks, including marine animal and polyp segmentation, underscoring its versatility and effectiveness.",
        "tags": [
            "Segment Anything",
            "Segmentation"
        ]
    },
    {
        "id": "57",
        "title": "Adapting Human Mesh Recovery with Vision-Language Feedback",
        "author": [
            "Chongyang Xu",
            "Buzhen Huang",
            "Chengfang Zhang",
            "Ziliang Feng",
            "Yangang Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03836",
        "abstract": "Human mesh recovery can be approached using either regression-based or optimization-based methods. Regression models achieve high pose accuracy but struggle with model-to-image alignment due to the lack of explicit 2D-3D correspondences. In contrast, optimization-based methods align 3D models to 2D observations but are prone to local minima and depth ambiguity. In this work, we leverage large vision-language models (VLMs) to generate interactive body part descriptions, which serve as implicit constraints to enhance 3D perception and limit the optimization space. Specifically, we formulate monocular human mesh recovery as a distribution adaptation task by integrating both 2D observations and language descriptions. To bridge the gap between text and 3D pose signals, we first train a text encoder and a pose VQ-VAE, aligning texts to body poses in a shared latent space using contrastive learning. Subsequently, we employ a diffusion-based framework to refine the initial parameters guided by gradients derived from both 2D observations and text descriptions. Finally, the model can produce poses with accurate 3D perception and image consistency. Experimental results on multiple benchmarks validate its effectiveness. The code will be made publicly available.",
        "tags": [
            "3D",
            "Diffusion",
            "VAE"
        ]
    },
    {
        "id": "58",
        "title": "Improving Natural Language Understanding for LLMs via Large-Scale Instruction Synthesis",
        "author": [
            "Lin Yuan",
            "Jun Xu",
            "Honghao Gui",
            "Mengshu Sun",
            "Zhiqiang Zhang",
            "Lei Liang",
            "Jun Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03843",
        "abstract": "High-quality, large-scale instructions are crucial for aligning large language models (LLMs), however, there is a severe shortage of instruction in the field of natural language understanding (NLU). Previous works on constructing NLU instructions mainly focus on information extraction (IE), neglecting tasks such as machine reading comprehension, question answering, and text classification. Furthermore, the lack of diversity in the data has led to a decreased generalization ability of trained LLMs in other NLU tasks and a noticeable decline in the fundamental model's general capabilities. To address this issue, we propose Hum, a large-scale, high-quality synthetic instruction corpus for NLU tasks, designed to enhance the NLU capabilities of LLMs. Specifically, Hum includes IE (either close IE or open IE), machine reading comprehension, text classification, and instruction generalist tasks, thereby enriching task diversity. Additionally, we introduce a human-LLMs collaborative mechanism to synthesize instructions, which enriches instruction diversity by incorporating guidelines, preference rules, and format variants. We conduct extensive experiments on 5 NLU tasks and 28 general capability evaluation datasets for LLMs. Experimental results show that Hum enhances the NLU capabilities of six LLMs by an average of 3.1\\%, with no significant decline observed in other general capabilities.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "59",
        "title": "BOLT: Bootstrap Long Chain-of-Thought in Language Models without Distillation",
        "author": [
            "Bo Pang",
            "Hanze Dong",
            "Jiacheng Xu",
            "Silvio Savarese",
            "Yingbo Zhou",
            "Caiming Xiong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03860",
        "abstract": "Large language models (LLMs), such as o1 from OpenAI, have demonstrated remarkable reasoning capabilities. o1 generates a long chain-of-thought (LongCoT) before answering a question. LongCoT allows LLMs to analyze problems, devise plans, reflect, and backtrack effectively. These actions empower LLM to solve complex problems. After the release of o1, many teams have attempted to replicate its LongCoT and reasoning capabilities. In terms of methods, they primarily rely on knowledge distillation with data from existing models with LongCoT capacities (e.g., OpenAI-o1, Qwen-QwQ, DeepSeek-R1-Preview), leaving significant uncertainties on systematically developing such reasoning abilities. In terms of data domains, these works focus narrowly on math while a few others include coding, limiting their generalizability. This paper introduces a novel approach to enable LLM's LongCoT capacity without distillation from o1-like models or expensive human annotations, where we bootstrap LongCoT (BOLT) from a standard instruct model. BOLT involves three stages: 1) LongCoT data bootstrapping with in-context learning on a standard instruct model; 2) LongCoT supervised finetuning; 3) online training to further refine LongCoT capacities. In BOLT, only a few in-context examples need to be constructed during the bootstrapping stage; in our experiments, we created 10 examples, demonstrating the feasibility of this approach. We use Llama-3.1-70B-Instruct to bootstrap LongCoT and apply our method to various model scales (7B, 8B, 70B). We achieve impressive performance on a variety of benchmarks, Arena-Hard, MT-Bench, WildBench, ZebraLogic, MATH500, which evaluate diverse task-solving and reasoning capabilities.",
        "tags": [
            "DeepSeek",
            "LLMs",
            "LLaMA",
            "Large Language Models",
            "Qwen"
        ]
    },
    {
        "id": "60",
        "title": "Rank Also Matters: Hierarchical Configuration for Mixture of Adapter Experts in LLM Fine-Tuning",
        "author": [
            "Peizhuang Cong",
            "Wenpu Liu",
            "Wenhan Yu",
            "Haochen Zhao",
            "Tong Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03884",
        "abstract": "Large language models (LLMs) have demonstrated remarkable success across various tasks, accompanied by a continuous increase in their parameter size. Parameter-efficient fine-tuning (PEFT) methods, such as Low-Rank Adaptation (LoRA), address the challenges of fine-tuning LLMs by significantly reducing the number of trainable parameters. Recent studies have integrated LoRA with Mixture of Experts (MoE) architectures, leveraging multiple adapter experts and gating mechanisms to further improve fine-tuning performance. However, existing approaches primarily focus on adjusting the allocations of adapter experts per layer to optimize the introduced trainable parameter size, while neglecting a critical factor of adapters' rank. To this end, we propose a hierarchical scheme for expert allocation and rank configuration, HILO, which dynamically adjusts the number and rank of adapter experts across layers, matching the varying representational complexity of model layers in adapter-granularity. Extensive experiments on multiple benchmark tasks demonstrate that HILO outperforms existing methods in accuracy while introducing fewer trainable parameters, providing an efficient and practical solution for fine-tuning LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "LoRA",
            "Low-Rank Adaptation"
        ]
    },
    {
        "id": "61",
        "title": "Counterfactual Query Rewriting to Use Historical Relevance Feedback",
        "author": [
            "JÃ¼ri Keller",
            "Maik FrÃ¶be",
            "Gijs Hendriksen",
            "Daria Alexander",
            "Martin Potthast",
            "Matthias Hagen",
            "Philipp Schaer"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03891",
        "abstract": "When a retrieval system receives a query it has encountered before, previous relevance feedback, such as clicks or explicit judgments can help to improve retrieval results. However, the content of a previously relevant document may have changed, or the document might not be available anymore. Despite this evolved corpus, we counterfactually use these previously relevant documents as relevance signals. In this paper we proposed approaches to rewrite user queries and compare them against a system that directly uses the previous qrels for the ranking. We expand queries with terms extracted from the previously relevant documents or derive so-called keyqueries that rank the previously relevant documents to the top of the current corpus. Our evaluation in the CLEF LongEval scenario shows that rewriting queries with historical relevance feedback improves the retrieval effectiveness and even outperforms computationally expensive transformer-based approaches.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "62",
        "title": "UniForm: A Unified Diffusion Transformer for Audio-Video Generation",
        "author": [
            "Lei Zhao",
            "Linfeng Feng",
            "Dongxu Ge",
            "Fangqiu Yi",
            "Chi Zhang",
            "Xiao-Lei Zhang",
            "Xuelong Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03897",
        "abstract": "As a natural multimodal content, audible video delivers an immersive sensory experience. Consequently, audio-video generation systems have substantial potential. However, existing diffusion-based studies mainly employ relatively independent modules for generating each modality, which lack exploration of shared-weight generative modules. This approach may under-use the intrinsic correlations between audio and visual modalities, potentially resulting in sub-optimal generation quality. To address this, we propose UniForm, a unified diffusion transformer designed to enhance cross-modal consistency. By concatenating auditory and visual information, UniForm learns to generate audio and video simultaneously within a unified latent space, facilitating the creation of high-quality and well-aligned audio-visual pairs. Extensive experiments demonstrate the superior performance of our method in joint audio-video generation, audio-guided video generation, and video-guided audio generation tasks. Our demos are available at https://uniform-t2av.github.io/.",
        "tags": [
            "Diffusion",
            "Diffusion Transformer",
            "Transformer",
            "Video Generation"
        ]
    },
    {
        "id": "63",
        "title": "Experiments with Large Language Models on Retrieval-Augmented Generation for Closed-Source Simulation Software",
        "author": [
            "Andreas Baumann",
            "Peter Eberhard"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03916",
        "abstract": "Large Language Models (LLMs) are increasingly helpful in text generation, even writing code in programming languages based on user prompts written in natural language. They are even applied to generate simulation models for multibody systems from natural language. Research results suggest that LLMs surpass the mere replication of existing code examples, where some LLMs have been trained on an open-source multibody simulation code. However, for closed-source simulation software, such results are not to be expected as their ideas and concepts might differ from other publicly available ones. LLMs can hallucinate for knowledge-intensive tasks, such as model creation, which can lead to wrong responses. This is especially the case for the LLM unknown closed-source simulation software. The same applies to other internal knowledge kept private to protect intellectual property or data privacy. The Retrieval-Augmented Generation (RAG) approach might yield a solution for these knowledge-intensive tasks. This paper explores the application of RAG to closed-source simulation software and presents first experiments. After a brief introduction to LLMs, the RAG approach, and the simulation method applied by the close-source simulation software, several examples are provided to test LLMs' knowledge of the simulation software and the creation of simulation models using two RAG systems. The examples show promising results indicating the benefits of applying RAG systems to closed-source simulation software, helping to access their knowledge. Nevertheless, they also reveal gaps in the applied information and open questions for further research.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "64",
        "title": "HEP-JEPA: A foundation model for collider physics using joint embedding predictive architecture",
        "author": [
            "Jai Bardhan",
            "Radhikesh Agrawal",
            "Abhiram Tilak",
            "Cyrin Neeraj",
            "Subhadip Mitra"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03933",
        "abstract": "We present a transformer architecture-based foundation model for tasks at high-energy particle colliders such as the Large Hadron Collider. We train the model to classify jets using a self-supervised strategy inspired by the Joint Embedding Predictive Architecture. We use the JetClass dataset containing 100M jets of various known particles to pre-train the model with a data-centric approach -- the model uses a fraction of the jet constituents as the context to predict the embeddings of the unseen target constituents. Our pre-trained model fares well with other datasets for standard classification benchmark tasks. We test our model on two additional downstream tasks: top tagging and differentiating light-quark jets from gluon jets. We also evaluate our model with task-specific metrics and baselines and compare it with state-of-the-art models in high-energy physics. Project site: https://hep-jepa.github.io/",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "65",
        "title": "MAQInstruct: Instruction-based Unified Event Relation Extraction",
        "author": [
            "Jun Xu",
            "Mengshu Sun",
            "Zhiqiang Zhang",
            "Jun Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03954",
        "abstract": "Extracting event relations that deviate from known schemas has proven challenging for previous methods based on multi-class classification, MASK prediction, or prototype matching. Recent advancements in large language models have shown impressive performance through instruction tuning. Nevertheless, in the task of event relation extraction, instruction-based methods face several challenges: there are a vast number of inference samples, and the relations between events are non-sequential. To tackle these challenges, we present an improved instruction-based event relation extraction framework named MAQInstruct. Firstly, we transform the task from extracting event relations using given event-event instructions to selecting events using given event-relation instructions, which reduces the number of samples required for inference. Then, by incorporating a bipartite matching loss, we reduce the dependency of the instruction-based method on the generation sequence. Our experimental results demonstrate that MAQInstruct significantly improves the performance of event relation extraction across multiple LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "66",
        "title": "MultiFloodSynth: Multi-Annotated Flood Synthetic Dataset Generation",
        "author": [
            "YoonJe Kang",
            "Yonghoon Jung",
            "Wonseop Shin",
            "Bumsoo Kim",
            "Sanghyun Seo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03966",
        "abstract": "In this paper, we present synthetic data generation framework for flood hazard detection system. For high fidelity and quality, we characterize several real-world properties into virtual world and simulate the flood situation by controlling them. For the sake of efficiency, recent generative models in image-to-3D and urban city synthesis are leveraged to easily composite flood environments so that we avoid data bias due to the hand-crafted manner. Based on our framework, we build the flood synthetic dataset with 5 levels, dubbed MultiFloodSynth which contains rich annotation types like normal map, segmentation, 3D bounding box for a variety of downstream task. In experiments, our dataset demonstrate the enhanced performance of flood hazard detection with on-par realism compared with real dataset.",
        "tags": [
            "3D",
            "Detection",
            "Image-to-3D",
            "Segmentation"
        ]
    },
    {
        "id": "67",
        "title": "RWKV-UI: UI Understanding with Enhanced Perception and Reasoning",
        "author": [
            "Jiaxi Yang",
            "Haowen Hou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03971",
        "abstract": "Existing Visual Language Modelsoften struggle with information loss and limited reasoning abilities when handling high-resolution web interfaces that combine complex visual, textual, and interactive elements. These challenges are particularly evident in tasks requiring webpage layout comprehension and multi-step interactive reasoning. To address these challenges, we propose RWKV-UI, a Visual Language Model based on the RWKV architecture, specifically designed to handle high-resolution UI images. During model training, we introduce layout detection as a visual prompt to help the model better understand the webpage layout structures. Additionally, we design a visual prompt based on the Chain-of-Thought(CoT) mechanism, which enhances the model's ability to understand and reason about webpage content through reasoning chains. Experimental results show that RWKV-UI demonstrates significant performance improvements in high-resolution UI understanding and interactive reasoning tasks.",
        "tags": [
            "Detection",
            "RWKV"
        ]
    },
    {
        "id": "68",
        "title": "PGB: One-Shot Pruning for BERT via Weight Grouping and Permutation",
        "author": [
            "Hyemin Lim",
            "Jaeyeon Lee",
            "Dong-Wan Choi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03984",
        "abstract": "Large pretrained language models such as BERT suffer from slow inference and high memory usage, due to their huge size. Recent approaches to compressing BERT rely on iterative pruning and knowledge distillation, which, however, are often too complicated and computationally intensive. This paper proposes a novel semi-structured one-shot pruning method for BERT, called $\\textit{Permutation and Grouping for BERT}$ (PGB), which achieves high compression efficiency and sparsity while preserving accuracy. To this end, PGB identifies important groups of individual weights by permutation and prunes all other weights as a structure in both multi-head attention and feed-forward layers. Furthermore, if no important group is formed in a particular layer, PGB drops the entire layer to produce an even more compact model. Our experimental results on BERT$_{\\text{BASE}}$ demonstrate that PGB outperforms the state-of-the-art structured pruning methods in terms of computational cost and accuracy preservation.",
        "tags": [
            "BERT"
        ]
    },
    {
        "id": "69",
        "title": "CAD-Editor: A Locate-then-Infill Framework with Automated Training Data Synthesis for Text-Based CAD Editing",
        "author": [
            "Yu Yuan",
            "Shizhao Sun",
            "Qi Liu",
            "Jiang Bian"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03997",
        "abstract": "Computer Aided Design (CAD) is indispensable across various industries. \\emph{Text-based CAD editing}, which automates the modification of CAD models based on textual instructions, holds great potential but remains underexplored. Existing methods primarily focus on design variation generation or text-based CAD generation, either lacking support for text-based control or neglecting existing CAD models as constraints. We introduce \\emph{CAD-Editor}, the first framework for text-based CAD editing. To address the challenge of demanding triplet data with accurate correspondence for training, we propose an automated data synthesis pipeline. This pipeline utilizes design variation models to generate pairs of original and edited CAD models and employs Large Vision-Language Models (LVLMs) to summarize their differences into editing instructions. To tackle the composite nature of text-based CAD editing, we propose a locate-then-infill framework that decomposes the task into two focused sub-tasks: locating regions requiring modification and infilling these regions with appropriate edits. Large Language Models (LLMs) serve as the backbone for both sub-tasks, leveraging their capabilities in natural language understanding and CAD knowledge. Experiments show that CAD-Editor achieves superior performance both quantitatively and qualitatively.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "70",
        "title": "Automating a Complete Software Test Process Using LLMs: An Automotive Case Study",
        "author": [
            "Shuai Wang",
            "Yinan Yu",
            "Robert Feldt",
            "Dhasarathy Parthasarathy"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04008",
        "abstract": "Vehicle API testing verifies whether the interactions between a vehicle's internal systems and external applications meet expectations, ensuring that users can access and control various vehicle functions and data. However, this task is inherently complex, requiring the alignment and coordination of API systems, communication protocols, and even vehicle simulation systems to develop valid test cases. In practical industrial scenarios, inconsistencies, ambiguities, and interdependencies across various documents and system specifications pose significant challenges. This paper presents a system designed for the automated testing of in-vehicle APIs. By clearly defining and segmenting the testing process, we enable Large Language Models (LLMs) to focus on specific tasks, ensuring a stable and controlled testing workflow. Experiments conducted on over 100 APIs demonstrate that our system effectively automates vehicle API testing. The results also confirm that LLMs can efficiently handle mundane tasks requiring human judgment, making them suitable for complete automation in similar industrial contexts.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "71",
        "title": "PINT: Physics-Informed Neural Time Series Models with Applications to Long-term Inference on WeatherBench 2m-Temperature Data",
        "author": [
            "Keon Vin Park",
            "Jisu Kim",
            "Jaemin Seo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04018",
        "abstract": "This paper introduces PINT (Physics-Informed Neural Time Series Models), a framework that integrates physical constraints into neural time series models to improve their ability to capture complex dynamics. We apply PINT to the ERA5 WeatherBench dataset, focusing on long-term forecasting of 2m-temperature data. PINT incorporates the Simple Harmonic Oscillator Equation as a physics-informed prior, embedding its periodic dynamics into RNN, LSTM, and GRU architectures. This equation's analytical solutions (sine and cosine functions) facilitate rigorous evaluation of the benefits of incorporating physics-informed constraints. By benchmarking against a linear regression baseline derived from its exact solutions, we quantify the impact of embedding physical principles in data-driven models. Unlike traditional time series models that rely on future observations, PINT is designed for practical forecasting. Using only the first 90 days of observed data, it iteratively predicts the next two years, addressing challenges posed by limited real-time updates. Experiments on the WeatherBench dataset demonstrate PINT's ability to generalize, capture periodic trends, and align with physical principles. This study highlights the potential of physics-informed neural models in bridging machine learning and interpretable climate applications.\nOur models and datasets are publicly available on GitHub: https://github.com/KV-Park.",
        "tags": [
            "RNN"
        ]
    },
    {
        "id": "72",
        "title": "Quantification of Biodiversity from Historical Survey Text with LLM-based Best-Worst Scaling",
        "author": [
            "Thomas Haider",
            "Tobias Perschl",
            "Malte Rehbein"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04022",
        "abstract": "In this study, we evaluate methods to determine the frequency of species via quantity estimation from historical survey text. To that end, we formulate classification tasks and finally show that this problem can be adequately framed as a regression task using Best-Worst Scaling (BWS) with Large Language Models (LLMs). We test Ministral-8B, DeepSeek-V3, and GPT-4, finding that the latter two have reasonable agreement with humans and each other. We conclude that this approach is more cost-effective and similarly robust compared to a fine-grained multi-class approach, allowing automated quantity estimation across species.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "73",
        "title": "Fine, I'll Merge It Myself: A Multi-Fidelity Framework for Automated Model Merging",
        "author": [
            "Guinan Su",
            "Jonas Geiping"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04030",
        "abstract": "Reasoning capabilities represent a critical frontier for large language models (LLMs), but developing them requires extensive proprietary datasets and computational resources. One way to efficiently supplement capabilities with is by model merging, which offers a promising alternative by combining multiple models without retraining. However, current merging approaches rely on manually-designed strategies for merging hyperparameters, limiting the exploration of potential model combinations and requiring significant human effort. We propose an Automated Model Merging Framework that enables fine-grained exploration of merging strategies while reducing costs through multi-fidelity approximations. We support both single and multi-objective optimization and introduce two novel search spaces: layerwise fusion (LFS) and depth-wise integration (DIS). Evaluating across a number of benchmarks, we find that the search autonomously finds 1) Merges that further boost single-objective performance, even on tasks the model has already been finetuned on, and 2) Merges that optimize multi-objective frontiers across tasks. Effective merges are found with limited compute, e.g. within less than 500 search steps.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "74",
        "title": "Exploring Imbalanced Annotations for Effective In-Context Learning",
        "author": [
            "Hongfu Gao",
            "Feipeng Zhang",
            "Hao Zeng",
            "Deyu Meng",
            "Bingyi Jing",
            "Hongxin Wei"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04037",
        "abstract": "Large language models (LLMs) have shown impressive performance on downstream tasks through in-context learning (ICL), which heavily relies on the demonstrations selected from annotated datasets. Existing selection methods may hinge on the distribution of annotated datasets, which can often be long-tailed in real-world scenarios. In this work, we show that imbalanced class distributions in annotated datasets significantly degrade the performance of ICL across various tasks and selection methods. Moreover, traditional rebalance methods fail to ameliorate the issue of class imbalance in ICL. Our method is motivated by decomposing the distributional differences between annotated and test datasets into two-component weights: class-wise weights and conditional bias. The key idea behind our method is to estimate the conditional bias by minimizing the empirical error on a balanced validation dataset and to employ the two-component weights to modify the original scoring functions during selection. Our approach can prevent selecting too many demonstrations from a single class while preserving the effectiveness of the original selection methods. Extensive experiments demonstrate the effectiveness of our method, improving the average accuracy by up to 5.46 on common benchmarks with imbalanced datasets.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "75",
        "title": "Leveraging Reasoning with Guidelines to Elicit and Utilize Knowledge for Enhancing Safety Alignment",
        "author": [
            "Haoyu Wang",
            "Zeyu Qin",
            "Li Shen",
            "Xueqian Wang",
            "Minhao Cheng",
            "Dacheng Tao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04040",
        "abstract": "Training safe LLMs is one of the most critical research challenge. However, the commonly used method, Refusal Training (RT), struggles to generalize against various OOD jailbreaking attacks. Many safety training methods have been proposed to address this issue. While they offer valuable insights, we aim to complement this line of research by investigating whether OOD attacks truly exceed the capability of RT model. Conducting evaluation with BoN, we observe significant improvements on generalization as N increases. This underscores that the model possesses sufficient safety-related latent knowledge, but RT fails to consistently elicit this knowledge when addressing OOD attacks. Further analysis based on domain adaptation reveals that training with direct refusal causes model to rely on superficial shortcuts, resulting in learning of non-robust representation mappings. Based on our findings, we propose training model to perform safety reasoning for each query. Reasoning supervision encourages model to perform more computations, explicitly eliciting and using latent knowledge through reasoning. To achieve this, we synthesize reasoning supervision based on pre-guidelines, training the model to reason in alignment with them, thereby effectively eliciting and utilizing latent knowledge from diverse perspectives. Extensive experiments show that our method significantly improves generalization performance against OOD attacks.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "76",
        "title": "PartEdit: Fine-Grained Image Editing using Pre-Trained Diffusion Models",
        "author": [
            "Aleksandar Cvejic",
            "Abdelrahman Eldesokey",
            "Peter Wonka"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04050",
        "abstract": "We present the first text-based image editing approach for object parts based on pre-trained diffusion models. Diffusion-based image editing approaches capitalized on the deep understanding of diffusion models of image semantics to perform a variety of edits. However, existing diffusion models lack sufficient understanding of many object parts, hindering fine-grained edits requested by users. To address this, we propose to expand the knowledge of pre-trained diffusion models to allow them to understand various object parts, enabling them to perform fine-grained edits. We achieve this by learning special textual tokens that correspond to different object parts through an efficient token optimization process. These tokens are optimized to produce reliable localization masks at each inference step to localize the editing region. Leveraging these masks, we design feature-blending and adaptive thresholding strategies to execute the edits seamlessly. To evaluate our approach, we establish a benchmark and an evaluation protocol for part editing. Experiments show that our approach outperforms existing editing methods on all metrics and is preferred by users 77-90% of the time in conducted user studies.",
        "tags": [
            "Diffusion",
            "Image Editing"
        ]
    },
    {
        "id": "77",
        "title": "TQ-DiT: Efficient Time-Aware Quantization for Diffusion Transformers",
        "author": [
            "Younghye Hwang",
            "Hyojin Lee",
            "Joonhyuk Kang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04056",
        "abstract": "Diffusion transformers (DiTs) combine transformer architectures with diffusion models. However, their computational complexity imposes significant limitations on real-time applications and sustainability of AI systems. In this study, we aim to enhance the computational efficiency through model quantization, which represents the weights and activation values with lower precision. Multi-region quantization (MRQ) is introduced to address the asymmetric distribution of network values in DiT blocks by allocating two scaling parameters to sub-regions. Additionally, time-grouping quantization (TGQ) is proposed to reduce quantization error caused by temporal variation in activations. The experimental results show that the proposed algorithm achieves performance comparable to the original full-precision model with only a 0.29 increase in FID at W8A8. Furthermore, it outperforms other baselines at W6A6, thereby confirming its suitability for low-bit quantization. These results highlight the potential of our method to enable efficient real-time generative models.",
        "tags": [
            "DiT",
            "Diffusion",
            "Transformer"
        ]
    },
    {
        "id": "78",
        "title": "Predicting Large Language Model Capabilities on Closed-Book QA Tasks Using Only Information Available Prior to Training",
        "author": [
            "Changhao Jiang",
            "Ming Zhang",
            "Junjie Ye",
            "Xiaoran Fan",
            "Yifei Cao",
            "Jiajun Sun",
            "Zhiheng Xi",
            "Shihan Dou",
            "Yi Dong",
            "Yujiong Shen",
            "Jingqi Tong",
            "Zhen Wang",
            "Tao Liang",
            "Zhihui Fei",
            "Mingyang Wan",
            "Guojun Ma",
            "Qi Zhang",
            "Tao Gui",
            "Xuanjing Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04066",
        "abstract": "The GPT-4 technical report from OpenAI suggests that model performance on specific tasks can be predicted prior to training, though methodologies remain unspecified. This approach is crucial for optimizing resource allocation and ensuring data alignment with target tasks. To achieve this vision, we focus on predicting performance on Closed-book Question Answering (CBQA) tasks, which are closely tied to pre-training data and knowledge retention. We address three major challenges: 1) mastering the entire pre-training process, especially data construction; 2) evaluating a model's knowledge retention; and 3) predicting task-specific knowledge retention using only information available prior to training. To tackle these challenges, we pre-train three large language models (i.e., 1.6B, 7B, and 13B) using 560k dollars and 520k GPU hours. We analyze the pre-training data with knowledge triples and assess knowledge retention using established methods. Additionally, we introduce the SMI metric, an information-theoretic measure that quantifies the relationship between pre-training data, model size, and task-specific knowledge retention. Our experiments reveal a strong linear correlation ($\\text{R}^2 > 0.84$) between the SMI metric and the model's accuracy on CBQA tasks across models of varying sizes (i.e., 1.1B, 1.6B, 7B, and 13B). The dataset, model, and code are available at https://github.com/yuhui1038/SMI.",
        "tags": [
            "GPT",
            "Large Language Models"
        ]
    },
    {
        "id": "79",
        "title": "Controllable Emotion Generation with Emotion Vectors",
        "author": [
            "Yurui Dong",
            "Luozhijie Jin",
            "Yao Yang",
            "Bingjie Lu",
            "Jiaxi Yang",
            "Zhi Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04075",
        "abstract": "In recent years, technologies based on large-scale language models (LLMs) have made remarkable progress in many fields, especially in customer service, content creation, and embodied intelligence, showing broad application potential. However, The LLM's ability to express emotions with proper tone, timing, and in both direct and indirect forms is still insufficient but significant. Few works have studied on how to build the controlable emotional expression capability of LLMs. In this work, we propose a method for emotion expression output by LLMs, which is universal, highly flexible, and well controllable proved with the extensive experiments and verifications. This method has broad application prospects in fields involving emotions output by LLMs, such as intelligent customer service, literary creation, and home companion robots. The extensive experiments on various LLMs with different model-scales and architectures prove the versatility and the effectiveness of the proposed method.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "80",
        "title": "Content-Rich AIGC Video Quality Assessment via Intricate Text Alignment and Motion-Aware Consistency",
        "author": [
            "Shangkun Sun",
            "Xiaoyu Liang",
            "Bowen Qu",
            "Wei Gao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04076",
        "abstract": "The advent of next-generation video generation models like \\textit{Sora} poses challenges for AI-generated content (AIGC) video quality assessment (VQA). These models substantially mitigate flickering artifacts prevalent in prior models, enable longer and complex text prompts and generate longer videos with intricate, diverse motion patterns. Conventional VQA methods designed for simple text and basic motion patterns struggle to evaluate these content-rich videos. To this end, we propose \\textbf{CRAVE} (\\underline{C}ontent-\\underline{R}ich \\underline{A}IGC \\underline{V}ideo \\underline{E}valuator), specifically for the evaluation of Sora-era AIGC videos. CRAVE proposes the multi-granularity text-temporal fusion that aligns long-form complex textual semantics with video dynamics. Additionally, CRAVE leverages the hybrid motion-fidelity modeling to assess temporal artifacts. Furthermore, given the straightforward prompts and content in current AIGC VQA datasets, we introduce \\textbf{CRAVE-DB}, a benchmark featuring content-rich videos from next-generation models paired with elaborate prompts. Extensive experiments have shown that the proposed CRAVE achieves excellent results on multiple AIGC VQA benchmarks, demonstrating a high degree of alignment with human perception. All data and code will be publicly available at https://github.com/littlespray/CRAVE.",
        "tags": [
            "Sora",
            "Video Generation"
        ]
    },
    {
        "id": "81",
        "title": "AttentionPredictor: Temporal Pattern Matters for Efficient LLM Inference",
        "author": [
            "Qingyue Yang",
            "Jie Wang",
            "Xing Li",
            "Zhihai Wang",
            "Chen Chen",
            "Lei Chen",
            "Xianzhi Yu",
            "Wulong Liu",
            "Jianye Hao",
            "Mingxuan Yuan",
            "Bin Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04077",
        "abstract": "With the development of large language models (LLMs), efficient inference through Key-Value (KV) cache compression has attracted considerable attention, especially for long-context generation. To compress the KV cache, recent methods identify critical KV tokens through heuristic ranking with attention scores. However, these methods often struggle to accurately determine critical tokens as they neglect the \\textit{temporal patterns} in attention scores, resulting in a noticeable degradation in LLM performance. To address this challenge, we propose AttentionPredictor, which is the first learning-based critical token identification approach. Specifically, AttentionPredictor learns a lightweight convolution model to capture spatiotemporal patterns and predict the next-token attention score. An appealing feature of AttentionPredictor is that it accurately predicts the attention score while consuming negligible memory. Moreover, we propose a cross-token critical cache prefetching framework that hides the token estimation time overhead to accelerate the decoding stage. By retaining most of the attention information, AttentionPredictor achieves 16$\\times$ KV cache compression with comparable LLM performance, significantly outperforming the state-of-the-art.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "82",
        "title": "LLMs to Support a Domain Specific Knowledge Assistant",
        "author": [
            "Maria-Flavia Lovin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04095",
        "abstract": "This work presents a custom approach to developing a domain specific knowledge assistant for sustainability reporting using the International Financial Reporting Standards (IFRS). In this domain, there is no publicly available question-answer dataset, which has impeded the development of a high-quality chatbot to support companies with IFRS reporting. The two key contributions of this project therefore are:\n(1) A high-quality synthetic question-answer (QA) dataset based on IFRS sustainability standards, created using a novel generation and evaluation pipeline leveraging Large Language Models (LLMs). This comprises 1,063 diverse QA pairs that address a wide spectrum of potential user queries in sustainability reporting. Various LLM-based techniques are employed to create the dataset, including chain-of-thought reasoning and few-shot prompting. A custom evaluation framework is developed to assess question and answer quality across multiple dimensions, including faithfulness, relevance, and domain specificity. The dataset averages a score range of 8.16 out of 10 on these metrics.\n(2) Two architectures for question-answering in the sustainability reporting domain - a RAG pipeline and a fully LLM-based pipeline. The architectures are developed by experimenting, fine-tuning, and training on the QA dataset. The final pipelines feature an LLM fine-tuned on domain specific data and an industry classification component to improve the handling of complex queries. The RAG architecture achieves an accuracy of 85.32% on single-industry and 72.15% on cross-industry multiple-choice questions, outperforming the baseline approach by 4.67 and 19.21 percentage points, respectively. The LLM-based pipeline achieves an accuracy of 93.45% on single-industry and 80.30% on cross-industry multiple-choice questions, an improvement of 12.80 and 27.36 percentage points over the baseline, respectively.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "83",
        "title": "Efficient Few-Shot Continual Learning in Vision-Language Models",
        "author": [
            "Aristeidis Panos",
            "Rahaf Aljundi",
            "Daniel Olmeda Reino",
            "Richard E. Turner"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04098",
        "abstract": "Vision-language models (VLMs) excel in tasks such as visual question answering and image captioning. However, VLMs are often limited by their use of pretrained image encoders, like CLIP, leading to image understanding errors that hinder overall performance. On top of that, real-world applications often require the model to be continuously adapted as new and often limited data continuously arrive. To address this, we propose LoRSU (Low-Rank Adaptation with Structured Updates), a robust and computationally efficient method for selectively updating image encoders within VLMs. LoRSU introduces structured and localized parameter updates, effectively correcting performance on previously error-prone data while preserving the model's general robustness. Our approach leverages theoretical insights to identify and update only the most critical parameters, achieving significant resource efficiency. Specifically, we demonstrate that LoRSU reduces computational overhead by over 25x compared to full VLM updates, without sacrificing performance. Experimental results on VQA tasks in the few-shot continual learning setting, validate LoRSU's scalability, efficiency, and effectiveness, making it a compelling solution for image encoder adaptation in resource-constrained environments.",
        "tags": [
            "CLIP",
            "Low-Rank Adaptation"
        ]
    },
    {
        "id": "84",
        "title": "VTutor: An Open-Source SDK for Generative AI-Powered Animated Pedagogical Agents with Multi-Media Output",
        "author": [
            "Eason Chen",
            "Chengyu Lin",
            "Xinyi Tang",
            "Aprille Xi",
            "Canwen Wang",
            "Jionghao Lin",
            "Kenneth R Koedinger"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04103",
        "abstract": "The rapid evolution of large language models (LLMs) has transformed human-computer interaction (HCI), but the interaction with LLMs is currently mainly focused on text-based interactions, while other multi-model approaches remain under-explored. This paper introduces VTutor, an open-source Software Development Kit (SDK) that combines generative AI with advanced animation technologies to create engaging, adaptable, and realistic APAs for human-AI multi-media interactions. VTutor leverages LLMs for real-time personalized feedback, advanced lip synchronization for natural speech alignment, and WebGL rendering for seamless web integration. Supporting various 2D and 3D character models, VTutor enables researchers and developers to design emotionally resonant, contextually adaptive learning agents. This toolkit enhances learner engagement, feedback receptivity, and human-AI interaction while promoting trustworthy AI principles in education. VTutor sets a new standard for next-generation APAs, offering an accessible, scalable solution for fostering meaningful and immersive human-AI interaction experiences. The VTutor project is open-sourced and welcomes community-driven contributions and showcases.",
        "tags": [
            "3D",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "85",
        "title": "Ancient Greek Technology: An Immersive Learning Use Case Described Using a Co-Intelligent Custom ChatGPT Assistant",
        "author": [
            "Vlasis Kasapakis",
            "Leonel Morgado"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04110",
        "abstract": "Achieving consistency in immersive learning case descriptions is essential but challenging due to variations in research focus, methodology, and researchers' background. We address these challenges by leveraging the Immersive Learning Case Sheet (ILCS), a methodological instrument to standardize case descriptions, that we applied to an immersive learning case on ancient Greek technology in VRChat. Research team members had differing levels of familiarity with the ILCS and the case content, so we developed a custom ChatGPT assistant to facilitate consistent terminology and process alignment across the team. This paper constitutes an example of how structured case reports can be a novel contribution to immersive learning literature. Our findings demonstrate how the ILCS supports structured reflection and interpretation of the case. Further we report that the use of a ChatGPT assistant significantly sup-ports the coherence and quality of the team members development of the final ILCS. This exposes the potential of employing AI-driven tools to enhance collaboration and standardization of research practices in qualitative educational research. However, we also discuss the limitations and challenges, including reliance on AI for interpretive tasks and managing varied levels of expertise within the team. This study thus provides insights into the practical application of AI in standardizing immersive learning research processes.",
        "tags": [
            "ChatGPT"
        ]
    },
    {
        "id": "86",
        "title": "Generative Adversarial Networks Bridging Art and Machine Intelligence",
        "author": [
            "Junhao Song",
            "Yichao Zhang",
            "Ziqian Bi",
            "Tianyang Wang",
            "Keyu Chen",
            "Ming Li",
            "Qian Niu",
            "Junyu Liu",
            "Benji Peng",
            "Sen Zhang",
            "Ming Liu",
            "Jiawei Xu",
            "Xuanhe Pan",
            "Jinlang Wang",
            "Pohsun Feng",
            "Yizhu Wen",
            "Lawrence K.Q. Yan",
            "Hong-Ming Tseng",
            "Xinyuan Song",
            "Jintao Ren",
            "Silin Chen",
            "Yunze Wang",
            "Weiche Hsieh",
            "Bowen Jing",
            "Junjie Yang",
            "Jun Zhou",
            "Zheyu Yao",
            "Chia Xin Liang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04116",
        "abstract": "This book begins with a detailed introduction to the fundamental principles and historical development of GANs, contrasting them with traditional generative models and elucidating the core adversarial mechanisms through illustrative Python examples. The text systematically addresses the mathematical and theoretical underpinnings including probability theory, statistics, and game theory providing a solid framework for understanding the objectives, loss functions, and optimisation challenges inherent to GAN training. Subsequent chapters review classic variants such as Conditional GANs, DCGANs, InfoGAN, and LAPGAN before progressing to advanced training methodologies like Wasserstein GANs, GANs with gradient penalty, least squares GANs, and spectral normalisation techniques. The book further examines architectural enhancements and task-specific adaptations in generators and discriminators, showcasing practical implementations in high resolution image generation, artistic style transfer, video synthesis, text to image generation and other multimedia applications. The concluding sections offer insights into emerging research trends, including self-attention mechanisms, transformer-based generative models, and a comparative analysis with diffusion models, thus charting promising directions for future developments in both academic and applied settings.",
        "tags": [
            "Diffusion",
            "GAN",
            "Style Transfer",
            "Text-to-Image",
            "Transformer"
        ]
    },
    {
        "id": "87",
        "title": "The Order Effect: Investigating Prompt Sensitivity in Closed-Source LLMs",
        "author": [
            "Bryan Guan",
            "Tanya Roosta",
            "Peyman Passban",
            "Mehdi Rezagholizadeh"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04134",
        "abstract": "As large language models (LLMs) become integral to diverse applications, ensuring their reliability under varying input conditions is crucial. One key issue affecting this reliability is order sensitivity, wherein slight variations in input arrangement can lead to inconsistent or biased outputs. Although recent advances have reduced this sensitivity, the problem remains unresolved. This paper investigates the extent of order sensitivity in closed-source LLMs by conducting experiments across multiple tasks, including paraphrasing, relevance judgment, and multiple-choice questions. Our results show that input order significantly affects performance across tasks, with shuffled inputs leading to measurable declines in output accuracy. Few-shot prompting demonstrates mixed effectiveness and offers partial mitigation, however, fails to fully resolve the problem. These findings highlight persistent risks, particularly in high-stakes applications, and point to the need for more robust LLMs or improved input-handling techniques in future development.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "88",
        "title": "Beyond the Final Layer: Hierarchical Query Fusion Transformer with Agent-Interpolation Initialization for 3D Instance Segmentation",
        "author": [
            "Jiahao Lu",
            "Jiacheng Deng",
            "Tianzhu Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04139",
        "abstract": "3D instance segmentation aims to predict a set of object instances in a scene and represent them as binary foreground masks with corresponding semantic labels. Currently, transformer-based methods are gaining increasing attention due to their elegant pipelines, reduced manual selection of geometric properties, and superior performance. However, transformer-based methods fail to simultaneously maintain strong position and content information during query initialization. Additionally, due to supervision at each decoder layer, there exists a phenomenon of object disappearance with the deepening of layers. To overcome these hurdles, we introduce Beyond the Final Layer: Hierarchical Query Fusion Transformer with Agent-Interpolation Initialization for 3D Instance Segmentation (BFL). Specifically, an Agent-Interpolation Initialization Module is designed to generate resilient queries capable of achieving a balance between foreground coverage and content learning. Additionally, a Hierarchical Query Fusion Decoder is designed to retain low overlap queries, mitigating the decrease in recall with the deepening of layers. Extensive experiments on ScanNetV2, ScanNet200, ScanNet++ and S3DIS datasets demonstrate the superior performance of BFL.",
        "tags": [
            "3D",
            "Segmentation",
            "Transformer"
        ]
    },
    {
        "id": "89",
        "title": "Numerical moment stabilization of central difference approximations for linear stationary reaction-convection-diffusion equations with applications to stationary Hamilton-Jacobi equations",
        "author": [
            "T. Lewis",
            "X. Xue"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04142",
        "abstract": "Linear stationary reaction-convection-diffusion equations with Dirichlet boundary conditions are approximated using a simple finite difference method corresponding to central differences and the addition of a high-order stabilization term called a numerical moment. The focus is on convection-dominated equations, and the formulation for the method is motivated by various results for fully nonlinear problems. The method features higher-order local truncation errors than monotone methods consistent with the use of the central difference approximation for the gradient. Stability and rates of convergence are derived in the $\\ell^2$ norm for the constant-coefficient case. Numerical tests are provided to compare the new methods to monotone methods. The methods are also tested for stationary Hamilton-Jacobi equations where they demonstrate higher rates of convergence than the Lax-Friedrich's method when the underlying viscosity solution is smooth and comparable performance when the underlying viscosity solution is not smooth.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "90",
        "title": "UltraIF: Advancing Instruction Following from the Wild",
        "author": [
            "Kaikai An",
            "Li Sheng",
            "Ganqu Cui",
            "Shuzheng Si",
            "Ning Ding",
            "Yu Cheng",
            "Baobao Chang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04153",
        "abstract": "Instruction-following made modern large language models (LLMs) helpful assistants. However, the key to taming LLMs on complex instructions remains mysterious, for that there are huge gaps between models trained by open-source community and those trained by leading companies. To bridge the gap, we propose a simple and scalable approach UltraIF for building LLMs that can follow complex instructions with open-source data. UltraIF first decomposes real-world user prompts into simpler queries, constraints, and corresponding evaluation questions for the constraints. Then, we train an UltraComposer to compose constraint-associated prompts with evaluation questions. This prompt composer allows us to synthesize complicated instructions as well as filter responses with evaluation questions. In our experiment, for the first time, we successfully align LLaMA-3.1-8B-Base to catch up with its instruct version on 5 instruction-following benchmarks without any benchmark information, using only 8B model as response generator and evaluator. The aligned model also achieved competitive scores on other benchmarks. Moreover, we also show that UltraIF could further improve LLaMA-3.1-8B-Instruct through self-alignment, motivating broader use cases for the method. Our code will be available at https://github.com/kkk-an/UltraIF.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "91",
        "title": "MRAMG-Bench: A BeyondText Benchmark for Multimodal Retrieval-Augmented Multimodal Generation",
        "author": [
            "Qinhan Yu",
            "Zhiyou Xiao",
            "Binghui Li",
            "Zhengren Wang",
            "Chong Chen",
            "Wentao Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04176",
        "abstract": "Recent advancements in Retrieval-Augmented Generation (RAG) have shown remarkable performance in enhancing response accuracy and relevance by integrating external knowledge into generative models. However, existing RAG methods primarily focus on providing text-only answers, even in multimodal retrieval-augmented generation scenarios. In this work, we introduce the Multimodal Retrieval-Augmented Multimodal Generation (MRAMG) task, which aims to generate answers that combine both text and images, fully leveraging the multimodal data within a corpus. Despite the importance of this task, there is a notable absence of a comprehensive benchmark to effectively evaluate MRAMG performance. To bridge this gap, we introduce the MRAMG-Bench, a carefully curated, human-annotated dataset comprising 4,346 documents, 14,190 images, and 4,800 QA pairs, sourced from three categories: Web Data, Academic Papers, and Lifestyle. The dataset incorporates diverse difficulty levels and complex multi-image scenarios, providing a robust foundation for evaluating multimodal generation tasks. To facilitate rigorous evaluation, our MRAMG-Bench incorporates a comprehensive suite of both statistical and LLM-based metrics, enabling a thorough analysis of the performance of popular generative models in the MRAMG task. Besides, we propose an efficient multimodal answer generation framework that leverages both LLMs and MLLMs to generate multimodal responses. Our datasets are available at: https://huggingface.co/MRAMG.",
        "tags": [
            "LLMs",
            "RAG"
        ]
    },
    {
        "id": "92",
        "title": "Automated Microservice Pattern Instance Detection Using Infrastructure-as-Code Artifacts and Large Language Models",
        "author": [
            "Carlos Eduardo Duarte"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04188",
        "abstract": "Documenting software architecture is essential to preserve architecture knowledge, even though it is frequently costly. Architecture pattern instances, including microservice pattern instances, provide important structural software information. Practitioners should document this information to prevent knowledge vaporization. However, architecture patterns may not be detectable by analyzing source code artifacts, requiring the analysis of other types of artifacts. Moreover, many existing pattern detection instance approaches are complex to extend. This article presents our ongoing PhD research, early experiments, and a prototype for a tool we call MicroPAD for automating the detection of microservice pattern instances. The prototype uses Large Language Models (LLMs) to analyze Infrastructure-as-Code (IaC) artifacts to aid detection, aiming to keep costs low and maximize the scope of detectable patterns. Early experiments ran the prototype thrice in 22 GitHub projects. We verified that 83\\% of the patterns that the prototype identified were in the project. The costs of detecting the pattern instances were minimal. These results indicate that the approach is likely viable and, by lowering the entry barrier to automating pattern instance detection, could help democratize developer access to this category of architecture knowledge. Finally, we present our overall research methodology, planned future work, and an overview of MicroPAD's potential industrial impact.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "93",
        "title": "PixFoundation: Are We Heading in the Right Direction with Pixel-level Vision Foundation Models?",
        "author": [
            "Mennatullah Siam"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04192",
        "abstract": "Multiple works have emerged to push the boundaries on multi-modal large language models (MLLMs) towards pixel-level understanding. Such approaches have shown strong performance on benchmarks for referring expression segmentation and grounded conversation generation. The current trend in pixel-level MLLMs is to train with pixel-level grounding supervision on large-scale labelled data. However, we show that such MLLMs when evaluated on recent challenging vision centric benchmarks, exhibit a weak ability in visual question answering. Surprisingly, some of these methods even downgrade the grounding ability of MLLMs that were never trained with such supervision. In this work, we propose two novel challenging benchmarks and show that MLLMs without pixel-level grounding supervision can outperform the state of the art in such tasks when evaluating both the pixel-level grounding and visual question answering. We propose simple baselines to extract the grounding information that can be plugged into any MLLM, which we call as PixFoundation. More importantly, we study the research question of ``When does grounding emerge in MLLMs that are not trained with pixel-level grounding supervision?'' We show that grounding can coincide with object parts or location/appearance information. Code repository is at https://github.com/MSiam/PixFoundation/.",
        "tags": [
            "Large Language Models",
            "Segmentation"
        ]
    },
    {
        "id": "94",
        "title": "The Best Instruction-Tuning Data are Those That Fit",
        "author": [
            "Dylan Zhang",
            "Qirun Dai",
            "Hao Peng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04194",
        "abstract": "High-quality supervised fine-tuning (SFT) data are crucial for eliciting strong capabilities from pretrained large language models (LLMs). Typically, instructions are paired with multiple responses sampled from other LLMs, which are often out of the distribution of the target model to be fine-tuned. This, at scale, can lead to diminishing returns and even hurt the models' performance and robustness. We propose **GRAPE**, a novel SFT framework that accounts for the unique characteristics of the target model. For each instruction, it gathers responses from various LLMs and selects the one with the highest probability measured by the target model, indicating that it aligns most closely with the target model's pretrained distribution; it then proceeds with standard SFT training.\nWe first evaluate GRAPE with a controlled experiment, where we sample various solutions for each question in UltraInteract from multiple models and fine-tune commonly used LMs like LLaMA3.1-8B, Mistral-7B, and Qwen2.5-7B on GRAPE-selected data. GRAPE significantly outperforms strong baselines, including distilling from the strongest model with an absolute gain of up to 13.8%, averaged across benchmarks, and training on 3x more data with a maximum performance improvement of 17.3%. GRAPE's strong performance generalizes to realistic settings. We experiment with the post-training data used for Tulu3 and Olmo-2. GRAPE outperforms strong baselines trained on 4.5 times more data by 6.1% and a state-of-the-art data selection approach by 3% on average performance. Remarkably, using 1/3 of the data and half the number of epochs, GRAPE enables LLaMA3.1-8B to surpass the performance of Tulu3-SFT by 3.5%.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "95",
        "title": "\"Short-length\" Adversarial Training Helps LLMs Defend \"Long-length\" Jailbreak Attacks: Theoretical and Empirical Evidence",
        "author": [
            "Shaopeng Fu",
            "Liang Ding",
            "Di Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04204",
        "abstract": "Jailbreak attacks against large language models (LLMs) aim to induce harmful behaviors in LLMs through carefully crafted adversarial prompts. To mitigate attacks, one way is to perform adversarial training (AT)-based alignment, i.e., training LLMs on some of the most adversarial prompts to help them learn how to behave safely under attacks. During AT, the length of adversarial prompts plays a critical role in the robustness of aligned LLMs. This paper focuses on adversarial suffix jailbreak attacks and unveils that to defend against a jailbreak attack with an adversarial suffix of length $\\Theta(M)$, it is enough to align LLMs on prompts with adversarial suffixes of length $\\Theta(\\sqrt{M})$. Theoretically, we analyze the adversarial in-context learning of linear transformers on linear regression tasks and prove a robust generalization bound for trained transformers. The bound depends on the term $\\Theta(\\sqrt{M_{\\text{test}}}/M_{\\text{train}})$, where $M_{\\text{train}}$ and $M_{\\text{test}}$ are the number of adversarially perturbed in-context samples during training and testing. Empirically, we conduct AT on popular open-source LLMs and evaluate their robustness against jailbreak attacks of different adversarial suffix lengths. Results confirm a positive correlation between the attack success rate and the ratio of the square root of the adversarial suffix during jailbreaking to the length during AT. Our findings show that it is practical to defend \"long-length\" jailbreak attacks via efficient \"short-length\" AT. The code is available at https://github.com/fshp971/adv-icl.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "96",
        "title": "Algorithmic causal structure emerging through compression",
        "author": [
            "Liang Wendong",
            "Simon Buchholz",
            "Bernhard SchÃ¶lkopf"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04210",
        "abstract": "We explore the relationship between causality, symmetry, and compression. We build on and generalize the known connection between learning and compression to a setting where causal models are not identifiable. We propose a framework where causality emerges as a consequence of compressing data across multiple environments. We define algorithmic causality as an alternative definition of causality when traditional assumptions for causal identifiability do not hold. We demonstrate how algorithmic causal and symmetric structures can emerge from minimizing upper bounds on Kolmogorov complexity, without knowledge of intervention targets. We hypothesize that these insights may also provide a novel perspective on the emergence of causality in machine learning models, such as large language models, where causal relationships may not be explicitly identifiable.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "97",
        "title": "Sports and Women's Sports: Gender Bias in Text Generation with Olympic Data",
        "author": [
            "Laura Biester"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04218",
        "abstract": "Large Language Models (LLMs) have been shown to be biased in prior work, as they generate text that is in line with stereotypical views of the world or that is not representative of the viewpoints and values of historically marginalized demographic groups. In this work, we propose using data from parallel men's and women's events at the Olympic Games to investigate different forms of gender bias in language models. We define three metrics to measure bias, and find that models are consistently biased against women when the gender is ambiguous in the prompt. In this case, the model frequently retrieves only the results of the men's event with or without acknowledging them as such, revealing pervasive gender bias in LLMs in the context of athletics.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "98",
        "title": "\\'Eclair -- Extracting Content and Layout with Integrated Reading Order for Documents",
        "author": [
            "Ilia Karmanov",
            "Amala Sanjay Deshmukh",
            "Lukas Voegtle",
            "Philipp Fischer",
            "Kateryna Chumachenko",
            "Timo Roman",
            "Jarno SeppÃ¤nen",
            "Jupinder Parmar",
            "Joseph Jennings",
            "Andrew Tao",
            "Karan Sapra"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04223",
        "abstract": "Optical Character Recognition (OCR) technology is widely used to extract text from images of documents, facilitating efficient digitization and data retrieval. However, merely extracting text is insufficient when dealing with complex documents. Fully comprehending such documents requires an understanding of their structure -- including formatting, formulas, tables, and the reading order of multiple blocks and columns across multiple pages -- as well as semantic information for detecting elements like footnotes and image captions. This comprehensive understanding is crucial for downstream tasks such as retrieval, document question answering, and data curation for training Large Language Models (LLMs) and Vision Language Models (VLMs). To address this, we introduce Ãclair, a general-purpose text-extraction tool specifically designed to process a wide range of document types. Given an image, Ãclair is able to extract formatted text in reading order, along with bounding boxes and their corresponding semantic classes. To thoroughly evaluate these novel capabilities, we introduce our diverse human-annotated benchmark for document-level OCR and semantic classification. Ãclair achieves state-of-the-art accuracy on this benchmark, outperforming other methods across key metrics. Additionally, we evaluate Ãclair on established benchmarks, demonstrating its versatility and strength across several evaluation standards.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "99",
        "title": "Keep It Light! Simplifying Image Clustering Via Text-Free Adapters",
        "author": [
            "Yicen Li",
            "Haitz SÃ¡ez de OcÃ¡riz Borde",
            "Anastasis Kratsios",
            "Paul D. McNicholas"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04226",
        "abstract": "Many competitive clustering pipelines have a multi-modal design, leveraging large language models (LLMs) or other text encoders, and text-image pairs, which are often unavailable in real-world downstream applications. Additionally, such frameworks are generally complicated to train and require substantial computational resources, making widespread adoption challenging. In this work, we show that in deep clustering, competitive performance with more complex state-of-the-art methods can be achieved using a text-free and highly simplified training pipeline. In particular, our approach, Simple Clustering via Pre-trained models (SCP), trains only a small cluster head while leveraging pre-trained vision model feature representations and positive data pairs. Experiments on benchmark datasets including CIFAR-10, CIFAR-20, CIFAR-100, STL-10, ImageNet-10, and ImageNet-Dogs, demonstrate that SCP achieves highly competitive performance. Furthermore, we provide a theoretical result explaining why, at least under ideal conditions, additional text-based embeddings may not be necessary to achieve strong clustering performance in vision.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "100",
        "title": "Can LLMs Hack Enterprise Networks? Autonomous Assumed Breach Penetration-Testing Active Directory Networks",
        "author": [
            "Andreas Happe",
            "JÃ¼rgen Cito"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04227",
        "abstract": "We explore the feasibility and effectiveness of using LLM-driven autonomous systems for Assumed Breach penetration testing in enterprise networks. We introduce a novel prototype that, driven by Large Language Models (LLMs), can compromise accounts within a real-life Active Directory testbed. Our research provides a comprehensive evaluation of the prototype's capabilities, and highlights both strengths and limitations while executing attack. The evaluation uses a realistic simulation environment (Game of Active Directory, GOAD) to capture intricate interactions, stochastic outcomes, and timing dependencies that characterize live network scenarios. The study concludes that autonomous LLMs are able to conduct Assumed Breach simulations, potentially democratizing access to penetration testing for organizations facing budgetary constraints.\nThe prototype's source code, traces, and analyzed logs are released as open-source to enhance collective cybersecurity and facilitate future research in LLM-driven cybersecurity automation.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "101",
        "title": "A Classification System Approach in Predicting Chinese Censorship",
        "author": [
            "Matt Prodani",
            "Tianchu Ze",
            "Yushen Hu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04234",
        "abstract": "This paper is dedicated to using a classifier to predict whether a Weibo post would be censored under the Chinese internet. Through randomized sampling from \\citeauthor{Fu2021} and Chinese tokenizing strategies, we constructed a cleaned Chinese phrase dataset with binary censorship markings. Utilizing various probability-based information retrieval methods on the data, we were able to derive 4 logistic regression models for classification. Furthermore, we experimented with pre-trained transformers to perform similar classification tasks. After evaluating both the macro-F1 and ROC-AUC metrics, we concluded that the Fined-Tuned BERT model exceeds other strategies in performance.",
        "tags": [
            "BERT"
        ]
    },
    {
        "id": "102",
        "title": "MAGA: MAssive Genre-Audience Reformulation to Pretraining Corpus Expansion",
        "author": [
            "Xintong Hao",
            "Ke Shen",
            "Chenggang Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04235",
        "abstract": "Despite the remarkable capabilities of large language models across various tasks, their continued scaling faces a critical challenge: the scarcity of high-quality pretraining data. While model architectures continue to evolve, the natural language data struggles to scale up. To tackle this bottleneck, we propose \\textbf{MA}ssive \\textbf{G}enre-\\textbf{A}udience~(MAGA) reformulation method, which systematic synthesizes diverse, contextually-rich pretraining data from existing corpus. This work makes three main contributions: (1) We propose MAGA reformulation method, a lightweight and scalable approach for pretraining corpus expansion, and build a 770B tokens MAGACorpus. (2) We evaluate MAGACorpus with different data budget scaling strategies, demonstrating consistent improvements across various model sizes (134M-13B), establishing the necessity for next-generation large-scale synthetic pretraining language models. (3) Through comprehensive analysis, we investigate prompt engineering's impact on synthetic training collapse and reveal limitations in conventional collapse detection metrics using validation losses. Our work shows that MAGA can substantially expand training datasets while maintaining quality, offering a reliably pathway for scaling models beyond data limitations.",
        "tags": [
            "Detection",
            "Large Language Models"
        ]
    },
    {
        "id": "103",
        "title": "TriNER: A Series of Named Entity Recognition Models For Hindi, Bengali & Marathi",
        "author": [
            "Mohammed Amaan Dhamaskar",
            "Rasika Ransing"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04245",
        "abstract": "India's rich cultural and linguistic diversity poses various challenges in the domain of Natural Language Processing (NLP), particularly in Named Entity Recognition (NER). NER is a NLP task that aims to identify and classify tokens into different entity groups like Person, Location, Organization, Number, etc. This makes NER very useful for downstream tasks like context-aware anonymization. This paper details our work to build a multilingual NER model for the three most spoken languages in India - Hindi, Bengali & Marathi. We train a custom transformer model and fine tune a few pretrained models, achieving an F1 Score of 92.11 for a total of 6 entity groups. Through this paper, we aim to introduce a single model to perform NER and significantly reduce the inconsistencies in entity groups and tag names, across the three languages.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "104",
        "title": "Combining Language and App UI Analysis for the Automated Assessment of Bug Reproduction Steps",
        "author": [
            "Junayed Mahmud",
            "Antu Saha",
            "Oscar Chaparro",
            "Kevin Moran",
            "Andrian Marcus"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04251",
        "abstract": "Bug reports are essential for developers to confirm software problems, investigate their causes, and validate fixes. Unfortunately, reports often miss important information or are written unclearly, which can cause delays, increased issue resolution effort, or even the inability to solve issues. One of the most common components of reports that are problematic is the steps to reproduce the bug(s) (S2Rs), which are essential to replicate the described program failures and reason about fixes. Given the proclivity for deficiencies in reported S2Rs, prior work has proposed techniques that assist reporters in writing or assessing the quality of S2Rs. However, automated understanding of S2Rs is challenging, and requires linking nuanced natural language phrases with specific, semantically related program information. Prior techniques often struggle to form such language to program connections - due to issues in language variability and limitations of information gleaned from program analyses.\nTo more effectively tackle the problem of S2R quality annotation, we propose a new technique called AstroBR, which leverages the language understanding capabilities of LLMs to identify and extract the S2Rs from bug reports and map them to GUI interactions in a program state model derived via dynamic analysis. We compared AstroBR to a related state-of-the-art approach and we found that AstroBR annotates S2Rs 25.2% better (in terms of F1 score) than the baseline. Additionally, AstroBR suggests more accurate missing S2Rs than the baseline (by 71.4% in terms of F1 score).",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "105",
        "title": "Cross the Gap: Exposing the Intra-modal Misalignment in CLIP via Modality Inversion",
        "author": [
            "Marco Mistretta",
            "Alberto Baldrati",
            "Lorenzo Agnolucci",
            "Marco Bertini",
            "Andrew D. Bagdanov"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04263",
        "abstract": "Pre-trained multi-modal Vision-Language Models like CLIP are widely used off-the-shelf for a variety of applications. In this paper, we show that the common practice of individually exploiting the text or image encoders of these powerful multi-modal models is highly suboptimal for intra-modal tasks like image-to-image retrieval. We argue that this is inherently due to the CLIP-style inter-modal contrastive loss that does not enforce any intra-modal constraints, leading to what we call intra-modal misalignment. To demonstrate this, we leverage two optimization-based modality inversion techniques that map representations from their input modality to the complementary one without any need for auxiliary data or additional trained adapters. We empirically show that, in the intra-modal tasks of image-to-image and text-to-text retrieval, approaching these tasks inter-modally significantly improves performance with respect to intra-modal baselines on more than fifteen datasets. Additionally, we demonstrate that approaching a native inter-modal task (e.g. zero-shot image classification) intra-modally decreases performance, further validating our findings. Finally, we show that incorporating an intra-modal term in the pre-training objective or narrowing the modality gap between the text and image feature embedding spaces helps reduce the intra-modal misalignment. The code is publicly available at: https://github.com/miccunifi/Cross-the-Gap.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "106",
        "title": "PILAF: Optimal Human Preference Sampling for Reward Modeling",
        "author": [
            "Yunzhen Feng",
            "Ariel Kwiatkowski",
            "Kunhao Zheng",
            "Julia Kempe",
            "Yaqi Duan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04270",
        "abstract": "As large language models increasingly drive real-world applications, aligning them with human values becomes paramount. Reinforcement Learning from Human Feedback (RLHF) has emerged as a key technique, translating preference data into reward models when oracle human values remain inaccessible. In practice, RLHF mostly relies on approximate reward models, which may not consistently guide the policy toward maximizing the underlying human values. We propose Policy-Interpolated Learning for Aligned Feedback (PILAF), a novel response sampling strategy for preference labeling that explicitly aligns preference learning with maximizing the underlying oracle reward. PILAF is theoretically grounded, demonstrating optimality from both an optimization and a statistical perspective. The method is straightforward to implement and demonstrates strong performance in iterative and online RLHF settings where feedback curation is critical.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "107",
        "title": "Beyond Prompt Content: Enhancing LLM Performance via Content-Format Integrated Prompt Optimization",
        "author": [
            "Yuanye Liu",
            "Jiahang Xu",
            "Li Lyna Zhang",
            "Qi Chen",
            "Xuan Feng",
            "Yang Chen",
            "Zhongxin Guo",
            "Yuqing Yang",
            "Cheng Peng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04295",
        "abstract": "Large Language Models (LLMs) have shown significant capability across various tasks, with their real-world effectiveness often driven by prompt design. While recent research has focused on optimizing prompt content, the role of prompt formatting, a critical but often overlooked dimension, has received limited systematic investigation. In this paper, we introduce Content-Format Integrated Prompt Optimization (CFPO), an innovative methodology that jointly optimizes both prompt content and formatting through an iterative refinement process. CFPO leverages natural language mutations to explore content variations and employs a dynamic format exploration strategy that systematically evaluates diverse format options. Our extensive evaluations across multiple tasks and open-source LLMs demonstrate that CFPO demonstrates measurable performance improvements compared to content-only optimization methods. This highlights the importance of integrated content-format optimization and offers a practical, model-agnostic approach to enhancing LLM performance. Code will be available at https://github.com/HenryLau7/CFPO.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "108",
        "title": "Learning Real-World Action-Video Dynamics with Heterogeneous Masked Autoregression",
        "author": [
            "Lirui Wang",
            "Kevin Zhao",
            "Chaoqi Liu",
            "Xinlei Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04296",
        "abstract": "We propose Heterogeneous Masked Autoregression (HMA) for modeling action-video dynamics to generate high-quality data and evaluation in scaling robot learning. Building interactive video world models and policies for robotics is difficult due to the challenge of handling diverse settings while maintaining computational efficiency to run in real time. HMA uses heterogeneous pre-training from observations and action sequences across different robotic embodiments, domains, and tasks. HMA uses masked autoregression to generate quantized or soft tokens for video predictions. \\ourshort achieves better visual fidelity and controllability than the previous robotic video generation models with 15 times faster speed in the real world. After post-training, this model can be used as a video simulator from low-level action inputs for evaluating policies and generating synthetic data. See this link https://liruiw.github.io/hma for more information.",
        "tags": [
            "Robot",
            "Robotics",
            "Video Generation"
        ]
    },
    {
        "id": "109",
        "title": "Statistical guarantees for continuous-time policy evaluation: blessing of ellipticity and new tradeoffs",
        "author": [
            "Wenlong Mou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04297",
        "abstract": "We study the estimation of the value function for continuous-time Markov diffusion processes using a single, discretely observed ergodic trajectory. Our work provides non-asymptotic statistical guarantees for the least-squares temporal-difference (LSTD) method, with performance measured in the first-order Sobolev norm. Specifically, the estimator attains an $O(1 / \\sqrt{T})$ convergence rate when using a trajectory of length $T$; notably, this rate is achieved as long as $T$ scales nearly linearly with both the mixing time of the diffusion and the number of basis functions employed.\nA key insight of our approach is that the ellipticity inherent in the diffusion process ensures robust performance even as the effective horizon diverges to infinity. Moreover, we demonstrate that the Markovian component of the statistical error can be controlled by the approximation error, while the martingale component grows at a slower rate relative to the number of basis functions. By carefully balancing these two sources of error, our analysis reveals novel trade-offs between approximation and statistical errors.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "110",
        "title": "MotionCanvas: Cinematic Shot Design with Controllable Image-to-Video Generation",
        "author": [
            "Jinbo Xing",
            "Long Mai",
            "Cusuh Ham",
            "Jiahui Huang",
            "Aniruddha Mahapatra",
            "Chi-Wing Fu",
            "Tien-Tsin Wong",
            "Feng Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04299",
        "abstract": "This paper presents a method that allows users to design cinematic video shots in the context of image-to-video generation. Shot design, a critical aspect of filmmaking, involves meticulously planning both camera movements and object motions in a scene. However, enabling intuitive shot design in modern image-to-video generation systems presents two main challenges: first, effectively capturing user intentions on the motion design, where both camera movements and scene-space object motions must be specified jointly; and second, representing motion information that can be effectively utilized by a video diffusion model to synthesize the image animations. To address these challenges, we introduce MotionCanvas, a method that integrates user-driven controls into image-to-video (I2V) generation models, allowing users to control both object and camera motions in a scene-aware manner. By connecting insights from classical computer graphics and contemporary video generation techniques, we demonstrate the ability to achieve 3D-aware motion control in I2V synthesis without requiring costly 3D-related training data. MotionCanvas enables users to intuitively depict scene-space motion intentions, and translates them into spatiotemporal motion-conditioning signals for video diffusion models. We demonstrate the effectiveness of our method on a wide range of real-world image content and shot-design scenarios, highlighting its potential to enhance the creative workflows in digital content creation and adapt to various image and video editing applications.",
        "tags": [
            "3D",
            "Diffusion",
            "Video Editing",
            "Video Generation"
        ]
    },
    {
        "id": "111",
        "title": "ChamaleonLLM: Batch-Aware Dynamic Low-Rank Adaptation via Inference-Time Clusters",
        "author": [
            "Kamer Ali Yuksel",
            "Hassan Sawaf"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04315",
        "abstract": "Recent advances in large language models (LLMs) have shown remarkable performance across diverse tasks. However, these models are typically deployed with fixed weights, which limits their ability to adapt dynamically to the variability inherent in real-world data during inference. This paper introduces ChamaleonLLM, a novel framework that enables inference-time adaptation of LLMs by leveraging batch-aware clustering and on-the-fly generation of low-rank updates. Unlike traditional fine-tuning approaches such as Low-Rank Adaptation (LoRA) or methods that rely on a fixed set of pre-learned uniforms (changeable masks), our method dynamically generates adaptive modifications to the decoder weights based on the aggregated statistics of clustered batches. By intelligently grouping similar inputs and computing context-aware low-rank updates via a hyper-network, ChamaleonLLM achieves significant performance gains, outperforming conventional LoRA methods while eliminating the overhead of maintaining multiple expert models. Our experiments highlight the potential of our approach to serve as a versatile and highly adaptive solution for language model inference. ChamaleonLLM is open-sourced to ensure the reproducibility of our experiments: https://anonymous.4open.science/r/ChamaleonLLM/",
        "tags": [
            "LLMs",
            "Large Language Models",
            "LoRA",
            "Low-Rank Adaptation"
        ]
    },
    {
        "id": "112",
        "title": "ConceptAttention: Diffusion Transformers Learn Highly Interpretable Features",
        "author": [
            "Alec Helbling",
            "Tuna Han Salih Meral",
            "Ben Hoover",
            "Pinar Yanardag",
            "Duen Horng Chau"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04320",
        "abstract": "Do the rich representations of multi-modal diffusion transformers (DiTs) exhibit unique properties that enhance their interpretability? We introduce ConceptAttention, a novel method that leverages the expressive power of DiT attention layers to generate high-quality saliency maps that precisely locate textual concepts within images. Without requiring additional training, ConceptAttention repurposes the parameters of DiT attention layers to produce highly contextualized concept embeddings, contributing the major discovery that performing linear projections in the output space of DiT attention layers yields significantly sharper saliency maps compared to commonly used cross-attention mechanisms. Remarkably, ConceptAttention even achieves state-of-the-art performance on zero-shot image segmentation benchmarks, outperforming 11 other zero-shot interpretability methods on the ImageNet-Segmentation dataset and on a single-class subset of PascalVOC. Our work contributes the first evidence that the representations of multi-modal DiT models like Flux are highly transferable to vision tasks like segmentation, even outperforming multi-modal foundation models like CLIP.",
        "tags": [
            "CLIP",
            "DiT",
            "Diffusion",
            "FLUX",
            "Segmentation"
        ]
    },
    {
        "id": "113",
        "title": "Speak Easy: Eliciting Harmful Jailbreaks from LLMs with Simple Interactions",
        "author": [
            "Yik Siu Chan",
            "Narutatsu Ri",
            "Yuxin Xiao",
            "Marzyeh Ghassemi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04322",
        "abstract": "Despite extensive safety alignment efforts, large language models (LLMs) remain vulnerable to jailbreak attacks that elicit harmful behavior. While existing studies predominantly focus on attack methods that require technical expertise, two critical questions remain underexplored: (1) Are jailbroken responses truly useful in enabling average users to carry out harmful actions? (2) Do safety vulnerabilities exist in more common, simple human-LLM interactions? In this paper, we demonstrate that LLM responses most effectively facilitate harmful actions when they are both actionable and informative--two attributes easily elicited in multi-step, multilingual interactions. Using this insight, we propose HarmScore, a jailbreak metric that measures how effectively an LLM response enables harmful actions, and Speak Easy, a simple multi-step, multilingual attack framework. Notably, by incorporating Speak Easy into direct request and jailbreak baselines, we see an average absolute increase of 0.319 in Attack Success Rate and 0.426 in HarmScore in both open-source and proprietary LLMs across four safety benchmarks. Our work reveals a critical yet often overlooked vulnerability: Malicious users can easily exploit common interaction patterns for harmful intentions.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "114",
        "title": "Can Grammarly and ChatGPT accelerate language change? AI-powered technologies and their impact on the English language: wordiness vs. conciseness",
        "author": [
            "Karolina Rudnicka"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04324",
        "abstract": "The proliferation of NLP-powered language technologies, AI-based natural language generation models, and English as a mainstream means of communication among both native and non-native speakers make the output of AI-powered tools especially intriguing to linguists. This paper investigates how Grammarly and ChatGPT affect the English language regarding wordiness vs. conciseness. A case study focusing on the purpose subordinator in order to is presented to illustrate the way in which Grammarly and ChatGPT recommend shorter grammatical structures instead of longer and more elaborate ones. Although the analysed sentences were produced by native speakers, are perfectly correct, and were extracted from a language corpus of contemporary English, both Grammarly and ChatGPT suggest more conciseness and less verbosity, even for relatively short sentences. The present article argues that technologies such as Grammarly not only mirror language change but also have the potential to facilitate or accelerate it.",
        "tags": [
            "ChatGPT"
        ]
    },
    {
        "id": "115",
        "title": "WorldSense: Evaluating Real-world Omnimodal Understanding for Multimodal LLMs",
        "author": [
            "Jack Hong",
            "Shilin Yan",
            "Jiayin Cai",
            "Xiaolong Jiang",
            "Yao Hu",
            "Weidi Xie"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04326",
        "abstract": "In this paper, we introduce WorldSense, the first benchmark to assess the multi-modal video understanding, that simultaneously encompasses visual, audio, and text inputs. In contrast to existing benchmarks, our WorldSense has several features: (i) collaboration of omni-modality, we design the evaluation tasks to feature a strong coupling of audio and video, requiring models to effectively utilize the synergistic perception of omni-modality; (ii) diversity of videos and tasks, WorldSense encompasses a diverse collection of 1,662 audio-visual synchronised videos, systematically categorized into 8 primary domains and 67 fine-grained subcategories to cover the broad scenarios, and 3,172 multi-choice QA pairs across 26 distinct tasks to enable the comprehensive evaluation; (iii) high-quality annotations, all the QA pairs are manually labeled by 80 expert annotators with multiple rounds of correction to ensure quality. Based on our WorldSense, we extensively evaluate various state-of-the-art models. The experimental results indicate that existing models face significant challenges in understanding real-world scenarios (48.0% best accuracy). We hope our WorldSense can provide a platform for evaluating the ability in constructing and understanding coherent contexts from omni-modality.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "116",
        "title": "Ola: Pushing the Frontiers of Omni-Modal Language Model with Progressive Modality Alignment",
        "author": [
            "Zuyan Liu",
            "Yuhao Dong",
            "Jiahui Wang",
            "Ziwei Liu",
            "Winston Hu",
            "Jiwen Lu",
            "Yongming Rao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04328",
        "abstract": "Recent advances in large language models, particularly following GPT-4o, have sparked increasing interest in developing omni-modal models capable of understanding more modalities. While some open-source alternatives have emerged, there is still a notable lag behind specialized single-modality models in performance. In this paper, we present Ola, an Omni-modal language model that achieves competitive performance across image, video, and audio understanding compared to specialized counterparts. The core design of Ola lies in its progressive modality alignment strategy that extends the supporting modality of the language model progressively. Our training pipeline begins with the most distinct modalities: image and text, then gradually expands the skill sets of the model using speech data that connects language and audio knowledge, and video data that connects all modalities. The progressive learning pipeline also enables us to maintain a relatively small size of the cross-modal alignment data, making developing omni-modal from existing vision-language models easy and less costly. Moreover, to unlock an advanced interactive experience like GPT-4o, we further design a sentence-wise decoding solution for streaming speech generation. Extensive experiments demonstrate that Ola surpasses existing open omni-modal LLMs across all modalities while achieving highly competitive performance compared to state-of-the-art specialized models of similar sizes. We aim to make Ola a fully open omni-modal understanding solution to advance future research in this emerging field. Model weights, code, and data are open-sourced at https://github.com/Ola-Omni/Ola.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "117",
        "title": "MetaFE-DE: Learning Meta Feature Embedding for Depth Estimation from Monocular Endoscopic Images",
        "author": [
            "Dawei Lu",
            "Deqiang Xiao",
            "Danni Ai",
            "Jingfan Fan",
            "Tianyu Fu",
            "Yucong Lin",
            "Hong Song",
            "Xujiong Ye",
            "Lei Zhang",
            "Jian Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03493",
        "abstract": "Depth estimation from monocular endoscopic images presents significant challenges due to the complexity of endoscopic surgery, such as irregular shapes of human soft tissues, as well as variations in lighting conditions. Existing methods primarily estimate the depth information from RGB images directly, and often surffer the limited interpretability and accuracy. Given that RGB and depth images are two views of the same endoscopic surgery scene, in this paper, we introduce a novel concept referred as ``meta feature embedding (MetaFE)\", in which the physical entities (e.g., tissues and surgical instruments) of endoscopic surgery are represented using the shared features that can be alternatively decoded into RGB or depth image. With this concept, we propose a two-stage self-supervised learning paradigm for the monocular endoscopic depth estimation. In the first stage, we propose a temporal representation learner using diffusion models, which are aligned with the spatial information through the cross normalization to construct the MetaFE. In the second stage, self-supervised monocular depth estimation with the brightness calibration is applied to decode the meta features into the depth image. Extensive evaluation on diverse endoscopic datasets demonstrates that our approach outperforms the state-of-the-art method in depth estimation, achieving superior accuracy and generalization. The source code will be publicly available.",
        "tags": [
            "Depth Estimation",
            "Diffusion"
        ]
    },
    {
        "id": "118",
        "title": "FreqPrior: Improving Video Diffusion Models with Frequency Filtering Gaussian Noise",
        "author": [
            "Yunlong Yuan",
            "Yuanfan Guo",
            "Chunwei Wang",
            "Wei Zhang",
            "Hang Xu",
            "Li Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03496",
        "abstract": "Text-driven video generation has advanced significantly due to developments in diffusion models. Beyond the training and sampling phases, recent studies have investigated noise priors of diffusion models, as improved noise priors yield better generation results. One recent approach employs the Fourier transform to manipulate noise, marking the initial exploration of frequency operations in this context. However, it often generates videos that lack motion dynamics and imaging details. In this work, we provide a comprehensive theoretical analysis of the variance decay issue present in existing methods, contributing to the loss of details and motion dynamics. Recognizing the critical impact of noise distribution on generation quality, we introduce FreqPrior, a novel noise initialization strategy that refines noise in the frequency domain. Our method features a novel filtering technique designed to address different frequency signals while maintaining the noise prior distribution that closely approximates a standard Gaussian distribution. Additionally, we propose a partial sampling process by perturbing the latent at an intermediate timestep during finding the noise prior, significantly reducing inference time without compromising quality. Extensive experiments on VBench demonstrate that our method achieves the highest scores in both quality and semantic assessments, resulting in the best overall total score. These results highlight the superiority of our proposed noise prior.",
        "tags": [
            "Diffusion",
            "Video Generation"
        ]
    },
    {
        "id": "119",
        "title": "Controllable Satellite-to-Street-View Synthesis with Precise Pose Alignment and Zero-Shot Environmental Control",
        "author": [
            "Xianghui Ze",
            "Zhenbo Song",
            "Qiwei Wang",
            "Jianfeng Lu",
            "Yujiao Shi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03498",
        "abstract": "Generating street-view images from satellite imagery is a challenging task, particularly in maintaining accurate pose alignment and incorporating diverse environmental conditions. While diffusion models have shown promise in generative tasks, their ability to maintain strict pose alignment throughout the diffusion process is limited. In this paper, we propose a novel Iterative Homography Adjustment (IHA) scheme applied during the denoising process, which effectively addresses pose misalignment and ensures spatial consistency in the generated street-view images. Additionally, currently, available datasets for satellite-to-street-view generation are limited in their diversity of illumination and weather conditions, thereby restricting the generalizability of the generated outputs. To mitigate this, we introduce a text-guided illumination and weather-controlled sampling strategy that enables fine-grained control over the environmental factors. Extensive quantitative and qualitative evaluations demonstrate that our approach significantly improves pose accuracy and enhances the diversity and realism of generated street-view images, setting a new benchmark for satellite-to-street-view generation tasks.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "120",
        "title": "Omni-DNA: A Unified Genomic Foundation Model for Cross-Modal and Multi-Task Learning",
        "author": [
            "Zehui Li",
            "Vallijah Subasri",
            "Yifei Shen",
            "Dongsheng Li",
            "Yiren Zhao",
            "Guy-Bart Stan",
            "Caihua Shan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03499",
        "abstract": "Large Language Models (LLMs) demonstrate remarkable generalizability across diverse tasks, yet genomic foundation models (GFMs) still require separate finetuning for each downstream application, creating significant overhead as model sizes grow. Moreover, existing GFMs are constrained by rigid output formats, limiting their applicability to various genomic tasks. In this work, we revisit the transformer-based auto-regressive models and introduce Omni-DNA, a family of cross-modal multi-task models ranging from 20 million to 1 billion parameters. Our approach consists of two stages: (i) pretraining on DNA sequences with next token prediction objective, and (ii) expanding the multi-modal task-specific tokens and finetuning for multiple downstream tasks simultaneously. When evaluated on the Nucleotide Transformer and GB benchmarks, Omni-DNA achieves state-of-the-art performance on 18 out of 26 tasks. Through multi-task finetuning, Omni-DNA addresses 10 acetylation and methylation tasks at once, surpassing models trained on each task individually. Finally, we design two complex genomic tasks, DNA2Function and Needle-in-DNA, which map DNA sequences to textual functional descriptions and images, respectively, indicating Omni-DNA's cross-modal capabilities to broaden the scope of genomic applications. All the models are available through https://huggingface.co/collections/zehui127",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "121",
        "title": "Efficient Image Restoration via Latent Consistency Flow Matching",
        "author": [
            "Elad Cohen",
            "Idan Achituve",
            "Idit Diamant",
            "Arnon Netzer",
            "Hai Victor Habi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03500",
        "abstract": "Recent advances in generative image restoration (IR) have demonstrated impressive results. However, these methods are hindered by their substantial size and computational demands, rendering them unsuitable for deployment on edge devices. This work introduces ELIR, an Efficient Latent Image Restoration method. ELIR operates in latent space by first predicting the latent representation of the minimum mean square error (MMSE) estimator and then transporting this estimate to high-quality images using a latent consistency flow-based model. Consequently, ELIR is more than 4x faster compared to the state-of-the-art diffusion and flow-based approaches. Moreover, ELIR is also more than 4x smaller, making it well-suited for deployment on resource-constrained edge devices. Comprehensive evaluations of various image restoration tasks show that ELIR achieves competitive results, effectively balancing distortion and perceptual quality metrics while offering improved efficiency in terms of memory and computation.",
        "tags": [
            "Diffusion",
            "Flow Matching"
        ]
    },
    {
        "id": "122",
        "title": "DC-VSR: Spatially and Temporally Consistent Video Super-Resolution with Video Diffusion Prior",
        "author": [
            "Janghyeok Han",
            "Gyujin Sim",
            "Geonung Kim",
            "Hyunseung Lee",
            "Kyuha Choi",
            "Youngseok Han",
            "Sunghyun Cho"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03502",
        "abstract": "Video super-resolution (VSR) aims to reconstruct a high-resolution (HR) video from a low-resolution (LR) counterpart. Achieving successful VSR requires producing realistic HR details and ensuring both spatial and temporal consistency. To restore realistic details, diffusion-based VSR approaches have recently been proposed. However, the inherent randomness of diffusion, combined with their tile-based approach, often leads to spatio-temporal inconsistencies. In this paper, we propose DC-VSR, a novel VSR approach to produce spatially and temporally consistent VSR results with realistic textures. To achieve spatial and temporal consistency, DC-VSR adopts a novel Spatial Attention Propagation (SAP) scheme and a Temporal Attention Propagation (TAP) scheme that propagate information across spatio-temporal tiles based on the self-attention mechanism. To enhance high-frequency details, we also introduce Detail-Suppression Self-Attention Guidance (DSSAG), a novel diffusion guidance scheme. Comprehensive experiments demonstrate that DC-VSR achieves spatially and temporally consistent, high-quality VSR results, outperforming previous approaches.",
        "tags": [
            "Diffusion",
            "Super Resolution"
        ]
    },
    {
        "id": "123",
        "title": "Two in context learning tasks with complex functions",
        "author": [
            "Omar Naim",
            "Nicholas Asher"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03503",
        "abstract": "We examine two in context learning (ICL) tasks with mathematical functions in several train and test settings for transformer models. Our study generalizes work on linear functions by showing that small transformers, even models with attention layers only, can approximate arbitrary polynomial functions and hence continuous functions under certain conditions. Our models also can approximate previously unseen classes of polynomial functions, as well as the zeros of complex functions. Our models perform far better on this task than LLMs like GPT4 and involve complex reasoning when provided with suitable training data and methods. Our models also have important limitations; they fail to generalize outside of training distributions and so don't learn class forms of functions. We explain why this is so.",
        "tags": [
            "LLMs",
            "Transformer"
        ]
    },
    {
        "id": "124",
        "title": "Comprehensive Layer-wise Analysis of SSL Models for Audio Deepfake Detection",
        "author": [
            "Yassine El Kheir",
            "Youness Samih",
            "Suraj Maharjan",
            "Tim Polzehl",
            "Sebastian MÃ¶ller"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03559",
        "abstract": "This paper conducts a comprehensive layer-wise analysis of self-supervised learning (SSL) models for audio deepfake detection across diverse contexts, including multilingual datasets (English, Chinese, Spanish), partial, song, and scene-based deepfake scenarios. By systematically evaluating the contributions of different transformer layers, we uncover critical insights into model behavior and performance. Our findings reveal that lower layers consistently provide the most discriminative features, while higher layers capture less relevant information. Notably, all models achieve competitive equal error rate (EER) scores even when employing a reduced number of layers. This indicates that we can reduce computational costs and increase the inference speed of detecting deepfakes by utilizing only a few lower layers. This work enhances our understanding of SSL models in deepfake detection, offering valuable insights applicable across varied linguistic and contextual settings. Our trained models and code are publicly available: https://github.com/Yaselley/SSL_Layerwise_Deepfake.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "125",
        "title": "SymmCD: Symmetry-Preserving Crystal Generation with Diffusion Models",
        "author": [
            "Daniel Levy",
            "Siba Smarak Panigrahi",
            "SÃ©kou-Oumar Kaba",
            "Qiang Zhu",
            "Kin Long Kelvin Lee",
            "Mikhail Galkin",
            "Santiago Miret",
            "Siamak Ravanbakhsh"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03638",
        "abstract": "Generating novel crystalline materials has potential to lead to advancements in fields such as electronics, energy storage, and catalysis. The defining characteristic of crystals is their symmetry, which plays a central role in determining their physical properties. However, existing crystal generation methods either fail to generate materials that display the symmetries of real-world crystals, or simply replicate the symmetry information from examples in a database. To address this limitation, we propose SymmCD, a novel diffusion-based generative model that explicitly incorporates crystallographic symmetry into the generative process. We decompose crystals into two components and learn their joint distribution through diffusion: 1) the asymmetric unit, the smallest subset of the crystal which can generate the whole crystal through symmetry transformations, and; 2) the symmetry transformations needed to be applied to each atom in the asymmetric unit. We also use a novel and interpretable representation for these transformations, enabling generalization across different crystallographic symmetry groups. We showcase the competitive performance of SymmCD on a subset of the Materials Project, obtaining diverse and valid crystals with realistic symmetries and predicted properties.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "126",
        "title": "DiTAR: Diffusion Transformer Autoregressive Modeling for Speech Generation",
        "author": [
            "Dongya Jia",
            "Zhuo Chen",
            "Jiawei Chen",
            "Chenpeng Du",
            "Jian Wu",
            "Jian Cong",
            "Xiaobin Zhuang",
            "Chumin Li",
            "Zhen Wei",
            "Yuping Wang",
            "Yuxuan Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03930",
        "abstract": "Several recent studies have attempted to autoregressively generate continuous speech representations without discrete speech tokens by combining diffusion and autoregressive models, yet they often face challenges with excessive computational loads or suboptimal outcomes. In this work, we propose Diffusion Transformer Autoregressive Modeling (DiTAR), a patch-based autoregressive framework combining a language model with a diffusion transformer. This approach significantly enhances the efficacy of autoregressive models for continuous tokens and reduces computational demands. DiTAR utilizes a divide-and-conquer strategy for patch generation, where the language model processes aggregated patch embeddings and the diffusion transformer subsequently generates the next patch based on the output of the language model. For inference, we propose defining temperature as the time point of introducing noise during the reverse diffusion ODE to balance diversity and determinism. We also show in the extensive scaling analysis that DiTAR has superb scalability. In zero-shot speech generation, DiTAR achieves state-of-the-art performance in robustness, speaker similarity, and naturalness.",
        "tags": [
            "Diffusion",
            "Diffusion Transformer",
            "ODE",
            "Transformer"
        ]
    },
    {
        "id": "127",
        "title": "Llasa: Scaling Train-Time and Inference-Time Compute for Llama-based Speech Synthesis",
        "author": [
            "Zhen Ye",
            "Xinfa Zhu",
            "Chi-Min Chan",
            "Xinsheng Wang",
            "Xu Tan",
            "Jiahe Lei",
            "Yi Peng",
            "Haohe Liu",
            "Yizhu Jin",
            "Zheqi DAI",
            "Hongzhan Lin",
            "Jianyi Chen",
            "Xingjian Du",
            "Liumeng Xue",
            "Yunlin Chen",
            "Zhifei Li",
            "Lei Xie",
            "Qiuqiang Kong",
            "Yike Guo",
            "Wei Xue"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04128",
        "abstract": "Recent advances in text-based large language models (LLMs), particularly in the GPT series and the o1 model, have demonstrated the effectiveness of scaling both training-time and inference-time compute. However, current state-of-the-art TTS systems leveraging LLMs are often multi-stage, requiring separate models (e.g., diffusion models after LLM), complicating the decision of whether to scale a particular model during training or testing. This work makes the following contributions: First, we explore the scaling of train-time and inference-time compute for speech synthesis. Second, we propose a simple framework Llasa for speech synthesis that employs a single-layer vector quantizer (VQ) codec and a single Transformer architecture to fully align with standard LLMs such as Llama. Our experiments reveal that scaling train-time compute for Llasa consistently improves the naturalness of synthesized speech and enables the generation of more complex and accurate prosody patterns. Furthermore, from the perspective of scaling inference-time compute, we employ speech understanding models as verifiers during the search, finding that scaling inference-time compute shifts the sampling modes toward the preferences of specific verifiers, thereby improving emotional expressiveness, timbre consistency, and content accuracy. In addition, we released the checkpoint and training code for our TTS model (1B, 3B, 8B) and codec model publicly available.",
        "tags": [
            "Diffusion",
            "GPT",
            "LLMs",
            "LLaMA",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "128",
        "title": "Expanding Training Data for Endoscopic Phenotyping of Eosinophilic Esophagitis",
        "author": [
            "Juming Xiong",
            "Hou Xiong",
            "Quan Liu",
            "Ruining Deng",
            "Regina N Tyree",
            "Girish Hiremath",
            "Yuankai Huo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.04199",
        "abstract": "Eosinophilic esophagitis (EoE) is a chronic esophageal disorder marked by eosinophil-dominated inflammation. Diagnosing EoE usually involves endoscopic inspection of the esophageal mucosa and obtaining esophageal biopsies for histologic confirmation. Recent advances have seen AI-assisted endoscopic imaging, guided by the EREFS system, emerge as a potential alternative to reduce reliance on invasive histological assessments. Despite these advancements, significant challenges persist due to the limited availability of data for training AI models - a common issue even in the development of AI for more prevalent diseases. This study seeks to improve the performance of deep learning-based EoE phenotype classification by augmenting our training data with a diverse set of images from online platforms, public datasets, and electronic textbooks increasing our dataset from 435 to 7050 images. We utilized the Data-efficient Image Transformer for image classification and incorporated attention map visualizations to boost interpretability. The findings show that our expanded dataset and model enhancements improved diagnostic accuracy, robustness, and comprehensive analysis, enhancing patient outcomes.",
        "tags": [
            "Transformer"
        ]
    }
]