[
    {
        "id": "1",
        "title": "Reconstructing 3D Flow from 2D Data with Diffusion Transformer",
        "author": [
            "Fan Lei"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02593",
        "abstract": "Fluid flow is a widely applied physical problem, crucial in various fields. Due to the highly nonlinear and chaotic nature of fluids, analyzing fluid-related problems is exceptionally challenging. Computational fluid dynamics (CFD) is the best tool for this analysis but involves significant computational resources, especially for 3D simulations, which are slow and resource-intensive. In experimental fluid dynamics, PIV cost increases with dimensionality. Reconstructing 3D flow fields from 2D PIV data could reduce costs and expand application scenarios. Here, We propose a Diffusion Transformer-based method for reconstructing 3D flow fields from 2D flow data. By embedding the positional information of 2D planes into the model, we enable the reconstruction of 3D flow fields from any combination of 2D slices, enhancing flexibility. We replace global attention with window and plane attention to reduce computational costs associated with higher dimensions without compromising performance. Our experiments demonstrate that our model can efficiently and accurately reconstruct 3D flow fields from 2D data, producing realistic results.",
        "tags": [
            "3D",
            "Diffusion",
            "Diffusion Transformer",
            "Transformer"
        ]
    },
    {
        "id": "2",
        "title": "MIND: Microstructure INverse Design with Generative Hybrid Neural Representation",
        "author": [
            "Tianyang Xue",
            "Haochen Li",
            "Longdu Liu",
            "Paul Henderson",
            "Pengbin Tang",
            "Lin Lu",
            "Jikai Liu",
            "Haisen Zhao",
            "Hao Peng",
            "Bernd Bickel"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02607",
        "abstract": "The inverse design of microstructures plays a pivotal role in optimizing metamaterials with specific, targeted physical properties. While traditional forward design methods are constrained by their inability to explore the vast combinatorial design space, inverse design offers a compelling alternative by directly generating structures that fulfill predefined performance criteria. However, achieving precise control over both geometry and material properties remains a significant challenge due to their intricate interdependence. Existing approaches, which typically rely on voxel or parametric representations, often limit design flexibility and structural diversity. In this work, we present a novel generative model that integrates latent diffusion with Holoplane, an advanced hybrid neural representation that simultaneously encodes both geometric and physical properties. This combination ensures superior alignment between geometry and properties. Our approach generalizes across multiple microstructure classes, enabling the generation of diverse, tileable microstructures with significantly improved property accuracy and enhanced control over geometric validity, surpassing the performance of existing methods. We introduce a multi-class dataset encompassing a variety of geometric morphologies, including truss, shell, tube, and plate structures, to train and validate our model. Experimental results demonstrate the model's ability to generate microstructures that meet target properties, maintain geometric validity, and integrate seamlessly into complex assemblies. Additionally, we explore the potential of our framework through the generation of new microstructures, cross-class interpolation, and the infilling of heterogeneous microstructures. The dataset and source code will be open-sourced upon publication.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "3",
        "title": "Secure & Personalized Music-to-Video Generation via CHARCHA",
        "author": [
            "Mehul Agarwal",
            "Gauri Agarwal",
            "Santiago Benoit",
            "Andrew Lippman",
            "Jean Oh"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02610",
        "abstract": "Music is a deeply personal experience and our aim is to enhance this with a fully-automated pipeline for personalized music video generation. Our work allows listeners to not just be consumers but co-creators in the music video generation process by creating personalized, consistent and context-driven visuals based on lyrics, rhythm and emotion in the music. The pipeline combines multimodal translation and generation techniques and utilizes low-rank adaptation on listeners' images to create immersive music videos that reflect both the music and the individual. To ensure the ethical use of users' identity, we also introduce CHARCHA (patent pending), a facial identity verification protocol that protects people against unauthorized use of their face while at the same time collecting authorized images from users for personalizing their videos. This paper thus provides a secure and innovative framework for creating deeply personalized music videos.",
        "tags": [
            "Low-Rank Adaptation",
            "Video Generation"
        ]
    },
    {
        "id": "4",
        "title": "PolarQuant: Quantizing KV Caches with Polar Transformation",
        "author": [
            "Insu Han",
            "Praneeth Kacham",
            "Amin Karbasi",
            "Vahab Mirrokni",
            "Amir Zandieh"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02617",
        "abstract": "Large language models (LLMs) require significant memory to store Key-Value (KV) embeddings in their KV cache, especially when handling long-range contexts. Quantization of these KV embeddings is a common technique to reduce memory consumption. This work introduces PolarQuant, a novel quantization method employing random preconditioning and polar transformation. Our method transforms the KV embeddings into polar coordinates using an efficient recursive algorithm and then quantizes resulting angles. Our key insight is that, after random preconditioning, the angles in the polar representation exhibit a tightly bounded and highly concentrated distribution with an analytically computable form. This nice distribution eliminates the need for explicit normalization, a step required by traditional quantization methods which introduces significant memory overhead because quantization parameters (e.g., zero point and scale) must be stored in full precision per each data block. PolarQuant bypasses this normalization step, enabling substantial memory savings. The long-context evaluation demonstrates that PolarQuant compresses the KV cache by over x4.2 while achieving the best quality scores compared to the state-of-the-art methods.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "5",
        "title": "e-SimFT: Alignment of Generative Models with Simulation Feedback for Pareto-Front Design Exploration",
        "author": [
            "Hyunmin Cheong",
            "Mohammadmehdi Ataei",
            "Amir Hosein Khasahmadi",
            "Pradeep Kumar Jayaraman"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02628",
        "abstract": "Deep generative models have recently shown success in solving complex engineering design problems where models predict solutions that address the design requirements specified as input. However, there remains a challenge in aligning such models for effective design exploration. For many design problems, finding a solution that meets all the requirements is infeasible. In such a case, engineers prefer to obtain a set of Pareto optimal solutions with respect to those requirements, but uniform sampling of generative models may not yield a useful Pareto front. To address this gap, we introduce a new framework for Pareto-front design exploration with simulation fine-tuned generative models. First, the framework adopts preference alignment methods developed for Large Language Models (LLMs) and showcases the first application in fine-tuning a generative model for engineering design. The important distinction here is that we use a simulator instead of humans to provide accurate and scalable feedback. Next, we propose epsilon-sampling, inspired by the epsilon-constraint method used for Pareto-front generation with classical optimization algorithms, to construct a high-quality Pareto front with the fine-tuned models. Our framework, named e-SimFT, is shown to produce better-quality Pareto fronts than existing multi-objective alignment methods.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "6",
        "title": "SiLVR: Scalable Lidar-Visual Radiance Field Reconstruction with Uncertainty Quantification",
        "author": [
            "Yifu Tao",
            "Maurice Fallon"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02657",
        "abstract": "We present a neural radiance field (NeRF) based large-scale reconstruction system that fuses lidar and vision data to generate high-quality reconstructions that are geometrically accurate and capture photorealistic texture. Our system adopts the state-of-the-art NeRF representation to additionally incorporate lidar. Adding lidar data adds strong geometric constraints on the depth and surface normals, which is particularly useful when modelling uniform texture surfaces which contain ambiguous visual reconstruction cues. Furthermore, we estimate the epistemic uncertainty of the reconstruction as the spatial variance of each point location in the radiance field given the sensor observations from camera and lidar. This enables the identification of areas that are reliably reconstructed by each sensor modality, allowing the map to be filtered according to the estimated uncertainty. Our system can also exploit the trajectory produced by a real-time pose-graph lidar SLAM system during online mapping to bootstrap a (post-processed) Structure-from-Motion (SfM) reconstruction procedure reducing SfM training time by up to 70%. It also helps to properly constrain the overall metric scale which is essential for the lidar depth loss. The globally-consistent trajectory can then be divided into submaps using Spectral Clustering to group sets of co-visible images together. This submapping approach is more suitable for visual reconstruction than distance-based partitioning. Each submap is filtered according to point-wise uncertainty estimates and merged to obtain the final large-scale 3D reconstruction. We demonstrate the reconstruction system using a multi-camera, lidar sensor suite in experiments involving both robot-mounted and handheld scanning. Our test datasets cover a total area of more than 20,000 square metres, including multiple university buildings and an aerial survey of a multi-storey.",
        "tags": [
            "3D",
            "NeRF",
            "Robot",
            "SLAM"
        ]
    },
    {
        "id": "7",
        "title": "A Training-Free Length Extrapolation Approach for LLMs: Greedy Attention Logit Interpolation (GALI)",
        "author": [
            "Yan Li",
            "Tianyi Zhang",
            "Zechuan Li",
            "Soyeon Caren Han"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02659",
        "abstract": "Transformer-based Large Language Models (LLMs) struggle to process inputs exceeding their training context window, with performance degrading due to positional out-of-distribution (O.O.D.) that disrupt attention computations. Existing solutions, fine-tuning and training-free methods, are limited by computational inefficiency, attention logit outliers or loss of local positional information. To address this, we propose Greedy Attention Logit Interpolation (GALI), a training-free length extrapolation method that maximizes the utilization of pretrained positional intervals while avoiding attention logit outliers through attention logit interpolation. The result demonstrates that GALI consistently outperforms state-of-the-art training-free methods. Our findings reveal that LLMs interpret positional intervals unevenly within their training context window, suggesting that extrapolating within a smaller positional interval range yields superior results-even for short-context tasks. GALI represents a significant step toward resolving the positional O.O.D. challenge, enabling more reliable long-text understanding in LLMs. Our implementation of GALI, along with the experiments from our paper, is open-sourced at https://github.com/AcademyCityL/GALI.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "8",
        "title": "Deep Reinforcement Learning Enabled Persistent Surveillance with Energy-Aware UAV-UGV Systems for Disaster Management Applications",
        "author": [
            "Md Safwan Mondal",
            "Subramanian Ramasamy",
            "Pranav Bhounsule"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02666",
        "abstract": "Integrating Unmanned Aerial Vehicles (UAVs) with Unmanned Ground Vehicles (UGVs) provides an effective solution for persistent surveillance in disaster management. UAVs excel at covering large areas rapidly, but their range is limited by battery capacity. UGVs, though slower, can carry larger batteries for extended missions. By using UGVs as mobile recharging stations, UAVs can extend mission duration through periodic refueling, leveraging the complementary strengths of both systems. To optimize this energy-aware UAV-UGV cooperative routing problem, we propose a planning framework that determines optimal routes and recharging points between a UAV and a UGV. Our solution employs a deep reinforcement learning (DRL) framework built on an encoder-decoder transformer architecture with multi-head attention mechanisms. This architecture enables the model to sequentially select actions for visiting mission points and coordinating recharging rendezvous between the UAV and UGV. The DRL model is trained to minimize the age periods (the time gap between consecutive visits) of mission points, ensuring effective surveillance. We evaluate the framework across various problem sizes and distributions, comparing its performance against heuristic methods and an existing learning-based model. Results show that our approach consistently outperforms these baselines in both solution quality and runtime. Additionally, we demonstrate the DRL policy's applicability in a real-world disaster scenario as a case study and explore its potential for online mission planning to handle dynamic changes. Adapting the DRL policy for priority-driven surveillance highlights the model's generalizability for real-time disaster response.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "9",
        "title": "Exploring LLMs Impact on Student-Created User Stories and Acceptance Testing in Software Development",
        "author": [
            "Allan Brockenbrough",
            "Henry Feild",
            "Dominic Salinas"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02675",
        "abstract": "In Agile software development methodology, a user story describes a new feature or functionality from an end user's perspective. The user story details may also incorporate acceptance testing criteria, which can be developed through negotiation with users. When creating stories from user feedback, the software engineer may maximize their usefulness by considering story attributes, including scope, independence, negotiability, and testability. This study investigates how LLMs (large language models), with guided instructions, affect undergraduate software engineering students' ability to transform user feedback into user stories. Students, working individually, were asked to analyze user feedback comments, appropriately group related items, and create user stories following the principles of INVEST, a framework for assessing user stories. We found that LLMs help students develop valuable stories with well-defined acceptance criteria. However, students tend to perform better without LLMs when creating user stories with an appropriate scope.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "10",
        "title": "Building Bridges between Users and Content across Multiple Platforms during Natural Disasters",
        "author": [
            "Lynnette Hui Xian Ng",
            "Iain J. Cruickshank",
            "David Farr"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02681",
        "abstract": "Social media is a primary medium for information diffusion during natural disasters. The social media ecosystem has been used to identify destruction, analyze opinions and organize aid. While the overall picture and aggregate trends may be important, a crucial part of the picture is the connections on these sites. These bridges are essential to facilitate information flow within the network. In this work, we perform a multi-platform analysis (X, Reddit, YouTube) of Hurricanes Helene and Milton, which occurred in quick session to each other in the US in late 2024. We construct network graphs to understand the properties of effective bridging content and users. We find that bridges tend to exist on X, that bridging content is complex, and that bridging users have relatable affiliations related to gender, race and job. Public organizations can use these characteristics to manage their social media personas during natural disasters more effectively.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "11",
        "title": "Controllable Video Generation with Provable Disentanglement",
        "author": [
            "Yifan Shen",
            "Peiyuan Zhu",
            "Zijian Li",
            "Shaoan Xie",
            "Zeyu Tang",
            "Namrata Deka",
            "Zongfang Liu",
            "Guangyi Chen",
            "Kun Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02690",
        "abstract": "Controllable video generation remains a significant challenge, despite recent advances in generating high-quality and consistent videos. Most existing methods for controlling video generation treat the video as a whole, neglecting intricate fine-grained spatiotemporal relationships, which limits both control precision and efficiency. In this paper, we propose Controllable Video Generative Adversarial Networks (CoVoGAN) to disentangle the video concepts, thus facilitating efficient and independent control over individual concepts. Specifically, following the minimal change principle, we first disentangle static and dynamic latent variables. We then leverage the sufficient change property to achieve component-wise identifiability of dynamic latent variables, enabling independent control over motion and identity. To establish the theoretical foundation, we provide a rigorous analysis demonstrating the identifiability of our approach. Building on these theoretical insights, we design a Temporal Transition Module to disentangle latent dynamics. To enforce the minimal change principle and sufficient change property, we minimize the dimensionality of latent dynamic variables and impose temporal conditional independence. To validate our approach, we integrate this module as a plug-in for GANs. Extensive qualitative and quantitative experiments on various video generation benchmarks demonstrate that our method significantly improves generation quality and controllability across diverse real-world scenarios.",
        "tags": [
            "Video Generation"
        ]
    },
    {
        "id": "12",
        "title": "Developing multilingual speech synthesis system for Ojibwe, Mi'kmaq, and Maliseet",
        "author": [
            "Shenran Wang",
            "Changbing Yang",
            "Mike Parkhill",
            "Chad Quinn",
            "Christopher Hammerly",
            "Jian Zhu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02703",
        "abstract": "We present lightweight flow matching multilingual text-to-speech (TTS) systems for Ojibwe, Mi'kmaq, and Maliseet, three Indigenous languages in North America. Our results show that training a multilingual TTS model on three typologically similar languages can improve the performance over monolingual models, especially when data are scarce. Attention-free architectures are highly competitive with self-attention architecture with higher memory efficiency. Our research not only advances technical development for the revitalization of low-resource languages but also highlights the cultural gap in human evaluation protocols, calling for a more community-centered approach to human evaluation.",
        "tags": [
            "Flow Matching"
        ]
    },
    {
        "id": "13",
        "title": "An Analysis of LLM Fine-Tuning and Few-Shot Learning for Flaky Test Detection and Classification",
        "author": [
            "Riddhi More",
            "Jeremy S. Bradbury"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02715",
        "abstract": "Flaky tests exhibit non-deterministic behavior during execution and they may pass or fail without any changes to the program under test. Detecting and classifying these flaky tests is crucial for maintaining the robustness of automated test suites and ensuring the overall reliability and confidence in the testing. However, flaky test detection and classification is challenging due to the variability in test behavior, which can depend on environmental conditions and subtle code interactions. Large Language Models (LLMs) offer promising approaches to address this challenge, with fine-tuning and few-shot learning (FSL) emerging as viable techniques. With enough data fine-tuning a pre-trained LLM can achieve high accuracy, making it suitable for organizations with more resources. Alternatively, we introduce FlakyXbert, an FSL approach that employs a Siamese network architecture to train efficiently with limited data. To understand the performance and cost differences between these two methods, we compare fine-tuning on larger datasets with FSL in scenarios restricted by smaller datasets. Our evaluation involves two existing flaky test datasets, FlakyCat and IDoFT. Our results suggest that while fine-tuning can achieve high accuracy, FSL provides a cost-effective approach with competitive accuracy, which is especially beneficial for organizations or projects with limited historical data available for training. These findings underscore the viability of both fine-tuning and FSL in flaky test detection and classification with each suited to different organizational needs and resource availability.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "14",
        "title": "A Unified Understanding and Evaluation of Steering Methods",
        "author": [
            "Shawn Im",
            "Yixuan Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02716",
        "abstract": "Steering methods provide a practical approach to controlling large language models by applying steering vectors to intermediate activations, guiding outputs toward desired behaviors while avoiding retraining. Despite their growing importance, the field lacks a unified understanding and consistent evaluation across tasks and datasets, hindering progress. This paper introduces a unified framework for analyzing and evaluating steering methods, formalizing their core principles and offering theoretical insights into their effectiveness. Through comprehensive empirical evaluations on multiple-choice and open-ended text generation tasks, we validate these insights, identifying key factors that influence performance and demonstrating the superiority of certain methods. Our work bridges theoretical and practical perspectives, offering actionable guidance for advancing the design, optimization, and deployment of steering methods in LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "15",
        "title": "Dobi-SVD: Differentiable SVD for LLM Compression and Some New Perspectives",
        "author": [
            "Qinsi Wang",
            "Jinghan Ke",
            "Masayoshi Tomizuka",
            "Yiran Chen",
            "Kurt Keutzer",
            "Chenfeng Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02723",
        "abstract": "We provide a new LLM-compression solution via SVD, unlocking new possibilities for LLM compression beyond quantization and pruning. We point out that the optimal use of SVD lies in truncating activations, rather than merely using activations as an optimization distance. Building on this principle, we address three critical challenges in SVD-based LLM compression: including (1) How can we determine the optimal activation truncation position for each weight matrix in LLMs? (2) How can we efficiently reconstruct the weight matrices based on truncated activations? (3) How can we address the inherent \"injection\" nature that results in the information loss of the SVD? We propose Dobi-SVD, which establishes a new, principled approach to SVD-based LLM compression.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "16",
        "title": "Peri-LN: Revisiting Layer Normalization in the Transformer Architecture",
        "author": [
            "Jeonghoon Kim",
            "Byeongchan Lee",
            "Cheonbok Park",
            "Yeontaek Oh",
            "Beomjun Kim",
            "Taehwan Yoo",
            "Seongjin Shin",
            "Dongyoon Han",
            "Jinwoo Shin",
            "Kang Min Yoo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02732",
        "abstract": "Designing Transformer architectures with the optimal layer normalization (LN) strategy that ensures large-scale training stability and expedite convergence has remained elusive, even in this era of large language models (LLMs). To this end, we present a comprehensive analytical foundation for understanding how different LN strategies influence training dynamics in large-scale Transformer training. Until recently, Pre-LN and Post-LN have long dominated standard practices despite their limitations in large-scale training. However, several open-source large-scale models have recently begun silently adopting a third strategy without much explanation. This strategy places layer normalization (LN) peripherally around sublayers, a design we term Peri-LN. While Peri-LN has demonstrated promising empirical performance, its precise mechanisms and benefits remain almost unexplored. Our in-depth analysis shows that Peri-LN strikes an ideal balance in variance growth -- unlike Pre-LN and Post-LN, which are prone to vanishing gradients and ``massive activations.'' To validate our theoretical insight, we conduct large-scale experiments on Transformers up to 3.2B parameters, showing that Peri-LN consistently achieves more balanced variance growth, steadier gradient flow, and convergence stability. Our results suggest that Peri-LN warrants broader consideration for large-scale Transformer architectures, providing renewed insights into the optimal placement and application of LN.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "17",
        "title": "SmolLM2: When Smol Goes Big -- Data-Centric Training of a Small Language Model",
        "author": [
            "Loubna Ben Allal",
            "Anton Lozhkov",
            "Elie Bakouch",
            "Gabriel MartÃ­n BlÃ¡zquez",
            "Guilherme Penedo",
            "Lewis Tunstall",
            "AndrÃ©s Marafioti",
            "Hynek KydlÃ­Äek",
            "AgustÃ­n Piqueres LajarÃ­n",
            "Vaibhav Srivastav",
            "Joshua Lochner",
            "Caleb Fahlgren",
            "Xuan-Son Nguyen",
            "ClÃ©mentine Fourrier",
            "Ben Burtenshaw",
            "Hugo Larcher",
            "Haojun Zhao",
            "Cyril Zakka",
            "Mathieu Morlon",
            "Colin Raffel",
            "Leandro von Werra",
            "Thomas Wolf"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02737",
        "abstract": "While large language models have facilitated breakthroughs in many applications of artificial intelligence, their inherent largeness makes them computationally expensive and challenging to deploy in resource-constrained settings. In this paper, we document the development of SmolLM2, a state-of-the-art \"small\" (1.7 billion parameter) language model (LM). To attain strong performance, we overtrain SmolLM2 on ~11 trillion tokens of data using a multi-stage training process that mixes web text with specialized math, code, and instruction-following data. We additionally introduce new specialized datasets (FineMath, Stack-Edu, and SmolTalk) at stages where we found existing datasets to be problematically small or low-quality. To inform our design decisions, we perform both small-scale ablations as well as a manual refinement process that updates the dataset mixing rates at each stage based on the performance at the previous stage. Ultimately, we demonstrate that SmolLM2 outperforms other recent small LMs including Qwen2.5-1.5B and Llama3.2-1B. To facilitate future research on LM development as well as applications of small LMs, we release both SmolLM2 as well as all of the datasets we prepared in the course of this project.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "18",
        "title": "LLM Bandit: Cost-Efficient LLM Generation via Preference-Conditioned Dynamic Routing",
        "author": [
            "Yang Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02743",
        "abstract": "The rapid advancement in large language models (LLMs) has brought forth a diverse range of models with varying capabilities that excel in different tasks and domains. However, selecting the optimal LLM for user queries often involves a challenging trade-off between accuracy and cost, a problem exacerbated by the diverse demands of individual queries. In this work, we present a novel framework that formulates the LLM selection process as a multi-armed bandit problem, enabling dynamic and intelligent routing of queries to the most appropriate model. Our approach incorporates a preference-conditioned dynamic routing mechanism, allowing users to specify their preferences at inference time, thereby offering a customizable balance between performance and cost. Additionally, our selection policy is designed to generalize to unseen LLMs, ensuring adaptability to new models as they emerge. Experimental results demonstrate that our method achieves significant improvements in both accuracy and cost-effectiveness across various LLM platforms, showcasing the potential of our framework to adaptively optimize LLM selection in real-world scenarios.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "19",
        "title": "PatchPilot: A Stable and Cost-Efficient Agentic Patching Framework",
        "author": [
            "Hongwei Li",
            "Yuheng Tang",
            "Shiqi Wang",
            "Wenbo Guo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02747",
        "abstract": "Recent research builds various patching agents that combine large language models (LLMs) with non-ML tools and achieve promising results on the state-of-the-art (SOTA) software patching benchmark, SWE-Bench. Based on how to determine the patching workflows, existing patching agents can be categorized as agent-based planning methods, which rely on LLMs for planning, and human-based planning methods, which follow a pre-defined workflow. At a high level, agent-based planning methods achieve high patching performance but with a high cost and limited stability. Human-based planning methods, on the other hand, are more stable and efficient but have key workflow limitations that compromise their patching performance. In this paper, we propose PatchPilot, an agentic patcher that strikes a balance between patching efficacy, stability, and cost-efficiency. PatchPilot proposes a novel human-based planning workflow with five components: reproduction, localization, generation, validation, and refinement (where refinement is unique to PatchPilot). We introduce novel and customized designs to each component to optimize their effectiveness and efficiency. Through extensive experiments on the SWE-Bench benchmarks, PatchPilot shows a superior performance than existing open-source methods while maintaining low cost (less than 1$ per instance) and ensuring higher stability. We also conduct a detailed ablation study to validate the key designs in each component.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "20",
        "title": "MuST: Multi-Head Skill Transformer for Long-Horizon Dexterous Manipulation with Skill Progress",
        "author": [
            "Kai Gao",
            "Fan Wang",
            "Erica Aduh",
            "Dylan Randle",
            "Jane Shi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02753",
        "abstract": "Robot picking and packing tasks require dexterous manipulation skills, such as rearranging objects to establish a good grasping pose, or placing and pushing items to achieve tight packing. These tasks are challenging for robots due to the complexity and variability of the required actions. To tackle the difficulty of learning and executing long-horizon tasks, we propose a novel framework called the Multi-Head Skill Transformer (MuST). This model is designed to learn and sequentially chain together multiple motion primitives (skills), enabling robots to perform complex sequences of actions effectively. MuST introduces a \"progress value\" for each skill, guiding the robot on which skill to execute next and ensuring smooth transitions between skills. Additionally, our model is capable of expanding its skill set and managing various sequences of sub-tasks efficiently. Extensive experiments in both simulated and real-world environments demonstrate that MuST significantly enhances the robot's ability to perform long-horizon dexterous manipulation tasks.",
        "tags": [
            "Robot",
            "Transformer"
        ]
    },
    {
        "id": "21",
        "title": "Too Noisy To Learn: Enhancing Data Quality for Code Review C",
        "author": [
            "Chunhua Liu",
            "Hong Yi Lin",
            "Patanamon Thongtanunam"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02757",
        "abstract": "Code review is an important practice in software development, yet it is time-consuming and requires substantial effort. While open-source datasets have been used to train neural models for automating code review tasks, including review comment generation, these datasets contain a significant amount of noisy comments (e.g., vague or non-actionable feedback) that persist despite cleaning methods using heuristics and machine learning approaches. Such remaining noise may lead models to generate low-quality review comments, yet removing them requires a complex semantic understanding of both code changes and natural language comments. In this paper, we investigate the impact of such noise on review comment generation and propose a novel approach using large language models (LLMs) to further clean these datasets. Based on an empirical study on a large-scale code review dataset, our LLM-based approach achieves 66-85% precision in detecting valid comments. Using the predicted valid comments to fine-tune the state-of-the-art code review models (cleaned models) can generate review comments that are 13.0% - 12.4% more similar to valid human-written comments than the original models. We also find that the cleaned models can generate more informative and relevant comments than the original models. Our findings underscore the critical impact of dataset quality on the performance of review comment generation. We advocate for further research into cleaning training data to enhance the practical utility and quality of automated code review.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "22",
        "title": "Rethinking Vision Transformer for Object Centric Foundation Models",
        "author": [
            "Manuel Traub",
            "Martin V. Butz"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02763",
        "abstract": "Recent state-of-the-art object segmentation mechanisms, such as the Segment Anything Model (SAM) and FastSAM, first encode the full image over several layers and then focus on generating the mask for one particular object or area. We present an off-grid Fovea-Like Input Patching (FLIP) approach, which selects image input and encodes it from the beginning in an object-focused manner. While doing so, it separates locational encoding from an object-centric perceptual code. FLIP is more data-efficient and yields improved segmentation performance when masking relatively small objects in high-resolution visual scenes. On standard benchmarks such as Hypersim, KITTI-360, and OpenImages, FLIP achieves Intersection over Union (IoU) scores that approach the performance of SAM with much less compute effort. It surpasses FastSAM in all IoU measurements. We also introduce an additional semi-natural but highly intuitive dataset where FLIP outperforms SAM and FastSAM overall and particularly on relatively small objects. Seeing that FLIP is an end-to-end object-centric segmentation approach, it has high potential particularly for applications that benefit from computationally efficient, spatially highly selective object tracking.",
        "tags": [
            "SAM",
            "Segment Anything",
            "Segmentation",
            "Transformer"
        ]
    },
    {
        "id": "23",
        "title": "LLM-USO: Large Language Model-based Universal Sizing Optimizer",
        "author": [
            "Karthik Somayaji N.S",
            "Peng Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02764",
        "abstract": "The design of analog circuits is a cornerstone of integrated circuit (IC) development, requiring the optimization of complex, interconnected sub-structures such as amplifiers, comparators, and buffers. Traditionally, this process relies heavily on expert human knowledge to refine design objectives by carefully tuning sub-components while accounting for their interdependencies. Existing methods, such as Bayesian Optimization (BO), offer a mathematically driven approach for efficiently navigating large design spaces. However, these methods fall short in two critical areas compared to human expertise: (i) they lack the semantic understanding of the sizing solution space and its direct correlation with design objectives before optimization, and (ii) they fail to reuse knowledge gained from optimizing similar sub-structures across different circuits. To overcome these limitations, we propose the Large Language Model-based Universal Sizing Optimizer (LLM-USO), which introduces a novel method for knowledge representation to encode circuit design knowledge in a structured text format. This representation enables the systematic reuse of optimization insights for circuits with similar sub-structures. LLM-USO employs a hybrid framework that integrates BO with large language models (LLMs) and a learning summary module. This approach serves to: (i) infuse domain-specific knowledge into the BO process and (ii) facilitate knowledge transfer across circuits, mirroring the cognitive strategies of expert designers. Specifically, LLM-USO constructs a knowledge summary mechanism to distill and apply design insights from one circuit to related ones. It also incorporates a knowledge summary critiquing mechanism to ensure the accuracy and quality of the summaries and employs BO-guided suggestion filtering to identify optimal design points efficiently.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "24",
        "title": "Twilight: Adaptive Attention Sparsity with Hierarchical Top-$p$ Pruning",
        "author": [
            "Chaofan Lin",
            "Jiaming Tang",
            "Shuo Yang",
            "Hanshuo Wang",
            "Tian Tang",
            "Boyu Tian",
            "Ion Stoica",
            "Song Han",
            "Mingyu Gao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02770",
        "abstract": "Leveraging attention sparsity to accelerate long-context large language models (LLMs) has been a hot research topic. However, current algorithms such as sparse attention or key-value (KV) cache compression tend to use a fixed budget, which presents a significant challenge during deployment because it fails to account for the dynamic nature of real-world scenarios, where the optimal balance between accuracy and efficiency can vary greatly. In this paper, we find that borrowing top-$p$ sampling (nucleus sampling) to sparse attention can surprisingly achieve adaptive budgeting. Based on this, we propose Twilight, a framework to bring adaptive sparsity to any existing sparse attention algorithm without sacrificing their accuracy. Empirical results show that Twilight can adaptively prune at most 98% of redundant tokens, leading to $15.4\\times$ acceleration in self-attention operations and $3.9\\times$ acceleration in end-to-end per token latency in long context LLM decoding.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "25",
        "title": "SD++: Enhancing Standard Definition Maps by Incorporating Road Knowledge using LLMs",
        "author": [
            "Hitvarth Diwanji",
            "Jing-Yan Liao",
            "Akshar Tumu",
            "Henrik I. Christensen",
            "Marcell Vazquez-Chanlatte",
            "Chikao Tsuchiya"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02773",
        "abstract": "High-definition maps (HD maps) are detailed and informative maps capturing lane centerlines and road elements. Although very useful for autonomous driving, HD maps are costly to build and maintain. Furthermore, access to these high-quality maps is usually limited to the firms that build them. On the other hand, standard definition (SD) maps provide road centerlines with an accuracy of a few meters. In this paper, we explore the possibility of enhancing SD maps by incorporating information from road manuals using LLMs. We develop SD++, an end-to-end pipeline to enhance SD maps with location-dependent road information obtained from a road manual. We suggest and compare several ways of using LLMs for such a task. Furthermore, we show the generalization ability of SD++ by showing results from both California and Japan.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "26",
        "title": "Classroom Simulacra: Building Contextual Student Generative Agents in Online Education for Learning Behavioral Simulation",
        "author": [
            "Songlin Xu",
            "Hao-Ning Wen",
            "Hongyi Pan",
            "Dallas Dominguez",
            "Dongyin Hu",
            "Xinyu Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02780",
        "abstract": "Student simulation supports educators to improve teaching by interacting with virtual students. However, most existing approaches ignore the modulation effects of course materials because of two challenges: the lack of datasets with granularly annotated course materials, and the limitation of existing simulation models in processing extremely long textual data. To solve the challenges, we first run a 6-week education workshop from N = 60 students to collect fine-grained data using a custom built online education system, which logs students' learning behaviors as they interact with lecture materials over time. Second, we propose a transferable iterative reflection (TIR) module that augments both prompting-based and finetuning-based large language models (LLMs) for simulating learning behaviors. Our comprehensive experiments show that TIR enables the LLMs to perform more accurate student simulation than classical deep learning models, even with limited demonstration data. Our TIR approach better captures the granular dynamism of learning performance and inter-student correlations in classrooms, paving the way towards a ''digital twin'' for online education.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "27",
        "title": "Runway capacity expansion planning for public airports under demand uncertainty",
        "author": [
            "Ziyue Li",
            "Joseph Y.J. Chow",
            "Qianwen Guo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02783",
        "abstract": "Flight delay is a significant issue affecting air travel. The runway system, frequently falling short of demand, serves as a bottleneck. As demand increases, runway capacity expansion becomes imperative to mitigate congestion. However, the decision to expand runway capacity is challenging due to inherent uncertainties in demand forecasts. This paper presents a novel approach to modeling air traffic demand growth as a jump diffusion process, incorporating two layers of uncertainty: Geometric Brownian Motion (GBM) for continuous variability and a Poisson process to capture the impact of crisis events, such as natural disasters or public health emergencies, on decision-making. We propose a real options model to jointly evaluate the interrelated factors of optimal runway capacity and investment timing under uncertainty, with investment timing linked to trigger demand. The findings suggest that increased uncertainty indicates more conservative decision-making. Furthermore, the relationship between optimal investment timing and expansion size is complex: if the expansion size remains unchanged, the trigger demand decreases as the demand growth rate increases; if the expansion size experiences a jump, the trigger demand also exhibits a sharp rise. This work provides valuable insights for airport authorities for informed capacity expansion decision-making.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "28",
        "title": "SimMark: A Robust Sentence-Level Similarity-Based Watermarking Algorithm for Large Language Models",
        "author": [
            "Amirhossein Dabiriaghdam",
            "Lele Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02787",
        "abstract": "The rapid proliferation of large language models (LLMs) has created an urgent need for reliable methods to detect whether a text is generated by such models. In this paper, we propose SimMark, a posthoc watermarking algorithm that makes LLMs' outputs traceable without requiring access to the model's internal logits, enabling compatibility with a wide range of LLMs, including API-only models. By leveraging the similarity of semantic sentence embeddings and rejection sampling to impose detectable statistical patterns imperceptible to humans, and employing a soft counting mechanism, SimMark achieves robustness against paraphrasing attacks. Experimental results demonstrate that SimMark sets a new benchmark for robust watermarking of LLM-generated content, surpassing prior sentence-level watermarking techniques in robustness, sampling efficiency, and applicability across diverse domains, all while preserving the text quality.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "29",
        "title": "Inducing Diversity in Differentiable Search Indexing",
        "author": [
            "Abhijeet Phatak",
            "Jayant Sachdev",
            "Sean D Rosario",
            "Swati Kirti",
            "Chittaranjan Tripathy"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02788",
        "abstract": "Differentiable Search Indexing (DSI) is a recent paradigm for information retrieval which uses a transformer-based neural network architecture as the document index to simplify the retrieval process. A differentiable index has many advantages enabling modifications, updates or extensions to the index. In this work, we explore balancing relevance and novel information content (diversity) for training DSI systems inspired by Maximal Marginal Relevance (MMR), and show the benefits of our approach over the naive DSI training. We present quantitative and qualitative evaluations of relevance and diversity measures obtained using our method on NQ320K and MSMARCO datasets in comparison to naive DSI. With our approach, it is possible to achieve diversity without any significant impact to relevance. Since we induce diversity while training DSI, the trained model has learned to diversify while being relevant. This obviates the need for a post-processing step to induce diversity in the recall set as typically performed using MMR. Our approach will be useful for Information Retrieval problems where both relevance and diversity are important such as in sub-topic retrieval. Our work can also be easily be extended to the incremental DSI settings which would enable fast updates to the index while retrieving a diverse recall set.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "30",
        "title": "Speculative Prefill: Turbocharging TTFT with Lightweight and Training-Free Token Importance Estimation",
        "author": [
            "Jingyu Liu",
            "Beidi Chen",
            "Ce Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02789",
        "abstract": "Improving time-to-first-token (TTFT) is an essentially important objective in modern large language model (LLM) inference engines. Because optimizing TTFT directly results in higher maximal QPS and meets the requirements of many critical applications. However, boosting TTFT is notoriously challenging since it is purely compute-bounded and the performance bottleneck shifts from the self-attention to the MLP part. We present SpecPrefill, a training free framework that accelerates the inference TTFT for both long and medium context queries based on the following insight: LLMs are generalized enough to still preserve the quality given only a carefully chosen subset of prompt tokens. At its core, SpecPrefill leverages a lightweight model to speculate locally important tokens based on the context. These tokens, along with the necessary positional information, are then sent to the main model for processing. We evaluate SpecPrefill with a diverse set of tasks, followed by a comprehensive benchmarking of performance improvement both in a real end-to-end setting and ablation studies. SpecPrefill manages to serve Llama-3.1-405B-Instruct-FP8 with up to $7\\times$ maximal end-to-end QPS on real downstream tasks and $7.66\\times$ TTFT improvement during benchmarking.",
        "tags": [
            "LLMs",
            "LLaMA"
        ]
    },
    {
        "id": "31",
        "title": "Leveraging the true depth of LLMs",
        "author": [
            "RamÃ³n Calvo GonzÃ¡lez",
            "Daniele Paliotta",
            "Matteo Pagliardini",
            "Martin Jaggi",
            "FranÃ§ois Fleuret"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02790",
        "abstract": "Large Language Models demonstrate remarkable capabilities at the cost of high compute requirements. While recent research has shown that intermediate layers can be removed or have their order shuffled without impacting performance significantly, these findings have not been employed to reduce the computational cost of inference. We investigate several potential ways to reduce the depth of pre-trained LLMs without significantly affecting performance. Leveraging our insights, we present a novel approach that exploits this decoupling between layers by grouping some of them into pairs that can be evaluated in parallel.\nThis modification of the computational graph -- through better parallelism -- results in an average improvement of around 1.20x on the number of tokens generated per second, without re-training nor fine-tuning, while retaining 95%-99% of the original accuracy. Empirical evaluation demonstrates that this approach significantly improves serving efficiency while maintaining model performance, offering a practical improvement for large-scale LLM deployment.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "32",
        "title": "Accessible and Portable LLM Inference by Compiling Computational Graphs into SQL",
        "author": [
            "Wenbo Sun",
            "Qiming Guo",
            "Wenlu Wang",
            "Rihan Hai"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02818",
        "abstract": "Serving large language models (LLMs) often demands specialized hardware, dedicated frameworks, and substantial development efforts, which restrict their accessibility, especially for edge devices and organizations with limited technical resources. We propose a novel compiler that translates LLM inference graphs into SQL queries, enabling relational databases, one of the most widely used and mature software systems globally, to serve as the runtime. By mapping neural operators such as matrix multiplication and attention into relational primitives like joins and aggregations, our approach leverages database capabilities, including disk-based data management and native caching. Supporting key transformer components, such as attention mechanisms and key-value caching, our system generates SQL pipelines for end-to-end LLM inference. Using the Llama3 family as a case study, we demonstrate up to 30x speedup in token generation for memory-constrained scenarios comparable to competitive CPU-based frameworks. Our work offers an accessible, portable, and efficient solution, facilitating the serving of LLMs across diverse deployment environments.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "33",
        "title": "COFFE: A Code Efficiency Benchmark for Code Generation",
        "author": [
            "Yun Peng",
            "Jun Wan",
            "Yichen Li",
            "Xiaoxue Ren"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02827",
        "abstract": "Code generation has largely improved development efficiency in the era of large language models (LLMs). With the ability to follow instructions, current LLMs can be prompted to generate code solutions given detailed descriptions in natural language. Many research efforts are being devoted to improving the correctness of LLM-generated code, and many benchmarks are proposed to evaluate the correctness comprehensively. Despite the focus on correctness, the time efficiency of LLM-generated code solutions is under-explored. Current correctness benchmarks are not suitable for time efficiency evaluation since their test cases cannot well distinguish the time efficiency of different code solutions. Besides, the current execution time measurement is not stable and comprehensive, threatening the validity of the time efficiency evaluation.\nTo address the challenges in the time efficiency evaluation of code generation, we propose COFFE, a code generation benchmark for evaluating the time efficiency of LLM-generated code solutions. COFFE contains 398 and 358 problems for function-level and file-level code generation, respectively. To improve the distinguishability, we design a novel stressful test case generation approach with contracts and two new formats of test cases to improve the accuracy of generation. For the time evaluation metric, we propose efficienct@k based on CPU instruction count to ensure a stable and solid comparison between different solutions. We evaluate 14 popular LLMs on COFFE and identify four findings. Based on the findings, we draw some implications for LLM researchers and software practitioners to facilitate future research and usage of LLMs in code generation.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "34",
        "title": "PH-VAE: A Polynomial Hierarchical Variational Autoencoder Towards Disentangled Representation Learning",
        "author": [
            "Xi Chen",
            "Shaofan Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02856",
        "abstract": "The variational autoencoder (VAE) is a simple and efficient generative artificial intelligence method for modeling complex probability distributions of various types of data, such as images and texts. However, it suffers some main shortcomings, such as lack of interpretability in the latent variables, difficulties in tuning hyperparameters while training, producing blurry, unrealistic downstream outputs or loss of information due to how it calculates loss functions and recovers data distributions, overfitting, and origin gravity effect for small data sets, among other issues. These and other limitations have caused unsatisfactory generation effects for the data with complex distributions. In this work, we proposed and developed a polynomial hierarchical variational autoencoder (PH-VAE), in which we used a polynomial hierarchical date format to generate or to reconstruct the data distributions. In doing so, we also proposed a novel Polynomial Divergence in the loss function to replace or generalize the Kullback-Leibler (KL) divergence, which results in systematic and drastic improvements in both accuracy and reproducibility of the re-constructed distribution function as well as the quality of re-constructed data images while keeping the dataset size the same but capturing fine resolution of the data. Moreover, we showed that the proposed PH-VAE has some form of disentangled representation learning ability.",
        "tags": [
            "VAE"
        ]
    },
    {
        "id": "35",
        "title": "OceanChat: The Effect of Virtual Conversational AI Agents on Sustainable Attitude and Behavior Change",
        "author": [
            "Pat Pataranutaporn",
            "Alexander Doudkin",
            "Pattie Maes"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02863",
        "abstract": "Marine ecosystems face unprecedented threats from climate change and plastic pollution, yet traditional environmental education often struggles to translate awareness into sustained behavioral change. This paper presents OceanChat, an interactive system leveraging large language models to create conversational AI agents represented as animated marine creatures -- specifically a beluga whale, a jellyfish, and a seahorse -- designed to promote environmental behavior (PEB) and foster awareness through personalized dialogue. Through a between-subjects experiment (N=900), we compared three conditions: (1) Static Scientific Information, providing conventional environmental education through text and images; (2) Static Character Narrative, featuring first-person storytelling from 3D-rendered marine creatures; and (3) Conversational Character Narrative, enabling real-time dialogue with AI-powered marine characters. Our analysis revealed that the Conversational Character Narrative condition significantly increased behavioral intentions and sustainable choice preferences compared to static approaches. The beluga whale character demonstrated consistently stronger emotional engagement across multiple measures, including perceived anthropomorphism and empathy. However, impacts on deeper measures like climate policy support and psychological distance were limited, highlighting the complexity of shifting entrenched beliefs. Our work extends research on sustainability interfaces facilitating PEB and offers design principles for creating emotionally resonant, context-aware AI characters. By balancing anthropomorphism with species authenticity, OceanChat demonstrates how interactive narratives can bridge the gap between environmental knowledge and real-world behavior change.",
        "tags": [
            "3D",
            "Large Language Models"
        ]
    },
    {
        "id": "36",
        "title": "A Systematic Approach for Assessing Large Language Models' Test Case Generation Capability",
        "author": [
            "Hung-Fu Chang",
            "Mohammad Shokrolah Shirazi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02866",
        "abstract": "Software testing ensures the quality and reliability of software products, but manual test case creation is labor-intensive. With the rise of large language models (LLMs), there is growing interest in unit test creation with LLMs. However, effective assessment of LLM-generated test cases is limited by the lack of standardized benchmarks that comprehensively cover diverse programming scenarios. To address the assessment of LLM's test case generation ability and lacking dataset for evaluation, we propose the Generated Benchmark from Control-Flow Structure and Variable Usage Composition (GBCV) approach, which systematically generates programs used for evaluating LLMs' test generation capabilities. By leveraging basic control-flow structures and variable usage, GBCV provides a flexible framework to create a spectrum of programs ranging from simple to complex. Because GPT-4o and GPT-3-Turbo are publicly accessible models, to present real-world regular user's use case, we use GBCV to assess LLM performance on them. Our findings indicate that GPT-4o performs better on complex program structures, while all models effectively detect boundary values in simple conditions but face challenges with arithmetic computations. This study highlights the strengths and limitations of LLMs in test generation, provides a benchmark framework, and suggests directions for future improvement.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "37",
        "title": "Position: Multimodal Large Language Models Can Significantly Advance Scientific Reasoning",
        "author": [
            "Yibo Yan",
            "Shen Wang",
            "Jiahao Huo",
            "Jingheng Ye",
            "Zhendong Chu",
            "Xuming Hu",
            "Philip S. Yu",
            "Carla Gomes",
            "Bart Selman",
            "Qingsong Wen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02871",
        "abstract": "Scientific reasoning, the process through which humans apply logic, evidence, and critical thinking to explore and interpret scientific phenomena, is essential in advancing knowledge reasoning across diverse fields. However, despite significant progress, current scientific reasoning models still struggle with generalization across domains and often fall short of multimodal perception. Multimodal Large Language Models (MLLMs), which integrate text, images, and other modalities, present an exciting opportunity to overcome these limitations and enhance scientific reasoning. Therefore, this position paper argues that MLLMs can significantly advance scientific reasoning across disciplines such as mathematics, physics, chemistry, and biology. First, we propose a four-stage research roadmap of scientific reasoning capabilities, and highlight the current state of MLLM applications in scientific reasoning, noting their ability to integrate and reason over diverse data types. Second, we summarize the key challenges that remain obstacles to achieving MLLM's full potential. To address these challenges, we propose actionable insights and suggestions for the future. Overall, our work offers a novel perspective on MLLM integration with scientific reasoning, providing the LLM community with a valuable vision for achieving Artificial General Intelligence (AGI).",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "38",
        "title": "SensorChat: Answering Qualitative and Quantitative Questions during Long-Term Multimodal Sensor Interactions",
        "author": [
            "Xiaofan Yu",
            "Lanxiang Hu",
            "Benjamin Reichman",
            "Dylan Chu",
            "Rushil Chandrupatla",
            "Xiyuan Zhang",
            "Larry Heck",
            "Tajana Rosing"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02883",
        "abstract": "Natural language interaction with sensing systems is crucial for enabling all users to comprehend sensor data and its impact on their everyday lives. However, existing systems, which typically operate in a Question Answering (QA) manner, are significantly limited in terms of the duration and complexity of sensor data they can handle. In this work, we introduce SensorChat, the first end-to-end QA system designed for long-term sensor monitoring with multimodal and high-dimensional data including time series. SensorChat effectively answers both qualitative (requiring high-level reasoning) and quantitative (requiring accurate responses derived from sensor data) questions in real-world scenarios. To achieve this, SensorChat uses an innovative three-stage pipeline that includes question decomposition, sensor data query, and answer assembly. The first and third stages leverage Large Language Models (LLMs) for intuitive human interactions and to guide the sensor data query process. Unlike existing multimodal LLMs, SensorChat incorporates an explicit query stage to precisely extract factual information from long-duration sensor data. We implement SensorChat and demonstrate its capability for real-time interactions on a cloud server while also being able to run entirely on edge platforms after quantization. Comprehensive QA evaluations show that SensorChat achieves up to 26% higher answer accuracy than state-of-the-art systems on quantitative questions. Additionally, a user study with eight volunteers highlights SensorChat's effectiveness in handling qualitative and open-ended questions.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "39",
        "title": "Expertized Caption Auto-Enhancement for Video-Text Retrieval",
        "author": [
            "Junxiang Chen",
            "Baoyao yang",
            "Wenbin Yao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02885",
        "abstract": "The burgeoning field of video-text retrieval has witnessed significant advancements with the advent of deep learning. However, the challenge of matching text and video persists due to inadequate textual descriptions of videos. The substantial information gap between the two modalities hinders a comprehensive understanding of videos, resulting in ambiguous retrieval results. While rewriting methods based on large language models have been proposed to broaden text expressions, carefully crafted prompts are essential to ensure the reasonableness and completeness of the rewritten texts. This paper proposes an automatic caption enhancement method that enhances expression quality and mitigates empiricism in augmented captions through self-learning. Additionally, an expertized caption selection mechanism is designed and introduced to customize augmented captions for each video, facilitating video-text matching. Our method is entirely data-driven, which not only dispenses with heavy data collection and computation workload but also improves self-adaptability by circumventing lexicon dependence and introducing personalized matching. The superiority of our method is validated by state-of-the-art results on various benchmarks, specifically achieving Top-1 recall accuracy of 68.5% on MSR-VTT, 68.1% on MSVD, and 62.0% on DiDeMo.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "40",
        "title": "Lowering the Barrier of Machine Learning: Achieving Zero Manual Labeling in Review Classification Using LLMs",
        "author": [
            "Yejian Zhang",
            "Shingo Takada"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02893",
        "abstract": "With the internet's evolution, consumers increasingly rely on online reviews for service or product choices, necessitating that businesses analyze extensive customer feedback to enhance their offerings. While machine learning-based sentiment classification shows promise in this realm, its technical complexity often bars small businesses and individuals from leveraging such advancements, which may end up making the competitive gap between small and large businesses even bigger in terms of improving customer satisfaction. This paper introduces an approach that integrates large language models (LLMs), specifically Generative Pre-trained Transformer (GPT) and Bidirectional Encoder Representations from Transformers (BERT)-based models, making it accessible to a wider audience. Our experiments across various datasets confirm that our approach retains high classification accuracy without the need for manual labeling, expert knowledge in tuning and data annotation, or substantial computational power. By significantly lowering the barriers to applying sentiment classification techniques, our methodology enhances competitiveness and paves the way for making machine learning technology accessible to a broader audience.",
        "tags": [
            "BERT",
            "GPT",
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "41",
        "title": "A Benchmark for the Detection of Metalinguistic Disagreements between LLMs and Knowledge Graphs",
        "author": [
            "Bradley P. Allen",
            "Paul T. Groth"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02896",
        "abstract": "Evaluating large language models (LLMs) for tasks like fact extraction in support of knowledge graph construction frequently involves computing accuracy metrics using a ground truth benchmark based on a knowledge graph (KG). These evaluations assume that errors represent factual disagreements. However, human discourse frequently features metalinguistic disagreement, where agents differ not on facts but on the meaning of the language used to express them. Given the complexity of natural language processing and generation using LLMs, we ask: do metalinguistic disagreements occur between LLMs and KGs? Based on an investigation using the T-REx knowledge alignment dataset, we hypothesize that metalinguistic disagreement does in fact occur between LLMs and KGs, with potential relevance for the practice of knowledge graph engineering. We propose a benchmark for evaluating the detection of factual and metalinguistic disagreements between LLMs and KGs. An initial proof of concept of such a benchmark is available on Github.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "42",
        "title": "COSMosFL: Ensemble of Small Language Models for Fault Localisation",
        "author": [
            "Hyunjoon Cho",
            "Sungmin Kang",
            "Gabin An",
            "Shin Yoo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02908",
        "abstract": "LLMs are rapidly being adopted to build powerful tools and agents for software engineering, but most of them rely heavily on extremely large closed-source models. This, in turn, can hinder wider adoption due to security issues as well as financial cost and environmental impact. Recently, a number of open source Small Language Models (SLMs) are being released and gaining traction. While SLMs are smaller, more energy-efficient, and therefore easier to locally deploy, they tend to show worse performance when compared to larger closed LLMs. We present COSMos, a task-level LLM ensemble technique that uses voting mechanism, to provide a broader range of choice between SLMs and LLMs. We instantiate COSMos with an LLM-based Fault Localisation technique, AutoFL, and report the cost-benefit trade-off between LLM accuracy and various costs such as energy consumption, inference time, and the number of tokens used. An empirical evaluation using Defects4J shows that COSMos can build effective ensembles that can achieve Pareto-optimality in terms of FL accuracy and inference cost, when compared to individual models.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "43",
        "title": "SPARC: Subspace-Aware Prompt Adaptation for Robust Continual Learning in LLMs",
        "author": [
            "Dinithi Jayasuriya",
            "Sina Tayebati",
            "Davide Ettori",
            "Ranganath Krishnan",
            "Amit Ranjan Trivedi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02909",
        "abstract": "We propose SPARC, a lightweight continual learning framework for large language models (LLMs) that enables efficient task adaptation through prompt tuning in a lower-dimensional space. By leveraging principal component analysis (PCA), we identify a compact subspace of the training data. Optimizing prompts in this lower-dimensional space enhances training efficiency, as it focuses updates on the most relevant features while reducing computational overhead. Furthermore, since the model's internal structure remains unaltered, the extensive knowledge gained from pretraining is fully preserved, ensuring that previously learned information is not compromised during adaptation. Our method achieves high knowledge retention in both task-incremental and domain-incremental continual learning setups while fine-tuning only 0.04% of the model's parameters. Additionally, by integrating LoRA, we enhance adaptability to computational constraints, allowing for a tradeoff between accuracy and training cost. Experiments on the SuperGLUE benchmark demonstrate that our PCA-based prompt tuning combined with LoRA maintains full knowledge retention while improving accuracy, utilizing only 1% of the model's parameters. These results establish our approach as a scalable and resource-efficient solution for continual learning in LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "LoRA"
        ]
    },
    {
        "id": "44",
        "title": "DANDI: Diffusion as Normative Distribution for Deep Neural Network Input",
        "author": [
            "Somin Kim",
            "Shin Yoo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02910",
        "abstract": "Surprise Adequacy (SA) has been widely studied as a test adequacy metric that can effectively guide software engineers towards inputs that are more likely to reveal unexpected behaviour of Deep Neural Networks (DNNs). Intuitively, SA is an out-of-distribution metric that quantifies the dissimilarity between the given input and the training data: if a new input is very different from those seen during training, the DNN is more likely to behave unexpectedly against the input. While SA has been widely adopted as a test prioritization method, its major weakness is the fact that the computation of the metric requires access to the training dataset, which is often not allowed in real-world use cases. We present DANDI, a technique that generates a surrogate input distribution using Stable Diffusion to compute SA values without requiring the original training data. An empirical evaluation of DANDI applied to image classifiers for CIFAR10 and ImageNet-1K shows that SA values computed against synthetic data are highly correlated with the values computed against the training data, with Spearman Rank correlation value of 0.852 for ImageNet-1K and 0.881 for CIFAR-10. Further, we show that SA value computed by DANDI achieves can prioritize inputs as effectively as those computed using the training data, when testing DNN models mutated by DeepMutation. We believe that DANDI can significantly improve the usability of SA for practical DNN testing.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "45",
        "title": "Interactive Symbolic Regression through Offline Reinforcement Learning: A Co-Design Framework",
        "author": [
            "Yuan Tian",
            "Wenqi Zhou",
            "Michele Viscione",
            "Hao Dong",
            "David Kammer",
            "Olga Fink"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02917",
        "abstract": "Symbolic Regression (SR) holds great potential for uncovering underlying mathematical and physical relationships from observed data. However, the vast combinatorial space of possible expressions poses significant challenges for both online search methods and pre-trained transformer models. Additionally, current state-of-the-art approaches typically do not consider the integration of domain experts' prior knowledge and do not support iterative interactions with the model during the equation discovery process. To address these challenges, we propose the Symbolic Q-network (Sym-Q), an advanced interactive framework for large-scale symbolic regression. Unlike previous large-scale transformer-based SR approaches, Sym-Q leverages reinforcement learning without relying on a transformer-based decoder. This formulation allows the agent to learn through offline reinforcement learning using any type of tree encoder, enabling more efficient training and inference. Furthermore, we propose a co-design mechanism, where the reinforcement learning-based Sym-Q facilitates effective interaction with domain experts at any stage of the equation discovery process. Users can dynamically modify generated nodes of the expression, collaborating with the agent to tailor the mathematical expression to best fit the problem and align with the assumed physical laws, particularly when there is prior partial knowledge of the expected behavior. Our experiments demonstrate that the pre-trained Sym-Q surpasses existing SR algorithms on the challenging SSDNC benchmark. Moreover, we experimentally show on real-world cases that its performance can be further enhanced by the interactive co-design mechanism, with Sym-Q achieving greater performance gains than other state-of-the-art models. Our reproducible code is available at https://github.com/EPFL-IMOS/Sym-Q.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "46",
        "title": "Maximizing the Position Embedding for Vision Transformers with Global Average Pooling",
        "author": [
            "Wonjun Lee",
            "Bumsub Ham",
            "Suhyun Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02919",
        "abstract": "In vision transformers, position embedding (PE) plays a crucial role in capturing the order of tokens. However, in vision transformer structures, there is a limitation in the expressiveness of PE due to the structure where position embedding is simply added to the token embedding. A layer-wise method that delivers PE to each layer and applies independent Layer Normalizations for token embedding and PE has been adopted to overcome this limitation. In this paper, we identify the conflicting result that occurs in a layer-wise structure when using the global average pooling (GAP) method instead of the class token. To overcome this problem, we propose MPVG, which maximizes the effectiveness of PE in a layer-wise structure with GAP. Specifically, we identify that PE counterbalances token embedding values at each layer in a layer-wise structure. Furthermore, we recognize that the counterbalancing role of PE is insufficient in the layer-wise structure, and we address this by maximizing the effectiveness of PE through MPVG. Through experiments, we demonstrate that PE performs a counterbalancing role and that maintaining this counterbalancing directionality significantly impacts vision transformers. As a result, the experimental results show that MPVG outperforms existing methods across vision transformers on various tasks.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "47",
        "title": "Elucidating the Preconditioning in Consistency Distillation",
        "author": [
            "Kaiwen Zheng",
            "Guande He",
            "Jianfei Chen",
            "Fan Bao",
            "Jun Zhu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02922",
        "abstract": "Consistency distillation is a prevalent way for accelerating diffusion models adopted in consistency (trajectory) models, in which a student model is trained to traverse backward on the probability flow (PF) ordinary differential equation (ODE) trajectory determined by the teacher model. Preconditioning is a vital technique for stabilizing consistency distillation, by linear combining the input data and the network output with pre-defined coefficients as the consistency function. It imposes the boundary condition of consistency functions without restricting the form and expressiveness of the neural network. However, previous preconditionings are hand-crafted and may be suboptimal choices. In this work, we offer the first theoretical insights into the preconditioning in consistency distillation, by elucidating its design criteria and the connection to the teacher ODE trajectory. Based on these analyses, we further propose a principled way dubbed \\textit{Analytic-Precond} to analytically optimize the preconditioning according to the consistency gap (defined as the gap between the teacher denoiser and the optimal student denoiser) on a generalized teacher ODE. We demonstrate that Analytic-Precond can facilitate the learning of trajectory jumpers, enhance the alignment of the student trajectory with the teacher's, and achieve $2\\times$ to $3\\times$ training acceleration of consistency trajectory models in multi-step generation across various datasets.",
        "tags": [
            "Diffusion",
            "ODE"
        ]
    },
    {
        "id": "48",
        "title": "Every Angle Is Worth A Second Glance: Mining Kinematic Skeletal Structures from Multi-view Joint Cloud",
        "author": [
            "Junkun Jiang",
            "Jie Chen",
            "Ho Yin Au",
            "Mingyuan Chen",
            "Wei Xue",
            "Yike Guo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02936",
        "abstract": "Multi-person motion capture over sparse angular observations is a challenging problem under interference from both self- and mutual-occlusions. Existing works produce accurate 2D joint detection, however, when these are triangulated and lifted into 3D, available solutions all struggle in selecting the most accurate candidates and associating them to the correct joint type and target identity. As such, in order to fully utilize all accurate 2D joint location information, we propose to independently triangulate between all same-typed 2D joints from all camera views regardless of their target ID, forming the Joint Cloud. Joint Cloud consist of both valid joints lifted from the same joint type and target ID, as well as falsely constructed ones that are from different 2D sources. These redundant and inaccurate candidates are processed over the proposed Joint Cloud Selection and Aggregation Transformer (JCSAT) involving three cascaded encoders which deeply explore the trajectile, skeletal structural, and view-dependent correlations among all 3D point candidates in the cross-embedding space. An Optimal Token Attention Path (OTAP) module is proposed which subsequently selects and aggregates informative features from these redundant observations for the final prediction of human motion. To demonstrate the effectiveness of JCSAT, we build and publish a new multi-person motion capture dataset BUMocap-X with complex interactions and severe occlusions. Comprehensive experiments over the newly presented as well as benchmark datasets validate the effectiveness of the proposed framework, which outperforms all existing state-of-the-art methods, especially under challenging occlusion scenarios.",
        "tags": [
            "3D",
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "49",
        "title": "LLaVAC: Fine-tuning LLaVA as a Multimodal Sentiment Classifier",
        "author": [
            "T. Chay-intr",
            "Y. Chen",
            "K. Viriyayudhakorn",
            "T. Theeramunkong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02938",
        "abstract": "We present LLaVAC, a method for constructing a classifier for multimodal sentiment analysis. This method leverages fine-tuning of the Large Language and Vision Assistant (LLaVA) to predict sentiment labels across both image and text modalities. Our approach involves designing a structured prompt that incorporates both unimodal and multimodal labels to fine-tune LLaVA, enabling it to perform sentiment classification effectively. Experiments on the MVSA-Single dataset demonstrate that LLaVAC outperforms existing methods in multimodal sentiment analysis across three data processing procedures. The implementation of LLaVAC is publicly available at https://github.com/tchayintr/llavac.",
        "tags": [
            "LLaVA"
        ]
    },
    {
        "id": "50",
        "title": "Fast T2T: Optimization Consistency Speeds Up Diffusion-Based Training-to-Testing Solving for Combinatorial Optimization",
        "author": [
            "Yang Li",
            "Jinpei Guo",
            "Runzhong Wang",
            "Hongyuan Zha",
            "Junchi Yan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02941",
        "abstract": "Diffusion models have recently advanced Combinatorial Optimization (CO) as a powerful backbone for neural solvers. However, their iterative sampling process requiring denoising across multiple noise levels incurs substantial overhead. We propose to learn direct mappings from different noise levels to the optimal solution for a given instance, facilitating high-quality generation with minimal shots. This is achieved through an optimization consistency training protocol, which, for a given instance, minimizes the difference among samples originating from varying generative trajectories and time steps relative to the optimal solution. The proposed model enables fast single-step solution generation while retaining the option of multi-step sampling to trade for sampling quality, which offers a more effective and efficient alternative backbone for neural solvers. In addition, within the training-to-testing (T2T) framework, to bridge the gap between training on historical instances and solving new instances, we introduce a novel consistency-based gradient search scheme during the test stage, enabling more effective exploration of the solution space learned during training. It is achieved by updating the latent solution probabilities under objective gradient guidance during the alternation of noise injection and denoising steps. We refer to this model as Fast T2T. Extensive experiments on two popular tasks, the Traveling Salesman Problem (TSP) and Maximal Independent Set (MIS), demonstrate the superiority of Fast T2T regarding both solution quality and efficiency, even outperforming LKH given limited time budgets. Notably, Fast T2T with merely one-step generation and one-step gradient search can mostly outperform the SOTA diffusion-based counterparts that require hundreds of steps, while achieving tens of times speedup.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "51",
        "title": "LLM-KT: Aligning Large Language Models with Knowledge Tracing using a Plug-and-Play Instruction",
        "author": [
            "Ziwei Wang",
            "Jie Zhou",
            "Qin Chen",
            "Min Zhang",
            "Bo Jiang",
            "Aimin Zhou",
            "Qinchun Bai",
            "Liang He"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02945",
        "abstract": "The knowledge tracing (KT) problem is an extremely important topic in personalized education, which aims to predict whether students can correctly answer the next question based on their past question-answer records. Prior work on this task mainly focused on learning the sequence of behaviors based on the IDs or textual information. However, these studies usually fail to capture students' sufficient behavioral patterns without reasoning with rich world knowledge about questions. In this paper, we propose a large language models (LLMs)-based framework for KT, named \\texttt{\\textbf{LLM-KT}}, to integrate the strengths of LLMs and traditional sequence interaction models. For task-level alignment, we design Plug-and-Play instruction to align LLMs with KT, leveraging LLMs' rich knowledge and powerful reasoning capacity. For modality-level alignment, we design the plug-in context and sequence to integrate multiple modalities learned by traditional methods. To capture the long context of history records, we present a plug-in context to flexibly insert the compressed context embedding into LLMs using question-specific and concept-specific tokens. Furthermore, we introduce a plug-in sequence to enhance LLMs with sequence interaction behavior representation learned by traditional sequence models using a sequence adapter. Extensive experiments show that \\texttt{\\textbf{LLM-KT}} obtains state-of-the-art performance on four typical datasets by comparing it with approximately 20 strong baselines.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "52",
        "title": "Direct Distributional Optimization for Provable Alignment of Diffusion Models",
        "author": [
            "Ryotaro Kawata",
            "Kazusato Oko",
            "Atsushi Nitanda",
            "Taiji Suzuki"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02954",
        "abstract": "We introduce a novel alignment method for diffusion models from distribution optimization perspectives while providing rigorous convergence guarantees. We first formulate the problem as a generic regularized loss minimization over probability distributions and directly optimize the distribution using the Dual Averaging method. Next, we enable sampling from the learned distribution by approximating its score function via Doob's $h$-transform technique. The proposed framework is supported by rigorous convergence guarantees and an end-to-end bound on the sampling error, which imply that when the original distribution's score is known accurately, the complexity of sampling from shifted distributions is independent of isoperimetric conditions. This framework is broadly applicable to general distribution optimization problems, including alignment tasks in Reinforcement Learning with Human Feedback (RLHF), Direct Preference Optimization (DPO), and Kahneman-Tversky Optimization (KTO). We empirically validate its performance on synthetic and image datasets using the DPO objective.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "53",
        "title": "Position: Editing Large Language Models Poses Serious Safety Risks",
        "author": [
            "Paul Youssef",
            "Zhixue Zhao",
            "Daniel Braun",
            "JÃ¶rg SchlÃ¶tterer",
            "Christin Seifert"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02958",
        "abstract": "Large Language Models (LLMs) contain large amounts of facts about the world. These facts can become outdated over time, which has led to the development of knowledge editing methods (KEs) that can change specific facts in LLMs with limited side effects. This position paper argues that editing LLMs poses serious safety risks that have been largely overlooked. First, we note the fact that KEs are widely available, computationally inexpensive, highly performant, and stealthy makes them an attractive tool for malicious actors. Second, we discuss malicious use cases of KEs, showing how KEs can be easily adapted for a variety of malicious purposes. Third, we highlight vulnerabilities in the AI ecosystem that allow unrestricted uploading and downloading of updated models without verification. Fourth, we argue that a lack of social and institutional awareness exacerbates this risk, and discuss the implications for different stakeholders. We call on the community to (i) research tamper-resistant models and countermeasures against malicious model editing, and (ii) actively engage in securing the AI ecosystem.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "54",
        "title": "Label Anything: An Interpretable, High-Fidelity and Prompt-Free Annotator",
        "author": [
            "Wei-Bin Kou",
            "Guangxu Zhu",
            "Rongguang Ye",
            "Shuai Wang",
            "Ming Tang",
            "Yik-Chung Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02972",
        "abstract": "Learning-based street scene semantic understanding in autonomous driving (AD) has advanced significantly recently, but the performance of the AD model is heavily dependent on the quantity and quality of the annotated training data. However, traditional manual labeling involves high cost to annotate the vast amount of required data for training robust model. To mitigate this cost of manual labeling, we propose a Label Anything Model (denoted as LAM), serving as an interpretable, high-fidelity, and prompt-free data annotator. Specifically, we firstly incorporate a pretrained Vision Transformer (ViT) to extract the latent features. On top of ViT, we propose a semantic class adapter (SCA) and an optimization-oriented unrolling algorithm (OptOU), both with a quite small number of trainable parameters. SCA is proposed to fuse ViT-extracted features to consolidate the basis of the subsequent automatic annotation. OptOU consists of multiple cascading layers and each layer contains an optimization formulation to align its output with the ground truth as closely as possible, though which OptOU acts as being interpretable rather than learning-based blackbox nature. In addition, training SCA and OptOU requires only a single pre-annotated RGB seed image, owing to their small volume of learnable parameters. Extensive experiments clearly demonstrate that the proposed LAM can generate high-fidelity annotations (almost 100% in mIoU) for multiple real-world datasets (i.e., Camvid, Cityscapes, and Apolloscapes) and CARLA simulation dataset.",
        "tags": [
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "55",
        "title": "Disentangling CLIP Features for Enhanced Localized Understanding",
        "author": [
            "Samyak Rawelekar",
            "Yujun Cai",
            "Yiwei Wang",
            "Ming-Hsuan Yang",
            "Narendra Ahuja"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02977",
        "abstract": "Vision-language models (VLMs) demonstrate impressive capabilities in coarse-grained tasks like image classification and retrieval. However, they struggle with fine-grained tasks that require localized understanding. To investigate this weakness, we comprehensively analyze CLIP features and identify an important issue: semantic features are highly correlated. Specifically, the features of a class encode information about other classes, which we call mutual feature information (MFI). This mutual information becomes evident when we query a specific class and unrelated objects are activated along with the target class. To address this issue, we propose Unmix-CLIP, a novel framework designed to reduce MFI and improve feature disentanglement. We introduce MFI loss, which explicitly separates text features by projecting them into a space where inter-class similarity is minimized. To ensure a corresponding separation in image features, we use multi-label recognition (MLR) to align the image features with the separated text features. This ensures that both image and text features are disentangled and aligned across modalities, improving feature separation for downstream tasks. For the COCO- 14 dataset, Unmix-CLIP reduces feature similarity by 24.9%. We demonstrate its effectiveness through extensive evaluations of MLR and zeroshot semantic segmentation (ZS3). In MLR, our method performs competitively on the VOC2007 and surpasses SOTA approaches on the COCO-14 dataset, using fewer training parameters. Additionally, Unmix-CLIP consistently outperforms existing ZS3 methods on COCO and VOC",
        "tags": [
            "CLIP",
            "Segmentation"
        ]
    },
    {
        "id": "56",
        "title": "Training an LLM-as-a-Judge Model: Pipeline, Insights, and Practical Lessons",
        "author": [
            "Renjun Hu",
            "Yi Cheng",
            "Libin Meng",
            "Jiaxin Xia",
            "Yi Zong",
            "Xing Shi",
            "Wei Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02988",
        "abstract": "The rapid advancement of large language models (LLMs) has opened new possibilities for their adoption as evaluative judges. This paper introduces Themis, a fine-tuned LLM judge that delivers sophisticated context-aware evaluations. We provide a comprehensive overview of the development pipeline for Themis, highlighting its scenario-dependent evaluation prompts and two novel methods for controlled instruction generation. These designs enable Themis to effectively distill evaluative skills from teacher models, while retaining flexibility for continuous development. We introduce two human-labeled benchmarks for meta-evaluation, demonstrating that Themis can achieve high alignment with human preferences in an economical manner. Additionally, we explore insights into the LLM-as-a-judge paradigm, revealing nuances in performance and the varied effects of reference answers. Notably, we observe that pure knowledge distillation from strong LLMs, though common, does not guarantee performance improvement through scaling. We propose a mitigation strategy based on instruction-following difficulty. Furthermore, we provide practical guidelines covering data balancing, prompt customization, multi-objective training, and metric aggregation. We aim for our method and findings, along with the fine-tuning data, benchmarks, and model checkpoints, to support future research and development in this area.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "57",
        "title": "Scaling Laws for Upcycling Mixture-of-Experts Language Models",
        "author": [
            "Seng Pei Liew",
            "Takuya Kato",
            "Sho Takase"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03009",
        "abstract": "Pretraining large language models (LLMs) is resource-intensive, often requiring months of training time even with high-end GPU clusters. There are two approaches of mitigating such computational demands: reusing smaller models to train larger ones (upcycling), and training computationally efficient models like mixture-of-experts (MoE). In this paper, we study the upcycling of LLMs to MoE models, of which the scaling behavior remains underexplored. Through extensive experiments, we identify empirical scaling laws that describe how performance depends on dataset size and model configuration. Particularly, we show that, while scaling these factors improves performance, there is a novel interaction term between the dense and upcycled training dataset that limits the efficiency of upcycling at large computational budgets. Based on these findings, we provide guidance to scale upcycling, and establish conditions under which upcycling outperforms from-scratch trainings within budget constraints.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "58",
        "title": "On Zero-Initialized Attention: Optimal Prompt and Gating Factor Estimation",
        "author": [
            "Nghiem T. Diep",
            "Huy Nguyen",
            "Chau Nguyen",
            "Minh Le",
            "Duy M. H. Nguyen",
            "Daniel Sonntag",
            "Mathias Niepert",
            "Nhat Ho"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03029",
        "abstract": "The LLaMA-Adapter has recently emerged as an efficient fine-tuning technique for LLaMA models, leveraging zero-initialized attention to stabilize training and enhance performance. However, despite its empirical success, the theoretical foundations of zero-initialized attention remain largely unexplored. In this paper, we provide a rigorous theoretical analysis, establishing a connection between zero-initialized attention and mixture-of-expert models. We prove that both linear and non-linear prompts, along with gating functions, can be optimally estimated, with non-linear prompts offering greater flexibility for future applications. Empirically, we validate our findings on the open LLM benchmarks, demonstrating that non-linear prompts outperform linear ones. Notably, even with limited training data, both prompt types consistently surpass vanilla attention, highlighting the robustness and adaptability of zero-initialized attention.",
        "tags": [
            "LLaMA"
        ]
    },
    {
        "id": "59",
        "title": "Analyze Feature Flow to Enhance Interpretation and Steering in Language Models",
        "author": [
            "Daniil Laptev",
            "Nikita Balagansky",
            "Yaroslav Aksenov",
            "Daniil Gavrilov"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03032",
        "abstract": "We introduce a new approach to systematically map features discovered by sparse autoencoder across consecutive layers of large language models, extending earlier work that examined inter-layer feature links. By using a data-free cosine similarity technique, we trace how specific features persist, transform, or first appear at each stage. This method yields granular flow graphs of feature evolution, enabling fine-grained interpretability and mechanistic insights into model computations. Crucially, we demonstrate how these cross-layer feature maps facilitate direct steering of model behavior by amplifying or suppressing chosen features, achieving targeted thematic control in text generation. Together, our findings highlight the utility of a causal, cross-layer interpretability framework that not only clarifies how features develop through forward passes but also provides new means for transparent manipulation of large language models.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "60",
        "title": "Knowledge Distillation from Large Language Models for Household Energy Modeling",
        "author": [
            "Mohannad Takrouri",
            "NicolÃ¡s M. Cuadrado",
            "Martin TakÃ¡Ä"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03034",
        "abstract": "Machine learning (ML) is increasingly vital for smart-grid research, yet restricted access to realistic, diverse data - often due to privacy concerns - slows progress and fuels doubts within the energy sector about adopting ML-based strategies. We propose integrating Large Language Models (LLMs) in energy modeling to generate realistic, culturally sensitive, and behavior-specific data for household energy usage across diverse geographies. In this study, we employ and compare five different LLMs to systematically produce family structures, weather patterns, and daily consumption profiles for households in six distinct countries. A four-stage methodology synthesizes contextual daily data, including culturally nuanced activities, realistic weather ranges, HVAC operations, and distinct `energy signatures' that capture unique consumption footprints. Additionally, we explore an alternative strategy where external weather datasets can be directly integrated, bypassing intermediate weather modeling stages while ensuring physically consistent data inputs. The resulting dataset provides insights into how cultural, climatic, and behavioral factors converge to shape carbon emissions, offering a cost-effective avenue for scenario-based energy optimization. This approach underscores how prompt engineering, combined with knowledge distillation, can advance sustainable energy research and climate mitigation efforts. Source code is available at https://github.com/Singularity-AI-Lab/LLM-Energy-Knowledge-Distillation .",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "61",
        "title": "UMC: Unified Resilient Controller for Legged Robots with Joint Malfunctions",
        "author": [
            "Yu Qiu",
            "Xin Lin",
            "Jingbo Wang",
            "Xiangtai Li",
            "Lu Qi",
            "Ming-Hsuan Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03035",
        "abstract": "Adaptation to unpredictable damages is crucial for autonomous legged robots, yet existing methods based on multi-policy or meta-learning frameworks face challenges like limited generalization and complex maintenance. To address this issue, we first analyze and summarize eight types of damage scenarios, including sensor failures and joint malfunctions. Then, we propose a novel, model-free, two-stage training framework, Unified Malfunction Controller (UMC), incorporating a masking mechanism to enhance damage resilience. Specifically, the model is initially trained with normal environments to ensure robust performance under standard conditions. In the second stage, we use masks to prevent the legged robot from relying on malfunctioning limbs, enabling adaptive gait and movement adjustments upon malfunction. Experimental results demonstrate that our approach improves the task completion capability by an average of 36% for the transformer and 39% for the MLP across three locomotion tasks. The source code and trained models will be made available to the public.",
        "tags": [
            "Robot",
            "Transformer"
        ]
    },
    {
        "id": "62",
        "title": "RepLoRA: Reparameterizing Low-Rank Adaptation via the Perspective of Mixture of Experts",
        "author": [
            "Tuan Truong",
            "Chau Nguyen",
            "Huy Nguyen",
            "Minh Le",
            "Trung Le",
            "Nhat Ho"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03044",
        "abstract": "Low-rank adaptation (LoRA) has emerged as a powerful method for fine-tuning large-scale foundation models. Despite its popularity, the theoretical understanding of LoRA has remained limited. This paper presents a theoretical analysis of LoRA by examining its connection to the Mixture of Experts models. Under this framework, we show that simple reparameterizations of the LoRA matrices can notably accelerate the low-rank matrix estimation process. In particular, we prove that reparameterization can reduce the data needed to achieve a desired estimation error from an exponential to a polynomial scale. Motivated by this insight, we propose Reparameterized Low-rank Adaptation (RepLoRA), which incorporates lightweight MLPs to reparameterize the LoRA matrices. Extensive experiments across multiple domains demonstrate that RepLoRA consistently outperforms vanilla LoRA. Notably, with limited data, RepLoRA surpasses LoRA by a margin of up to 40.0% and achieves LoRA's performance with only 30.0% of the training data, highlighting both the theoretical and empirical robustness of our PEFT method.",
        "tags": [
            "LoRA",
            "Low-Rank Adaptation"
        ]
    },
    {
        "id": "63",
        "title": "Understanding and Enhancing the Transferability of Jailbreaking Attacks",
        "author": [
            "Runqi Lin",
            "Bo Han",
            "Fengwang Li",
            "Tongling Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03052",
        "abstract": "Jailbreaking attacks can effectively manipulate open-source large language models (LLMs) to produce harmful responses. However, these attacks exhibit limited transferability, failing to disrupt proprietary LLMs consistently. To reliably identify vulnerabilities in proprietary LLMs, this work investigates the transferability of jailbreaking attacks by analysing their impact on the model's intent perception. By incorporating adversarial sequences, these attacks can redirect the source LLM's focus away from malicious-intent tokens in the original input, thereby obstructing the model's intent recognition and eliciting harmful responses. Nevertheless, these adversarial sequences fail to mislead the target LLM's intent perception, allowing the target LLM to refocus on malicious-intent tokens and abstain from responding. Our analysis further reveals the inherent distributional dependency within the generated adversarial sequences, whose effectiveness stems from overfitting the source LLM's parameters, resulting in limited transferability to target LLMs. To this end, we propose the Perceived-importance Flatten (PiF) method, which uniformly disperses the model's focus across neutral-intent tokens in the original input, thus obscuring malicious-intent tokens without relying on overfitted adversarial sequences. Extensive experiments demonstrate that PiF provides an effective and efficient red-teaming evaluation for proprietary LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "64",
        "title": "Optimizing Electric Vehicles Charging using Large Language Models and Graph Neural Networks",
        "author": [
            "Stavros Orfanoudakis",
            "Peter Palensky",
            "Pedro P. Vergara"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03067",
        "abstract": "Maintaining grid stability amid widespread electric vehicle (EV) adoption is vital for sustainable transportation. Traditional optimization methods and Reinforcement Learning (RL) approaches often struggle with the high dimensionality and dynamic nature of real-time EV charging, leading to sub-optimal solutions. To address these challenges, this study demonstrates that combining Large Language Models (LLMs), for sequence modeling, with Graph Neural Networks (GNNs), for relational information extraction, not only outperforms conventional EV smart charging methods, but also paves the way for entirely new research directions and innovative solutions.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RL"
        ]
    },
    {
        "id": "65",
        "title": "Internal layer solutions and coefficient recovery in time-periodic reaction-diffusion-advection equations",
        "author": [
            "Dmitrii Chaikovskii",
            "Ye Zhang",
            "Aleksei Liubavin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03068",
        "abstract": "This article investigates the non-stationary reaction-diffusion-advection equation, emphasizing solutions with internal layers and the associated inverse problems. We examine a nonlinear singularly perturbed partial differential equation (PDE) within a bounded spatial domain and an infinite temporal domain, subject to periodic temporal boundary conditions. A periodic asymptotic solution featuring an inner transition layer is proposed, advancing the mathematical modeling of reaction-diffusion-advection dynamics. Building on this asymptotic analysis, we develop a simple yet effective numerical algorithm to address ill-posed nonlinear inverse problems aimed at reconstructing coefficient functions that depend solely on spatial or temporal variables. Conditions ensuring the existence and uniqueness of solutions for both forward and inverse problems are established. The proposed method's effectiveness is validated through numerical experiments, demonstrating high accuracy in reconstructing coefficient functions under varying noise conditions.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "66",
        "title": "RoboGrasp: A Universal Grasping Policy for Robust Robotic Control",
        "author": [
            "Yiqi Huang",
            "Travis Davies",
            "Jiahuan Yan",
            "Xiang Chen",
            "Yu Tian",
            "Luhui Hu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03072",
        "abstract": "Imitation learning and world models have shown significant promise in advancing generalizable robotic learning, with robotic grasping remaining a critical challenge for achieving precise manipulation. Existing methods often rely heavily on robot arm state data and RGB images, leading to overfitting to specific object shapes or positions. To address these limitations, we propose RoboGrasp, a universal grasping policy framework that integrates pretrained grasp detection models with robotic learning. By leveraging robust visual guidance from object detection and segmentation tasks, RoboGrasp significantly enhances grasp precision, stability, and generalizability, achieving up to 34% higher success rates in few-shot learning and grasping box prompt tasks. Built on diffusion-based methods, RoboGrasp is adaptable to various robotic learning paradigms, enabling precise and reliable manipulation across diverse and complex scenarios. This framework represents a scalable and versatile solution for tackling real-world challenges in robotic grasping.",
        "tags": [
            "Detection",
            "Diffusion",
            "Robot",
            "Segmentation"
        ]
    },
    {
        "id": "67",
        "title": "IAO Prompting: Making Knowledge Flow Explicit in LLMs through Structured Reasoning Templates",
        "author": [
            "Aissatou Diallo",
            "Antonis Bikakis",
            "Luke Dickens",
            "Anthony Hunter",
            "Rob Miller"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03080",
        "abstract": "While Large Language Models (LLMs) demonstrate impressive reasoning capabilities, understanding and validating their knowledge utilization remains challenging. Chain-of-thought (CoT) prompting partially addresses this by revealing intermediate reasoning steps, but the knowledge flow and application remain implicit. We introduce IAO (Input-Action-Output) prompting, a structured template-based method that explicitly models how LLMs access and apply their knowledge during complex reasoning tasks. IAO decomposes problems into sequential steps, each clearly identifying the input knowledge being used, the action being performed, and the resulting output. This structured decomposition enables us to trace knowledge flow, verify factual consistency, and identify potential knowledge gaps or misapplications. Through experiments across diverse reasoning tasks, we demonstrate that IAO not only improves zero-shot performance but also provides transparency in how LLMs leverage their stored knowledge. Human evaluation confirms that this structured approach enhances our ability to verify knowledge utilization and detect potential hallucinations or reasoning errors. Our findings provide insights into both knowledge representation within LLMs and methods for more reliable knowledge application.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "68",
        "title": "Reveal the Mystery of DPO: The Connection between DPO and RL Algorithms",
        "author": [
            "Xuerui Su",
            "Yue Wang",
            "Jinhua Zhu",
            "Mingyang Yi",
            "Feng Xu",
            "Zhiming Ma",
            "Yuting Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03095",
        "abstract": "With the rapid development of Large Language Models (LLMs), numerous Reinforcement Learning from Human Feedback (RLHF) algorithms have been introduced to improve model safety and alignment with human preferences. These algorithms can be divided into two main frameworks based on whether they require an explicit reward (or value) function for training: actor-critic-based Proximal Policy Optimization (PPO) and alignment-based Direct Preference Optimization (DPO). The mismatch between DPO and PPO, such as DPO's use of a classification loss driven by human-preferred data, has raised confusion about whether DPO should be classified as a Reinforcement Learning (RL) algorithm. To address these ambiguities, we focus on three key aspects related to DPO, RL, and other RLHF algorithms: (1) the construction of the loss function; (2) the target distribution at which the algorithm converges; (3) the impact of key components within the loss function. Specifically, we first establish a unified framework named UDRRA connecting these algorithms based on the construction of their loss functions. Next, we uncover their target policy distributions within this framework. Finally, we investigate the critical components of DPO to understand their impact on the convergence rate. Our work provides a deeper understanding of the relationship between DPO, RL, and other RLHF algorithms, offering new insights for improving existing algorithms.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RL"
        ]
    },
    {
        "id": "69",
        "title": "Structured Token Retention and Computational Memory Paths in Large Language Models",
        "author": [
            "Jonathan Delena",
            "Augustin Moreau",
            "Dominic Ravensdale",
            "Frederick Chatterton"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03102",
        "abstract": "Memory retention mechanisms play a central role in determining the efficiency of computational architectures designed for processing extended sequences. Conventional methods for token management often impose fixed retention thresholds or rely on uniform attention weight distributions, leading to inefficient memory utilization and premature information loss in extended sequence modeling. Structured Token Retention (STR) introduces a probabilistic selection framework that dynamically adjusts token persistence based on contextual significance, ensuring that computational resources are allocated to semantically relevant elements. Computational Memory Paths (CMP) extend this framework through hierarchical memory allocation, refining retention efficiency through structured reallocation of token embeddings. Comparative assessments against baseline models demonstrate that STR and CMP improve token survival rates across long input sequences while reducing cumulative error propagation across processing layers. Experimental results further indicate reductions in computational overhead, improving inference speed without degrading contextual coherence. Token distribution analyses reveal that structured memory allocation prevents excessive redundancy in attention weight calculations, optimizing information retrieval efficiency in large-scale generative architectures. The integration of STR and CMP into an open-source model illustrates the adaptability of structured memory retention methodologies, highlighting their applicability in generative text processing, long-context comprehension, and scalable sequence modeling.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "70",
        "title": "Edge Attention Module for Object Classification",
        "author": [
            "Santanu Roy",
            "Ashvath Suresh",
            "Archit Gupta"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03103",
        "abstract": "A novel ``edge attention-based Convolutional Neural Network (CNN)'' is proposed in this research for object classification task. With the advent of advanced computing technology, CNN models have achieved to remarkable success, particularly in computer vision applications. Nevertheless, the efficacy of the conventional CNN is often hindered due to class imbalance and inter-class similarity problems, which are particularly prominent in the computer vision field. In this research, we introduce for the first time an ``Edge Attention Module (EAM)'' consisting of a Max-Min pooling layer, followed by convolutional layers. This Max-Min pooling is entirely a novel pooling technique, specifically designed to capture only the edge information that is crucial for any object classification task. Therefore, by integrating this novel pooling technique into the attention module, the CNN network inherently prioritizes on essential edge features, thereby boosting the accuracy and F1-score of the model significantly. We have implemented our proposed EAM or 2EAMs on several standard pre-trained CNN models for Caltech-101, Caltech-256, CIFAR-100 and Tiny ImageNet-200 datasets. The extensive experiments reveal that our proposed framework (that is, EAM with CNN and 2EAMs with CNN), outperforms all pre-trained CNN models as well as recent trend models ``Pooling-based Vision Transformer (PiT)'', ``Convolutional Block Attention Module (CBAM)'', and ConvNext, by substantial margins. We have achieved the accuracy of 95.5% and 86% by the proposed framework on Caltech-101 and Caltech-256 datasets, respectively. So far, this is the best results on these datasets, to the best of our knowledge.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "71",
        "title": "Teaching Large Language Models Number-Focused Headline Generation With Key Element Rationales",
        "author": [
            "Zhen Qian",
            "Xiuzhen Zhang",
            "Xiaofei Xu",
            "Feng Xia"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03129",
        "abstract": "Number-focused headline generation is a summarization task requiring both high textual quality and precise numerical accuracy, which poses a unique challenge for Large Language Models (LLMs). Existing studies in the literature focus only on either textual quality or numerical reasoning and thus are inadequate to address this challenge. In this paper, we propose a novel chain-of-thought framework for using rationales comprising key elements of the Topic, Entities, and Numerical reasoning (TEN) in news articles to enhance the capability for LLMs to generate topic-aligned high-quality texts with precise numerical accuracy. Specifically, a teacher LLM is employed to generate TEN rationales as supervision data, which are then used to teach and fine-tune a student LLM. Our approach teaches the student LLM automatic generation of rationales with enhanced capability for numerical reasoning and topic-aligned numerical headline generation. Experiments show that our approach achieves superior performance in both textual quality and numerical accuracy.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "72",
        "title": "PICBench: Benchmarking LLMs for Photonic Integrated Circuits Design",
        "author": [
            "Yuchao Wu",
            "Xiaofei Yu",
            "Hao Chen",
            "Yang Luo",
            "Yeyu Tong",
            "Yuzhe Ma"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03159",
        "abstract": "While large language models (LLMs) have shown remarkable potential in automating various tasks in digital chip design, the field of Photonic Integrated Circuits (PICs)-a promising solution to advanced chip designs-remains relatively unexplored in this context. The design of PICs is time-consuming and prone to errors due to the extensive and repetitive nature of code involved in photonic chip design. In this paper, we introduce PICBench, the first benchmarking and evaluation framework specifically designed to automate PIC design generation using LLMs, where the generated output takes the form of a netlist. Our benchmark consists of dozens of meticulously crafted PIC design problems, spanning from fundamental device designs to more complex circuit-level designs. It automatically evaluates both the syntax and functionality of generated PIC designs by comparing simulation outputs with expert-written solutions, leveraging an open-source simulator. We evaluate a range of existing LLMs, while also conducting comparative tests on various prompt engineering techniques to enhance LLM performance in automated PIC design. The results reveal the challenges and potential of LLMs in the PIC design domain, offering insights into the key areas that require further research and development to optimize automation in this field. Our benchmark and evaluation code is available at https://github.com/PICDA/PICBench.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "73",
        "title": "MaxInfo: A Training-Free Key-Frame Selection Method Using Maximum Volume for Enhanced Video Understanding",
        "author": [
            "Pengyi Li",
            "Irina Abdullaeva",
            "Alexander Gambashidze",
            "Andrey Kuznetsov",
            "Ivan Oseledets"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03183",
        "abstract": "Modern Video Large Language Models (VLLMs) often rely on uniform frame sampling for video understanding, but this approach frequently fails to capture critical information due to frame redundancy and variations in video content. We propose MaxInfo, a training-free method based on the maximum volume principle, which selects and retains the most representative frames from the input video. By maximizing the geometric volume formed by selected embeddings, MaxInfo ensures that the chosen frames cover the most informative regions of the embedding space, effectively reducing redundancy while preserving diversity. This method enhances the quality of input representations and improves long video comprehension performance across benchmarks. For instance, MaxInfo achieves a 3.28% improvement on LongVideoBench and a 6.4% improvement on EgoSchema for LLaVA-Video-7B. It also achieves a 3.47% improvement for LLaVA-Video-72B. The approach is simple to implement and works with existing VLLMs without the need for additional training, making it a practical and effective alternative to traditional uniform sampling methods.",
        "tags": [
            "LLaVA",
            "Large Language Models"
        ]
    },
    {
        "id": "74",
        "title": "Improve Decoding Factuality by Token-wise Cross Layer Entropy of Large Language Models",
        "author": [
            "Jialiang Wu",
            "Yi Shen",
            "Sijia Liu",
            "Yi Tang",
            "Sen Song",
            "Xiaoyi Wang",
            "Longjun Cai"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03199",
        "abstract": "Despite their impressive capacities, Large language models (LLMs) often struggle with the hallucination issue of generating inaccurate or fabricated content even when they possess correct knowledge. In this paper, we extend the exploration of the correlation between hidden-state prediction changes and output factuality into a deeper, token-wise level. Based on the insights , we propose cross-layer Entropy eNhanced Decoding (END), a decoding method that mitigates hallucinations without requiring extra training. END leverages inner probability changes across layers to individually quantify the factual knowledge required for each candidate token, and adjusts the final predicting distribution to prioritize tokens with higher factuality. Experiments on both hallucination and QA benchmarks demonstrate that END significantly enhances the truthfulness and informativeness of generated content while maintaining robust QA accuracy. Moreover, our work provides a deeper perspective on understanding the correlations between inherent knowledge and output factuality.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "75",
        "title": "Multilevel Picard approximations for McKean-Vlasov stochastic differential equations with nonconstant diffusion",
        "author": [
            "Ariel Neufeld",
            "Tuan Anh Nguyen",
            "Philipp Schmocker"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03205",
        "abstract": "We introduce multilevel Picard (MLP) approximations for McKean-Vlasov stochastic differential equations (SDEs) with nonconstant diffusion coefficient. Under standard Lipschitz assumptions on the coefficients, we show that the MLP algorithm approximates the solution of the SDE in the $L^2$-sense without the curse of dimensionality. The latter means that its computational cost grows at most polynomially in both the dimension and the reciprocal of the prescribed error tolerance. In two numerical experiments, we demonstrate its applicability by approximating McKean-Vlasov SDEs in dimensions up to 10000.",
        "tags": [
            "Diffusion",
            "SDE"
        ]
    },
    {
        "id": "76",
        "title": "MotionAgent: Fine-grained Controllable Video Generation via Motion Field Agent",
        "author": [
            "Xinyao Liao",
            "Xianfang Zeng",
            "Liao Wang",
            "Gang Yu",
            "Guosheng Lin",
            "Chi Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03207",
        "abstract": "We propose MotionAgent, enabling fine-grained motion control for text-guided image-to-video generation. The key technique is the motion field agent that converts motion information in text prompts into explicit motion fields, providing flexible and precise motion guidance. Specifically, the agent extracts the object movement and camera motion described in the text and converts them into object trajectories and camera extrinsics, respectively. An analytical optical flow composition module integrates these motion representations in 3D space and projects them into a unified optical flow. An optical flow adapter takes the flow to control the base image-to-video diffusion model for generating fine-grained controlled videos. The significant improvement in the Video-Text Camera Motion metrics on VBench indicates that our method achieves precise control over camera motion. We construct a subset of VBench to evaluate the alignment of motion information in the text and the generated video, outperforming other advanced models on motion generation accuracy.",
        "tags": [
            "3D",
            "Diffusion",
            "Video Generation"
        ]
    },
    {
        "id": "77",
        "title": "GARAD-SLAM: 3D GAussian splatting for Real-time Anti Dynamic SLAM",
        "author": [
            "Mingrui Li",
            "Weijian Chen",
            "Na Cheng",
            "Jingyuan Xu",
            "Dong Li",
            "Hongyu Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03228",
        "abstract": "The 3D Gaussian Splatting (3DGS)-based SLAM system has garnered widespread attention due to its excellent performance in real-time high-fidelity rendering. However, in real-world environments with dynamic objects, existing 3DGS-based SLAM systems often face mapping errors and tracking drift issues. To address these problems, we propose GARAD-SLAM, a real-time 3DGS-based SLAM system tailored for dynamic scenes. In terms of tracking, unlike traditional methods, we directly perform dynamic segmentation on Gaussians and map them back to the front-end to obtain dynamic point labels through a Gaussian pyramid network, achieving precise dynamic removal and robust tracking. For mapping, we impose rendering penalties on dynamically labeled Gaussians, which are updated through the network, to avoid irreversible erroneous removal caused by simple pruning. Our results on real-world datasets demonstrate that our method is competitive in tracking compared to baseline methods, generating fewer artifacts and higher-quality reconstructions in rendering.",
        "tags": [
            "3D",
            "Gaussian Splatting",
            "SLAM",
            "Segmentation"
        ]
    },
    {
        "id": "78",
        "title": "Exploring the Security Threats of Knowledge Base Poisoning in Retrieval-Augmented Code Generation",
        "author": [
            "Bo Lin",
            "Shangwen Wang",
            "Liqian Chen",
            "Xiaoguang Mao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03233",
        "abstract": "The integration of Large Language Models (LLMs) into software development has revolutionized the field, particularly through the use of Retrieval-Augmented Code Generation (RACG) systems that enhance code generation with information from external knowledge bases. However, the security implications of RACG systems, particularly the risks posed by vulnerable code examples in the knowledge base, remain largely unexplored. This risk is particularly concerning given that public code repositories, which often serve as the sources for knowledge base collection in RACG systems, are usually accessible to anyone in the community. Malicious attackers can exploit this accessibility to inject vulnerable code into the knowledge base, making it toxic. Once these poisoned samples are retrieved and incorporated into the generated code, they can propagate security vulnerabilities into the final product. This paper presents the first comprehensive study on the security risks associated with RACG systems, focusing on how vulnerable code in the knowledge base compromises the security of generated code. We investigate the LLM-generated code security across different settings through extensive experiments using four major LLMs, two retrievers, and two poisoning scenarios. Our findings highlight the significant threat of knowledge base poisoning, where even a single poisoned code example can compromise up to 48% of generated code. Our findings provide crucial insights into vulnerability introduction in RACG systems and offer practical mitigation recommendations, thereby helping improve the security of LLM-generated code in future works.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "79",
        "title": "Practical Introduction to FEM with GMSH: A MATLAB/Octave Perspective",
        "author": [
            "Victor Dominguez",
            "Alejandro Duque"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03248",
        "abstract": "The Finite Element Method (FEM) is a powerful computational tool for solving partial differential equations (PDEs). Although commercial and open-source FEM software packages are widely available, an independent implementation of FEM provides significant educational value, provides a deeper understanding of the method, and enables the development of custom solutions tailored to specialized applications or integration with other solvers. This work introduces a 3D $\\mathbb{P}_m$-element FEM implementation in MATLAB/Octave that is designed to balance educational clarity with computational efficiency. A key feature is its integration with GMSH, an open-source 3D mesh generator with CAD capabilities that streamlines mesh generation for complex geometries. By leveraging GMSH data structures, we provide a seamless connection between geometric modeling and numerical simulation. The implementation focuses on solving the general convection-diffusion-advection equation and serves as a flexible foundation for addressing advanced problems, including elasticity, mixed formulations, and integration with other numerical methods.",
        "tags": [
            "3D",
            "Diffusion"
        ]
    },
    {
        "id": "80",
        "title": "RiemannGFM: Learning a Graph Foundation Model from Riemannian Geometry",
        "author": [
            "Li Sun",
            "Zhenhao Huang",
            "Suyang Zhou",
            "Qiqi Wan",
            "Hao Peng",
            "Philip Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03251",
        "abstract": "The foundation model has heralded a new era in artificial intelligence, pretraining a single model to offer cross-domain transferability on different datasets. Graph neural networks excel at learning graph data, the omnipresent non-Euclidean structure, but often lack the generalization capacity. Hence, graph foundation model is drawing increasing attention, and recent efforts have been made to leverage Large Language Models. On the one hand, existing studies primarily focus on text-attributed graphs, while a wider range of real graphs do not contain fruitful textual attributes. On the other hand, the sequential graph description tailored for the Large Language Model neglects the structural complexity, which is a predominant characteristic of the graph. Such limitations motivate an important question: Can we go beyond Large Language Models, and pretrain a universal model to learn the structural knowledge for any graph? The answer in the language or vision domain is a shared vocabulary. We observe the fact that there also exist shared substructures underlying graph domain, and thereby open a new opportunity of graph foundation model with structural vocabulary. The key innovation is the discovery of a simple yet effective structural vocabulary of trees and cycles, and we explore its inherent connection to Riemannian geometry. Herein, we present a universal pretraining model, RiemannGFM. Concretely, we first construct a novel product bundle to incorporate the diverse geometries of the vocabulary. Then, on this constructed space, we stack Riemannian layers where the structural vocabulary, regardless of specific graph, is learned in Riemannian manifold offering cross-domain transferability. Extensive experiments show the effectiveness of RiemannGFM on a diversity of real graphs.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "81",
        "title": "How do Humans and Language Models Reason About Creativity? A Comparative Analysis",
        "author": [
            "Antonio Laverghetta Jr.",
            "Tuhin Chakrabarty",
            "Tom Hope",
            "Jimmy Pronchick",
            "Krupa Bhawsar",
            "Roger E. Beaty"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03253",
        "abstract": "Creativity assessment in science and engineering is increasingly based on both human and AI judgment, but the cognitive processes and biases behind these evaluations remain poorly understood. We conducted two experiments examining how including example solutions with ratings impact creativity evaluation, using a finegrained annotation protocol where raters were tasked with explaining their originality scores and rating for the facets of remoteness (whether the response is \"far\" from everyday ideas), uncommonness (whether the response is rare), and cleverness. In Study 1, we analyzed creativity ratings from 72 experts with formal science or engineering training, comparing those who received example solutions with ratings (example) to those who did not (no example). Computational text analysis revealed that, compared to experts with examples, no-example experts used more comparative language (e.g., \"better/worse\") and emphasized solution uncommonness, suggesting they may have relied more on memory retrieval for comparisons. In Study 2, parallel analyses with state-of-the-art LLMs revealed that models prioritized uncommonness and remoteness of ideas when rating originality, suggesting an evaluative process rooted around the semantic similarity of ideas. In the example condition, while LLM accuracy in predicting the true originality scores improved, the correlations of remoteness, uncommonness, and cleverness with originality also increased substantially - to upwards of 0.99 - suggesting a homogenization in the LLMs evaluation of the individual facets. These findings highlight important implications for how humans and AI reason about creativity and suggest diverging preferences for what different populations prioritize when rating.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "82",
        "title": "Efficient extraction of medication information from clinical notes: an evaluation in two languages",
        "author": [
            "Thibaut Fabacher",
            "Erik-AndrÃ© Sauleau",
            "Emmanuelle Arcay",
            "Bineta Faye",
            "Maxime Alter",
            "Archia Chahard",
            "Nathan Miraillet",
            "Adrien Coulet",
            "AurÃ©lie NÃ©vÃ©ol"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03257",
        "abstract": "Objective: To evaluate the accuracy, computational cost and portability of a new Natural Language Processing (NLP) method for extracting medication information from clinical narratives. Materials and Methods: We propose an original transformer-based architecture for the extraction of entities and their relations pertaining to patients' medication regimen. First, we used this approach to train and evaluate a model on French clinical notes, using a newly annotated corpus from HÃ´pitaux Universitaires de Strasbourg. Second, the portability of the approach was assessed by conducting an evaluation on clinical documents in English from the 2018 n2c2 shared task. Information extraction accuracy and computational cost were assessed by comparison with an available method using transformers. Results: The proposed architecture achieves on the task of relation extraction itself performance that are competitive with the state-of-the-art on both French and English (F-measures 0.82 and 0.96 vs 0.81 and 0.95), but reduce the computational cost by 10. End-to-end (Named Entity recognition and Relation Extraction) F1 performance is 0.69 and 0.82 for French and English corpus. Discussion: While an existing system developed for English notes was deployed in a French hospital setting with reasonable effort, we found that an alternative architecture offered end-to-end drug information extraction with comparable extraction performance and lower computational impact for both French and English clinical text processing, respectively. Conclusion: The proposed architecture can be used to extract medication information from clinical text with high performance and low computational cost and consequently suits with usually limited hospital IT resources",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "83",
        "title": "ZISVFM: Zero-Shot Object Instance Segmentation in Indoor Robotic Environments with Vision Foundation Models",
        "author": [
            "Ying Zhang",
            "Maoliang Yin",
            "Wenfu Bi",
            "Haibao Yan",
            "Shaohan Bian",
            "Cui-Hua Zhang",
            "Changchun Hua"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03266",
        "abstract": "Service robots operating in unstructured environments must effectively recognize and segment unknown objects to enhance their functionality. Traditional supervised learningbased segmentation techniques require extensive annotated datasets, which are impractical for the diversity of objects encountered in real-world scenarios. Unseen Object Instance Segmentation (UOIS) methods aim to address this by training models on synthetic data to generalize to novel objects, but they often suffer from the simulation-to-reality gap. This paper proposes a novel approach (ZISVFM) for solving UOIS by leveraging the powerful zero-shot capability of the segment anything model (SAM) and explicit visual representations from a selfsupervised vision transformer (ViT). The proposed framework operates in three stages: (1) generating object-agnostic mask proposals from colorized depth images using SAM, (2) refining these proposals using attention-based features from the selfsupervised ViT to filter non-object masks, and (3) applying K-Medoids clustering to generate point prompts that guide SAM towards precise object segmentation. Experimental validation on two benchmark datasets and a self-collected dataset demonstrates the superior performance of ZISVFM in complex environments, including hierarchical settings such as cabinets, drawers, and handheld objects. Our source code is available at https://github.com/Yinmlmaoliang/zisvfm.",
        "tags": [
            "SAM",
            "Segment Anything",
            "Segmentation",
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "84",
        "title": "Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning",
        "author": [
            "DiJia Su",
            "Hanlin Zhu",
            "Yingchen Xu",
            "Jiantao Jiao",
            "Yuandong Tian",
            "Qinqing Zheng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03275",
        "abstract": "Large Language Models (LLMs) excel at reasoning and planning when trained on chainof-thought (CoT) data, where the step-by-step thought process is explicitly outlined by text tokens. However, this results in lengthy inputs where many words support textual coherence rather than core reasoning information, and processing these inputs consumes substantial computation resources. In this work, we propose a hybrid representation of the reasoning process, where we partially abstract away the initial reasoning steps using latent discrete tokens generated by VQ-VAE, significantly reducing the length of reasoning traces. We explore the use of latent trace abstractions in two scenarios: 1) training the model from scratch for the Keys-Finding Maze problem, 2) fine-tuning LLMs on this hybrid data with an extended vocabulary including unseen latent tokens, for both logical and mathematical reasoning problems. To facilitate effective learning, we introduce a simple training procedure that randomly mixes latent and text tokens, which enables fast adaptation to new latent tokens. Our approach consistently outperforms the baselines methods in various benchmarks.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "VAE"
        ]
    },
    {
        "id": "85",
        "title": "SymAgent: A Neural-Symbolic Self-Learning Agent Framework for Complex Reasoning over Knowledge Graphs",
        "author": [
            "Ben Liu",
            "Jihai Zhang",
            "Fangquan Lin",
            "Cheng Yang",
            "Min Peng",
            "Wotao Yin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03283",
        "abstract": "Recent advancements have highlighted that Large Language Models (LLMs) are prone to hallucinations when solving complex reasoning problems, leading to erroneous results. To tackle this issue, researchers incorporate Knowledge Graphs (KGs) to improve the reasoning ability of LLMs. However, existing methods face two limitations: 1) they typically assume that all answers to the questions are contained in KGs, neglecting the incompleteness issue of KGs, and 2) they treat the KG as a static repository and overlook the implicit logical reasoning structures inherent in KGs. In this paper, we introduce SymAgent, an innovative neural-symbolic agent framework that achieves collaborative augmentation between KGs and LLMs. We conceptualize KGs as dynamic environments and transform complex reasoning tasks into a multi-step interactive process, enabling KGs to participate deeply in the reasoning process. SymAgent consists of two modules: Agent-Planner and Agent-Executor. The Agent-Planner leverages LLM's inductive reasoning capability to extract symbolic rules from KGs, guiding efficient question decomposition. The Agent-Executor autonomously invokes predefined action tools to integrate information from KGs and external documents, addressing the issues of KG incompleteness. Furthermore, we design a self-learning framework comprising online exploration and offline iterative policy updating phases, enabling the agent to automatically synthesize reasoning trajectories and improve performance. Experimental results demonstrate that SymAgent with weak LLM backbones (i.e., 7B series) yields better or comparable performance compared to various strong baselines. Further analysis reveals that our agent can identify missing triples, facilitating automatic KG updates.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "86",
        "title": "Harmony in Divergence: Towards Fast, Accurate, and Memory-efficient Zeroth-order LLM Fine-tuning",
        "author": [
            "Qitao Tan",
            "Jun Liu",
            "Zheng Zhan",
            "Caiwei Ding",
            "Yanzhi Wang",
            "Jin Lu",
            "Geng Yuan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03304",
        "abstract": "Large language models (LLMs) excel across various tasks, but standard first-order (FO) fine-tuning demands considerable memory, significantly limiting real-world deployment. Recently, zeroth-order (ZO) optimization stood out as a promising memory-efficient training paradigm, avoiding backward passes and relying solely on forward passes for gradient estimation, making it attractive for resource-constrained scenarios. However, ZO method lags far behind FO method in both convergence speed and accuracy. To bridge the gap, we introduce a novel layer-wise divergence analysis that uncovers the distinct update pattern of FO and ZO optimization. Aiming to resemble the learning capacity of FO method from the findings, we propose \\textbf{Di}vergence-driven \\textbf{Z}eroth-\\textbf{O}rder (\\textbf{DiZO}) optimization. DiZO conducts divergence-driven layer adaptation by incorporating projections to ZO updates, generating diverse-magnitude updates precisely scaled to layer-wise individual optimization needs. Our results demonstrate that DiZO significantly reduces the needed iterations for convergence without sacrificing throughput, cutting training GPU hours by up to 48\\% on various datasets. Moreover, DiZO consistently outperforms the representative ZO baselines in fine-tuning RoBERTa-large, OPT-series, and Llama-series on downstream tasks and, in some cases, even surpasses memory-intensive FO fine-tuning.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "87",
        "title": "Simplifying Formal Proof-Generating Models with ChatGPT and Basic Searching Techniques",
        "author": [
            "Sangjun Han",
            "Taeil Hur",
            "Youngmi Hur",
            "Kathy Sangkyung Lee",
            "Myungyoon Lee",
            "Hyojae Lim"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03321",
        "abstract": "The challenge of formal proof generation has a rich history, but with modern techniques, we may finally be at the stage of making actual progress in real-life mathematical problems. This paper explores the integration of ChatGPT and basic searching techniques to simplify generating formal proofs, with a particular focus on the miniF2F dataset. We demonstrate how combining a large language model like ChatGPT with a formal language such as Lean, which has the added advantage of being verifiable, enhances the efficiency and accessibility of formal proof generation. Despite its simplicity, our best-performing Lean-based model surpasses all known benchmarks with a 31.15% pass rate. We extend our experiments to include other datasets and employ alternative language models, showcasing our models' comparable performance in diverse settings and allowing for a more nuanced analysis of our results. Our findings offer insights into AI-assisted formal proof generation, suggesting a promising direction for future research in formal mathematical proof.",
        "tags": [
            "ChatGPT"
        ]
    },
    {
        "id": "88",
        "title": "An efficient end-to-end computational framework for the generation of ECG calibrated volumetric models of human atrial electrophysiology",
        "author": [
            "Elena Zappon",
            "Luca Azzolin",
            "Matthias A.F. Gsell",
            "Franz Thaler",
            "Anton J. Prassl",
            "Robert Arnold",
            "Karli Gillette",
            "Mohammadreza Kariman",
            "Martin Manninger-WÃ¼nscher",
            "Daniel Scherr",
            "Aurel Neic",
            "Martin Urschler",
            "Christoph M. Augustin",
            "Edward J. Vigmond",
            "Gernot Plank"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03322",
        "abstract": "Computational models of atrial electrophysiology (EP) are increasingly utilized for applications such as the development of advanced mapping systems, personalized clinical therapy planning, and the generation of virtual cohorts and digital twins. These models have the potential to establish robust causal links between simulated in silico behaviors and observed human atrial EP, enabling safer, cost-effective, and comprehensive exploration of atrial dynamics. However, current state-of-the-art approaches lack the fidelity and scalability required for regulatory-grade applications, particularly in creating high-quality virtual cohorts or patient-specific digital twins. Challenges include anatomically accurate model generation, calibration to sparse and uncertain clinical data, and computational efficiency within a streamlined workflow. This study addresses these limitations by introducing novel methodologies integrated into an automated end-to-end workflow for generating high-fidelity digital twin snapshots and virtual cohorts of atrial EP. These innovations include: (i) automated multi-scale generation of volumetric biatrial models with detailed anatomical structures and fiber architecture; (ii) a robust method for defining space-varying atrial parameter fields; (iii) a parametric approach for modeling inter-atrial conduction pathways; and (iv) an efficient forward EP model for high-fidelity electrocardiogram computation. We evaluated this workflow on a cohort of 50 atrial fibrillation patients, producing high-quality meshes suitable for reaction-eikonal and reaction-diffusion models and demonstrating the ability to simulate atrial ECGs under parametrically controlled conditions. These advancements represent a critical step toward scalable, precise, and clinically applicable digital twin models and virtual cohorts, enabling enhanced patient-specific predictions and therapeutic planning.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "89",
        "title": "Out-of-Distribution Detection using Synthetic Data Generation",
        "author": [
            "Momin Abbas",
            "Muneeza Azmat",
            "Raya Horesh",
            "Mikhail Yurochkin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03323",
        "abstract": "Distinguishing in- and out-of-distribution (OOD) inputs is crucial for reliable deployment of classification systems. However, OOD data is typically unavailable or difficult to collect, posing a significant challenge for accurate OOD detection. In this work, we present a method that harnesses the generative capabilities of Large Language Models (LLMs) to create high-quality synthetic OOD proxies, eliminating the dependency on any external OOD data source. We study the efficacy of our method on classical text classification tasks such as toxicity detection and sentiment classification as well as classification tasks arising in LLM development and deployment, such as training a reward model for RLHF and detecting misaligned generations. Extensive experiments on nine InD-OOD dataset pairs and various model sizes show that our approach dramatically lowers false positive rates (achieving a perfect zero in some cases) while maintaining high accuracy on in-distribution tasks, outperforming baseline methods by a significant margin.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "90",
        "title": "ECM: A Unified Electronic Circuit Model for Explaining the Emergence of In-Context Learning and Chain-of-Thought in Large Language Model",
        "author": [
            "Qiguang Chen",
            "Libo Qin",
            "Jinhao Liu",
            "Dengyun Peng",
            "Jiaqi Wang",
            "Mengkang Hu",
            "Zhi Chen",
            "Wanxiang Che",
            "Ting Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03325",
        "abstract": "Recent advancements in large language models (LLMs) have led to significant successes across various applications, where the most noticeable is to a series of emerging capabilities, particularly in the areas of In-Context Learning (ICL) and Chain-of-Thought (CoT). To better understand and control model performance, many studies have begun investigating the underlying causes of these phenomena and their impact on task outcomes. However, existing explanatory frameworks predominantly focus on isolating and explaining ICL and CoT independently, leading to an incomplete understanding of their combined influence on model performance. To address this gap, we propose the Electronic Circuit Model (ECM), which provides a foundation for developing scalable, learnable policies and improving the management of AI-generated content. Specifically, ECM conceptualizes model behavior as an electronic circuit: ICL is represented as semantic magnetic field to providing an additional voltage following Faraday's Law, while CoT is modeled as series resistors to constrain the model output performance following Ohm's Law. Experimental results demonstrate that the ECM effectively predicts and explains LLM performance across a variety of prompting strategies. Furthermore, we apply ECM to advanced reasoning strategy optimization on a series of tasks, such as the International Olympiad in Informatics (IOI) and the International Mathematical Olympiad (IMO), achieving competitive performance that surpasses nearly 80% of top human competitors.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "91",
        "title": "Controllable GUI Exploration",
        "author": [
            "Aryan Garg",
            "Yue Jiang",
            "Antti Oulasvirta"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03330",
        "abstract": "During the early stages of interface design, designers need to produce multiple sketches to explore a design space. Design tools often fail to support this critical stage, because they insist on specifying more details than necessary. Although recent advances in generative AI have raised hopes of solving this issue, in practice they fail because expressing loose ideas in a prompt is impractical. In this paper, we propose a diffusion-based approach to the low-effort generation of interface sketches. It breaks new ground by allowing flexible control of the generation process via three types of inputs: A) prompts, B) wireframes, and C) visual flows. The designer can provide any combination of these as input at any level of detail, and will get a diverse gallery of low-fidelity solutions in response. The unique benefit is that large design spaces can be explored rapidly with very little effort in input-specification. We present qualitative results for various combinations of input specifications. Additionally, we demonstrate that our model aligns more accurately with these specifications than other models.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "92",
        "title": "Minerva: A Programmable Memory Test Benchmark for Language Models",
        "author": [
            "Menglin Xia",
            "Victor Ruehle",
            "Saravan Rajmohan",
            "Reza Shokri"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03358",
        "abstract": "How effectively can LLM-based AI assistants utilize their memory (context) to perform various tasks? Traditional data benchmarks, which are often manually crafted, suffer from several limitations: they are static, susceptible to overfitting, difficult to interpret, and lack actionable insights--failing to pinpoint the specific capabilities a model lacks when it does not pass a test. In this paper, we present a framework for automatically generating a comprehensive set of tests to evaluate models' abilities to use their memory effectively. Our framework extends the range of capability tests beyond the commonly explored (passkey, key-value, needle in the haystack) search, a dominant focus in the literature. Specifically, we evaluate models on atomic tasks such as searching, recalling, editing, matching, comparing information in context memory, and performing basic operations when inputs are structured into distinct blocks, simulating real-world data. Additionally, we design composite tests to investigate the models' ability to maintain state while operating on memory. Our benchmark enables an interpretable, detailed assessment of memory capabilities of LLMs.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "93",
        "title": "Scaling laws in wearable human activity recognition",
        "author": [
            "Tom Hoddes",
            "Alex Bijamov",
            "Saket Joshi",
            "Daniel Roggen",
            "Ali Etemad",
            "Robert Harle",
            "David Racz"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03364",
        "abstract": "Many deep architectures and self-supervised pre-training techniques have been proposed for human activity recognition (HAR) from wearable multimodal sensors. Scaling laws have the potential to help move towards more principled design by linking model capacity with pre-training data volume. Yet, scaling laws have not been established for HAR to the same extent as in language and vision. By conducting an exhaustive grid search on both amount of pre-training data and Transformer architectures, we establish the first known scaling laws for HAR. We show that pre-training loss scales with a power law relationship to amount of data and parameter count and that increasing the number of users in a dataset results in a steeper improvement in performance than increasing data per user, indicating that diversity of pre-training data is important, which contrasts to some previously reported findings in self-supervised HAR. We show that these scaling laws translate to downstream performance improvements on three HAR benchmark datasets of postures, modes of locomotion and activities of daily living: UCI HAR and WISDM Phone and WISDM Watch. Finally, we suggest some previously published works should be revisited in light of these scaling laws with more adequate model capacities.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "94",
        "title": "PalimpChat: Declarative and Interactive AI analytics",
        "author": [
            "Chunwei Liu",
            "Gerardo Vitagliano",
            "Brandon Rose",
            "Matt Prinz",
            "David Andrew Samson",
            "Michael Cafarella"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03368",
        "abstract": "Thanks to the advances in generative architectures and large language models, data scientists can now code pipelines of machine-learning operations to process large collections of unstructured data. Recent progress has seen the rise of declarative AI frameworks (e.g., Palimpzest, Lotus, and DocETL) to build optimized and increasingly complex pipelines, but these systems often remain accessible only to expert programmers. In this demonstration, we present PalimpChat, a chat-based interface to Palimpzest that bridges this gap by letting users create and run sophisticated AI pipelines through natural language alone. By integrating Archytas, a ReAct-based reasoning agent, and Palimpzest's suite of relational and LLM-based operators, PalimpChat provides a practical illustration of how a chat interface can make declarative AI frameworks truly accessible to non-experts.\nOur demo system is publicly available online. At SIGMOD'25, participants can explore three real-world scenarios--scientific discovery, legal discovery, and real estate search--or apply PalimpChat to their own datasets. In this paper, we focus on how PalimpChat, supported by the Palimpzest optimizer, simplifies complex AI workflows such as extracting and analyzing biomedical data.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "95",
        "title": "Demystifying Long Chain-of-Thought Reasoning in LLMs",
        "author": [
            "Edward Yeo",
            "Yuxuan Tong",
            "Morry Niu",
            "Graham Neubig",
            "Xiang Yue"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03373",
        "abstract": "Scaling inference compute enhances reasoning in large language models (LLMs), with long chains-of-thought (CoTs) enabling strategies like backtracking and error correction. Reinforcement learning (RL) has emerged as a crucial method for developing these capabilities, yet the conditions under which long CoTs emerge remain unclear, and RL training requires careful design choices. In this study, we systematically investigate the mechanics of long CoT reasoning, identifying the key factors that enable models to generate long CoT trajectories. Through extensive supervised fine-tuning (SFT) and RL experiments, we present four main findings: (1) While SFT is not strictly necessary, it simplifies training and improves efficiency; (2) Reasoning capabilities tend to emerge with increased training compute, but their development is not guaranteed, making reward shaping crucial for stabilizing CoT length growth; (3) Scaling verifiable reward signals is critical for RL. We find that leveraging noisy, web-extracted solutions with filtering mechanisms shows strong potential, particularly for out-of-distribution (OOD) tasks such as STEM reasoning; and (4) Core abilities like error correction are inherently present in base models, but incentivizing these skills effectively for complex tasks via RL demands significant compute, and measuring their emergence requires a nuanced approach. These insights provide practical guidance for optimizing training strategies to enhance long CoT reasoning in LLMs. Our code is available at: https://github.com/eddycmu/demystify-long-cot.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RL"
        ]
    },
    {
        "id": "96",
        "title": "Energy-Efficient Flying LoRa Gateways: A Multi-Agent Reinforcement Learning Approach",
        "author": [
            "Abdullahi Isa Ahmed",
            "El Mehdi Amhoud"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03377",
        "abstract": "With the rapid development of next-generation Internet of Things (NG-IoT) networks, the increasing number of connected devices has led to a surge in power consumption. This rise in energy demand poses significant challenges to resource availability and raises sustainability concerns for large-scale IoT deployments. Efficient energy utilization in communication networks, particularly for power-constrained IoT devices, has thus become a critical area of research. In this paper, we deployed flying LoRa gateways (GWs) mounted on unmanned aerial vehicles (UAVs) to collect data from LoRa end devices (EDs) and transmit it to a central server. Our primary objective is to maximize the global system energy efficiency (EE) of wireless LoRa networks by joint optimization of transmission power (TP), spreading factor (SF), bandwidth (W), and ED association. To solve this challenging problem, we model the problem as a partially observable Markov decision process (POMDP), where each flying LoRa GW acts as a learning agent using a cooperative Multi-Agent Reinforcement Learning (MARL) approach under centralized training and decentralized execution (CTDE). Simulation results demonstrate that our proposed method, based on the multi-agent proximal policy optimization (MAPPO) algorithm, significantly improves the global system EE and surpasses the conventional MARL schemes.",
        "tags": [
            "LoRA"
        ]
    },
    {
        "id": "97",
        "title": "LIMO: Less is More for Reasoning",
        "author": [
            "Yixin Ye",
            "Zhen Huang",
            "Yang Xiao",
            "Ethan Chern",
            "Shijie Xia",
            "Pengfei Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03387",
        "abstract": "We present a fundamental discovery that challenges our understanding of how complex reasoning emerges in large language models. While conventional wisdom suggests that sophisticated reasoning tasks demand extensive training data (>100,000 examples), we demonstrate that complex mathematical reasoning abilities can be effectively elicited with surprisingly few examples. Through comprehensive experiments, our proposed model LIMO demonstrates unprecedented performance in mathematical reasoning. With merely 817 curated training samples, LIMO achieves 57.1% accuracy on AIME and 94.8% on MATH, improving from previous SFT-based models' 6.5% and 59.2% respectively, while only using 1% of the training data required by previous approaches. LIMO demonstrates exceptional out-of-distribution generalization, achieving 40.5% absolute improvement across 10 diverse benchmarks, outperforming models trained on 100x more data, challenging the notion that SFT leads to memorization rather than generalization. Based on these results, we propose the Less-Is-More Reasoning Hypothesis (LIMO Hypothesis): In foundation models where domain knowledge has been comprehensively encoded during pre-training, sophisticated reasoning capabilities can emerge through minimal but precisely orchestrated demonstrations of cognitive processes. This hypothesis posits that the elicitation threshold for complex reasoning is determined by two key factors: (1) the completeness of the model's encoded knowledge foundation during pre-training, and (2) the effectiveness of post-training examples as \"cognitive templates\" that show the model how to utilize its knowledge base to solve complex reasoning tasks. To facilitate reproducibility and future research in data-efficient reasoning, we release LIMO as a comprehensive open-source suite at https://github.com/GAIR-NLP/LIMO.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "98",
        "title": "SPRI: Aligning Large Language Models with Context-Situated Principles",
        "author": [
            "Hongli Zhan",
            "Muneeza Azmat",
            "Raya Horesh",
            "Junyi Jessy Li",
            "Mikhail Yurochkin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03397",
        "abstract": "Aligning Large Language Models to integrate and reflect human values, especially for tasks that demand intricate human oversight, is arduous since it is resource-intensive and time-consuming to depend on human expertise for context-specific guidance. Prior work has utilized predefined sets of rules or principles to steer the behavior of models (Bai et al., 2022; Sun et al., 2023). However, these principles tend to be generic, making it challenging to adapt them to each individual input query or context. In this work, we present Situated-PRInciples (SPRI), a framework requiring minimal or no human effort that is designed to automatically generate guiding principles in real-time for each input query and utilize them to align each response. We evaluate SPRI on three tasks, and show that 1) SPRI can derive principles in a complex domain-specific task that leads to on-par performance as expert-crafted ones; 2) SPRI-generated principles lead to instance-specific rubrics that outperform prior LLM-as-a-judge frameworks; 3) using SPRI to generate synthetic SFT data leads to substantial improvement on truthfulness. We release our code and model generations at https://github.com/honglizhan/SPRI-public.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "99",
        "title": "Detecting Strategic Deception Using Linear Probes",
        "author": [
            "Nicholas Goldowsky-Dill",
            "Bilal Chughtai",
            "Stefan Heimersheim",
            "Marius Hobbhahn"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03407",
        "abstract": "AI models might use deceptive strategies as part of scheming or misaligned behaviour. Monitoring outputs alone is insufficient, since the AI might produce seemingly benign outputs while their internal reasoning is misaligned. We thus evaluate if linear probes can robustly detect deception by monitoring model activations. We test two probe-training datasets, one with contrasting instructions to be honest or deceptive (following Zou et al., 2023) and one of responses to simple roleplaying scenarios. We test whether these probes generalize to realistic settings where Llama-3.3-70B-Instruct behaves deceptively, such as concealing insider trading (Scheurer et al., 2023) and purposely underperforming on safety evaluations (Benton et al., 2024). We find that our probe distinguishes honest and deceptive responses with AUROCs between 0.96 and 0.999 on our evaluation datasets. If we set the decision threshold to have a 1% false positive rate on chat data not related to deception, our probe catches 95-99% of the deceptive responses. Overall we think white-box probes are promising for future monitoring systems, but current performance is insufficient as a robust defence against deception. Our probes' outputs can be viewed at http://data.apolloresearch.ai/dd and our code at http://github.com/ApolloResearch/deception-detection.",
        "tags": [
            "Detection",
            "LLaMA"
        ]
    },
    {
        "id": "100",
        "title": "From Features to Transformers: Redefining Ranking for Scalable Impact",
        "author": [
            "Fedor Borisyuk",
            "Lars Hertel",
            "Ganesh Parameswaran",
            "Gaurav Srivastava",
            "Sudarshan Srinivasa Ramanujam",
            "Borja Ocejo",
            "Peng Du",
            "Andrei Akterskii",
            "Neil Daftary",
            "Shao Tang",
            "Daqi Sun",
            "Qiang Charles Xiao",
            "Deepesh Nathani",
            "Mohit Kothari",
            "Yun Dai",
            "Aman Gupta"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03417",
        "abstract": "We present LiGR, a large-scale ranking framework developed at LinkedIn that brings state-of-the-art transformer-based modeling architectures into production. We introduce a modified transformer architecture that incorporates learned normalization and simultaneous set-wise attention to user history and ranked items. This architecture enables several breakthrough achievements, including: (1) the deprecation of most manually designed feature engineering, outperforming the prior state-of-the-art system using only few features (compared to hundreds in the baseline), (2) validation of the scaling law for ranking systems, showing improved performance with larger models, more training data, and longer context sequences, and (3) simultaneous joint scoring of items in a set-wise manner, leading to automated improvements in diversity. To enable efficient serving of large ranking models, we describe techniques to scale inference effectively using single-pass processing of user history and set-wise attention. We also summarize key insights from various ablation studies and A/B tests, highlighting the most impactful technical approaches.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "101",
        "title": "Think or Step-by-Step? UnZIPping the Black Box in Zero-Shot Prompts",
        "author": [
            "Nikta Gohari Sadr",
            "Sangmitra Madhusudan",
            "Ali Emami"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03418",
        "abstract": "Zero-shot prompting techniques have significantly improved the performance of Large Language Models (LLMs). However, we lack a clear understanding of why zero-shot prompts are so effective. For example, in the prompt \"Let's think step-by-step,\" is \"think\" or \"step-by-step\" more crucial to its success? Existing interpretability methods, such as gradient-based and attention-based approaches, are computationally intensive and restricted to open-source models. We introduce the ZIP score (Zero-shot Importance of Perturbation score), a versatile metric applicable to both open and closed-source models, based on systematic input word perturbations. Our experiments across four recent LLMs, seven widely-used prompts, and several tasks, reveal interesting patterns in word importance. For instance, while both 'step-by-step' and 'think' show high ZIP scores, which one is more influential depends on the model and task. We validate our method using controlled experiments and compare our results with human judgments, finding that proprietary models align more closely with human intuition regarding word significance. These findings enhance our understanding of LLM behavior and contribute to developing more effective zero-shot prompts and improved model analysis.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "102",
        "title": "Can Text-to-Image Generative Models Accurately Depict Age? A Comparative Study on Synthetic Portrait Generation and Age Estimation",
        "author": [
            "Alexey A. Novikov",
            "Miroslav Vranka",
            "FranÃ§ois David",
            "Artem Voronin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03420",
        "abstract": "Text-to-image generative models have shown remarkable progress in producing diverse and photorealistic outputs. In this paper, we present a comprehensive analysis of their effectiveness in creating synthetic portraits that accurately represent various demographic attributes, with a special focus on age, nationality, and gender. Our evaluation employs prompts specifying detailed profiles (e.g., Photorealistic selfie photo of a 32-year-old Canadian male), covering a broad spectrum of 212 nationalities, 30 distinct ages from 10 to 78, and balanced gender representation. We compare the generated images against ground truth age estimates from two established age estimation models to assess how faithfully age is depicted. Our findings reveal that although text-to-image models can consistently generate faces reflecting different identities, the accuracy with which they capture specific ages and do so across diverse demographic backgrounds remains highly variable. These results suggest that current synthetic data may be insufficiently reliable for high-stakes age-related tasks requiring robust precision, unless practitioners are prepared to invest in significant filtering and curation. Nevertheless, they may still be useful in less sensitive or exploratory applications, where absolute age precision is not critical.",
        "tags": [
            "Text-to-Image"
        ]
    },
    {
        "id": "103",
        "title": "Harnessing Large Language Models for Curated Code Reviews",
        "author": [
            "Oussama Ben Sghaier",
            "Martin Weyssow",
            "Houari Sahraoui"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03425",
        "abstract": "In code review, generating structured and relevant comments is crucial for identifying code issues and facilitating accurate code changes that ensure an efficient code review process. Well-crafted comments not only streamline the code review itself but are also essential for subsequent tasks like code refinement, where the code is modified to satisfy the input review comment. Although various AI-based approaches aimed to automate comment generation, their effectiveness remains limited by the quality of the training data. Existing code review datasets are often noisy and unrefined, posing limitations to the learning potential of AI models and hindering the automation process.\nTo address these challenges, we propose a curation pipeline designed to enhance the quality of the largest publicly available code review dataset. We begin by establishing an evaluation framework, incorporating specific criteria and categories to empirically study the initial quality of the dataset. Using a large language model (LLM)-driven approach, we then apply our curation pipeline to refine the dataset. A comparative analysis of the newly curated dataset, based on the same evaluation framework, demonstrates substantial improvements in the clarity and conciseness of the comments. Additionally, we assess the impact of the curated dataset on automating downstream tasks, specifically comment generation and code refinement. Our findings show that the curated dataset leads to enhanced model performance in generating more accurate comments. Curated comments are also more useful as they lead to more accurate code refinement.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "104",
        "title": "TruePose: Human-Parsing-guided Attention Diffusion for Full-ID Preserving Pose Transfer",
        "author": [
            "Zhihong Xu",
            "Dongxia Wang",
            "Peng Du",
            "Yang Cao",
            "Qing Guo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03426",
        "abstract": "Pose-Guided Person Image Synthesis (PGPIS) generates images that maintain a subject's identity from a source image while adopting a specified target pose (e.g., skeleton). While diffusion-based PGPIS methods effectively preserve facial features during pose transformation, they often struggle to accurately maintain clothing details from the source image throughout the diffusion process. This limitation becomes particularly problematic when there is a substantial difference between the source and target poses, significantly impacting PGPIS applications in the fashion industry where clothing style preservation is crucial for copyright protection. Our analysis reveals that this limitation primarily stems from the conditional diffusion model's attention modules failing to adequately capture and preserve clothing patterns. To address this limitation, we propose human-parsing-guided attention diffusion, a novel approach that effectively preserves both facial and clothing appearance while generating high-quality results. We propose a human-parsing-aware Siamese network that consists of three key components: dual identical UNets (TargetNet for diffusion denoising and SourceNet for source image embedding extraction), a human-parsing-guided fusion attention (HPFA), and a CLIP-guided attention alignment (CAA). The HPFA and CAA modules can embed the face and clothes patterns into the target image generation adaptively and effectively. Extensive experiments on both the in-shop clothes retrieval benchmark and the latest in-the-wild human editing dataset demonstrate our method's significant advantages over 13 baseline approaches for preserving both facial and clothes appearance in the source image.",
        "tags": [
            "CLIP",
            "Diffusion"
        ]
    },
    {
        "id": "105",
        "title": "On Fairness of Unified Multimodal Large Language Model for Image Generation",
        "author": [
            "Ming Liu",
            "Hao Chen",
            "Jindong Wang",
            "Liwen Wang",
            "Bhiksha Raj Ramakrishnan",
            "Wensheng Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03429",
        "abstract": "Unified multimodal large language models (U-MLLMs) have demonstrated impressive performance in visual understanding and generation in an end-to-end pipeline. Compared with generation-only models (e.g., Stable Diffusion), U-MLLMs may raise new questions about bias in their outputs, which can be affected by their unified capabilities. This gap is particularly concerning given the under-explored risk of propagating harmful stereotypes. In this paper, we benchmark the latest U-MLLMs and find that most exhibit significant demographic biases, such as gender and race bias. To better understand and mitigate this issue, we propose a locate-then-fix strategy, where we audit and show how the individual model component is affected by bias. Our analysis shows that bias originates primarily from the language model. More interestingly, we observe a \"partial alignment\" phenomenon in U-MLLMs, where understanding bias appears minimal, but generation bias remains substantial. Thus, we propose a novel balanced preference model to balance the demographic distribution with synthetic data. Experiments demonstrate that our approach reduces demographic bias while preserving semantic fidelity. We hope our findings underscore the need for more holistic interpretation and debiasing strategies of U-MLLMs in the future.",
        "tags": [
            "Diffusion",
            "Large Language Models"
        ]
    },
    {
        "id": "106",
        "title": "BFS-Prover: Scalable Best-First Tree Search for LLM-based Automatic Theorem Proving",
        "author": [
            "Ran Xin",
            "Chenguang Xi",
            "Jie Yang",
            "Feng Chen",
            "Hang Wu",
            "Xia Xiao",
            "Yifan Sun",
            "Shen Zheng",
            "Kai Shen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03438",
        "abstract": "Recent advancements in large language models (LLMs) have spurred growing interest in automatic theorem proving using Lean4, where effective tree search methods are crucial for navigating proof search spaces. While the existing approaches primarily rely on value functions and Monte Carlo Tree Search (MCTS), the potential of simpler methods like Best-First Search (BFS) remains underexplored. This paper investigates whether BFS can achieve competitive performance in large-scale theorem proving tasks. We present \\texttt{BFS-Prover}, a scalable expert iteration framework, featuring three key innovations. First, we implement strategic data filtering at each expert iteration round, excluding problems solvable via beam search node expansion to focus on harder cases. Second, we improve the sample efficiency of BFS through Direct Preference Optimization (DPO) applied to state-tactic pairs automatically annotated with compiler error feedback, refining the LLM's policy to prioritize productive expansions. Third, we employ length normalization in BFS to encourage exploration of deeper proof paths. \\texttt{BFS-Prover} achieves a score of $71.31$ on the MiniF2F test set and therefore challenges the perceived necessity of complex tree search methods, demonstrating that BFS can achieve competitive performance when properly scaled.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "107",
        "title": "Masked Autoencoders Are Effective Tokenizers for Diffusion Models",
        "author": [
            "Hao Chen",
            "Yujin Han",
            "Fangyi Chen",
            "Xiang Li",
            "Yidong Wang",
            "Jindong Wang",
            "Ze Wang",
            "Zicheng Liu",
            "Difan Zou",
            "Bhiksha Raj"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03444",
        "abstract": "Recent advances in latent diffusion models have demonstrated their effectiveness for high-resolution image synthesis. However, the properties of the latent space from tokenizer for better learning and generation of diffusion models remain under-explored. Theoretically and empirically, we find that improved generation quality is closely tied to the latent distributions with better structure, such as the ones with fewer Gaussian Mixture modes and more discriminative features. Motivated by these insights, we propose MAETok, an autoencoder (AE) leveraging mask modeling to learn semantically rich latent space while maintaining reconstruction fidelity. Extensive experiments validate our analysis, demonstrating that the variational form of autoencoders is not necessary, and a discriminative latent space from AE alone enables state-of-the-art performance on ImageNet generation using only 128 tokens. MAETok achieves significant practical improvements, enabling a gFID of 1.69 with 76x faster training and 31x higher inference throughput for 512x512 generation. Our findings show that the structure of the latent space, rather than variational constraints, is crucial for effective diffusion models. Code and trained models are released.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "108",
        "title": "Designing LLM-simulated Immersive Spaces to Enhance Autistic Children's Social Affordances Understanding",
        "author": [
            "Yancheng Cao",
            "Yangyang HE",
            "Yonglin Chen",
            "Menghan Chen",
            "Shanhe You",
            "Yulin Qiu",
            "Min Liu",
            "Chuan Luo",
            "Chen Zheng",
            "Xin Tong",
            "Jing Liang",
            "Jiangtao Gong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03447",
        "abstract": "One of the key challenges faced by autistic children is understanding social affordances in complex environments, which further impacts their ability to respond appropriately to social signals.\nIn traffic scenarios, this impairment can even lead to safety concerns. In this paper, we introduce an LLM-simulated immersive projection environment designed to improve this ability in autistic children while ensuring their safety. We first propose 17 design considerations across four major categories, derived from a comprehensive review of previous research. Next, we developed a system called AIroad, which leverages LLMs to simulate drivers with varying social intents, expressed through explicit multimodal social signals. AIroad helps autistic children bridge the gap in recognizing the intentions behind behaviors and learning appropriate responses through various stimuli. A user study involving 14 participants demonstrated that this technology effectively engages autistic children and leads to significant improvements in their comprehension of social affordances in traffic scenarios. Additionally, parents reported high perceived usability of the system. These findings highlight the potential of combining LLM technology with immersive environments for the functional rehabilitation of autistic children in the future.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "109",
        "title": "Dress-1-to-3: Single Image to Simulation-Ready 3D Outfit with Diffusion Prior and Differentiable Physics",
        "author": [
            "Xuan Li",
            "Chang Yu",
            "Wenxin Du",
            "Ying Jiang",
            "Tianyi Xie",
            "Yunuo Chen",
            "Yin Yang",
            "Chenfanfu Jiang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03449",
        "abstract": "Recent advances in large models have significantly advanced image-to-3D reconstruction. However, the generated models are often fused into a single piece, limiting their applicability in downstream tasks. This paper focuses on 3D garment generation, a key area for applications like virtual try-on with dynamic garment animations, which require garments to be separable and simulation-ready. We introduce Dress-1-to-3, a novel pipeline that reconstructs physics-plausible, simulation-ready separated garments with sewing patterns and humans from an in-the-wild image. Starting with the image, our approach combines a pre-trained image-to-sewing pattern generation model for creating coarse sewing patterns with a pre-trained multi-view diffusion model to produce multi-view images. The sewing pattern is further refined using a differentiable garment simulator based on the generated multi-view images. Versatile experiments demonstrate that our optimization approach substantially enhances the geometric alignment of the reconstructed 3D garments and humans with the input image. Furthermore, by integrating a texture generation module and a human motion generation module, we produce customized physics-plausible and realistic dynamic garment demonstrations. Project page: https://dress-1-to-3.github.io/",
        "tags": [
            "3D",
            "Diffusion",
            "Image-to-3D",
            "Virtual Try-On"
        ]
    },
    {
        "id": "110",
        "title": "A Schema-Guided Reason-while-Retrieve framework for Reasoning on Scene Graphs with Large-Language-Models (LLMs)",
        "author": [
            "Yiye Chen",
            "Harpreet Sawhney",
            "Nicholas GydÃ©",
            "Yanan Jian",
            "Jack Saunders",
            "Patricio Vela",
            "Ben Lundell"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03450",
        "abstract": "Scene graphs have emerged as a structured and serializable environment representation for grounded spatial reasoning with Large Language Models (LLMs). In this work, we propose SG-RwR, a Schema-Guided Retrieve-while-Reason framework for reasoning and planning with scene graphs. Our approach employs two cooperative, code-writing LLM agents: a (1) Reasoner for task planning and information queries generation, and a (2) Retriever for extracting corresponding graph information following the queries. Two agents collaborate iteratively, enabling sequential reasoning and adaptive attention to graph information. Unlike prior works, both agents are prompted only with the scene graph schema rather than the full graph data, which reduces the hallucination by limiting input tokens, and drives the Reasoner to generate reasoning trace http://abstractly.Following the trace, the Retriever programmatically query the scene graph data based on the schema understanding, allowing dynamic and global attention on the graph that enhances alignment between reasoning and retrieval. Through experiments in multiple simulation environments, we show that our framework surpasses existing LLM-based approaches in numerical Q\\&A and planning tasks, and can benefit from task-level few-shot examples, even in the absence of agent-level demonstrations. Project code will be released.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "111",
        "title": "SKI Models: Skeleton Induced Vision-Language Embeddings for Understanding Activities of Daily Living",
        "author": [
            "Arkaprava Sinha",
            "Dominick Reilly",
            "Francois Bremond",
            "Pu Wang",
            "Srijan Das"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03459",
        "abstract": "The introduction of vision-language models like CLIP has enabled the development of foundational video models capable of generalizing to unseen videos and human actions. However, these models are typically trained on web videos, which often fail to capture the challenges present in Activities of Daily Living (ADL) videos. Existing works address ADL-specific challenges, such as similar appearances, subtle motion patterns, and multiple viewpoints, by combining 3D skeletons and RGB videos. However, these approaches are not integrated with language, limiting their ability to generalize to unseen action classes. In this paper, we introduce SKI models, which integrate 3D skeletons into the vision-language embedding space. SKI models leverage a skeleton-language model, SkeletonCLIP, to infuse skeleton information into Vision Language Models (VLMs) and Large Vision Language Models (LVLMs) through collaborative training. Notably, SKI models do not require skeleton data during inference, enhancing their robustness for real-world applications. The effectiveness of SKI models is validated on three popular ADL datasets for zero-shot action recognition and video caption generation tasks.",
        "tags": [
            "3D",
            "CLIP"
        ]
    },
    {
        "id": "112",
        "title": "Adapt-Pruner: Adaptive Structural Pruning for Efficient Small Language Model Training",
        "author": [
            "Boyao Wang",
            "Rui Pan",
            "Shizhe Diao",
            "Xingyuan Pan",
            "Jipeng Zhang",
            "Renjie Pi",
            "Tong Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03460",
        "abstract": "Small language models (SLMs) have attracted considerable attention from both academia and industry due to their broad range of applications in edge devices. To obtain SLMs with strong performance, conventional approaches either pre-train the models from scratch, which incurs substantial computational costs, or compress/prune existing large language models (LLMs), which results in performance drops and falls short in comparison to pre-training. In this paper, we investigate the family of acceleration methods that involve both structured pruning and model training. We found 1) layer-wise adaptive pruning (Adapt-Pruner) is extremely effective in LLMs and yields significant improvements over existing pruning techniques, 2) adaptive pruning equipped with further training leads to models comparable to those pre-training from scratch, 3) incremental pruning brings non-trivial performance gain by interleaving pruning with training and only removing a small portion of neurons ($\\sim$5%) at a time. Experimental results on LLaMA-3.1-8B demonstrate that Adapt-Pruner outperforms conventional pruning methods, such as LLM-Pruner, FLAP, and SliceGPT, by an average of 1%-7% in accuracy on commonsense benchmarks. Additionally, Adapt-Pruner restores the performance of MobileLLM-125M to 600M on the MMLU benchmark with 200$\\times$ fewer tokens via pruning from its larger counterparts, and discovers a new 1B model that surpasses LLaMA-3.2-1B in multiple benchmarks.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "113",
        "title": "Do Large Language Model Benchmarks Test Reliability?",
        "author": [
            "Joshua Vendrow",
            "Edward Vendrow",
            "Sara Beery",
            "Aleksander Madry"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03461",
        "abstract": "When deploying large language models (LLMs), it is important to ensure that these models are not only capable, but also reliable. Many benchmarks have been created to track LLMs' growing capabilities, however there has been no similar focus on measuring their reliability. To understand the potential ramifications of this gap, we investigate how well current benchmarks quantify model reliability. We find that pervasive label errors can compromise these evaluations, obscuring lingering model failures and hiding unreliable behavior.\nMotivated by this gap in the evaluation of reliability, we then propose the concept of so-called platinum benchmarks, i.e., benchmarks carefully curated to minimize label errors and ambiguity. As a first attempt at constructing such benchmarks, we revise examples from fifteen existing popular benchmarks. We evaluate a wide range of models on these platinum benchmarks and find that, indeed, frontier LLMs still exhibit failures on simple tasks such as elementary-level math word problems. Analyzing these failures further reveals previously unidentified patterns of problems on which frontier models consistently struggle. We provide code at https://github.com/MadryLab/platinum-benchmarks",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "114",
        "title": "SEAL: Speech Embedding Alignment Learning for Speech Large Language Model with Retrieval-Augmented Generation",
        "author": [
            "Chunyu Sun",
            "Bingyu Liu",
            "Zhichao Cui",
            "Anbin Qi",
            "Tian-hao Zhang",
            "Dinghao Zhou",
            "Lewei Lu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02603",
        "abstract": "Embedding-based retrieval models have made significant strides in retrieval-augmented generation (RAG) techniques for text and multimodal large language models (LLMs) applications. However, when it comes to speech larage language models (SLLMs), these methods are limited to a two-stage process, where automatic speech recognition (ASR) is combined with text-based retrieval. This sequential architecture suffers from high latency and error propagation. To address these limitations, we propose a unified embedding framework that eliminates the need for intermediate text representations. Specifically, the framework includes separate speech and text encoders, followed by a shared scaling layer that maps both modalities into a common embedding space. Our model reduces pipeline latency by 50\\% while achieving higher retrieval accuracy compared to traditional two-stage methods. We also provide a theoretical analysis of the challenges inherent in end-to-end speech retrieval and introduce architectural principles for effective speech-to-document matching. Extensive experiments demonstrate the robustness of our approach across diverse acoustic conditions and speaker variations, paving the way for a new paradigm in multimodal SLLMs retrieval systems.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "115",
        "title": "Muographic Image Upsampling with Machine Learning for Built Infrastructure Applications",
        "author": [
            "William O'Donnell",
            "David Mahon",
            "Guangliang Yang",
            "Simon Gardner"
        ],
        "pdf": "https://arxiv.org/pdf/2502.02624",
        "abstract": "The civil engineering industry faces a critical need for innovative non-destructive evaluation methods, particularly for ageing critical infrastructure, such as bridges, where current techniques fall short. Muography, a non-invasive imaging technique, constructs three-dimensional density maps by detecting interactions of naturally occurring cosmic-ray muons within the scanned volume. Cosmic-ray muons provide deep penetration and inherent safety due to their high momenta and natural source. However, the technology's reliance on this source results in constrained muon flux, leading to prolonged acquisition times, noisy reconstructions and image interpretation challenges. To address these limitations, we developed a two-model deep learning approach. First, we employed a conditional Wasserstein generative adversarial network with gradient penalty (cWGAN-GP) to perform predictive upsampling of undersampled muography images. Using the structural similarity index measure (SSIM), 1-day sampled images matched the perceptual qualities of a 21-day image, while the peak signal-to-noise ratio (PSNR) indicated noise improvement equivalent to 31 days of sampling. A second cWGAN-GP model, trained for semantic segmentation, quantitatively assessed the upsampling model's impact on concrete sample features. This model achieved segmentation of rebar grids and tendon ducts, with Dice-SÃ¸rensen accuracy coefficients of 0.8174 and 0.8663. Notably, it could mitigate or remove z-plane smearing artifacts caused by muography's inverse imaging problem. Both models were trained on a comprehensive Geant4 Monte-Carlo simulation dataset reflecting realistic civil infrastructure scenarios. Our results demonstrate significant improvements in acquisition speed and image quality, marking a substantial step toward making muography more practical for reinforced concrete infrastructure monitoring applications.",
        "tags": [
            "FLUX",
            "Segmentation"
        ]
    },
    {
        "id": "116",
        "title": "CARROT: A Cost Aware Rate Optimal Router",
        "author": [
            "Seamus Somerstep",
            "Felipe Maia Polo",
            "Allysson Flavio Melo de Oliveira",
            "Prattyush Mangal",
            "MÃ­rian Silva",
            "Onkar Bhardwaj",
            "Mikhail Yurochkin",
            "Subha Maity"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03261",
        "abstract": "With the rapid growth in the number of Large Language Models (LLMs), there has been a recent interest in LLM routing, or directing queries to the cheapest LLM that can deliver a suitable response. Following this line of work, we introduce CARROT, a Cost AwaRe Rate Optimal rouTer that can select models based on any desired trade-off between performance and cost. Given a query, CARROT selects a model based on estimates of models' cost and performance. Its simplicity lends CARROT computational efficiency, while our theoretical analysis demonstrates minimax rate-optimality in its routing performance. Alongside CARROT, we also introduce the Smart Price-aware Routing (SPROUT) dataset to facilitate routing on a wide spectrum of queries with the latest state-of-the-art LLMs. Using SPROUT and prior benchmarks such as Routerbench and open-LLM-leaderboard-v2 we empirically validate CARROT's performance against several alternative routers.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "117",
        "title": "Is In-Context Universality Enough? MLPs are Also Universal In-Context",
        "author": [
            "Anastasis Kratsios",
            "Takashi Furuya"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03327",
        "abstract": "The success of transformers is often linked to their ability to perform in-context learning. Recent work shows that transformers are universal in context, capable of approximating any real-valued continuous function of a context (a probability measure over $\\mathcal{X}\\subseteq \\mathbb{R}^d$) and a query $x\\in \\mathcal{X}$. This raises the question: Does in-context universality explain their advantage over classical models? We answer this in the negative by proving that MLPs with trainable activation functions are also universal in-context. This suggests the transformer's success is likely due to other factors like inductive bias or training stability.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "118",
        "title": "A Mixture-Based Framework for Guiding Diffusion Models",
        "author": [
            "Yazid Janati",
            "Badr Moufad",
            "Mehdi Abou El Qassime",
            "Alain Durmus",
            "Eric Moulines",
            "Jimmy Olsson"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03332",
        "abstract": "Denoising diffusion models have driven significant progress in the field of Bayesian inverse problems. Recent approaches use pre-trained diffusion models as priors to solve a wide range of such problems, only leveraging inference-time compute and thereby eliminating the need to retrain task-specific models on the same dataset. To approximate the posterior of a Bayesian inverse problem, a diffusion model samples from a sequence of intermediate posterior distributions, each with an intractable likelihood function. This work proposes a novel mixture approximation of these intermediate distributions. Since direct gradient-based sampling of these mixtures is infeasible due to intractable terms, we propose a practical method based on Gibbs sampling. We validate our approach through extensive experiments on image inverse problems, utilizing both pixel- and latent-space diffusion priors, as well as on source separation with an audio diffusion model. The code is available at https://www.github.com/badr-moufad/mgdm",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "119",
        "title": "Taking a Big Step: Large Learning Rates in Denoising Score Matching Prevent Memorization",
        "author": [
            "Yu-Han Wu",
            "Pierre Marion",
            "GÃ©rard Biau",
            "Claire Boyer"
        ],
        "pdf": "https://arxiv.org/pdf/2502.03435",
        "abstract": "Denoising score matching plays a pivotal role in the performance of diffusion-based generative models. However, the empirical optimal score--the exact solution to the denoising score matching--leads to memorization, where generated samples replicate the training data. Yet, in practice, only a moderate degree of memorization is observed, even without explicit regularization. In this paper, we investigate this phenomenon by uncovering an implicit regularization mechanism driven by large learning rates. Specifically, we show that in the small-noise regime, the empirical optimal score exhibits high irregularity. We then prove that, when trained by stochastic gradient descent with a large enough learning rate, neural networks cannot stably converge to a local minimum with arbitrarily small excess risk. Consequently, the learned score cannot be arbitrarily close to the empirical optimal score, thereby mitigating memorization. To make the analysis tractable, we consider one-dimensional data and two-layer neural networks. Experiments validate the crucial role of the learning rate in preventing memorization, even beyond the one-dimensional setting.",
        "tags": [
            "Diffusion",
            "Score Matching"
        ]
    }
]