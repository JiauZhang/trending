[
    {
        "id": "1",
        "title": "Efficient and Trustworthy Block Propagation for Blockchain-enabled Mobile Embodied AI Networks: A Graph Resfusion Approach",
        "author": [
            "Jiawen Kang",
            "Jiana Liao",
            "Runquan Gao",
            "Jinbo Wen",
            "Huawei Huang",
            "Maomao Zhang",
            "Changyan Yi",
            "Tao Zhang",
            "Dusit Niyato",
            "Zibin Zheng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09624",
        "abstract": "By synergistically integrating mobile networks and embodied artificial intelligence (AI), Mobile Embodied AI Networks (MEANETs) represent an advanced paradigm that facilitates autonomous, context-aware, and interactive behaviors within dynamic environments. Nevertheless, the rapid development of MEANETs is accompanied by challenges in trustworthiness and operational efficiency. Fortunately, blockchain technology, with its decentralized and immutable characteristics, offers promising solutions for MEANETs. However, existing block propagation mechanisms suffer from challenges such as low propagation efficiency and weak security for block propagation, which results in delayed transmission of vehicular messages or vulnerability to malicious tampering, potentially causing severe traffic accidents in blockchain-enabled MEANETs. Moreover, current block propagation strategies cannot effectively adapt to real-time changes of dynamic topology in MEANETs. Therefore, in this paper, we propose a graph Resfusion model-based trustworthy block propagation optimization framework for consortium blockchain-enabled MEANETs. Specifically, we propose an innovative trust calculation mechanism based on the trust cloud model, which comprehensively accounts for randomness and fuzziness in the miner trust evaluation. Furthermore, by leveraging the strengths of graph neural networks and diffusion models, we develop a graph Resfusion model to effectively and adaptively generate the optimal block propagation trajectory. Simulation results demonstrate that the proposed model outperforms other routing mechanisms in terms of block propagation efficiency and trustworthiness. Additionally, the results highlight its strong adaptability to dynamic environments, making it particularly suitable for rapidly changing MEANETs.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "2",
        "title": "Reading between the Lines: Can LLMs Identify Cross-Cultural Communication Gaps?",
        "author": [
            "Sougata Saha",
            "Saurabh Kumar Pandey",
            "Harshit Gupta",
            "Monojit Choudhury"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09636",
        "abstract": "In a rapidly globalizing and digital world, content such as book and product reviews created by people from diverse cultures are read and consumed by others from different corners of the world. In this paper, we investigate the extent and patterns of gaps in understandability of book reviews due to the presence of culturally-specific items and elements that might be alien to users from another culture. Our user-study on 57 book reviews from Goodreads reveal that 83\\% of the reviews had at least one culture-specific difficult-to-understand element. We also evaluate the efficacy of GPT-4o in identifying such items, given the cultural background of the reader; the results are mixed, implying a significant scope for improvement. Our datasets are available here: https://github.com/sougata-ub/reading_between_lines",
        "tags": [
            "GPT",
            "LLMs"
        ]
    },
    {
        "id": "3",
        "title": "Meta-Cultural Competence: Climbing the Right Hill of Cultural Awareness",
        "author": [
            "Sougata Saha",
            "Saurabh Kumar Pandey",
            "Monojit Choudhury"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09637",
        "abstract": "Numerous recent studies have shown that Large Language Models (LLMs) are biased towards a Western and Anglo-centric worldview, which compromises their usefulness in non-Western cultural settings. However, \"culture\" is a complex, multifaceted topic, and its awareness, representation, and modeling in LLMs and LLM-based applications can be defined and measured in numerous ways. In this position paper, we ask what does it mean for an LLM to possess \"cultural awareness\", and through a thought experiment, which is an extension of the Octopus test proposed by Bender and Koller (2020), we argue that it is not cultural awareness or knowledge, rather meta-cultural competence, which is required of an LLM and LLM-based AI system that will make it useful across various, including completely unseen, cultures. We lay out the principles of meta-cultural competence AI systems, and discuss ways to measure and model those.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "4",
        "title": "Jailbreaking to Jailbreak",
        "author": [
            "Jeremy Kritz",
            "Vaughn Robinson",
            "Robert Vacareanu",
            "Bijan Varjavand",
            "Michael Choi",
            "Bobby Gogov",
            "Scale Red Team",
            "Summer Yue",
            "Willow E. Primack",
            "Zifan Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09638",
        "abstract": "Refusal training on Large Language Models (LLMs) prevents harmful outputs, yet this defense remains vulnerable to both automated and human-crafted jailbreaks. We present a novel LLM-as-red-teamer approach in which a human jailbreaks a refusal-trained LLM to make it willing to jailbreak itself or other LLMs. We refer to the jailbroken LLMs as $J_2$ attackers, which can systematically evaluate target models using various red teaming strategies and improve its performance via in-context learning from the previous failures. Our experiments demonstrate that Sonnet 3.5 and Gemini 1.5 pro outperform other LLMs as $J_2$, achieving 93.0% and 91.0% attack success rates (ASRs) respectively against GPT-4o (and similar results across other capable LLMs) on Harmbench. Our work not only introduces a scalable approach to strategic red teaming, drawing inspiration from human red teamers, but also highlights jailbreaking-to-jailbreak as an overlooked failure mode of the safeguard. Specifically, an LLM can bypass its own safeguards by employing a jailbroken version of itself that is willing to assist in further jailbreaking. To prevent any direct misuse with $J_2$, while advancing research in AI safety, we publicly share our methodology while keeping specific prompting details private.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "5",
        "title": "Online Social Support Detection in Spanish Social Media Texts",
        "author": [
            "Moein Shahiki Tash",
            "Luis Ramos",
            "Zahra Ahani",
            "Raul Monroy",
            "Olga kolesnikova",
            "Hiram Calvo",
            "Grigori Sidorov"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09640",
        "abstract": "The advent of social media has transformed communication, enabling individuals to share their experiences, seek support, and participate in diverse discussions. While extensive research has focused on identifying harmful content like hate speech, the recognition and promotion of positive and supportive interactions remain largely unexplored. This study proposes an innovative approach to detecting online social support in Spanish-language social media texts. We introduce the first annotated dataset specifically created for this task, comprising 3,189 YouTube comments classified as supportive or non-supportive. To address data imbalance, we employed GPT-4o to generate paraphrased comments and create a balanced dataset. We then evaluated social support classification using traditional machine learning models, deep learning architectures, and transformer-based models, including GPT-4o, but only on the unbalanced dataset. Subsequently, we utilized a transformer model to compare the performance between the balanced and unbalanced datasets. Our findings indicate that the balanced dataset yielded improved results for Task 2 (Individual and Group) and Task 3 (Nation, Other, LGBTQ, Black Community, Women, Religion), whereas GPT-4o performed best for Task 1 (Social Support and Non-Support). This study highlights the significance of fostering a supportive online environment and lays the groundwork for future research in automated social support detection.",
        "tags": [
            "Detection",
            "GPT",
            "Transformer"
        ]
    },
    {
        "id": "6",
        "title": "Krutrim LLM: Multilingual Foundational Model for over a Billion People",
        "author": [
            "Aditya Kallappa",
            "Palash Kamble",
            "Abhinav Ravi",
            "Akshat Patidar",
            "Vinayak Dhruv",
            "Deepak Kumar",
            "Raghav Awasthi",
            "Arveti Manjunath",
            "Shubham Agarwal",
            "Kumar Ashish",
            "Gautam Bhargava",
            "Chandra Khatri"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09642",
        "abstract": "India is a diverse society with unique challenges in developing AI systems, including linguistic diversity, oral traditions, data accessibility, and scalability. Existing foundation models are primarily trained on English, limiting their effectiveness for India's population. Indic languages comprise only 1 percent of Common Crawl corpora despite India representing 18 percent of the global population, leading to linguistic biases. Thousands of regional languages, dialects, and code mixing create additional representation challenges due to sparse training data.\nWe introduce Krutrim LLM, a 2 trillion token multilingual model designed for India's linguistic landscape. It incorporates the largest known Indic dataset, mitigating data scarcity and ensuring balanced performance across dialects. Krutrim outperforms or matches state-of-the-art models on Indic benchmarks while maintaining competitive English performance. Despite being significantly smaller in training flops, Krutrim LLM matches or exceeds models like LLAMA-2 on 10 out of 16 tasks, with an average score of 0.57 versus 0.55. This evidences Krutrim's flexible multilingual fluency across diverse linguistic contexts.\nKrutrim is integrated with real-time search to improve factual accuracy in conversational AI applications. This enhances accessibility for over 1 billion users worldwide. Through intentional design choices addressing data imbalances, Krutrim LLM signifies meaningful progress in building ethical, globally representative AI models.",
        "tags": [
            "LLaMA"
        ]
    },
    {
        "id": "7",
        "title": "Imit Diff: Semantics Guided Diffusion Transformer with Dual Resolution Fusion for Imitation Learning",
        "author": [
            "Yuhang Dong",
            "Haizhou Ge",
            "Yupei Zeng",
            "Jiangning Zhang",
            "Beiwen Tian",
            "Guanzhong Tian",
            "Hongrui Zhu",
            "Yufei Jia",
            "Ruixiang Wang",
            "Ran Yi",
            "Guyue Zhou",
            "Longhua Ma"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09649",
        "abstract": "Visuomotor imitation learning enables embodied agents to effectively acquire manipulation skills from video demonstrations and robot proprioception. However, as scene complexity and visual distractions increase, existing methods that perform well in simple scenes tend to degrade in performance. To address this challenge, we introduce Imit Diff, a semanstic guided diffusion transformer with dual resolution fusion for imitation learning. Our approach leverages prior knowledge from vision language foundation models to translate high-level semantic instruction into pixel-level visual localization. This information is explicitly integrated into a multi-scale visual enhancement framework, constructed with a dual resolution encoder. Additionally, we introduce an implementation of Consistency Policy within the diffusion transformer architecture to improve both real-time performance and motion smoothness in embodied agent http://control.We evaluate Imit Diff on several challenging real-world tasks. Due to its task-oriented visual localization and fine-grained scene perception, it significantly outperforms state-of-the-art methods, especially in complex scenes with visual distractions, including zero-shot experiments focused on visual distraction and category generalization. The code will be made publicly available.",
        "tags": [
            "Diffusion",
            "Diffusion Transformer",
            "Robot",
            "Transformer"
        ]
    },
    {
        "id": "8",
        "title": "Principled Data Selection for Alignment: The Hidden Risks of Difficult Examples",
        "author": [
            "Chengqian Gao",
            "Haonan Li",
            "Liu Liu",
            "Zeke Xie",
            "Peilin Zhao",
            "Zhiqiang Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09650",
        "abstract": "The alignment of large language models (LLMs) often assumes that using more clean data yields better outcomes, overlooking the match between model capacity and example difficulty. Challenging this, we propose a new principle: Preference data vary in difficulty, and overly difficult examples hinder alignment, by exceeding the model's capacity. Through systematic experimentation, we validate this principle with three key findings: (1) preference examples vary in difficulty, as evidenced by consistent learning orders across alignment runs; (2) overly difficult examples significantly degrade performance across four LLMs and two datasets; and (3) the capacity of a model dictates its threshold for handling difficult examples, underscoring a critical relationship between data selection and model capacity. Building on this principle, we introduce Selective DPO, which filters out overly difficult examples. This simple adjustment improves alignment performance by 9-16% in win rates on the AlpacaEval 2 benchmark compared to the DPO baseline, suppressing a series of DPO variants with different algorithmic adjustments. Together, these results illuminate the importance of aligning data difficulty with model capacity, offering a transformative perspective for improving alignment strategies in LLMs. Code is available at https://github.com/glorgao/SelectiveDPO.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "9",
        "title": "AI-VERDE: A Gateway for Egalitarian Access to Large Language Model-Based Resources For Educational Institutions",
        "author": [
            "Paul Mithun",
            "Enrique Noriega-Atala",
            "Nirav Merchant",
            "Edwin Skidmore"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09651",
        "abstract": "We present AI-VERDE, a unified LLM-as-a-platform service designed to facilitate seamless integration of commercial, cloud-hosted, and on-premise open LLMs in academic settings. AI-VERDE streamlines access management for instructional and research groups by providing features such as robust access control, privacy-preserving mechanisms, native Retrieval-Augmented Generation (RAG) support, budget management for third-party LLM services, and both a conversational web interface and API access. In a pilot deployment at a large public university, AI-VERDE demonstrated significant engagement across diverse educational and research groups, enabling activities that would typically require substantial budgets for commercial LLM services with limited user and team management capabilities. To the best of our knowledge, AI-Verde is the first platform to address both academic and research needs for LLMs within an higher education institutional framework.",
        "tags": [
            "LLMs",
            "RAG"
        ]
    },
    {
        "id": "10",
        "title": "GraphCompNet: A Position-Aware Model for Predicting and Compensating Shape Deviations in 3D Printing",
        "author": [
            "Chen",
            "Juheon Lee",
            "Juan Carlos Catana",
            "Tsegai Yhdego",
            "Nathan Moroney",
            "Mohammad Amin Nabian",
            "Hui Wang",
            "Jun Zeng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09652",
        "abstract": "This paper introduces a data-driven algorithm for modeling and compensating shape deviations in additive manufacturing (AM), addressing challenges in geometric accuracy and batch production. While traditional methods, such as analytical models and metrology, laid the groundwork for geometric precision, they are often impractical for large-scale production. Recent advancements in machine learning (ML) have improved compensation precision, but issues remain in generalizing across complex geometries and adapting to position-dependent variations. We present a novel approach for powder bed fusion (PBF) processes, using GraphCompNet, which is a computational framework combining graph-based neural networks with a generative adversarial network (GAN)-inspired training process. By leveraging point cloud data and dynamic graph convolutional neural networks (DGCNNs), GraphCompNet models complex shapes and incorporates position-specific thermal and mechanical factors. A two-stage adversarial training procedure iteratively refines compensated designs via a compensator-predictor architecture, offering real-time feedback and optimization. Experimental validation across diverse shapes and positions shows the framework significantly improves compensation accuracy (35 to 65 percent) across the entire print space, adapting to position-dependent variations. This work advances the development of Digital Twin technology for AM, enabling scalable, real-time monitoring and compensation, and addressing critical gaps in AM process control. The proposed method supports high-precision, automated industrial-scale design and manufacturing systems.",
        "tags": [
            "3D",
            "GAN"
        ]
    },
    {
        "id": "11",
        "title": "Bidirectional Diffusion Bridge Models",
        "author": [
            "Duc Kieu",
            "Kien Do",
            "Toan Nguyen",
            "Dang Nguyen",
            "Thin Nguyen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09655",
        "abstract": "Diffusion bridges have shown potential in paired image-to-image (I2I) translation tasks. However, existing methods are limited by their unidirectional nature, requiring separate models for forward and reverse translations. This not only doubles the computational cost but also restricts their practicality. In this work, we introduce the Bidirectional Diffusion Bridge Model (BDBM), a scalable approach that facilitates bidirectional translation between two coupled distributions using a single network. BDBM leverages the Chapman-Kolmogorov Equation for bridges, enabling it to model data distribution shifts across timesteps in both forward and backward directions by exploiting the interchangeability of the initial and target timesteps within this framework. Notably, when the marginal distribution given endpoints is Gaussian, BDBM's transition kernels in both directions possess analytical forms, allowing for efficient learning with a single network. We demonstrate the connection between BDBM and existing bridge methods, such as Doob's h-transform and variational approaches, and highlight its advantages. Extensive experiments on high-resolution I2I translation tasks demonstrate that BDBM not only enables bidirectional translation with minimal additional cost but also outperforms state-of-the-art bridge models. Our source code is available at [https://github.com/kvmduc/BDBM||https://github.com/kvmduc/BDBM].",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "12",
        "title": "Integrating Spatiotemporal Vision Transformer into Digital Twins for High-Resolution Heat Stress Forecasting in Campus Environments",
        "author": [
            "Wenjing Gong",
            "Xinyue Ye",
            "Keshu Wu",
            "Suphanut Jamonnak",
            "Wenyu Zhang",
            "Yifan Yang",
            "Xiao Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09657",
        "abstract": "Extreme heat events exacerbated by climate change pose significant challenges to urban resilience and planning. This study introduces a climate-responsive digital twin framework integrating the Spatiotemporal Vision Transformer (ST-ViT) model to enhance heat stress forecasting and decision-making. Using a Texas campus as a testbed, we synthesized high-resolution physical model simulations with spatial and meteorological data to develop fine-scale human thermal predictions. The ST-ViT-powered digital twin enables efficient, data-driven insights for planners, policymakers, and campus stakeholders, supporting targeted heat mitigation strategies and advancing climate-adaptive urban design.",
        "tags": [
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "13",
        "title": "Towards Fine-grained Interactive Segmentation in Images and Videos",
        "author": [
            "Yuan Yao",
            "Qiushi Yang",
            "Miaomiao Cui",
            "Liefeng Bo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09660",
        "abstract": "The recent Segment Anything Models (SAMs) have emerged as foundational visual models for general interactive segmentation. Despite demonstrating robust generalization abilities, they still suffer performance degradations in scenarios demanding accurate masks. Existing methods for high-precision interactive segmentation face a trade-off between the ability to perceive intricate local details and maintaining stable prompting capability, which hinders the applicability and effectiveness of foundational segmentation models. To this end, we present an SAM2Refiner framework built upon the SAM2 backbone. This architecture allows SAM2 to generate fine-grained segmentation masks for both images and videos while preserving its inherent strengths. Specifically, we design a localization augment module, which incorporates local contextual cues to enhance global features via a cross-attention mechanism, thereby exploiting potential detailed patterns and maintaining semantic information. Moreover, to strengthen the prompting ability toward the enhanced object embedding, we introduce a prompt retargeting module to renew the embedding with spatially aligned prompt features. In addition, to obtain accurate high resolution segmentation masks, a mask refinement module is devised by employing a multi-scale cascaded structure to fuse mask features with hierarchical representations from the encoder. Extensive experiments demonstrate the effectiveness of our approach, revealing that the proposed method can produce highly precise masks for both images and videos, surpassing state-of-the-art methods.",
        "tags": [
            "Segment Anything",
            "Segmentation"
        ]
    },
    {
        "id": "14",
        "title": "k-LLMmeans: Summaries as Centroids for Interpretable and Scalable LLM-Based Text Clustering",
        "author": [
            "Jairo Diaz-Rodriguez"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09667",
        "abstract": "We introduce k-LLMmeans, a novel modification of the k-means clustering algorithm that utilizes LLMs to generate textual summaries as cluster centroids, thereby capturing contextual and semantic nuances often lost when relying on purely numerical means of document embeddings. This modification preserves the properties of k-means while offering greater interpretability: the cluster centroid is represented by an LLM-generated summary, whose embedding guides cluster assignments. We also propose a mini-batch variant, enabling efficient online clustering for streaming text data and providing real-time interpretability of evolving cluster centroids. Through extensive simulations, we show that our methods outperform vanilla k-means on multiple metrics while incurring only modest LLM usage that does not scale with dataset size. Finally, We present a case study showcasing the interpretability of evolving cluster centroids in sequential text streams. As part of our evaluation, we compile a new dataset from StackExchange, offering a benchmark for text-stream clustering.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "15",
        "title": "Are Smarter LLMs Safer? Exploring Safety-Reasoning Trade-offs in Prompting and Fine-Tuning",
        "author": [
            "Ang Li",
            "Yichuan Mo",
            "Mingjie Li",
            "Yifei Wang",
            "Yisen Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09673",
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable success across various NLP benchmarks. However, excelling in complex tasks that require nuanced reasoning and precise decision-making demands more than raw language proficiency--LLMs must reason, i.e., think logically, draw from past experiences, and synthesize information to reach conclusions and take action. To enhance reasoning abilities, approaches such as prompting and fine-tuning have been widely explored. While these methods have led to clear improvements in reasoning, their impact on LLM safety remains less understood. In this work, we investigate the interplay between reasoning and safety in LLMs. We highlight the latent safety risks that arise as reasoning capabilities improve, shedding light on previously overlooked vulnerabilities. At the same time, we explore how reasoning itself can be leveraged to enhance safety, uncovering potential mitigation strategies. By examining both the risks and opportunities in reasoning-driven LLM safety, our study provides valuable insights for developing models that are not only more capable but also more trustworthy in real-world deployments.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "16",
        "title": "The Hidden Dimensions of LLM Alignment: A Multi-Dimensional Safety Analysis",
        "author": [
            "Wenbo Pan",
            "Zhichao Liu",
            "Qiguang Chen",
            "Xiangyang Zhou",
            "Haining Yu",
            "Xiaohua Jia"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09674",
        "abstract": "Large Language Models' safety-aligned behaviors, such as refusing harmful queries, can be represented by linear directions in activation space. Previous research modeled safety behavior with a single direction, limiting mechanistic understanding to an isolated safety feature. In this work, we discover that safety-aligned behavior is jointly controlled by multi-dimensional directions. Namely, we study the vector space of representation shifts during safety fine-tuning on Llama 3 8B for refusing jailbreaks. By studying orthogonal directions in the space, we first find that a dominant direction governs the model's refusal behavior, while multiple smaller directions represent distinct and interpretable features like hypothetical narrative and role-playing. We then measure how different directions promote or suppress the dominant direction, showing the important role of secondary directions in shaping the model's refusal representation. Finally, we demonstrate that removing certain trigger tokens in harmful queries can mitigate these directions to bypass the learned safety capability, providing new insights on understanding safety alignment vulnerability from a multi-dimensional perspective. Code and artifacts are available at https://github.com/BMPixel/safety-residual-space.",
        "tags": [
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "17",
        "title": "Channel Dependence, Limited Lookback Windows, and the Simplicity of Datasets: How Biased is Time Series Forecasting?",
        "author": [
            "Ibram Abdelmalak",
            "Kiran Madhusudhanan",
            "Jungmin Choi",
            "Maximilian Stubbemann",
            "Lars Schmidt-Thieme"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09683",
        "abstract": "Time-series forecasting research has converged to a small set of datasets and a standardized collection of evaluation scenarios. Such a standardization is to a specific extent needed for comparable research. However, the underlying assumption is, that the considered setting is a representative for the problem as a whole. In this paper, we challenge this assumption and show that the current scenario gives a strongly biased perspective on the state of time-series forecasting research. To be more detailed, we show that the current evaluation scenario is heavily biased by the simplicity of the current datasets. We furthermore emphasize, that when the lookback-window is properly tuned, current models usually do not need any information flow across channels. However, when using more complex benchmark data, the situation changes: Here, modeling channel-interactions in a sophisticated manner indeed enhances performances. Furthermore, in this complex evaluation scenario, Crossformer, a method regularly neglected as an important baseline, is the SOTA method for time series forecasting. Based on this, we present the Fast Channel-dependent Transformer (FaCT), a simplified version of Crossformer which closes the runtime gap between Crossformer and TimeMixer, leading to an efficient model for complex forecasting datasets.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "18",
        "title": "Mind What You Ask For: Emotional and Rational Faces of Persuasion by Large Language Models",
        "author": [
            "Wiktoria Mieleszczenko-Kowszewicz",
            "Beata Bajcar",
            "Jolanta Babiak",
            "Berenika Dyczek",
            "Jakub Åwistak",
            "PrzemysÅaw Biecek"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09687",
        "abstract": "Be careful what you ask for, you just might get it. This saying fits with the way large language models (LLMs) are trained, which, instead of being rewarded for correctness, are increasingly rewarded for pleasing the recipient. So, they are increasingly effective at persuading us that their answers are valuable. But what tricks do they use in this persuasion? In this study, we examine what are the psycholinguistic features of the responses used by twelve different language models. By grouping response content according to rational or emotional prompts and exploring social influence principles employed by LLMs, we ask whether and how we can mitigate the risks of LLM-driven mass misinformation. We position this study within the broader discourse on human-centred AI, emphasizing the need for interdisciplinary approaches to mitigate cognitive and societal risks posed by persuasive AI responses.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "19",
        "title": "Large Language Models and Provenance Metadata for Determining the Relevance of Images and Videos in News Stories",
        "author": [
            "Tomas Peterka",
            "Matyas Bohacek"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09689",
        "abstract": "The most effective misinformation campaigns are multimodal, often combining text with images and videos taken out of context -- or fabricating them entirely -- to support a given narrative. Contemporary methods for detecting misinformation, whether in deepfakes or text articles, often miss the interplay between multiple modalities. Built around a large language model, the system proposed in this paper addresses these challenges. It analyzes both the article's text and the provenance metadata of included images and videos to determine whether they are relevant. We open-source the system prototype and interactive web interface.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "20",
        "title": "Trust at Your Own Peril: A Mixed Methods Exploration of the Ability of Large Language Models to Generate Expert-Like Systems Engineering Artifacts and a Characterization of Failure Modes",
        "author": [
            "Taylan G. Topcu",
            "Mohammed Husain",
            "Max Ofsa",
            "Paul Wach"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09690",
        "abstract": "Multi-purpose Large Language Models (LLMs), a subset of generative Artificial Intelligence (AI), have recently made significant progress. While expectations for LLMs to assist systems engineering (SE) tasks are paramount; the interdisciplinary and complex nature of systems, along with the need to synthesize deep-domain knowledge and operational context, raise questions regarding the efficacy of LLMs to generate SE artifacts, particularly given that they are trained using data that is broadly available on the internet. To that end, we present results from an empirical exploration, where a human expert-generated SE artifact was taken as a benchmark, parsed, and fed into various LLMs through prompt engineering to generate segments of typical SE artifacts. This procedure was applied without any fine-tuning or calibration to document baseline LLM performance. We then adopted a two-fold mixed-methods approach to compare AI generated artifacts against the benchmark. First, we quantitatively compare the artifacts using natural language processing algorithms and find that when prompted carefully, the state-of-the-art algorithms cannot differentiate AI-generated artifacts from the human-expert benchmark. Second, we conduct a qualitative deep dive to investigate how they differ in terms of quality. We document that while the two-material appear very similar, AI generated artifacts exhibit serious failure modes that could be difficult to detect. We characterize these as: premature requirements definition, unsubstantiated numerical estimates, and propensity to overspecify. We contend that this study tells a cautionary tale about why the SE community must be more cautious adopting AI suggested feedback, at least when generated by multi-purpose LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "21",
        "title": "NeuralCFD: Deep Learning on High-Fidelity Automotive Aerodynamics Simulations",
        "author": [
            "Maurits Bleeker",
            "Matthias Dorfer",
            "Tobias Kronlachner",
            "Reinhard Sonnleitner",
            "Benedikt Alkin",
            "Johannes Brandstetter"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09692",
        "abstract": "Recent advancements in neural operator learning are paving the way for transformative innovations in fields such as automotive aerodynamics. However, key challenges must be overcome before neural network-based simulation surrogates can be implemented at an industry scale. First, surrogates must become scalable to large surface and volume meshes, especially when using raw geometry inputs only, i.e., without relying on the simulation mesh. Second, surrogates must be trainable with a limited number of high-fidelity numerical simulation samples while still reaching the required performance levels. To this end, we introduce Geometry-preserving Universal Physics Transformer (GP-UPT), which separates geometry encoding and physics predictions, ensuring flexibility with respect to geometry representations and surface sampling strategies. GP-UPT enables independent scaling of the respective parts of the model according to practical requirements, offering scalable solutions to open challenges. GP-UPT circumvents the creation of high-quality simulation meshes, enables accurate 3D velocity field predictions at 20 million mesh cells, and excels in transfer learning from low-fidelity to high-fidelity simulation datasets, requiring less than half of the high-fidelity data to match the performance of models trained from scratch.",
        "tags": [
            "3D",
            "Transformer"
        ]
    },
    {
        "id": "22",
        "title": "\"Ronaldo's a poser!\": How the Use of Generative AI Shapes Debates in Online Forums",
        "author": [
            "Yuhan Zeng",
            "Yingxuan Shi",
            "Xuehan Huang",
            "Fiona Nah",
            "Ray LC"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09693",
        "abstract": "Online debates can enhance critical thinking but may escalate into hostile attacks. As humans are increasingly reliant on Generative AI (GenAI) in writing tasks, we need to understand how people utilize GenAI in online debates. To examine the patterns of writing behavior while making arguments with GenAI, we created an online forum for soccer fans to engage in turn-based and free debates in a post format with the assistance of ChatGPT, arguing on the topic of \"Messi vs Ronaldo\". After 13 sessions of two-part study and semi-structured interviews with 39 participants, we conducted content and thematic analyses to integrate insights from interview transcripts, ChatGPT records, and forum posts. We found that participants prompted ChatGPT for aggressive responses, created posts with similar content and logical fallacies, and sacrificed the use of ChatGPT for better human-human communication. This work uncovers how polarized forum members work with GenAI to engage in debates online.",
        "tags": [
            "ChatGPT"
        ]
    },
    {
        "id": "23",
        "title": "Evaluating GPT's Capability in Identifying Stages of Cognitive Impairment from Electronic Health Data",
        "author": [
            "Yu Leng",
            "Yingnan He",
            "Colin Magdamo",
            "Ana-Maria Vranceanu",
            "Christine S. Ritchie",
            "Shibani S. Mukerji",
            "Lidia M. V. R. Moura",
            "John R. Dickson",
            "Deborah Blacker",
            "Sudeshna Das"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09715",
        "abstract": "Identifying cognitive impairment within electronic health records (EHRs) is crucial not only for timely diagnoses but also for facilitating research. Information about cognitive impairment often exists within unstructured clinician notes in EHRs, but manual chart reviews are both time-consuming and error-prone. To address this issue, our study evaluates an automated approach using zero-shot GPT-4o to determine stage of cognitive impairment in two different tasks. First, we evaluated the ability of GPT-4o to determine the global Clinical Dementia Rating (CDR) on specialist notes from 769 patients who visited the memory clinic at Massachusetts General Hospital (MGH), and achieved a weighted kappa score of 0.83. Second, we assessed GPT-4o's ability to differentiate between normal cognition, mild cognitive impairment (MCI), and dementia on all notes in a 3-year window from 860 Medicare patients. GPT-4o attained a weighted kappa score of 0.91 in comparison to specialist chart reviews and 0.96 on cases that the clinical adjudicators rated with high confidence. Our findings demonstrate GPT-4o's potential as a scalable chart review tool for creating research datasets and assisting diagnosis in clinical settings in the future.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "24",
        "title": "Genetic Data Governance in Crisis: Policy Recommendations for Safeguarding Privacy and Preventing Discrimination",
        "author": [
            "Vivek Ramanan",
            "Ria Vinod",
            "Cole Williams",
            "Sohini Ramachandran",
            "Suresh Venkatasubramanian"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09716",
        "abstract": "Genetic data collection has become ubiquitous today. The ability to meaningfully interpret genetic data has motivated its widespread use, providing crucial insights into human health and ancestry while driving important public health initiatives. Easy access to genetic testing has fueled a rapid expansion of recreational direct-to-consumer offerings. However, the growth of genetic datasets and their applications has created significant privacy and discrimination risks, as our understanding of the scientific basis for genetic traits continues to evolve. In this paper, we organize the uses of genetic data along four distinct \"pillars\": clinical practice, research, forensic and government use, and recreational use. Using our scientific understanding of genetics, genetic inference methods and their associated risks, and current public protections, we build a risk assessment framework that identifies key values that any governance system must preserve. We analyze case studies using this framework to assess how well existing regulatory frameworks preserve desired values. Our investigation reveals critical gaps in these frameworks and identifies specific threats to privacy and personal liberties, particularly through genetic discrimination. We propose comprehensive policy reforms to: (1) update the legal definition of genetic data to protect against modern technological capabilities, (2) expand the Genetic Information Nondiscrimination Act (GINA) to cover currently unprotected domains, and (3) establish a unified regulatory framework under a single governing body to oversee all applications of genetic data. We conclude with three open questions about genetic data: the challenges posed by its relational nature, including consent for relatives and minors; the complexities of international data transfer; and its potential integration into large language models.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "25",
        "title": "NestQuant: Nested Lattice Quantization for Matrix Products and LLMs",
        "author": [
            "Semyon Savkin",
            "Eitan Porat",
            "Or Ordentlich",
            "Yury Polyanskiy"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09720",
        "abstract": "Post-training quantization (PTQ) has emerged as a critical technique for efficient deployment of large language models (LLMs). This work proposes NestQuant, a novel PTQ scheme for weights and activations that is based on self-similar nested lattices. Recent work have mathematically shown such quantizers to be information-theoretically optimal for low-precision matrix multiplication. We implement a practical low-complexity version of NestQuant based on Gosset lattice, making it a drop-in quantizer for any matrix multiplication step (e.g., in self-attention, MLP etc). For example, NestQuant quantizes weights, KV-cache, and activations of Llama-3-8B to 4 bits, achieving perplexity of 6.6 on wikitext2. This represents more than 55% reduction in perplexity gap with respect to unquantized model (perplexity of 6.14) compared to state-of-the-art Meta's SpinQuant (perplexity 7.3). Comparisons on various LLM evaluation benchmarks also show a reduction in performance degradation induced by quantization.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "26",
        "title": "Making Them a Malicious Database: Exploiting Query Code to Jailbreak Aligned Large Language Models",
        "author": [
            "Qingsong Zou",
            "Jingyu Xiao",
            "Qing Li",
            "Zhi Yan",
            "Yuhang Wang",
            "Li Xu",
            "Wenxuan Wang",
            "Kuofeng Gao",
            "Ruoyu Li",
            "Yong Jiang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09723",
        "abstract": "Recent advances in large language models (LLMs) have demonstrated remarkable potential in the field of natural language processing. Unfortunately, LLMs face significant security and ethical risks. Although techniques such as safety alignment are developed for defense, prior researches reveal the possibility of bypassing such defenses through well-designed jailbreak attacks. In this paper, we propose QueryAttack, a novel framework to systematically examine the generalizability of safety alignment. By treating LLMs as knowledge databases, we translate malicious queries in natural language into code-style structured query to bypass the safety alignment mechanisms of LLMs. We conduct extensive experiments on mainstream LLMs, ant the results show that QueryAttack achieves high attack success rates (ASRs) across LLMs with different developers and capabilities. We also evaluate QueryAttack's performance against common defenses, confirming that it is difficult to mitigate with general defensive techniques. To defend against QueryAttack, we tailor a defense method which can reduce ASR by up to 64\\% on GPT-4-1106. The code of QueryAttack can be found on https://anonymous.4open.science/r/QueryAttack-334B.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "27",
        "title": "FoNE: Precise Single-Token Number Embeddings via Fourier Features",
        "author": [
            "Tianyi Zhou",
            "Deqing Fu",
            "Mahdi Soltanolkotabi",
            "Robin Jia",
            "Vatsal Sharan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09741",
        "abstract": "Large Language Models (LLMs) typically represent numbers using multiple tokens, which requires the model to aggregate these tokens to interpret numerical values. This fragmentation makes both training and inference less efficient and adversely affects the model's performance on number-related tasks. Inspired by the observation that pre-trained LLMs internally learn Fourier-like features for number tokens, we propose Fourier Number Embedding (FoNE), a novel method that directly maps numbers into the embedding space with their Fourier features. FoNE encodes each number as a single token with only two embedding dimensions per digit, effectively capturing numerical values without fragmentation. This compact representation accelerates both training and inference. Compared to traditional subword and digit-wise embeddings, FoNE not only reduces computational overhead but also achieves higher accuracy across various numerical tasks including addition, subtraction and multiplication. On 6-digit decimal addition, FoNE requires 64$\\times$ less data to achieve 99% accuracy than subword and digit-wise embeddings while using 3$\\times$ and 6$\\times$ fewer tokens per number, respectively. Furthermore, FoNE is the only method that yields 100% accuracy on over 100,000 test examples for addition, subtraction, and multiplication. The codes and visualization are available at https://fouriernumber.github.io/.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "28",
        "title": "The Widespread Adoption of Large Language Model-Assisted Writing Across Society",
        "author": [
            "Weixin Liang",
            "Yaohui Zhang",
            "Mihai Codreanu",
            "Jiayu Wang",
            "Hancheng Cao",
            "James Zou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09747",
        "abstract": "The recent advances in large language models (LLMs) attracted significant public and policymaker interest in its adoption patterns. In this paper, we systematically analyze LLM-assisted writing across four domains-consumer complaints, corporate communications, job postings, and international organization press releases-from January 2022 to September 2024. Our dataset includes 687,241 consumer complaints, 537,413 corporate press releases, 304.3 million job postings, and 15,919 United Nations (UN) press releases. Using a robust population-level statistical framework, we find that LLM usage surged following the release of ChatGPT in November 2022. By late 2024, roughly 18% of financial consumer complaint text appears to be LLM-assisted, with adoption patterns spread broadly across regions and slightly higher in urban areas. For corporate press releases, up to 24% of the text is attributable to LLMs. In job postings, LLM-assisted writing accounts for just below 10% in small firms, and is even more common among younger firms. UN press releases also reflect this trend, with nearly 14% of content being generated or modified by LLMs. Although adoption climbed rapidly post-ChatGPT, growth appears to have stabilized by 2024, reflecting either saturation in LLM adoption or increasing subtlety of more advanced models. Our study shows the emergence of a new reality in which firms, consumers and even international organizations substantially rely on generative AI for communications.",
        "tags": [
            "ChatGPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "29",
        "title": "Vote-Tree-Planner: Optimizing Execution Order in LLM-based Task Planning Pipeline via Voting",
        "author": [
            "Chaoyuan Zhang",
            "Zhaowei Li",
            "Wentao Yuan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09749",
        "abstract": "Integrating large language models (LLMs) into closed-loop robotic task planning has become increasingly popular within embodied artificial intelligence. Previous efforts mainly focused on leveraging the strong reasoning abilities of LLMs to enhance task planning performance while often overlooking task planning efficiency and executability due to repetitive queries to LLMs. This paper addresses the synergy between LLMs and task planning systems, aiming to minimize redundancy while enhancing planning effectiveness. Specifically, building upon Prog-Prompt and the high-level concept of Tree-Planner, we propose Vote-Tree-Planner. This sampling strategy utilizes votes to guide plan traversal during the decision-making process. Our approach is motivated by a straightforward observation: assigning weights to agents during decision-making enables the evaluation of critical paths before execution. With this simple vote-tree construction, our method further improves the success rate and reduces the number of queries to LLMs. The experimental results highlight that our Vote-Tree-Planner demonstrates greater stability and shows a higher average success rate and goal condition recall on the unseen dataset compared with previous baseline methods. These findings underscore the potential of the Vote-Tree-Planner to enhance planning accuracy, reliability, and efficiency in LLM-based planning systems.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "30",
        "title": "Robust Adaptive Meshing, Mesh Density Functions, and Nonlocal Observations for Ensemble Based Data Assimilation",
        "author": [
            "Jeremiah Buenger",
            "Weizhang Huang",
            "Erik Van Vleck"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09754",
        "abstract": "Adaptive spatial meshing has proven invaluable for the accurate, efficient computation of solutions of time dependent partial differential equations. In a DA context the use of adaptive spatial meshes addresses several factors that place increased demands on meshing; these include the location and relative importance of observations and the use of ensemble solutions. To increase the efficiency of adaptive meshes for data assimilation, robust look ahead meshes are developed that fix the same adaptive mesh for all ensemble members for the entire time interval of the forecasts and that incorporates the observations at the next analysis time. This allows for increased vectorization of the ensemble forecasts while minimizing interpolation of solutions between different meshes. The techniques to determine these robust meshes are based upon combining metric tensors or mesh density functions to define nonuniform meshes. We illustrate the robust ensemble look ahead meshes using traveling wave solutions of a bistable reaction-diffusion equation. Observation operators based on convolution type integrals and their associated metric tensors are derived. These further the goals of making efficient use of adaptive meshes in ensemble based DA techniques, developing and employing robust meshes that are effective for a range of similar behaviors in both the ensembles and the observations, and the integration with advanced numerical PDE techniques (a quasi-Lagrangian moving mesh DG technique employing embedded pairs for time stepping). Numerical experiments with different observation scenarios are presented for a 2D inviscid Burgers' equation, a multi-component system, a 2D Shallow Water model, and for a coupled system of two 1D Kuramoto-Sivashinsky equations.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "31",
        "title": "Enhancing Jailbreak Attacks via Compliance-Refusal-Based Initialization",
        "author": [
            "Amit Levi",
            "Rom Himelstein",
            "Yaniv Nemcovsky",
            "Avi Mendelson",
            "Chaim Baskin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09755",
        "abstract": "Jailbreak attacks aim to exploit large language models (LLMs) and pose a significant threat to their proper conduct; they seek to bypass models' safeguards and often provoke transgressive behaviors. However, existing automatic jailbreak attacks require extensive computational resources and are prone to converge on suboptimal solutions. In this work, we propose \\textbf{C}ompliance \\textbf{R}efusal \\textbf{I}nitialization (CRI), a novel, attack-agnostic framework that efficiently initializes the optimization in the proximity of the compliance subspace of harmful prompts. By narrowing the initial gap to the adversarial objective, CRI substantially improves adversarial success rates (ASR) and drastically reduces computational overhead -- often requiring just a single optimization step. We evaluate CRI on the widely-used AdvBench dataset over the standard jailbreak attacks of GCG and AutoDAN. Results show that CRI boosts ASR and decreases the median steps to success by up to \\textbf{\\(\\times 60\\)}. The project page, along with the reference implementation, is publicly available at \\texttt{https://amit1221levi.github.io/CRI-Jailbreak-Init-LLMs-evaluation/}.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "32",
        "title": "LLM-Generated Microservice Implementations from RESTful API Definitions",
        "author": [
            "Saurabh Chauhan",
            "Zeeshan Rasheed",
            "Abdul Malik Sami",
            "Zheying Zhang",
            "Jussi Rasku",
            "Kai-Kristian Kemell",
            "Pekka Abrahamsson"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09766",
        "abstract": "The growing need for scalable, maintainable, and fast-deploying systems has made microservice architecture widely popular in software development. This paper presents a system that uses Large Language Models (LLMs) to automate the API-first development of RESTful microservices. This system assists in creating OpenAPI specification, generating server code from it, and refining the code through a feedback loop that analyzes execution logs and error messages. By focusing on the API-first methodology, this system ensures that microservices are designed with well-defined interfaces, promoting consistency and reliability across the development life-cycle. The integration of log analysis enables the LLM to detect and address issues efficiently, reducing the number of iterations required to produce functional and robust services. This process automates the generation of microservices and also simplifies the debugging and refinement phases, allowing developers to focus on higher-level design and integration tasks. This system has the potential to benefit software developers, architects, and organizations to speed up software development cycles and reducing manual effort. To assess the potential of the system, we conducted surveys with six industry practitioners. After surveying practitioners, the system demonstrated notable advantages in enhancing development speed, automating repetitive tasks, and simplifying the prototyping process. While experienced developers appreciated its efficiency for specific tasks, some expressed concerns about its limitations in handling advanced customizations and larger scale projects. The code is publicly available at https://github.com/sirbh/code-gen",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "33",
        "title": "Non-Markovian Discrete Diffusion with Causal Language Models",
        "author": [
            "Yangtian Zhang",
            "Sizhuang He",
            "Daniel Levine",
            "Lawrence Zhao",
            "David Zhang",
            "Syed A Rizvi",
            "Emanuele Zappala",
            "Rex Ying",
            "David van Dijk"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09767",
        "abstract": "Discrete diffusion models have emerged as a flexible and controllable paradigm for structured sequence modeling, yet they still lag behind causal language models in expressiveness. To bridge the gap between two paradigms, we introduce CaDDi, a causal discrete diffusion model that unifies sequential and temporal modeling within a non-Markovian diffusion framework. Unlike conventional diffusion models that operate step by step with no access to prior states, CaDDi integrates the temporal trajectory, enabling more expressive and controllable generation. Our approach also treats causal language models as a special case, allowing seamless adoption of pretrained large language models (LLMs) for discrete diffusion without the need for architectural modifications. Empirically, we demonstrate that CaDDi outperforms state-of-the-art discrete diffusion models on both natural language and biological sequence tasks, narrowing the gap between diffusion-based methods and large-scale autoregressive transformers.",
        "tags": [
            "Diffusion",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "34",
        "title": "Knowledge-Enhanced Program Repair for Data Science Code",
        "author": [
            "Shuyin Ouyang",
            "Jie M. Zhang",
            "Zeyu Sun",
            "Albert Merono Penuela"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09771",
        "abstract": "This paper introduces DSrepair, a knowledge-enhanced program repair method designed to repair the buggy code generated by LLMs in the data science domain. DSrepair uses knowledge graph based RAG for API knowledge retrieval as well as bug knowledge enrichment to construct repair prompts for LLMs. Specifically, to enable knowledge graph based API retrieval, we construct DS-KG (Data Science Knowledge Graph) for widely used data science libraries. For bug knowledge enrichment, we employ an abstract syntax tree (AST) to localize errors at the AST node level. DSrepair's effectiveness is evaluated against five state-of-the-art LLM-based repair baselines using four advanced LLMs on the DS-1000 dataset. The results show that DSrepair surpasses all five baselines. Specifically, when compared to the second-best baseline, DSrepair demonstrates significant improvements, fixing 44.4%, 14.2%, 20.6%, and 32.1% more buggy code snippets for each of the four evaluated LLMs, respectively. Additionally, it achieves greater efficiency, reducing the number of tokens required per code task by 17.49%, 34.24%, 24.71%, and 17.59%, respectively.",
        "tags": [
            "LLMs",
            "RAG"
        ]
    },
    {
        "id": "35",
        "title": "Prompt and circumstance: A word-by-word LLM prompting approach to interlinear glossing for low-resource languages",
        "author": [
            "Micha Elsner",
            "David Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09778",
        "abstract": "Partly automated creation of interlinear glossed text (IGT) has the potential to assist in linguistic documentation. We argue that LLMs can make this process more accessible to linguists because of their capacity to follow natural-language instructions. We investigate the effectiveness of a retrieval-based LLM prompting approach to glossing, applied to the seven languages from the SIGMORPHON 2023 shared task. Our system beats the BERT-based shared task baseline for every language in the morpheme-level score category, and we show that a simple 3-best oracle has higher word-level scores than the challenge winner (a tuned sequence model) in five languages. In a case study on Tsez, we ask the LLM to automatically create and follow linguistic instructions, reducing errors on a confusing grammatical feature. Our results thus demonstrate the potential contributions which LLMs can make in interactive systems for glossing, both in making suggestions to human annotators and following directions.",
        "tags": [
            "BERT",
            "LLMs"
        ]
    },
    {
        "id": "36",
        "title": "Improving Acoustic Side-Channel Attacks on Keyboards Using Transformers and Large Language Models",
        "author": [
            "Jin Hyun Park",
            "Seyyed Ali Ayati",
            "Yichen Cai"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09782",
        "abstract": "The increasing prevalence of microphones in everyday devices and the growing reliance on online services have amplified the risk of acoustic side-channel attacks (ASCAs) targeting keyboards. This study explores deep learning techniques, specifically vision transformers (VTs) and large language models (LLMs), to enhance the effectiveness and applicability of such attacks. We present substantial improvements over prior research, with the CoAtNet model achieving state-of-the-art performance. Our CoAtNet shows a 5.0% improvement for keystrokes recorded via smartphone (Phone) and 5.9% for those recorded via Zoom compared to previous benchmarks. We also evaluate transformer architectures and language models, with the best VT model matching CoAtNet's performance. A key advancement is the introduction of a noise mitigation method for real-world scenarios. By using LLMs for contextual understanding, we detect and correct erroneous keystrokes in noisy environments, enhancing ASCA performance. Additionally, fine-tuned lightweight language models with Low-Rank Adaptation (LoRA) deliver comparable performance to heavyweight models with 67X more parameters. This integration of VTs and LLMs improves the practical applicability of ASCA mitigation, marking the first use of these technologies to address ASCAs and error correction in real-world scenarios.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "LoRA",
            "Low-Rank Adaptation",
            "Transformer"
        ]
    },
    {
        "id": "37",
        "title": "TableTalk: Scaffolding Spreadsheet Development with a Language Agent",
        "author": [
            "Jenny T. Liang",
            "Aayush Kumar",
            "Yasharth Bajpai",
            "Sumit Gulwani",
            "Vu Le",
            "Chris Parnin",
            "Arjun Radhakrishna",
            "Ashish Tiwari",
            "Emerson Murphy-Hill",
            "Guastavo Soares"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09787",
        "abstract": "Despite its ubiquity in the workforce, spreadsheet programming remains challenging as programmers need both spreadsheet-specific knowledge (e.g., APIs to write formulas) and problem-solving skills to create complex spreadsheets. Large language models (LLMs) can help automate aspects of this process, and recent advances in planning and reasoning have enabled language agents, which dynamically plan, use tools, and take iterative actions to complete complex tasks. These agents observe, plan, and act, making them well-suited to scaffold spreadsheet programming by following expert processes.\nWe present TableTalk, a language agent that helps programmers build spreadsheets conversationally. Its design reifies three design principles -- scaffolding, flexibility, and incrementality -- which we derived from two studies of seven programmers and 62 Excel templates. TableTalk structures spreadsheet development by generating step-by-step plans and suggesting three next steps users can choose from. It also integrates tools that enable incremental spreadsheet construction. A user study with 20 programmers shows that TableTalk produces spreadsheets 2.3 times more likely to be preferred over a baseline agent, while reducing cognitive load and time spent reasoning about spreadsheet actions by 12.6%. TableTalk's approach has implications for human-agent collaboration. This includes providing persistent direct manipulation interfaces for stopping or undoing agent actions, while ensuring that such interfaces for accepting actions can be deactivated.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "38",
        "title": "Noise Controlled CT Super-Resolution with Conditional Diffusion Model",
        "author": [
            "Yuang Wang",
            "Siyeop Yoon",
            "Rui Hu",
            "Baihui Yu",
            "Duhgoon Lee",
            "Rajiv Gupta",
            "Li Zhang",
            "Zhiqiang Chen",
            "Dufan Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09793",
        "abstract": "Improving the spatial resolution of CT images is a meaningful yet challenging task, often accompanied by the issue of noise amplification. This article introduces an innovative framework for noise-controlled CT super-resolution utilizing the conditional diffusion model. The model is trained on hybrid datasets, combining noise-matched simulation data with segmented details from real data. Experimental results with real CT images validate the effectiveness of our proposed framework, showing its potential for practical applications in CT imaging.",
        "tags": [
            "Diffusion",
            "Super Resolution"
        ]
    },
    {
        "id": "39",
        "title": "A Survey on LLM-based News Recommender Systems",
        "author": [
            "Rongyao Wang",
            "Veronica Liesaputra",
            "Zhiyi Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09797",
        "abstract": "News recommender systems play a critical role in mitigating the information overload problem. In recent years, due to the successful applications of large language model technologies, researchers have utilized Discriminative Large Language Models (DLLMs) or Generative Large Language Models (GLLMs) to improve the performance of news recommender systems. Although several recent surveys review significant challenges for deep learning-based news recommender systems, such as fairness, privacy-preserving, and responsibility, there is a lack of a systematic survey on Large Language Model (LLM)-based news recommender systems. In order to review different core methodologies and explore potential issues systematically, we categorize DLLM-based and GLLM-based news recommender systems under the umbrella of LLM-based news recommender systems. In this survey, we first overview the development of deep learning-based news recommender systems. Then, we review LLM-based news recommender systems based on three aspects: news-oriented modeling, user-oriented modeling, and prediction-oriented modeling. Next, we examine the challenges from various perspectives, including datasets, benchmarking tools, and methodologies. Furthermore, we conduct extensive experiments to analyze how large language model technologies affect the performance of different news recommender systems. Finally, we comprehensively explore the future directions for LLM-based news recommendations in the era of LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "40",
        "title": "Co-designing Large Language Model Tools for Project-Based Learning with K12 Educators",
        "author": [
            "Prerna Ravi",
            "John Masla",
            "Gisella Kakoti",
            "Grace Lin",
            "Emma Anderson",
            "Matt Taylor",
            "Anastasia Ostrowski",
            "Cynthia Breazeal",
            "Eric Klopfer",
            "Hal Abelson"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09799",
        "abstract": "The emergence of generative AI, particularly large language models (LLMs), has opened the door for student-centered and active learning methods like project-based learning (PBL). However, PBL poses practical implementation challenges for educators around project design and management, assessment, and balancing student guidance with student autonomy. The following research documents a co-design process with interdisciplinary K-12 teachers to explore and address the current PBL challenges they face. Through teacher-driven interviews, collaborative workshops, and iterative design of wireframes, we gathered evidence for ways LLMs can support teachers in implementing high-quality PBL pedagogy by automating routine tasks and enhancing personalized learning. Teachers in the study advocated for supporting their professional growth and augmenting their current roles without replacing them. They also identified affordances and challenges around classroom integration, including resource requirements and constraints, ethical concerns, and potential immediate and long-term impacts. Drawing on these, we propose design guidelines for future deployment of LLM tools in PBL.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "41",
        "title": "Unit Testing Past vs. Present: Examining LLMs' Impact on Defect Detection and Efficiency",
        "author": [
            "Rudolf Ramler",
            "Philipp Straubinger",
            "Reinhold PlÃ¶sch",
            "Dietmar Winkler"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09801",
        "abstract": "The integration of Large Language Models (LLMs), such as ChatGPT and GitHub Copilot, into software engineering workflows has shown potential to enhance productivity, particularly in software testing. This paper investigates whether LLM support improves defect detection effectiveness during unit testing. Building on prior studies comparing manual and tool-supported testing, we replicated and extended an experiment where participants wrote unit tests for a Java-based system with seeded defects within a time-boxed session, supported by LLMs. Comparing LLM supported and manual testing, results show that LLM support significantly increases the number of unit tests generated, defect detection rates, and overall testing efficiency. These findings highlight the potential of LLMs to improve testing and defect detection outcomes, providing empirical insights into their practical application in software testing.",
        "tags": [
            "ChatGPT",
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "42",
        "title": "AgentGuard: Repurposing Agentic Orchestrator for Safety Evaluation of Tool Orchestration",
        "author": [
            "Jizhou Chen",
            "Samuel Lee Cong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09809",
        "abstract": "The integration of tool use into large language models (LLMs) enables agentic systems with real-world impact. In the meantime, unlike standalone LLMs, compromised agents can execute malicious workflows with more consequential impact, signified by their tool-use capability. We propose AgentGuard, a framework to autonomously discover and validate unsafe tool-use workflows, followed by generating safety constraints to confine the behaviors of agents, achieving the baseline of safety guarantee at deployment. AgentGuard leverages the LLM orchestrator's innate capabilities - knowledge of tool functionalities, scalable and realistic workflow generation, and tool execution privileges - to act as its own safety evaluator. The framework operates through four phases: identifying unsafe workflows, validating them in real-world execution, generating safety constraints, and validating constraint efficacy. The output, an evaluation report with unsafe workflows, test cases, and validated constraints, enables multiple security applications. We empirically demonstrate AgentGuard's feasibility with experiments. With this exploratory work, we hope to inspire the establishment of standardized testing and hardening procedures for LLM agents to enhance their trustworthiness in real-world applications.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "43",
        "title": "INJONGO: A Multicultural Intent Detection and Slot-filling Dataset for 16 African Languages",
        "author": [
            "Hao Yu",
            "Jesujoba O. Alabi",
            "Andiswa Bukula",
            "Jian Yun Zhuang",
            "En-Shiun Annie Lee",
            "Tadesse Kebede Guge",
            "Israel Abebe Azime",
            "Happy Buzaaba",
            "Blessing Kudzaishe Sibanda",
            "Godson K. Kalipe",
            "Jonathan Mukiibi",
            "Salomon Kabongo Kabenamualu",
            "Mmasibidi Setaka",
            "Lolwethu Ndolela",
            "Nkiruka Odu",
            "Rooweither Mabuya",
            "Shamsuddeen Hassan Muhammad",
            "Salomey Osei",
            "Sokhar Samb",
            "Juliet W. Murage",
            "Dietrich Klakow",
            "David Ifeoluwa Adelani"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09814",
        "abstract": "Slot-filling and intent detection are well-established tasks in Conversational AI. However, current large-scale benchmarks for these tasks often exclude evaluations of low-resource languages and rely on translations from English benchmarks, thereby predominantly reflecting Western-centric concepts. In this paper, we introduce Injongo -- a multicultural, open-source benchmark dataset for 16 African languages with utterances generated by native speakers across diverse domains, including banking, travel, home, and dining. Through extensive experiments, we benchmark the fine-tuning multilingual transformer models and the prompting large language models (LLMs), and show the advantage of leveraging African-cultural utterances over Western-centric utterances for improving cross-lingual transfer from the English language. Experimental results reveal that current LLMs struggle with the slot-filling task, with GPT-4o achieving an average performance of 26 F1-score. In contrast, intent detection performance is notably better, with an average accuracy of 70.6%, though it still falls behind the fine-tuning baselines. Compared to the English language, GPT-4o and fine-tuning baselines perform similarly on intent detection, achieving an accuracy of approximately 81%. Our findings suggest that the performance of LLMs is still behind for many low-resource African languages, and more work is needed to further improve their downstream performance.",
        "tags": [
            "Detection",
            "GPT",
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "44",
        "title": "On the robustness of multimodal language model towards distractions",
        "author": [
            "Ming Liu",
            "Hao Chen",
            "Jindong Wang",
            "Wensheng Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09818",
        "abstract": "Although vision-language models (VLMs) have achieved significant success in various applications such as visual question answering, their resilience to prompt variations remains an under-explored area. Understanding how distractions affect VLMs is crucial for improving their real-world applicability, as inputs could have noisy and irrelevant information in many practical scenarios. This paper aims to assess the robustness of VLMs against both visual and textual distractions in the context of science question answering. Built on the ScienceQA dataset, we developed a new benchmark that introduces distractions in both the visual and textual contexts to evaluate the reasoning capacity of VLMs amid these distractions. Our findings reveal that most-of-the-art VLMs, including GPT-4, are vulnerable to various types of distractions, experiencing noticeable degradation in reasoning capabilities when confronted with distractions. Notably, models such as InternVL2 demonstrate a higher degree of robustness to these distractions. We also found that models exhibit greater sensitivity to textual distractions than visual ones. Additionally, we explored various mitigation strategies, such as prompt engineering, to counteract the impact of distractions. While these strategies improved solution accuracy, our analysis shows that there remain significant opportunities for improvement.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "45",
        "title": "A Solver-Aided Hierarchical Language for LLM-Driven CAD Design",
        "author": [
            "Benjamin T. Jones",
            "Felix HÃ¤hnlein",
            "Zihan Zhang",
            "Maaz Ahmad",
            "Vladimir Kim",
            "Adriana Schulz"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09819",
        "abstract": "Large language models (LLMs) have been enormously successful in solving a wide variety of structured and unstructured generative tasks, but they struggle to generate procedural geometry in Computer Aided Design (CAD). These difficulties arise from an inability to do spatial reasoning and the necessity to guide a model through complex, long range planning to generate complex geometry. We enable generative CAD Design with LLMs through the introduction of a solver-aided, hierarchical domain specific language (DSL) called AIDL, which offloads the spatial reasoning requirements to a geometric constraint solver. Additionally, we show that in the few-shot regime, AIDL outperforms even a language with in-training data (OpenSCAD), both in terms of generating visual results closer to the prompt and creating objects that are easier to post-process and reason about.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "46",
        "title": "MuDoC: An Interactive Multimodal Document-grounded Conversational AI System",
        "author": [
            "Karan Taneja",
            "Ashok K. Goel"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09843",
        "abstract": "Multimodal AI is an important step towards building effective tools to leverage multiple modalities in human-AI communication. Building a multimodal document-grounded AI system to interact with long documents remains a challenge. Our work aims to fill the research gap of directly leveraging grounded visuals from documents alongside textual content in documents for response generation. We present an interactive conversational AI agent 'MuDoC' based on GPT-4o to generate document-grounded responses with interleaved text and figures. MuDoC's intelligent textbook interface promotes trustworthiness and enables verification of system responses by allowing instant navigation to source text and figures in the documents. We also discuss qualitative observations based on MuDoC responses highlighting its strengths and limitations.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "47",
        "title": "Solving Empirical Bayes via Transformers",
        "author": [
            "Anzo Teh",
            "Mark Jabbour",
            "Yury Polyanskiy"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09844",
        "abstract": "This work applies modern AI tools (transformers) to solving one of the oldest statistical problems: Poisson means under empirical Bayes (Poisson-EB) setting. In Poisson-EB a high-dimensional mean vector $\\theta$ (with iid coordinates sampled from an unknown prior $\\pi$) is estimated on the basis of $X=\\mathrm{Poisson}(\\theta)$. A transformer model is pre-trained on a set of synthetically generated pairs $(X,\\theta)$ and learns to do in-context learning (ICL) by adapting to unknown $\\pi$. Theoretically, we show that a sufficiently wide transformer can achieve vanishing regret with respect to an oracle estimator who knows $\\pi$ as dimension grows to infinity. Practically, we discover that already very small models (100k parameters) are able to outperform the best classical algorithm (non-parametric maximum likelihood, or NPMLE) both in runtime and validation loss, which we compute on out-of-distribution synthetic data as well as real-world datasets (NHL hockey, MLB baseball, BookCorpusOpen). Finally, by using linear probes, we confirm that the transformer's EB estimator appears to internally work differently from either NPMLE or Robbins' estimators.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "48",
        "title": "Efficient Multitask Learning in Small Language Models Through Upside-Down Reinforcement Learning",
        "author": [
            "Yu-Chen Lin",
            "Sanat Sharma",
            "Hari Manikandan",
            "Jayant Kumar",
            "Tracy Holloway King",
            "Jing Zheng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09854",
        "abstract": "In this work, we demonstrate that small language models (SLMs), specifically a 100M parameter GPT-2 model, can achieve competitive performance in multitask prompt generation tasks while requiring only a fraction of the computational resources needed by large language models (LLMs). Through a novel combination of upside-down reinforcement learning and synthetic data distillation from a powerful LLM, Llama-3, we train an SLM that achieves relevance scores within 5% of state-of-the-art models, including Llama-3, Qwen2, and Mistral, despite being up to 80 times smaller, making it highly suitable for resource-constrained and real-time applications. This study highlights the potential of SLMs as efficient multitask learners in multimodal settings, providing a promising alternative to LLMs for scalable, low-latency deployments.",
        "tags": [
            "GPT",
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "49",
        "title": "Automated Hypothesis Validation with Agentic Sequential Falsifications",
        "author": [
            "Kexin Huang",
            "Ying Jin",
            "Ryan Li",
            "Michael Y. Li",
            "Emmanuel CandÃ¨s",
            "Jure Leskovec"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09858",
        "abstract": "Hypotheses are central to information acquisition, decision-making, and discovery. However, many real-world hypotheses are abstract, high-level statements that are difficult to validate directly. This challenge is further intensified by the rise of hypothesis generation from Large Language Models (LLMs), which are prone to hallucination and produce hypotheses in volumes that make manual validation impractical. Here we propose Popper, an agentic framework for rigorous automated validation of free-form hypotheses. Guided by Karl Popper's principle of falsification, Popper validates a hypothesis using LLM agents that design and execute falsification experiments targeting its measurable implications. A novel sequential testing framework ensures strict Type-I error control while actively gathering evidence from diverse observations, whether drawn from existing data or newly conducted procedures. We demonstrate Popper on six domains including biology, economics, and sociology. Popper delivers robust error control, high power, and scalability. Furthermore, compared to human scientists, Popper achieved comparable performance in validating complex biological hypotheses while reducing time by 10 folds, providing a scalable, rigorous solution for hypothesis validation.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "50",
        "title": "Solvable Dynamics of Self-Supervised Word Embeddings and the Emergence of Analogical Reasoning",
        "author": [
            "Dhruva Karkada",
            "James B. Simon",
            "Yasaman Bahri",
            "Michael R. DeWeese"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09863",
        "abstract": "The remarkable success of large language models relies on their ability to implicitly learn structured latent representations from the pretraining corpus. As a simpler surrogate for representation learning in language modeling, we study a class of solvable contrastive self-supervised algorithms which we term quadratic word embedding models. These models resemble the word2vec algorithm and perform similarly on downstream tasks. Our main contributions are analytical solutions for both the training dynamics (under certain hyperparameter choices) and the final word embeddings, given in terms of only the corpus statistics. Our solutions reveal that these models learn orthogonal linear subspaces one at a time, each one incrementing the effective rank of the embeddings until model capacity is saturated. Training on WikiText, we find that the top subspaces represent interpretable concepts. Finally, we use our dynamical theory to predict how and when models acquire the ability to complete analogies.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "51",
        "title": "DesignWeaver: Dimensional Scaffolding for Text-to-Image Product Design",
        "author": [
            "Sirui Tao",
            "Ivan Liang",
            "Cindy Peng",
            "Zhiqing Wang",
            "Srishti Palani",
            "Steven Dow"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09867",
        "abstract": "Generative AI has enabled novice designers to quickly create professional-looking visual representations for product concepts. However, novices have limited domain knowledge that could constrain their ability to write prompts that effectively explore a product design space. To understand how experts explore and communicate about design spaces, we conducted a formative study with 12 experienced product designers and found that experts -- and their less-versed clients -- often use visual references to guide co-design discussions rather than written descriptions. These insights inspired DesignWeaver, an interface that helps novices generate prompts for a text-to-image model by surfacing key product design dimensions from generated images into a palette for quick selection. In a study with 52 novices, DesignWeaver enabled participants to craft longer prompts with more domain-specific vocabularies, resulting in more diverse, innovative product designs. However, the nuanced prompts heightened participants' expectations beyond what current text-to-image models could deliver. We discuss implications for AI-based product design support tools.",
        "tags": [
            "Text-to-Image"
        ]
    },
    {
        "id": "52",
        "title": "A Taxonomy of Linguistic Expressions That Contribute To Anthropomorphism of Language Technologies",
        "author": [
            "Alicia DeVrio",
            "Myra Cheng",
            "Lisa Egede",
            "Alexandra Olteanu",
            "Su Lin Blodgett"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09870",
        "abstract": "Recent attention to anthropomorphism -- the attribution of human-like qualities to non-human objects or entities -- of language technologies like LLMs has sparked renewed discussions about potential negative impacts of anthropomorphism. To productively discuss the impacts of this anthropomorphism and in what contexts it is appropriate, we need a shared vocabulary for the vast variety of ways that language can be anthropomorphic. In this work, we draw on existing literature and analyze empirical cases of user interactions with language technologies to develop a taxonomy of textual expressions that can contribute to anthropomorphism. We highlight challenges and tensions involved in understanding linguistic anthropomorphism, such as how all language is fundamentally human and how efforts to characterize and shift perceptions of humanness in machines can also dehumanize certain humans. We discuss ways that our taxonomy supports more precise and effective discussions of and decisions about anthropomorphism of language technologies.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "53",
        "title": "Compression-Aware One-Step Diffusion Model for JPEG Artifact Removal",
        "author": [
            "Jinpei Guo",
            "Zheng Chen",
            "Wenbo Li",
            "Yong Guo",
            "Yulun Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09873",
        "abstract": "Diffusion models have demonstrated remarkable success in image restoration tasks. However, their multi-step denoising process introduces significant computational overhead, limiting their practical deployment. Furthermore, existing methods struggle to effectively remove severe JPEG artifact, especially in highly compressed images. To address these challenges, we propose CODiff, a compression-aware one-step diffusion model for JPEG artifact removal. The core of CODiff is the compression-aware visual embedder (CaVE), which extracts and leverages JPEG compression priors to guide the diffusion model. We propose a dual learning strategy that combines explicit and implicit learning. Specifically, explicit learning enforces a quality prediction objective to differentiate low-quality images with different compression levels. Implicit learning employs a reconstruction objective that enhances the model's generalization. This dual learning allows for a deeper and more comprehensive understanding of JPEG compression. Experimental results demonstrate that CODiff surpasses recent leading methods in both quantitative and visual quality metrics. The code and models will be released at https://github.com/jp-guo/CODiff.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "54",
        "title": "Video2Policy: Scaling up Manipulation Tasks in Simulation through Internet Videos",
        "author": [
            "Weirui Ye",
            "Fangchen Liu",
            "Zheng Ding",
            "Yang Gao",
            "Oleh Rybkin",
            "Pieter Abbeel"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09886",
        "abstract": "Simulation offers a promising approach for cheaply scaling training data for generalist policies. To scalably generate data from diverse and realistic tasks, existing algorithms either rely on large language models (LLMs) that may hallucinate tasks not interesting for robotics; or digital twins, which require careful real-to-sim alignment and are hard to scale. To address these challenges, we introduce Video2Policy, a novel framework that leverages internet RGB videos to reconstruct tasks based on everyday human behavior. Our approach comprises two phases: (1) task generation in simulation from videos; and (2) reinforcement learning utilizing in-context LLM-generated reward functions iteratively. We demonstrate the efficacy of Video2Policy by reconstructing over 100 videos from the Something-Something-v2 (SSv2) dataset, which depicts diverse and complex human behaviors on 9 different tasks. Our method can successfully train RL policies on such tasks, including complex and challenging tasks such as throwing. Finally, we show that the generated simulation data can be scaled up for training a general policy, and it can be transferred back to the real robot in a Real2Sim2Real way.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RL",
            "Robot",
            "Robotics"
        ]
    },
    {
        "id": "55",
        "title": "ArchRAG: Attributed Community-based Hierarchical Retrieval-Augmented Generation",
        "author": [
            "Shu Wang",
            "Yixiang Fang",
            "Yingli Zhou",
            "Xilin Liu",
            "Yuchi Ma"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09891",
        "abstract": "Retrieval-Augmented Generation (RAG) has proven effective in integrating external knowledge into large language models (LLMs) for question-answer (QA) tasks. The state-of-the-art RAG approaches often use the graph data as the external data since they capture the rich semantic information and link relationships between entities. However, existing graph-based RAG approaches cannot accurately identify the relevant information from the graph and also consume large numbers of tokens in the online retrieval process. To address these issues, we introduce a novel graph-based RAG approach, called Attributed Community-based Hierarchical RAG (ArchRAG), by augmenting the question using attributed communities, and also introducing a novel LLM-based hierarchical clustering method. To retrieve the most relevant information from the graph for the question, we build a novel hierarchical index structure for the attributed communities and develop an effective online retrieval method. Experimental results demonstrate that ArchRAG outperforms existing methods in terms of both accuracy and token cost.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "56",
        "title": "ChatIoT: Large Language Model-based Security Assistant for Internet of Things with Retrieval-Augmented Generation",
        "author": [
            "Ye Dong",
            "Yan Lin Aung",
            "Sudipta Chattopadhyay",
            "Jianying Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09896",
        "abstract": "Internet of Things (IoT) has gained widespread popularity, revolutionizing industries and daily life. However, it has also emerged as a prime target for attacks. Numerous efforts have been made to improve IoT security, and substantial IoT security and threat information, such as datasets and reports, have been developed. However, existing research often falls short in leveraging these insights to assist or guide users in harnessing IoT security practices in a clear and actionable way. In this paper, we propose ChatIoT, a large language model (LLM)-based IoT security assistant designed to disseminate IoT security and threat intelligence. By leveraging the versatile property of retrieval-augmented generation (RAG), ChatIoT successfully integrates the advanced language understanding and reasoning capabilities of LLM with fast-evolving IoT security information. Moreover, we develop an end-to-end data processing toolkit to handle heterogeneous datasets. This toolkit converts datasets of various formats into retrievable documents and optimizes chunking strategies for efficient retrieval. Additionally, we define a set of common use case specifications to guide the LLM in generating answers aligned with users' specific needs and expertise levels. Finally, we implement a prototype of ChatIoT and conduct extensive experiments with different LLMs, such as LLaMA3, LLaMA3.1, and GPT-4o. Experimental evaluations demonstrate that ChatIoT can generate more reliable, relevant, and technical in-depth answers for most use cases. When evaluating the answers with LLaMA3:70B, ChatIoT improves the above metrics by over 10% on average, particularly in relevance and technicality, compared to using LLMs alone.",
        "tags": [
            "GPT",
            "LLMs",
            "RAG"
        ]
    },
    {
        "id": "57",
        "title": "The Ann Arbor Architecture for Agent-Oriented Programming",
        "author": [
            "Wei Dong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09903",
        "abstract": "In this paper, we reexamine prompt engineering for large language models through the lens of automata theory. We argue that language models function as automata and, like all automata, should be programmed in the languages they accept, a unified collection of all natural and formal languages. Therefore, traditional software engineering practices--conditioned on the clear separation of programming languages and natural languages--must be rethought. We introduce the Ann Arbor Architecture, a conceptual framework for agent-oriented programming of language models, as a higher-level abstraction over raw token generation, and provide a new perspective on in-context learning. Based on this framework, we present the design of our agent platform Postline, and report on our initial experiments in agent training.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "58",
        "title": "Insect-Foundation: A Foundation Model and Large Multimodal Dataset for Vision-Language Insect Understanding",
        "author": [
            "Thanh-Dat Truong",
            "Hoang-Quan Nguyen",
            "Xuan-Bac Nguyen",
            "Ashley Dowling",
            "Xin Li",
            "Khoa Luu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09906",
        "abstract": "Multimodal conversational generative AI has shown impressive capabilities in various vision and language understanding through learning massive text-image data. However, current conversational models still lack knowledge about visual insects since they are often trained on the general knowledge of vision-language data. Meanwhile, understanding insects is a fundamental problem in precision agriculture, helping to promote sustainable development in agriculture. Therefore, this paper proposes a novel multimodal conversational model, Insect-LLaVA, to promote visual understanding in insect-domain knowledge. In particular, we first introduce a new large-scale Multimodal Insect Dataset with Visual Insect Instruction Data that enables the capability of learning the multimodal foundation models. Our proposed dataset enables conversational models to comprehend the visual and semantic features of the insects. Second, we propose a new Insect-LLaVA model, a new general Large Language and Vision Assistant in Visual Insect Understanding. Then, to enhance the capability of learning insect features, we develop an Insect Foundation Model by introducing a new micro-feature self-supervised learning with a Patch-wise Relevant Attention mechanism to capture the subtle differences among insect images. We also present Description Consistency loss to improve micro-feature learning via text descriptions. The experimental results evaluated on our new Visual Insect Question Answering benchmarks illustrate the effective performance of our proposed approach in visual insect understanding and achieve State-of-the-Art performance on standard benchmarks of insect-related tasks.",
        "tags": [
            "LLaVA"
        ]
    },
    {
        "id": "59",
        "title": "Dual Control for Interactive Autonomous Merging with Model Predictive Diffusion",
        "author": [
            "Jacob Knaup",
            "Jovin D'sa",
            "Behdad Chalaki",
            "Hossein Nourkhiz Mahjoub",
            "Ehsan Moradi-Pari",
            "Panagiotis Tsiotras"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09918",
        "abstract": "Interactive decision-making is essential in applications such as autonomous driving, where the agent must infer the behavior of nearby human drivers while planning in real-time. Traditional predict-then-act frameworks are often insufficient or inefficient because accurate inference of human behavior requires a continuous interaction rather than isolated prediction. To address this, we propose an active learning framework in which we rigorously derive predicted belief distributions. Additionally, we introduce a novel model-based diffusion solver tailored for online receding horizon control problems, demonstrated through a complex, non-convex highway merging scenario. Our approach extends previous high-fidelity dual control simulations to hardware experiments, which may be viewed at https://youtu.be/Q_JdZuopGL4, and verifies behavior inference in human-driven traffic scenarios, moving beyond idealized models. The results show improvements in adaptive planning under uncertainty, advancing the field of interactive decision-making for real-world applications.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "60",
        "title": "INF^2: High-Throughput Generative Inference of Large Language Models using Near-Storage Processing",
        "author": [
            "Hongsun Jang",
            "Siung Noh",
            "Changmin Shin",
            "Jaewon Jung",
            "Jaeyong Song",
            "Jinho Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09921",
        "abstract": "The growing memory and computational demands of large language models (LLMs) for generative inference present significant challenges for practical deployment. One promising solution to address these challenges is offloading-based batched inference, which leverages host memory and disk as an extended memory hierarchy for GPUs. While the approach cost-effectively enables LLM inference, its performance is limited by substantial I/O overhead, primarily due to the large key-value (KV) cache sizes, which increase with batch size and LLM context window length.\nIn this paper, we introduce INFerence-INFinity (INF^2), a framework that boosts generative inference throughput using computational storage devices (CSDs). The core of INF^2 is attention-near storage, which offloads memory-intensive self-attention operations to near-storage accelerators, significantly reducing traffic through the system interconnect. We also propose delayed KV cache writeback to hide storage write latency by delaying newly generated KV cache writes until the cache reaches sufficient size in system memory. Additionally, we introduce cooperative X-cache, a technique designed to further trade off the remaining memory capacity for storage bandwidth. Our methods effectively minimize idle time for computation, improving the overall throughput.\nTo demonstrate the effectiveness of our approach, \\thiswork has been implemented on PyTorch and evaluated on a real system. Our experiments show that INF^2 achieves up to 3.46$\\times$ throughput improvement compared to state-of-the-art baselines. We will open-source INF^2 to facilitate broader adoption.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "61",
        "title": "Î»Scale: Enabling Fast Scaling for Serverless Large Language Model Inference",
        "author": [
            "Minchen Yu",
            "Rui Yang",
            "Chaobo Jia",
            "Zhaoyuan Su",
            "Sheng Yao",
            "Tingfeng Lan",
            "Yuchen Yang",
            "Yue Cheng",
            "Wei Wang",
            "Ao Wang",
            "Ruichuan Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09922",
        "abstract": "Serverless computing has emerged as a compelling solution for cloud-based model inference. However, as modern large language models (LLMs) continue to grow in size, existing serverless platforms often face substantial model startup overhead. This poses a significant challenge in efficiently scaling model instances to accommodate dynamic, bursty workloads commonly observed in real-world inference services. In this paper, we introduce {\\lambda}Scale, an efficient serverless inference system to achieve fast model scaling. The key idea behind {\\lambda}Scale is to leverage high-speed RDMA networks between GPU nodes for fast model multicast, while enabling distributed inference execution during model transmission -- referred to as \"execute-while-load\". {\\lambda}Scale proposes an efficient model scaling scheme, {\\lambda}Pipe, which supports adaptive model multicast and dynamically constructs execution pipelines across receiving nodes for collaborative, distributed inference. Additionally, {\\lambda}Scale supports efficient model management across GPU and host memory, allowing fast scaling for models across different storage tiers. Evaluation results show that {\\lambda}Scale enables fast model scaling and effectively handles load spikes, achieving up to 5x tail-latency improvement and 31.3% cost reduction compared to state-of-the-art solutions on real-world LLM inference traces.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "62",
        "title": "TaskGalaxy: Scaling Multi-modal Instruction Fine-tuning with Tens of Thousands Vision Task Types",
        "author": [
            "Jiankang Chen",
            "Tianke Zhang",
            "Changyi Liu",
            "Haojie Ding",
            "Yaya Shi",
            "Feng Cheng",
            "Huihui Xiao",
            "Bin Wen",
            "Fan Yang",
            "Tingting Gao",
            "Di Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09925",
        "abstract": "Multimodal visual language models are gaining prominence in open-world applications, driven by advancements in model architectures, training techniques, and high-quality data. However, their performance is often limited by insufficient task-specific data, leading to poor generalization and biased outputs. Existing efforts to increase task diversity in fine-tuning datasets are hindered by the labor-intensive process of manual task labeling, which typically produces only a few hundred task types. To address this, we propose TaskGalaxy, a large-scale multimodal instruction fine-tuning dataset comprising 19,227 hierarchical task types and 413,648 samples. TaskGalaxy utilizes GPT-4o to enrich task diversity by expanding from a small set of manually defined tasks, with CLIP and GPT-4o filtering those that best match open-source images, and generating relevant question-answer pairs. Multiple models are employed to ensure sample quality. This automated process enhances both task diversity and data quality, reducing manual intervention. Incorporating TaskGalaxy into LLaVA-v1.5 and InternVL-Chat-v1.0 models shows substantial performance improvements across 16 benchmarks, demonstrating the critical importance of task diversity. TaskGalaxy is publicly released at https://github.com/Kwai-YuanQi/TaskGalaxy.",
        "tags": [
            "CLIP",
            "GPT",
            "LLaVA"
        ]
    },
    {
        "id": "63",
        "title": "MIR-Bench: Benchmarking LLM's Long-Context Intelligence via Many-Shot In-Context Inductive Reasoning",
        "author": [
            "Kai Yan",
            "Zhan Ling",
            "Kang Liu",
            "Yifan Yang",
            "Ting-Han Fan",
            "Lingfeng Shen",
            "Zhengyin Du",
            "Jiecao Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09933",
        "abstract": "Inductive Reasoning (IR), the ability to summarize rules from examples and apply on new ones, has long been viewed as a primal ability for general intelligence and widely studied by cognitive science and AI researchers. Many benchmarks have been proposed to measure such ability for Large Language Models (LLMs); however, they focus on few-shot (usually $<$10) setting and lack evaluation for aggregating many pieces of information from long contexts. On the other hand, the ever-growing context length of LLMs have brought forth the novel paradigm of many-shot In-Context Learning (ICL), which addresses new tasks with hundreds to thousands of examples without expensive and inefficient fine-tuning. However, many-shot evaluations are mostly focused on classification (a very limited aspect of IR), and popular long-context LLM tasks such as Needle-In-A-Haystack (NIAH) seldom require complicated intelligence for integrating many pieces of information. To fix the issues from both worlds, we propose MIR-Bench, the first many-shot in-context inductive reasoning benchmark that asks LLM to induce output via input-output examples from underlying functions with diverse data format. Based on MIR-Bench, we study many novel problems for inductive reasoning and many-shot ICL, including robustness against erroneous shots and the effect of Chain-of-Thought (CoT), and acquired insightful findings.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "64",
        "title": "Precise Parameter Localization for Textual Generation in Diffusion Models",
        "author": [
            "Åukasz Staniszewski",
            "Bartosz CywiÅski",
            "Franziska Boenisch",
            "Kamil Deja",
            "Adam Dziedzic"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09935",
        "abstract": "Novel diffusion models can synthesize photo-realistic images with integrated high-quality text. Surprisingly, we demonstrate through attention activation patching that only less than 1% of diffusion models' parameters, all contained in attention layers, influence the generation of textual content within the images. Building on this observation, we improve textual generation efficiency and performance by targeting cross and joint attention layers of diffusion models. We introduce several applications that benefit from localizing the layers responsible for textual content generation. We first show that a LoRA-based fine-tuning solely of the localized layers enhances, even more, the general text-generation capabilities of large diffusion models while preserving the quality and diversity of the diffusion models' generations. Then, we demonstrate how we can use the localized layers to edit textual content in generated images. Finally, we extend this idea to the practical use case of preventing the generation of toxic text in a cost-free manner. In contrast to prior work, our localization approach is broadly applicable across various diffusion model architectures, including U-Net (e.g., LDM and SDXL) and transformer-based (e.g., DeepFloyd IF and Stable Diffusion 3), utilizing diverse text encoders (e.g., from CLIP to the large language models like T5). Project page available at https://t2i-text-loc.github.io/.",
        "tags": [
            "CLIP",
            "Diffusion",
            "Large Language Models",
            "LoRA",
            "SDXL",
            "Transformer"
        ]
    },
    {
        "id": "65",
        "title": "A Preliminary Exploration with GPT-4o Voice Mode",
        "author": [
            "Yu-Xiang Lin",
            "Chih-Kai Yang",
            "Wei-Chih Chen",
            "Chen-An Li",
            "Chien-yu Huang",
            "Xuanjun Chen",
            "Hung-yi Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09940",
        "abstract": "With the rise of multimodal large language models, GPT-4o stands out as a pioneering model, driving us to evaluate its capabilities. This report assesses GPT-4o across various tasks to analyze its audio processing and reasoning abilities. We find that GPT-4o exhibits strong knowledge in audio, speech, and music understanding, performing well in tasks like intent classification, spoken command classification, semantic and grammatical reasoning., multilingual speech recognition, and singing analysis. It also shows greater robustness against hallucinations than other large audio-language models (LALMs). However, it struggles with tasks such as audio duration prediction and instrument classification. Additionally, GPT-4o's safety mechanisms cause it to decline tasks like speaker identification, age classification, MOS prediction, and audio deepfake detection. Notably, the model exhibits a significantly different refusal rate when responding to speaker verification tasks on different datasets. This is likely due to variations in the accompanying instructions or the quality of the input audio, suggesting the sensitivity of its built-in safeguards. Finally, we acknowledge that model performance varies with evaluation protocols. This report only serves as a preliminary exploration of the current state of LALMs.",
        "tags": [
            "Detection",
            "GPT",
            "Large Language Models"
        ]
    },
    {
        "id": "66",
        "title": "A Lightweight and Effective Image Tampering Localization Network with Vision Mamba",
        "author": [
            "Kun Guo",
            "Gang Cao",
            "Zijie Lou",
            "Xianglin Huang",
            "Jiaoyun Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09941",
        "abstract": "Current image tampering localization methods primarily rely on Convolutional Neural Networks (CNNs) and Transformers. While CNNs suffer from limited local receptive fields, Transformers offer global context modeling at the expense of quadratic computational complexity. Recently, the state space model Mamba has emerged as a competitive alternative, enabling linear-complexity global dependency modeling. Inspired by it, we propose a lightweight and effective FORensic network based on vision MAmba (ForMa) for blind image tampering localization. Firstly, ForMa captures multi-scale global features that achieves efficient global dependency modeling through linear complexity. Then the pixel-wise localization map is generated by a lightweight decoder, which employs a parameter-free pixel shuffle layer for upsampling. Additionally, a noise-assisted decoding strategy is proposed to integrate complementary manipulation traces from tampered images, boosting decoder sensitivity to forgery cues. Experimental results on 10 standard datasets demonstrate that ForMa achieves state-of-the-art generalization ability and robustness, while maintaining the lowest computational complexity. Code is available at https://github.com/multimediaFor/ForMa.",
        "tags": [
            "Mamba"
        ]
    },
    {
        "id": "67",
        "title": "Diverse Inference and Verification for Advanced Reasoning",
        "author": [
            "Iddo Drori",
            "Gaston Longhitano",
            "Mao Mao",
            "Seunghwan Hyun",
            "Yuke Zhang",
            "Sungjun Park",
            "Zachary Meeks",
            "Xin-Yu Zhang",
            "Ben Segev",
            "Howard Yong",
            "Nakul Verma",
            "Avi Shporer",
            "Alon Amit",
            "Madeleine Udell"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09955",
        "abstract": "Reasoning LLMs such as OpenAI o1, o3 and DeepSeek R1 have made significant progress in mathematics and coding, yet find challenging advanced tasks such as International Mathematical Olympiad (IMO) combinatorics problems, Abstraction and Reasoning Corpus (ARC) puzzles, and Humanity's Last Exam (HLE) questions. We use a diverse inference approach that combines multiple models and methods at test time. We find that verifying mathematics and code problems, and rejection sampling on other problems is simple and effective. We automatically verify correctness of solutions to IMO problems by Lean, and ARC puzzles by code, and find that best-of-N effectively answers HLE questions. Our approach increases answer accuracy on IMO combinatorics problems from 33.3% to 77.8%, accuracy on HLE questions from 8% to 37%, and solves 80% of ARC puzzles that 948 humans could not and 26.5% of ARC puzzles that o3 high compute does not. Test-time simulations, reinforcement learning, and meta-learning with inference feedback improve generalization by adapting agent graph representations and varying prompts, code, and datasets. Our approach is reliable, robust, and scalable, and in the spirit of reproducible research, we will make it publicly available upon publication.",
        "tags": [
            "DeepSeek",
            "LLMs"
        ]
    },
    {
        "id": "68",
        "title": "Generating on Generated: An Approach Towards Self-Evolving Diffusion Models",
        "author": [
            "Xulu Zhang",
            "Xiaoyong Wei",
            "Jinlin Wu",
            "Jiaxin Wu",
            "Zhaoxiang Zhang",
            "Zhen Lei",
            "Qing Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09963",
        "abstract": "Recursive Self-Improvement (RSI) enables intelligence systems to autonomously refine their capabilities. This paper explores the application of RSI in text-to-image diffusion models, addressing the challenge of training collapse caused by synthetic data. We identify two key factors contributing to this collapse: the lack of perceptual alignment and the accumulation of generative hallucinations. To mitigate these issues, we propose three strategies: (1) a prompt construction and filtering pipeline designed to facilitate the generation of perceptual aligned data, (2) a preference sampling method to identify human-preferred samples and filter out generative hallucinations, and (3) a distribution-based weighting scheme to penalize selected samples with hallucinatory errors. Our extensive experiments validate the effectiveness of these approaches.",
        "tags": [
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "69",
        "title": "Has My System Prompt Been Used? Large Language Model Prompt Membership Inference",
        "author": [
            "Roman Levin",
            "Valeriia Cherepanova",
            "Abhimanyu Hans",
            "Avi Schwarzschild",
            "Tom Goldstein"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09974",
        "abstract": "Prompt engineering has emerged as a powerful technique for optimizing large language models (LLMs) for specific applications, enabling faster prototyping and improved performance, and giving rise to the interest of the community in protecting proprietary system prompts. In this work, we explore a novel perspective on prompt privacy through the lens of membership inference. We develop Prompt Detective, a statistical method to reliably determine whether a given system prompt was used by a third-party language model. Our approach relies on a statistical test comparing the distributions of two groups of model outputs corresponding to different system prompts. Through extensive experiments with a variety of language models, we demonstrate the effectiveness of Prompt Detective for prompt membership inference. Our work reveals that even minor changes in system prompts manifest in distinct response distributions, enabling us to verify prompt usage with statistical significance.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "70",
        "title": "LaRA: Benchmarking Retrieval-Augmented Generation and Long-Context LLMs - No Silver Bullet for LC or RAG Routing",
        "author": [
            "Kuan Li",
            "Liwen Zhang",
            "Yong Jiang",
            "Pengjun Xie",
            "Fei Huang",
            "Shuai Wang",
            "Minhao Cheng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09977",
        "abstract": "Effectively incorporating external knowledge into Large Language Models (LLMs) is crucial for enhancing their capabilities and addressing real-world needs. Retrieval-Augmented Generation (RAG) offers an effective method for achieving this by retrieving the most relevant fragments into LLMs. However, the advancements in context window size for LLMs offer an alternative approach, raising the question of whether RAG remains necessary for effectively handling external knowledge. Several existing studies provide inconclusive comparisons between RAG and long-context (LC) LLMs, largely due to limitations in the benchmark designs. In this paper, we present LaRA, a novel benchmark specifically designed to rigorously compare RAG and LC LLMs. LaRA encompasses 2,326 test cases across four practical QA task categories and three types of naturally occurring long texts. Through systematic evaluation of seven open-source and four proprietary LLMs, we find that the optimal choice between RAG and LC depends on a complex interplay of factors, including the model's parameter size, long-text capabilities, context length, task type, and the characteristics of the retrieved chunks. Our findings provide actionable guidelines for practitioners to effectively leverage both RAG and LC approaches in developing and deploying LLM applications. Our code and dataset is provided at: \\href{https://github.com/likuanppd/LaRA}{\\textbf{https://github.com/likuanppd/LaRA}}.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "71",
        "title": "V2V-LLM: Vehicle-to-Vehicle Cooperative Autonomous Driving with Multi-Modal Large Language Models",
        "author": [
            "Hsu-kuang Chiu",
            "Ryo Hachiuma",
            "Chien-Yi Wang",
            "Stephen F. Smith",
            "Yu-Chiang Frank Wang",
            "Min-Hung Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09980",
        "abstract": "Current autonomous driving vehicles rely mainly on their individual sensors to understand surrounding scenes and plan for future trajectories, which can be unreliable when the sensors are malfunctioning or occluded. To address this problem, cooperative perception methods via vehicle-to-vehicle (V2V) communication have been proposed, but they have tended to focus on detection and tracking. How those approaches contribute to overall cooperative planning performance is still under-explored. Inspired by recent progress using Large Language Models (LLMs) to build autonomous driving systems, we propose a novel problem setting that integrates an LLM into cooperative autonomous driving, with the proposed Vehicle-to-Vehicle Question-Answering (V2V-QA) dataset and benchmark. We also propose our baseline method Vehicle-to-Vehicle Large Language Model (V2V-LLM), which uses an LLM to fuse perception information from multiple connected autonomous vehicles (CAVs) and answer driving-related questions: grounding, notable object identification, and planning. Experimental results show that our proposed V2V-LLM can be a promising unified model architecture for performing various tasks in cooperative autonomous driving, and outperforms other baseline methods that use different fusion approaches. Our work also creates a new research direction that can improve the safety of future autonomous driving systems. Our project website: https://eddyhkchiu.github.io/v2vllm.github.io/ .",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "72",
        "title": "X-Boundary: Establishing Exact Safety Boundary to Shield LLMs from Multi-Turn Jailbreaks without Compromising Usability",
        "author": [
            "Xiaoya Lu",
            "Dongrui Liu",
            "Yi Yu",
            "Luxin Xu",
            "Jing Shao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09990",
        "abstract": "Despite the rapid development of safety alignment techniques for LLMs, defending against multi-turn jailbreaks is still a challenging task. In this paper, we conduct a comprehensive comparison, revealing that some existing defense methods can improve the robustness of LLMs against multi-turn jailbreaks but compromise usability, i.e., reducing general capabilities or causing the over-refusal problem. From the perspective of mechanism interpretability of LLMs, we discover that these methods fail to establish a boundary that exactly distinguishes safe and harmful feature representations. Therefore, boundary-safe representations close to harmful representations are inevitably disrupted, leading to a decline in usability. To address this issue, we propose X-Boundary to push harmful representations away from boundary-safe representations and obtain an exact distinction boundary. In this way, harmful representations can be precisely erased without disrupting safe ones. Experimental results show that X-Boundary achieves state-of-the-art defense performance against multi-turn jailbreaks, while reducing the over-refusal rate by about 20% and maintaining nearly complete general capability. Furthermore, we theoretically prove and empirically verify that X-Boundary can accelerate the convergence process during training. Please see our code at: https://github.com/AI45Lab/X-Boundary.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "73",
        "title": "Large Language Diffusion Models",
        "author": [
            "Shen Nie",
            "Fengqi Zhu",
            "Zebin You",
            "Xiaolu Zhang",
            "Jingyang Ou",
            "Jun Hu",
            "Jun Zhou",
            "Yankai Lin",
            "Ji-Rong Wen",
            "Chongxuan Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09992",
        "abstract": "Autoregressive models (ARMs) are widely regarded as the cornerstone of large language models (LLMs). We challenge this notion by introducing LLaDA, a diffusion model trained from scratch under the pre-training and supervised fine-tuning (SFT) paradigm. LLaDA models distributions through a forward data masking process and a reverse process, parameterized by a vanilla Transformer to predict masked tokens. By optimizing a likelihood bound, it provides a principled generative approach for probabilistic inference. Across extensive benchmarks, LLaDA demonstrates strong scalability, outperforming our self-constructed ARM baselines. Remarkably, LLaDA 8B is competitive with strong LLMs like LLaMA3 8B in in-context learning and, after SFT, exhibits impressive instruction-following abilities in case studies such as multi-turn dialogue. Moreover, LLaDA addresses the reversal curse, surpassing GPT-4o in a reversal poem completion task. Our findings establish diffusion models as a viable and promising alternative to ARMs, challenging the assumption that key LLM capabilities discussed above are inherently tied to ARMs.",
        "tags": [
            "Diffusion",
            "GPT",
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "74",
        "title": "Decision Information Meets Large Language Models: The Future of Explainable Operations Research",
        "author": [
            "Yansen Zhang",
            "Qingcan Kang",
            "Wing Yin Yu",
            "Hailei Gong",
            "Xiaojin Fu",
            "Xiongwei Han",
            "Tao Zhong",
            "Chen Ma"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09994",
        "abstract": "Operations Research (OR) is vital for decision-making in many industries. While recent OR methods have seen significant improvements in automation and efficiency through integrating Large Language Models (LLMs), they still struggle to produce meaningful explanations. This lack of clarity raises concerns about transparency and trustworthiness in OR applications. To address these challenges, we propose a comprehensive framework, Explainable Operations Research (EOR), emphasizing actionable and understandable explanations accompanying optimization. The core of EOR is the concept of Decision Information, which emerges from what-if analysis and focuses on evaluating the impact of complex constraints (or parameters) changes on decision-making. Specifically, we utilize bipartite graphs to quantify the changes in the OR model and adopt LLMs to improve the explanation capabilities. Additionally, we introduce the first industrial benchmark to rigorously evaluate the effectiveness of explanations and analyses in OR, establishing a new standard for transparency and clarity in the field.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "75",
        "title": "EmbBERT-Q: Breaking Memory Barriers in Embedded NLP",
        "author": [
            "Riccardo Bravin",
            "Massimo Pavan",
            "Hazem Hesham Yousef Shalby",
            "Fabrizio Pittorino",
            "Manuel Roveri"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10001",
        "abstract": "Large Language Models (LLMs) have revolutionized natural language processing, setting new standards across a wide range of applications. However, their relevant memory and computational demands make them impractical for deployment on technologically-constrained tiny devices such as wearable devices and Internet-of-Things units. To address this limitation, we introduce EmbBERT-Q, a novel tiny language model specifically designed for tiny devices with stringent memory constraints. EmbBERT-Q achieves state-of-the-art (SotA) accuracy in Natural Language Processing tasks in this scenario, with a total memory footprint (weights and activations) of just 781 kB, representing a 25x reduction in size with respect to SotA models. By combining architectural innovations with hardware-compatible 8-bit quantization, EmbBERT-Q consistently outperforms several baseline models scaled down to a 2 MB memory budget (i.e., the maximum memory typically available in tiny devices), including heavily compressed versions of BERT and MAMBA. Extensive experimental evaluations on both a selected benchmark dataset, TinyNLP, specifically curated to evaluate Tiny Language Models in NLP tasks and real-world scenarios, and the GLUE benchmark, demonstrate EmbBERT-Q ability to deliver competitive accuracy with respect to existing approaches, achieving an unmatched balance between memory and performance. To ensure the complete and immediate reproducibility of all our results, we release all code, scripts, and model checkpoints at https://github.com/RiccardoBravin/tiny-LLM.",
        "tags": [
            "BERT",
            "LLMs",
            "Large Language Models",
            "Mamba"
        ]
    },
    {
        "id": "76",
        "title": "Probabilistic Lexical Manifold Construction in Large Language Models via Hierarchical Vector Field Interpolation",
        "author": [
            "Clive Pendleton",
            "Ewan Harrington",
            "Giles Fairbrother",
            "Jasper Arkwright",
            "Nigel Fenwick",
            "Richard Katrix"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10013",
        "abstract": "Hierarchical vector field interpolation introduces a structured probabilistic framework for lexical representation, ensuring that word embeddings transition smoothly across a continuous manifold rather than being constrained to discrete token mappings. The proposed methodology constructs a probabilistic function space where word representations adhere to topological consistency, mitigating representational discontinuities commonly observed in transformer-based embeddings. Empirical evaluations reveal that probabilistic constraints enhance lexical coherence by refining contextual relationships, leading to improvements in semantic stability across multiple linguistic distributions. The application of divergence minimization techniques ensures that interpolated embeddings maintain probabilistic consistency while preserving computational feasibility for large-scale implementations. Experimental findings demonstrate that interpolated lexical manifolds improve representation density alignment, reducing anisotropic distortions in contextual embedding distributions. Comparative analyses with standard transformer-based models highlight that structured interpolation yields more stable representations, particularly in tasks requiring fine-grained semantic differentiation. The statistical evaluation of embedding divergence confirms that probabilistic lexical manifolds reduce representational inconsistencies while maintaining coherence across varying scales of contextual abstraction. An assessment of computational efficiency reveals that while interpolation introduces minor processing overhead, the structured representation learning approach remains scalable for practical deployment.",
        "tags": [
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "77",
        "title": "ManiTrend: Bridging Future Generation and Action Prediction with 3D Flow for Robotic Manipulation",
        "author": [
            "Yuxin He",
            "Qiang Nie"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10028",
        "abstract": "Language-conditioned manipulation is a vital but challenging robotic task due to the high-level abstraction of language. To address this, researchers have sought improved goal representations derived from natural language. In this paper, we highlight 3D flow - representing the motion trend of 3D particles within a scene - as an effective bridge between language-based future image generation and fine-grained action prediction. To this end, we develop ManiTrend, a unified framework that models the dynamics of 3D particles, vision observations and manipulation actions with a causal transformer. Within this framework, features for 3D flow prediction serve as additional conditions for future image generation and action prediction, alleviating the complexity of pixel-wise spatiotemporal modeling and providing seamless action guidance. Furthermore, 3D flow can substitute missing or heterogeneous action labels during large-scale pretraining on cross-embodiment demonstrations. Experiments on two comprehensive benchmarks demonstrate that our method achieves state-of-the-art performance with high efficiency. Our code and model checkpoints will be available upon acceptance.",
        "tags": [
            "3D",
            "Transformer"
        ]
    },
    {
        "id": "78",
        "title": "POI-Enhancer: An LLM-based Semantic Enhancement Framework for POI Representation Learning",
        "author": [
            "Jiawei Cheng",
            "Jingyuan Wang",
            "Yichuan Zhang",
            "Jiahao Ji",
            "Yuanshao Zhu",
            "Zhibo Zhang",
            "Xiangyu Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10038",
        "abstract": "POI representation learning plays a crucial role in handling tasks related to user mobility data. Recent studies have shown that enriching POI representations with multimodal information can significantly enhance their task performance. Previously, the textual information incorporated into POI representations typically involved only POI categories or check-in content, leading to relatively weak textual features in existing methods. In contrast, large language models (LLMs) trained on extensive text data have been found to possess rich textual knowledge. However leveraging such knowledge to enhance POI representation learning presents two key challenges: first, how to extract POI-related knowledge from LLMs effectively, and second, how to integrate the extracted information to enhance POI representations. To address these challenges, we propose POI-Enhancer, a portable framework that leverages LLMs to improve POI representations produced by classic POI learning models. We first design three specialized prompts to extract semantic information from LLMs efficiently. Then, the Dual Feature Alignment module enhances the quality of the extracted information, while the Semantic Feature Fusion module preserves its integrity. The Cross Attention Fusion module then fully adaptively integrates such high-quality information into POI representations and Multi-View Contrastive Learning further injects human-understandable semantic information into these representations. Extensive experiments on three real-world datasets demonstrate the effectiveness of our framework, showing significant improvements across all baseline representations.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "79",
        "title": "Diffusion Trajectory-guided Policy for Long-horizon Robot Manipulation",
        "author": [
            "Shichao Fan",
            "Quantao Yang",
            "Yajie Liu",
            "Kun Wu",
            "Zhengping Che",
            "Qingjie Liu",
            "Min Wan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10040",
        "abstract": "Recently, Vision-Language-Action models (VLA) have advanced robot imitation learning, but high data collection costs and limited demonstrations hinder generalization and current imitation learning methods struggle in out-of-distribution scenarios, especially for long-horizon tasks. A key challenge is how to mitigate compounding errors in imitation learning, which lead to cascading failures over extended trajectories. To address these challenges, we propose the Diffusion Trajectory-guided Policy (DTP) framework, which generates 2D trajectories through a diffusion model to guide policy learning for long-horizon tasks. By leveraging task-relevant trajectories, DTP provides trajectory-level guidance to reduce error accumulation. Our two-stage approach first trains a generative vision-language model to create diffusion-based trajectories, then refines the imitation policy using them. Experiments on the CALVIN benchmark show that DTP outperforms state-of-the-art baselines by 25% in success rate, starting from scratch without external pretraining. Moreover, DTP significantly improves real-world robot performance.",
        "tags": [
            "Diffusion",
            "Robot"
        ]
    },
    {
        "id": "80",
        "title": "ViRAC: A Vision-Reasoning Agent Head Movement Control Framework in Arbitrary Virtual Environments",
        "author": [
            "Juyeong Hwang",
            "Seong-Eun Hong",
            "Hyeongyeop Kang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10046",
        "abstract": "Creating lifelike virtual agents capable of interacting with their environments is a longstanding goal in computer graphics. This paper addresses the challenge of generating natural head rotations, a critical aspect of believable agent behavior for visual information gathering and dynamic responses to environmental cues. Although earlier methods have made significant strides, many rely on data-driven or saliency-based approaches, which often underperform in diverse settings and fail to capture deeper cognitive factors such as risk assessment, information seeking, and contextual prioritization. Consequently, generated behaviors can appear rigid or overlook critical scene elements, thereby diminishing the sense of realism. In this paper, we propose \\textbf{ViRAC}, a \\textbf{Vi}sion-\\textbf{R}easoning \\textbf{A}gent Head Movement \\textbf{C}ontrol framework, which exploits the common-sense knowledge and reasoning capabilities of large-scale models, including Vision-Language Models (VLMs) and Large-Language Models (LLMs). Rather than explicitly modeling every cognitive mechanism, ViRAC leverages the biases and patterns internalized by these models from extensive training, thus emulating human-like perceptual processes without hand-tuned heuristics. Experimental results in multiple scenarios reveal that ViRAC produces more natural and context-aware head rotations than recent state-of-the-art techniques. Quantitative evaluations show a closer alignment with real human head-movement data, while user studies confirm improved realism and cognitive plausibility.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "81",
        "title": "Janus: Collaborative Vision Transformer Under Dynamic Network Environment",
        "author": [
            "Linyi Jiang",
            "Silvery D. Fu",
            "Yifei Zhu",
            "Bo Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10047",
        "abstract": "Vision Transformers (ViTs) have outperformed traditional Convolutional Neural Network architectures and achieved state-of-the-art results in various computer vision tasks. Since ViTs are computationally expensive, the models either have to be pruned to run on resource-limited edge devices only or have to be executed on remote cloud servers after receiving the raw data transmitted over fluctuating networks. The resulting degraded performance or high latency all hinder their widespread applications. In this paper, we present Janus, the first framework for low-latency cloud-device collaborative Vision Transformer inference over dynamic networks. Janus overcomes the intrinsic model limitations of ViTs and realizes collaboratively executing ViT models on both cloud and edge devices, achieving low latency, high accuracy, and low communication overhead. Specifically, Janus judiciously combines token pruning techniques with a carefully designed fine-to-coarse model splitting policy and non-static mixed pruning policy. It attains a balance between accuracy and latency by dynamically selecting the optimal pruning level and split point. Experimental results across various tasks demonstrate that Janus enhances throughput by up to 5.15 times and reduces latency violation ratios by up to 98.7% when compared with baseline approaches under various network environments.",
        "tags": [
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "82",
        "title": "ORI: O Routing Intelligence",
        "author": [
            "Ahmad Shadid",
            "Rahul Kumar",
            "Mohit Mayank"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10051",
        "abstract": "Single large language models (LLMs) often fall short when faced with the ever-growing range of tasks, making a single-model approach insufficient. We address this challenge by proposing ORI (O Routing Intelligence), a dynamic framework that leverages a set of LLMs. By intelligently routing incoming queries to the most suitable model, ORI not only improves task-specific accuracy, but also maintains efficiency. Comprehensive evaluations across diverse benchmarks demonstrate consistent accuracy gains while controlling computational overhead. By intelligently routing queries, ORI outperforms the strongest individual models by up to 2.7 points on MMLU and 1.8 points on MuSR, ties the top performance on ARC, and on BBH. These results underscore the benefits of a multi-model strategy and demonstrate how ORI's adaptive architecture can more effectively handle diverse tasks, offering a scalable, high-performance solution for a system of multiple large language models.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "83",
        "title": "MTLM: an Innovative Language Model Training Paradigm for ASR",
        "author": [
            "Qingliang Meng",
            "Pengju Ren",
            "Tian Li",
            "Changsong Dai"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10058",
        "abstract": "Pre-training Transformer-based language models (LMs) on a large amount of text has proven crucial for improving automatic speech recognition (ASR) performance. Generally, traditional LMs are unidirectional and unable to access the context on the right. This paper proposes a method for training LMs that enable traditional unidirectional LMs to fully utilize left and right contexts. Compared with the unidirectional LMs, our LM facilitates ASR to transcribe hypotheses more consistently and in a more semantically unambiguous way, as it incorporates richer contextual representations. Finally, our experimental results on the LibriSpeech corpus demonstrate that our model outperforms traditional unidirectional LMs, whether n-best rescoring or shallow fusion is used as the decoding algorithm.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "84",
        "title": "RealCam-I2V: Real-World Image-to-Video Generation with Interactive Complex Camera Control",
        "author": [
            "Teng Li",
            "Guangcong Zheng",
            "Rui Jiang",
            "Shuigenzhan",
            "Tao Wu",
            "Yehao Lu",
            "Yining Lin",
            "Xi Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10059",
        "abstract": "Recent advancements in camera-trajectory-guided image-to-video generation offer higher precision and better support for complex camera control compared to text-based approaches. However, they also introduce significant usability challenges, as users often struggle to provide precise camera parameters when working with arbitrary real-world images without knowledge of their depth nor scene scale. To address these real-world application issues, we propose RealCam-I2V, a novel diffusion-based video generation framework that integrates monocular metric depth estimation to establish 3D scene reconstruction in a preprocessing step. During training, the reconstructed 3D scene enables scaling camera parameters from relative to absolute values, ensuring compatibility and scale consistency across diverse real-world images. In inference, RealCam-I2V offers an intuitive interface where users can precisely draw camera trajectories by dragging within the 3D scene. To further enhance precise camera control and scene consistency, we propose scene-constrained noise shaping, which shapes high-level noise and also allows the framework to maintain dynamic, coherent video generation in lower noise stages. RealCam-I2V achieves significant improvements in controllability and video quality on the RealEstate10K and out-of-domain images. We further enables applications like camera-controlled looping video generation and generative frame interpolation. We will release our absolute-scale annotation, codes, and all checkpoints. Please see dynamic results in https://zgctroy.github.io/RealCam-I2V.",
        "tags": [
            "3D",
            "Depth Estimation",
            "Diffusion",
            "Video Generation"
        ]
    },
    {
        "id": "85",
        "title": "Hands-off Image Editing: Language-guided Editing without any Task-specific Labeling, Masking or even Training",
        "author": [
            "Rodrigo Santos",
            "AntÃ³nio Branco",
            "JoÃ£o Silva",
            "JoÃ£o Rodrigues"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10064",
        "abstract": "Instruction-guided image editing consists in taking an image and an instruction and deliverring that image altered according to that instruction. State-of-the-art approaches to this task suffer from the typical scaling up and domain adaptation hindrances related to supervision as they eventually resort to some kind of task-specific labelling, masking or training. We propose a novel approach that does without any such task-specific supervision and offers thus a better potential for improvement. Its assessment demonstrates that it is highly effective, achieving very competitive performance.",
        "tags": [
            "Image Editing"
        ]
    },
    {
        "id": "86",
        "title": "Bound preserving {P}oint-{A}verage-{M}oment {P}olynomi{A}l-interpreted ({PAMPA}) on polygonal meshes",
        "author": [
            "RÃ©mi Abgrall",
            "Yongle Liu",
            "Walter Boscheri"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10069",
        "abstract": "We present a novel discretisation strategy, strongly inspired from Roe's Active Flux scheme. It can use polygonal meshes and is provably bound preserving for scalar problems and the Euler equations. Several cases demonstrates the quality of the method, and improvements with respect to previous work of the authors. This paper is a summary of \\cite{BPPampa}.",
        "tags": [
            "FLUX"
        ]
    },
    {
        "id": "87",
        "title": "A novel approach to data generation in generative model",
        "author": [
            "JaeHong Kim",
            "Jaewon Shim"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10092",
        "abstract": "Variational Autoencoders (VAEs) and other generative models are widely employed in artificial intelligence to synthesize new data. However, current approaches rely on Euclidean geometric assumptions and statistical approximations that fail to capture the structured and emergent nature of data generation. This paper introduces the Convergent Fusion Paradigm (CFP) theory, a novel geometric framework that redefines data generation by integrating dimensional expansion accompanied by qualitative transformation. By modifying the latent space geometry to interact with emergent high-dimensional structures, CFP theory addresses key challenges such as identifiability issues and unintended artifacts like hallucinations in Large Language Models (LLMs). CFP theory is based on two key conceptual hypotheses that redefine how generative models structure relationships between data and algorithms. Through the lens of CFP theory, we critically examine existing metric-learning approaches. CFP theory advances this perspective by introducing time-reversed metric embeddings and structural convergence mechanisms, leading to a novel geometric approach that better accounts for data generation as a structured epistemic process. Beyond its computational implications, CFP theory provides philosophical insights into the ontological underpinnings of data generation. By offering a systematic framework for high-dimensional learning dynamics, CFP theory contributes to establishing a theoretical foundation for understanding the data-relationship structures in AI. Finally, future research in CFP theory will be led to its implications for fully realizing qualitative transformations, introducing the potential of Hilbert space in generative modeling.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "88",
        "title": "ScamFerret: Detecting Scam Websites Autonomously with Large Language Models",
        "author": [
            "Hiroki Nakano",
            "Takashi Koide",
            "Daiki Chiba"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10110",
        "abstract": "With the rise of sophisticated scam websites that exploit human psychological vulnerabilities, distinguishing between legitimate and scam websites has become increasingly challenging. This paper presents ScamFerret, an innovative agent system employing a large language model (LLM) to autonomously collect and analyze data from a given URL to determine whether it is a scam. Unlike traditional machine learning models that require large datasets and feature engineering, ScamFerret leverages LLMs' natural language understanding to accurately identify scam websites of various types and languages without requiring additional training or fine-tuning. Our evaluation demonstrated that ScamFerret achieves 0.972 accuracy in classifying four scam types in English and 0.993 accuracy in classifying online shopping websites across three different languages, particularly when using GPT-4. Furthermore, we confirmed that ScamFerret collects and analyzes external information such as web content, DNS records, and user reviews as necessary, providing a basis for identifying scam websites from multiple perspectives. These results suggest that LLMs have significant potential in enhancing cybersecurity measures against sophisticated scam websites.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "89",
        "title": "Compress image to patches for Vision Transformer",
        "author": [
            "Xinfeng Zhao",
            "Yaoru Sun"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10120",
        "abstract": "The Vision Transformer (ViT) has made significant strides in the field of computer vision. However, as the depth of the model and the resolution of the input images increase, the computational cost associated with training and running ViT models has surged http://dramatically.This paper proposes a hybrid model based on CNN and Vision Transformer, named CI2P-ViT. The model incorporates a module called CI2P, which utilizes the CompressAI encoder to compress images and subsequently generates a sequence of patches through a series of convolutions. CI2P can replace the Patch Embedding component in the ViT model, enabling seamless integration into existing ViT http://models.Compared to ViT-B/16, CI2P-ViT has the number of patches input to the self-attention layer reduced to a quarter of the http://original.This design not only significantly reduces the computational cost of the ViT model but also effectively enhances the model's accuracy by introducing the inductive bias properties of http://CNN.The ViT model's precision is markedly http://enhanced.When trained from the ground up on the Animals-10 dataset, CI2P-ViT achieved an accuracy rate of 92.37%, representing a 3.3% improvement over the ViT-B/16 baseline. Additionally, the model's computational operations, measured in floating-point operations per second (FLOPs), were diminished by 63.35%, and it exhibited a 2-fold increase in training velocity on identical hardware configurations.",
        "tags": [
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "90",
        "title": "Modern Hopfield Networks with Continuous-Time Memories",
        "author": [
            "Saul Santos",
            "AntÃ³nio Farinhas",
            "Daniel C. McNamee",
            "AndrÃ© F.T. Martins"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10122",
        "abstract": "Recent research has established a connection between modern Hopfield networks (HNs) and transformer attention heads, with guarantees of exponential storage capacity. However, these models still face challenges scaling storage efficiently. Inspired by psychological theories of continuous neural resource allocation in working memory, we propose an approach that compresses large discrete Hopfield memories into smaller, continuous-time memories. Leveraging continuous attention, our new energy function modifies the update rule of HNs, replacing the traditional softmax-based probability mass function with a probability density, over the continuous memory. This formulation aligns with modern perspectives on human executive function, offering a principled link between attractor dynamics in working memory and resource-efficient memory allocation. Our framework maintains competitive performance with HNs while leveraging a compressed memory, reducing computational costs across synthetic and video datasets.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "91",
        "title": "Small Models, Big Impact: Efficient Corpus and Graph-Based Adaptation of Small Multilingual Language Models for Low-Resource Languages",
        "author": [
            "Daniil Gurgurov",
            "Ivan Vykopal",
            "Josef van Genabith",
            "Simon Ostermann"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10140",
        "abstract": "Low-resource languages (LRLs) face significant challenges in natural language processing (NLP) due to limited data. While current state-of-the-art large language models (LLMs) still struggle with LRLs, smaller multilingual models (mLMs) such as mBERT and XLM-R offer greater promise due to a better fit of their capacity to low training data sizes. This study systematically investigates parameter-efficient adapter-based methods for adapting mLMs to LRLs, evaluating three architectures: Sequential Bottleneck, Invertible Bottleneck, and Low-Rank Adaptation. Using unstructured text from GlotCC and structured knowledge from ConceptNet, we show that small adaptation datasets (e.g., up to 1 GB of free-text or a few MB of knowledge graph data) yield gains in intrinsic (masked language modeling) and extrinsic tasks (topic classification, sentiment analysis, and named entity recognition). We find that Sequential Bottleneck adapters excel in language modeling, while Invertible Bottleneck adapters slightly outperform other methods on downstream tasks due to better embedding alignment and larger parameter counts. Adapter-based methods match or outperform full fine-tuning while using far fewer parameters, and smaller mLMs prove more effective for LRLs than massive LLMs like LLaMA-3, GPT-4, and DeepSeek-R1-based distilled models. While adaptation improves performance, pre-training data size remains the dominant factor, especially for languages with extensive pre-training coverage.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLMs",
            "LLaMA",
            "Large Language Models",
            "Low-Rank Adaptation"
        ]
    },
    {
        "id": "92",
        "title": "Cooperative Multi-Agent Planning with Adaptive Skill Synthesis",
        "author": [
            "Zhiyuan Li",
            "Wenshuai Zhao",
            "Joni Pajarinen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10148",
        "abstract": "Despite much progress in training distributed artificial intelligence (AI), building cooperative multi-agent systems with multi-agent reinforcement learning (MARL) faces challenges in sample efficiency, interpretability, and transferability. Unlike traditional learning-based methods that require extensive interaction with the environment, large language models (LLMs) demonstrate remarkable capabilities in zero-shot planning and complex reasoning. However, existing LLM-based approaches heavily rely on text-based observations and struggle with the non-Markovian nature of multi-agent interactions under partial observability. We present COMPASS, a novel multi-agent architecture that integrates vision-language models (VLMs) with a dynamic skill library and structured communication for decentralized closed-loop decision-making. The skill library, bootstrapped from demonstrations, evolves via planner-guided tasks to enable adaptive strategies. COMPASS propagates entity information through multi-hop communication under partial observability. Evaluations on the improved StarCraft Multi-Agent Challenge (SMACv2) demonstrate COMPASS achieves up to 30\\% higher win rates than state-of-the-art MARL algorithms in symmetric scenarios.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "93",
        "title": "IRS-assisted Edge Computing for Vehicular Networks: A Generative Diffusion Model-based Stackelberg Game Approach",
        "author": [
            "Yixian Wang",
            "Geng Sun",
            "Zemin Sun",
            "Long He",
            "Jiacheng Wang",
            "Shiwen Mao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10149",
        "abstract": "Recent advancements in intelligent reflecting surfaces (IRS) and mobile edge computing (MEC) offer new opportunities to enhance the performance of vehicular networks. However, meeting the computation-intensive and latency-sensitive demands of vehicles remains challenging due to the energy constraints and dynamic environments. To address this issue, we study an IRS-assisted MEC architecture for vehicular networks. We formulate a multi-objective optimization problem aimed at minimizing the total task completion delay and total energy consumption by jointly optimizing task offloading, IRS phase shift vector, and computation resource allocation. Given the mixed-integer nonlinear programming (MINLP) and NP-hard nature of the problem, we propose a generative diffusion model (GDM)-based Stackelberg game (GDMSG) approach. Specifically, the problem is reformulated within a Stackelberg game framework, where generative GDM is integrated to capture complex dynamics to efficiently derive optimal solutions. Simulation results indicate that the proposed GDMSG achieves outstanding performance compared to the benchmark approaches.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "94",
        "title": "Semantica: Decentralized Search using a LLM-Guided Semantic Tree Overlay",
        "author": [
            "Petru Neague",
            "Quinten Stokkink",
            "Naman Goel",
            "Johan Pouwelse"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10151",
        "abstract": "Centralized search engines are key for the Internet, but lead to undesirable concentration of power. Decentralized alternatives fail to offer equal document retrieval accuracy and speed. Nevertheless, Semantic Overlay Networks can come close to the performance of centralized solutions when the semantics of documents are properly captured. This work uses embeddings from Large Language Models to capture semantics and fulfill the promise of Semantic Overlay Networks. Our proposed algorithm, called Semantica, constructs a prefix tree (trie) utilizing document embeddings calculated by a language model. Users connect to each other based on the embeddings of their documents, ensuring that semantically similar users are directly linked. Thereby, this construction makes it more likely for user searches to be answered by the users that they are directly connected to, or by the users they are close to in the network connection graph. The implementation of our algorithm also accommodates the semantic diversity of individual users by spawning \"clone\" user identifiers in the tree. Our experiments use emulation with a real-world workload to show Semantica's ability to identify and connect to similar users quickly. Semantica finds up to ten times more semantically similar users than current state-of-the-art approaches. At the same time, Semantica can retrieve more than two times the number of relevant documents given the same network load. We also make our code publicly available to facilitate further research in the area.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "95",
        "title": "MonoForce: Learnable Image-conditioned Physics Engine",
        "author": [
            "Ruslan Agishev",
            "Karel Zimmermann"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10156",
        "abstract": "We propose a novel model for the prediction of robot trajectories on rough offroad terrain from the onboard camera images. This model enforces the laws of classical mechanics through a physics-aware neural symbolic layer while preserving the ability to learn from large-scale data as it is end-to-end differentiable. The proposed hybrid model integrates a black-box component that predicts robot-terrain interaction forces with a neural-symbolic layer. This layer includes a differentiable physics engine that computes the robot's trajectory by querying these forces at the points of contact with the terrain. As the proposed architecture comprises substantial geometrical and physics priors, the resulting model can also be seen as a learnable physics engine conditioned on real images that delivers $10^4$ trajectories per second. We argue and empirically demonstrate that this architecture reduces the sim-to-real gap and mitigates out-of-distribution sensitivity. The differentiability, in conjunction with the rapid simulation speed, makes the model well-suited for various applications including model predictive control, trajectory shooting, supervised and reinforcement learning or SLAM. The codes and data are publicly available.",
        "tags": [
            "Robot",
            "SLAM"
        ]
    },
    {
        "id": "96",
        "title": "From Markov to Laplace: How Mamba In-Context Learns Markov Chains",
        "author": [
            "Marco Bondaschi",
            "Nived Rajaraman",
            "Xiuying Wei",
            "Kannan Ramchandran",
            "Razvan Pascanu",
            "Caglar Gulcehre",
            "Michael Gastpar",
            "Ashok Vardhan Makkuva"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10178",
        "abstract": "While transformer-based language models have driven the AI revolution thus far, their computational complexity has spurred growing interest in viable alternatives, such as structured state space sequence models (SSMs) and Selective SSMs. Among these, Mamba (S6) and its variant Mamba-2 have shown remarkable inference speed ups over transformers while achieving comparable or superior performance on complex language modeling tasks. However, despite these architectural innovations and empirical successes, the fundamental learning capabilities of Mamba remain poorly understood. In this paper, we address this gap by studying in-context learning (ICL) on Markov chains and uncovering a surprising phenomenon: unlike transformers, even a single-layer Mamba efficiently learns the in-context Laplacian smoothing estimator, which is both Bayes and minimax optimal, for all Markovian orders. To explain this, we theoretically characterize the representation capacity of Mamba and reveal the fundamental role of convolution in enabling it to represent the optimal Laplacian smoothing. These theoretical insights align strongly with empirical results and, to the best of our knowledge, represent the first formal connection between Mamba and optimal statistical estimators. Finally, we outline promising research directions inspired by these findings.",
        "tags": [
            "Mamba",
            "SSMs",
            "Transformer"
        ]
    },
    {
        "id": "97",
        "title": "VideoDiff: Human-AI Video Co-Creation with Alternatives",
        "author": [
            "Mina Huh",
            "Dingzeyu Li",
            "Kim Pimmel",
            "Hijung Valentina Shin",
            "Amy Pavel",
            "Mira Dontcheva"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10190",
        "abstract": "To make an engaging video, people sequence interesting moments and add visuals such as B-rolls or text. While video editing requires time and effort, AI has recently shown strong potential to make editing easier through suggestions and automation. A key strength of generative models is their ability to quickly generate multiple variations, but when provided with many alternatives, creators struggle to compare them to find the best fit. We propose VideoDiff, an AI video editing tool designed for editing with alternatives. With VideoDiff, creators can generate and review multiple AI recommendations for each editing process: creating a rough cut, inserting B-rolls, and adding text effects. VideoDiff simplifies comparisons by aligning videos and highlighting differences through timelines, transcripts, and video previews. Creators have the flexibility to regenerate and refine AI suggestions as they compare alternatives. Our study participants (N=12) could easily compare and customize alternatives, creating more satisfying results.",
        "tags": [
            "Video Editing"
        ]
    },
    {
        "id": "98",
        "title": "Translating Common Security Assertions Across Processor Designs: A RISC-V Case Study",
        "author": [
            "Sharjeel Imtiaz",
            "Uljana Reinsalu",
            "Tara Ghasempouri"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10194",
        "abstract": "RISC-V is gaining popularity for its adaptability and cost-effectiveness in processor design. With the increasing adoption of RISC-V, the importance of implementing robust security verification has grown significantly. In the state of the art, various approaches have been developed to strengthen the security verification process. Among these methods, assertion-based security verification has proven to be a promising approach for ensuring that security features are effectively met. To this end, some approaches manually define security assertions for processor designs; however, these manual methods require significant time, cost, and human expertise. Consequently, recent approaches focus on translating pre-defined security assertions from one design to another. Nonetheless, these methods are not primarily centered on processor security, particularly RISC-V. Furthermore, many of these approaches have not been validated against real-world attacks, such as hardware Trojans. In this work, we introduce a methodology for translating security assertions across processors with different architectures, using RISC-V as a case study. Our approach reduces time and cost compared to developing security assertions manually from the outset. Our methodology was applied to five critical security modules with assertion translation achieving nearly 100% success across all modules. These results validate the efficacy of our approach and highlight its potential for enhancing security verification in modern processor designs. The effectiveness of the translated assertions was rigorously tested against hardware Trojans defined by large language models (LLMs), demonstrating their reliability in detecting security breaches.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "99",
        "title": "MathConstruct: Challenging LLM Reasoning with Constructive Proofs",
        "author": [
            "Mislav BalunoviÄ",
            "Jasper Dekoninck",
            "Nikola JovanoviÄ",
            "Ivo Petrov",
            "Martin Vechev"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10197",
        "abstract": "While Large Language Models (LLMs) demonstrate impressive performance in mathematics, existing math benchmarks come with significant limitations. Many focus on problems with fixed ground-truth answers, and are often saturated due to problem simplicity or the viability of guessing or memorization. Crucially, they capture only a narrow subset of relevant math problems. To address this research gap, we introduce \\mc, a new benchmark of 126 challenging problems sourced from various math competitions, which targets constructive proofs, a widely encountered problem type requiring the construction of mathematical objects with specific properties. These proofs are particularly suitable for LLM evaluation, as solution correctness can be easily verified. Our automated verifiers also enable MathConstruct to generate problem variations, used to evaluate robustness. State-of-the-art LLMs solve only 54% of MathConstruct problems, highlighting its complexity and importance for LLM evaluation.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "100",
        "title": "Prediction hubs are context-informed frequent tokens in LLMs",
        "author": [
            "Beatrix M. G. Nielsen",
            "Iuri Macocco",
            "Marco Baroni"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10201",
        "abstract": "Hubness, the tendency for few points to be among the nearest neighbours of a disproportionate number of other points, commonly arises when applying standard distance measures to high-dimensional data, often negatively impacting distance-based analysis. As autoregressive large language models (LLMs) operate on high-dimensional representations, we ask whether they are also affected by hubness. We first show, theoretically, that the only representation comparison operation performed by LLMs, namely that between context and unembedding vectors to determine continuation probabilities, is not characterized by the concentration of distances phenomenon that typically causes the appeareance of nuisance hubness. We then empirically show that this comparison still leads to a high degree of hubness, but the hubs in this case do not constitute a disturbance. They are rather the result of context-modulated frequent tokens often appearing in the pool of likely candidates for next token prediction. On the other hand, when other distance computations involving LLM representations are performed, we do not have the same theoretical guarantees, and, indeed, we see nuisance hubs appear. In summary, our work highlights, on the one hand, how hubness, while omnipresent in high-dimensional spaces, is not always a negative property that needs to be mitigated, and, on the other hand, it shows that various widely-used LLMs have developed a guessing strategy that consists in constantly assigning a high probability to frequent tokens.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "101",
        "title": "Can Post-Training Quantization Benefit from an Additional QLoRA Integration?",
        "author": [
            "Xiliang Zhu",
            "Elena Khasanova",
            "Cheng Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10202",
        "abstract": "Large language models (LLMs) have transformed natural language processing but pose significant challenges for real-world deployment. These models necessitate considerable computing resources, which can be costly and frequently unavailable. Model compression techniques such as quantization are often leveraged to alleviate resource demand, but they may have a negative impact on the generation quality. In this study, we explore the integration of 4-bit Post-training Quantization (PTQ) with QLoRA to address these issues. We demonstrate through extensive experiments that this integration outperforms standard PTQ, and in some cases even 16-bit full-parameter fine-tuning on LLMs, validated across proprietary and public datasets with different quantization algorithms. The results demonstrate the efficacy of PTQ-QLoRA integration, offering a viable solution for deploying powerful LLMs in resource-constrained environments without compromising on performance.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "102",
        "title": "Do Large Language Models Reason Causally Like Us? Even Better?",
        "author": [
            "Hanna M. Dettki",
            "Brenden M. Lake",
            "Charley M. Wu",
            "Bob Rehder"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10215",
        "abstract": "Causal reasoning is a core component of intelligence. Large language models (LLMs) have shown impressive capabilities in generating human-like text, raising questions about whether their responses reflect true understanding or statistical patterns. We compared causal reasoning in humans and four LLMs using tasks based on collider graphs, rating the likelihood of a query variable occurring given evidence from other variables. We find that LLMs reason causally along a spectrum from human-like to normative inference, with alignment shifting based on model, context, and task. Overall, GPT-4o and Claude showed the most normative behavior, including \"explaining away\", whereas Gemini-Pro and GPT-3.5 did not. Although all agents deviated from the expected independence of causes - Claude the least - they exhibited strong associative reasoning and predictive inference when assessing the likelihood of the effect given its causes. These findings underscore the need to assess AI biases as they increasingly assist human decision-making.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "103",
        "title": "Forget the Data and Fine-Tuning! Just Fold the Network to Compress",
        "author": [
            "Dong Wang",
            "Haris Å ikiÄ",
            "Lothar Thiele",
            "Olga Saukh"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10216",
        "abstract": "We introduce model folding, a novel data-free model compression technique that merges structurally similar neurons across layers, significantly reducing the model size without the need for fine-tuning or access to training data. Unlike existing methods, model folding preserves data statistics during compression by leveraging k-means clustering, and using novel data-free techniques to prevent variance collapse or explosion. Our theoretical framework and experiments across standard benchmarks, including ResNet18 and LLaMA-7B, demonstrate that model folding achieves comparable performance to data-driven compression techniques and outperforms recently proposed data-free methods, especially at high sparsity levels. This approach is particularly effective for compressing large-scale models, making it suitable for deployment in resource-constrained environments.",
        "tags": [
            "LLaMA"
        ]
    },
    {
        "id": "104",
        "title": "Shaping Inductive Bias in Diffusion Models through Frequency-Based Noise Control",
        "author": [
            "Thomas Jiralerspong",
            "Berton Earnshaw",
            "Jason Hartford",
            "Yoshua Bengio",
            "Luca Scimeca"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10236",
        "abstract": "Diffusion Probabilistic Models (DPMs) are powerful generative models that have achieved unparalleled success in a number of generative tasks. In this work, we aim to build inductive biases into the training and sampling of diffusion models to better accommodate the target distribution of the data to model. For topologically structured data, we devise a frequency-based noising operator to purposefully manipulate, and set, these inductive biases. We first show that appropriate manipulations of the noising forward process can lead DPMs to focus on particular aspects of the distribution to learn. We show that different datasets necessitate different inductive biases, and that appropriate frequency-based noise control induces increased generative performance compared to standard diffusion. Finally, we demonstrate the possibility of ignoring information at particular frequencies while learning. We show this in an image corruption and recovery task, where we train a DPM to recover the original target distribution after severe noise corruption.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "105",
        "title": "Efficient Zero-Order Federated Finetuning of Language Models for Resource-Constrained Devices",
        "author": [
            "Mohamed Aboelenien Ahmed",
            "Kilian Pfeiffer",
            "Ramin Khalili",
            "Heba Khdr",
            "JÃ¶rg Henkel"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10239",
        "abstract": "Federated fine-tuning offers a promising approach for tuning Large Language Models (LLMs) on edge devices while preserving data privacy. However, fine-tuning these models on edge devices remains challenging due to high memory, communication, and computational demands. Zero-order optimization with task alignment provides a potential solution, enabling fine-tuning with inference-level memory requirements but requires a longer convergence time. In this paper, we propose Federated Split-Perturbation Zero-order Optimization (FedSPZO) that divides the network into two blocks, applying a different number of perturbations per block in a computationally effective way, achieving faster convergence. Our evaluation shows a $2.5 - 7\\times $ reduction in computation overhead compared to zero-order state of the art techniques in federated learning.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "106",
        "title": "Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model",
        "author": [
            "Guoqing Ma",
            "Haoyang Huang",
            "Kun Yan",
            "Liangyu Chen",
            "Nan Duan",
            "Shengming Yin",
            "Changyi Wan",
            "Ranchen Ming",
            "Xiaoniu Song",
            "Xing Chen",
            "Yu Zhou",
            "Deshan Sun",
            "Deyu Zhou",
            "Jian Zhou",
            "Kaijun Tan",
            "Kang An",
            "Mei Chen",
            "Wei Ji",
            "Qiling Wu",
            "Wen Sun",
            "Xin Han",
            "Yanan Wei",
            "Zheng Ge",
            "Aojie Li",
            "Bin Wang",
            "Bizhu Huang",
            "Bo Wang",
            "Brian Li",
            "Changxing Miao",
            "Chen Xu",
            "Chenfei Wu",
            "Chenguang Yu",
            "Dapeng Shi",
            "Dingyuan Hu",
            "Enle Liu",
            "Gang Yu",
            "Ge Yang",
            "Guanzhe Huang",
            "Gulin Yan",
            "Haiyang Feng",
            "Hao Nie",
            "Haonan Jia",
            "Hanpeng Hu",
            "Hanqi Chen",
            "Haolong Yan",
            "Heng Wang",
            "Hongcheng Guo",
            "Huilin Xiong",
            "Huixin Xiong",
            "Jiahao Gong",
            "Jianchang Wu",
            "Jiaoren Wu",
            "Jie Wu",
            "Jie Yang",
            "Jiashuai Liu",
            "Jiashuo Li",
            "Jingyang Zhang",
            "Junjing Guo",
            "Junzhe Lin",
            "Kaixiang Li",
            "Lei Liu",
            "Lei Xia",
            "Liang Zhao",
            "Liguo Tan",
            "Liwen Huang",
            "Liying Shi",
            "Ming Li",
            "Mingliang Li",
            "Muhua Cheng",
            "Na Wang",
            "Qiaohui Chen",
            "Qinglin He",
            "Qiuyan Liang",
            "Quan Sun",
            "Ran Sun",
            "Rui Wang",
            "Shaoliang Pang",
            "Shiliang Yang",
            "Sitong Liu",
            "Siqi Liu",
            "Shuli Gao",
            "Tiancheng Cao",
            "Tianyu Wang",
            "Weipeng Ming",
            "Wenqing He",
            "Xu Zhao",
            "Xuelin Zhang",
            "Xianfang Zeng",
            "Xiaojia Liu",
            "Xuan Yang",
            "Yaqi Dai",
            "Yanbo Yu",
            "Yang Li",
            "Yineng Deng",
            "Yingming Wang",
            "Yilei Wang",
            "Yuanwei Lu",
            "Yu Chen",
            "Yu Luo",
            "Yuchu Luo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10248",
        "abstract": "We present Step-Video-T2V, a state-of-the-art text-to-video pre-trained model with 30B parameters and the ability to generate videos up to 204 frames in length. A deep compression Variational Autoencoder, Video-VAE, is designed for video generation tasks, achieving 16x16 spatial and 8x temporal compression ratios, while maintaining exceptional video reconstruction quality. User prompts are encoded using two bilingual text encoders to handle both English and Chinese. A DiT with 3D full attention is trained using Flow Matching and is employed to denoise input noise into latent frames. A video-based DPO approach, Video-DPO, is applied to reduce artifacts and improve the visual quality of the generated videos. We also detail our training strategies and share key observations and insights. Step-Video-T2V's performance is evaluated on a novel video generation benchmark, Step-Video-T2V-Eval, demonstrating its state-of-the-art text-to-video quality when compared with both open-source and commercial engines. Additionally, we discuss the limitations of current diffusion-based model paradigm and outline future directions for video foundation models. We make both Step-Video-T2V and Step-Video-T2V-Eval available at https://github.com/stepfun-ai/Step-Video-T2V. The online version can be accessed from https://yuewen.cn/videos as well. Our goal is to accelerate the innovation of video foundation models and empower video content creators.",
        "tags": [
            "3D",
            "DiT",
            "Diffusion",
            "Flow Matching",
            "Text-to-Video",
            "VAE",
            "Video Generation"
        ]
    },
    {
        "id": "107",
        "title": "VisCon-100K: Leveraging Contextual Web Data for Fine-tuning Vision Language Models",
        "author": [
            "Gokul Karthik Kumar",
            "Iheb Chaabane",
            "Kebin Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10250",
        "abstract": "Vision-language models (VLMs) excel in various visual benchmarks but are often constrained by the lack of high-quality visual fine-tuning data. To address this challenge, we introduce VisCon-100K, a novel dataset derived from interleaved image-text web documents. Our approach transforms 45K web documents from the OBELICS dataset into 100K image conversation samples. We utilize GPT-4V to generate image-contextual captions and OpenChat 3.5 model to convert these captions into diverse free-form and multiple-choice question-answer pairs. Integrating this dataset for fine-tuning considerably enhances VLM performance across multiple benchmarks. Unlike methods that focus solely on fine-grained visual content, our approach leverages accompanying web context, yielding superior results. We also discover that a `leaky modality mix,' where conversation samples contain questions answerable from both the image and its contextual caption, outperforms non-leaky combinations of captions and Q\\&A pairs. VisCon-100k dataset shows strong performance with two popular VLM approaches: text-only large language model (LLM) aligned with a vision encoder using image captions data (ShareGPT4V-7b) and multimodally pretrained LLM (IDEFICS2-8b) using interleaved image-text data. In addition to releasing the VisCon-100K dataset, we provide a contextual captioner trained on this dataset, facilitating scalable fine-tuning data generation for future research and open-source applications. Using the same pipeline, but substituting our trained contextual captioner for GPT-4V, we also release the larger VisCon-1M dataset.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "108",
        "title": "PromptArtisan: Multi-instruction Image Editing in Single Pass with Complete Attention Control",
        "author": [
            "Kunal Swami",
            "Raghu Chittersu",
            "Pranav Adlinge",
            "Rajeev Irny",
            "Shashavali Doodekula",
            "Alok Shukla"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10258",
        "abstract": "We present PromptArtisan, a groundbreaking approach to multi-instruction image editing that achieves remarkable results in a single pass, eliminating the need for time-consuming iterative refinement. Our method empowers users to provide multiple editing instructions, each associated with a specific mask within the image. This flexibility allows for complex edits involving mask intersections or overlaps, enabling the realization of intricate and nuanced image transformations. PromptArtisan leverages a pre-trained InstructPix2Pix model in conjunction with a novel Complete Attention Control Mechanism (CACM). This mechanism ensures precise adherence to user instructions, granting fine-grained control over the editing process. Furthermore, our approach is zero-shot, requiring no additional training, and boasts improved processing complexity compared to traditional iterative methods. By seamlessly integrating multi-instruction capabilities, single-pass efficiency, and complete attention control, PromptArtisan unlocks new possibilities for creative and efficient image editing workflows, catering to both novice and expert users alike.",
        "tags": [
            "Image Editing"
        ]
    },
    {
        "id": "109",
        "title": "MITO: Enabling Non-Line-of-Sight Perception using Millimeter-waves through Real-World Datasets and Simulation Tools",
        "author": [
            "Laura Dodds",
            "Tara Boroushaki",
            "Fadel Adib"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10259",
        "abstract": "We present MITO, the first dataset of multi-spectral millimeter-wave (mmWave) images of everyday objects. Unlike visible light, mmWave signals can image through everyday occlusions (e.g., cardboard boxes, fabric, plastic). However, due to the dearth of publicly-available mmWave images and the interdisciplinary challenges in collecting and processing mmWave signals, it remains difficult today for computer vision researchers to develop mmWave-based non-line-of-sight perception algorithms and models.\nTo overcome these challenges, we introduce a real-world dataset and open-source simulation tool for mmWave imaging. The dataset is acquired using a UR5 robotic arm with two mmWave radars operating at different frequencies and an RGB-D camera. Through a signal processing pipeline, we capture and create over 580 real-world 3D mmWave images from over 76 different objects in the YCB dataset, a standard dataset for robotics manipulation. We provide real-world mmWave images in line-of-sight and non-line-of-sight, as well as RGB-D images and ground truth segmentation masks. We also develop an open-source simulation tool that can be used to generate synthetic mmWave images for any 3D triangle mesh, which achieves a median F-Score of 94% when compared to real-world mmWave images.\nWe show the usefulness of this dataset and simulation tool in multiple CV tasks in non-line-of-sight. First, we perform object segmentation for mmWave images using the segment anything model (SAM), and achieve a median precision and recall of 92.6% and 64%. Second, we train a classifier that can recognize objects in non-line-of-sight. It is trained on synthetic images and can classify real-world images with 85% accuracy.\nWe believe MITO will be a valuable resource for computer vision researchers in developing non-line-of-sight perception, similar to how early camera-based datasets shaped the field.",
        "tags": [
            "3D",
            "Robotics",
            "SAM",
            "Segment Anything",
            "Segmentation"
        ]
    },
    {
        "id": "110",
        "title": "Large Language Models and Synthetic Data for Monitoring Dataset Mentions in Research Papers",
        "author": [
            "Aivin V. Solatorio",
            "Rafael Macalaba",
            "James Liounis"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10263",
        "abstract": "Tracking how data is mentioned and used in research papers provides critical insights for improving data discoverability, quality, and production. However, manually identifying and classifying dataset mentions across vast academic literature is resource-intensive and not scalable. This paper presents a machine learning framework that automates dataset mention detection across research domains by leveraging large language models (LLMs), synthetic data, and a two-stage fine-tuning process. We employ zero-shot extraction from research papers, an LLM-as-a-Judge for quality assessment, and a reasoning agent for refinement to generate a weakly supervised synthetic dataset. The Phi-3.5-mini instruct model is pre-fine-tuned on this dataset, followed by fine-tuning on a manually annotated subset. At inference, a ModernBERT-based classifier efficiently filters dataset mentions, reducing computational overhead while maintaining high recall. Evaluated on a held-out manually annotated sample, our fine-tuned model outperforms NuExtract-v1.5 and GLiNER-large-v2.1 in dataset extraction accuracy. Our results highlight how LLM-generated synthetic data can effectively address training data scarcity, improving generalization in low-resource settings. This framework offers a pathway toward scalable monitoring of dataset usage, enhancing transparency, and supporting researchers, funders, and policymakers in identifying data gaps and strengthening data accessibility for informed decision-making.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "111",
        "title": "Are Large Language Models the future crowd workers of Linguistics?",
        "author": [
            "Iris Ferrazzo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10266",
        "abstract": "Data elicitation from human participants is one of the core data collection strategies used in empirical linguistic research. The amount of participants in such studies may vary considerably, ranging from a handful to crowdsourcing dimensions. Even if they provide resourceful extensive data, both of these settings come alongside many disadvantages, such as low control of participants' attention during task completion, precarious working conditions in crowdsourcing environments, and time-consuming experimental designs. For these reasons, this research aims to answer the question of whether Large Language Models (LLMs) may overcome those obstacles if included in empirical linguistic pipelines. Two reproduction case studies are conducted to gain clarity into this matter: Cruz (2023) and Lombard et al. (2021). The two forced elicitation tasks, originally designed for human participants, are reproduced in the proposed framework with the help of OpenAI's GPT-4o-mini model. Its performance with our zero-shot prompting baseline shows the effectiveness and high versatility of LLMs, that tend to outperform human informants in linguistic tasks. The findings of the second replication further highlight the need to explore additional prompting techniques, such as Chain-of-Thought (CoT) prompting, which, in a second follow-up experiment, demonstrates higher alignment to human performance on both critical and filler items. Given the limited scale of this study, it is worthwhile to further explore the performance of LLMs in empirical Linguistics and in other future applications in the humanities.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "112",
        "title": "DeltaProduct: Increasing the Expressivity of DeltaNet Through Products of Householders",
        "author": [
            "Julien Siems",
            "Timur Carstensen",
            "Arber Zela",
            "Frank Hutter",
            "Massimiliano Pontil",
            "Riccardo Grazzi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10297",
        "abstract": "Linear Recurrent Neural Networks (linear RNNs) have emerged as competitive alternatives to Transformers for sequence modeling, offering efficient training and linear-time inference. However, existing architectures face a fundamental trade-off between expressivity and efficiency, dictated by the structure of their state-transition matrices. While diagonal matrices used in architectures like Mamba, GLA, or mLSTM yield fast runtime, they suffer from severely limited expressivity. To address this, recent architectures such as (Gated) DeltaNet and RWKVv7 adopted a diagonal plus rank-1 structure, allowing simultaneous token-channel mixing, which overcomes some expressivity limitations with only a slight decrease in training efficiency. Building on the interpretation of DeltaNet's recurrence as performing one step of online gradient descent per token on an associative recall loss, we introduce DeltaProduct, which instead takes multiple ($n_h$) steps per token. This naturally leads to diagonal plus rank-$n_h$ state-transition matrices, formed as products of $n_h$ generalized Householder transformations, providing a tunable mechanism to balance expressivity and efficiency and a stable recurrence. Through extensive experiments, we demonstrate that DeltaProduct achieves superior state-tracking and language modeling capabilities while exhibiting significantly improved length extrapolation compared to DeltaNet. Additionally, we also strengthen the theoretical foundation of DeltaNet's expressivity by proving that it can solve dihedral group word problems in just two layers.",
        "tags": [
            "Mamba"
        ]
    },
    {
        "id": "113",
        "title": "Open-Source AI-Powered Optimization in Scalene: Advancing Python Performance Profiling with DeepSeek-R1 and LLaMA 3.2",
        "author": [
            "Saem Hasan",
            "Sanju Basak"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10299",
        "abstract": "Python's flexibility and ease of use come at the cost of performance inefficiencies, requiring developers to rely on profilers to optimize execution. SCALENE, a high-performance CPU, GPU, and memory profiler, provides fine-grained insights into Python applications while running significantly faster than traditional profilers. Originally, SCALENE integrated OpenAI's API to generate AI-powered optimization suggestions, but its reliance on a proprietary API limited accessibility. This study explores the feasibility of using opensource large language models (LLMs), such as DeepSeek-R1 and Llama 3.2, to generate optimization recommendations within SCALENE. Our evaluation reveals that DeepSeek-R1 provides effective code optimizations comparable to proprietary models. We integrate DeepSeek-R1 into SCALENE to automatically analyze performance bottlenecks and suggest improvements, enhancing SCALENE's utility while maintaining its open-source nature. This study demonstrates that open-source LLMs can be viable alternatives for AI-driven code optimization, paving the way for more accessible and cost-effective performance analysis tools.",
        "tags": [
            "DeepSeek",
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "114",
        "title": "LLM-Powered Preference Elicitation in Combinatorial Assignment",
        "author": [
            "Ermis Soumalias",
            "Yanchen Jiang",
            "Kehang Zhu",
            "Michael Curry",
            "Sven Seuken",
            "David C. Parkes"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10308",
        "abstract": "We study the potential of large language models (LLMs) as proxies for humans to simplify preference elicitation (PE) in combinatorial assignment. While traditional PE methods rely on iterative queries to capture preferences, LLMs offer a one-shot alternative with reduced human effort. We propose a framework for LLM proxies that can work in tandem with SOTA ML-powered preference elicitation schemes. Our framework handles the novel challenges introduced by LLMs, such as response variability and increased computational costs. We experimentally evaluate the efficiency of LLM proxies against human queries in the well-studied course allocation domain, and we investigate the model capabilities required for success. We find that our approach improves allocative efficiency by up to 20%, and these results are robust across different LLMs and to differences in quality and accuracy of reporting.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "115",
        "title": "Process Reward Models for LLM Agents: Practical Framework and Directions",
        "author": [
            "Sanjiban Choudhury"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10325",
        "abstract": "We introduce Agent Process Reward Models (AgentPRM), a simple and scalable framework for training LLM agents to continually improve through interactions. AgentPRM follows a lightweight actor-critic paradigm, using Monte Carlo rollouts to compute reward targets and optimize policies. It requires minimal modifications to existing RLHF pipelines, making it easy to integrate at scale. Beyond AgentPRM, we propose InversePRM, which learns process rewards directly from demonstrations without explicit outcome supervision. We also explore key challenges and opportunities, including exploration, process reward shaping, and model-predictive reasoning. We evaluate on ALFWorld benchmark, show that small 3B models trained with AgentPRM and InversePRM outperform strong GPT-4o baselines, and analyze test-time scaling, reward hacking, and more. Our code is available at: https://github.com/sanjibanc/agent_prm.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "116",
        "title": "DiOpt: Self-supervised Diffusion for Constrained Optimization",
        "author": [
            "Shutong Ding",
            "Yimiao Zhou",
            "Ke Hu",
            "Xi Yao",
            "Junchi Yan",
            "Xiaoying Tang",
            "Ye Shi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10330",
        "abstract": "Recent advances in diffusion models show promising potential for learning-based optimization by leveraging their multimodal sampling capability to escape local optima. However, existing diffusion-based optimization approaches, often reliant on supervised training, lacks a mechanism to ensure strict constraint satisfaction which is often required in real-world applications. One resulting observation is the distributional misalignment, i.e. the generated solution distribution often exhibits small overlap with the feasible domain. In this paper, we propose DiOpt, a novel diffusion paradigm that systematically learns near-optimal feasible solution distributions through iterative self-training. Our framework introduces several key innovations: a target distribution specifically designed to maximize overlap with the constrained solution manifold; a bootstrapped self-training mechanism that adaptively weights candidate solutions based on the severity of constraint violations and optimality gaps; and a dynamic memory buffer that accelerates convergence by retaining high-quality solutions over training iterations. To our knowledge, DiOpt represents the first successful integration of self-supervised diffusion with hard constraint satisfaction. Evaluations on diverse tasks, including power grid control, motion retargeting, wireless allocation demonstrate its superiority in terms of both optimality and constraint satisfaction.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "117",
        "title": "Evaluating the Meta- and Object-Level Reasoning of Large Language Models for Question Answering",
        "author": [
            "Nick Ferguson",
            "Liane Guillou",
            "Alan Bundy",
            "Kwabena Nuamah"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10338",
        "abstract": "Large Language Models (LLMs) excel in natural language tasks but still face challenges in Question Answering (QA) tasks requiring complex, multi-step reasoning. We outline the types of reasoning required in some of these tasks, and reframe them in terms of meta-level reasoning (akin to high-level strategic reasoning or planning) and object-level reasoning (embodied in lower-level tasks such as mathematical reasoning). Franklin, a novel dataset with requirements of meta- and object-level reasoning, is introduced and used along with three other datasets to evaluate four LLMs at question answering tasks requiring multiple steps of reasoning. Results from human annotation studies suggest LLMs demonstrate meta-level reasoning with high frequency, but struggle with object-level reasoning tasks in some of the datasets used. Additionally, evidence suggests that LLMs find the object-level reasoning required for the questions in the Franklin dataset challenging, yet they do exhibit strong performance with respect to the meta-level reasoning requirements.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "118",
        "title": "Agentic Verification for Ambiguous Query Disambiguation",
        "author": [
            "Youngwon Lee",
            "Seung-won Hwang",
            "Ruofan Wu",
            "Feng Yan",
            "Danmei Xu",
            "Moutasem Akkad",
            "Zhewei Yao",
            "Yuxiong He"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10352",
        "abstract": "In this work, we tackle the challenge of disambiguating queries in retrieval-augmented generation (RAG) to diverse yet answerable interpretations. State-of-the-arts follow a Diversify-then-Verify (DtV) pipeline, where diverse interpretations are generated by an LLM, later used as search queries to retrieve supporting passages. Such a process may introduce noise in either interpretations or retrieval, particularly in enterprise settings, where LLMs -- trained on static data -- may struggle with domain-specific disambiguations. Thus, a post-hoc verification phase is introduced to prune noises. Our distinction is to unify diversification with verification by incorporating feedback from retriever and generator early on. This joint approach improves both efficiency and robustness by reducing reliance on multiple retrieval and inference steps, which are susceptible to cascading errors. We validate the efficiency and effectiveness of our method, Verified-Diversification with Consolidation (VERDICT), on the widely adopted ASQA benchmark to achieve diverse yet verifiable interpretations. Empirical results show that VERDICT improves grounding-aware F1 score by an average of 23% over the strongest baseline across different backbone LLMs.",
        "tags": [
            "LLMs",
            "RAG"
        ]
    },
    {
        "id": "119",
        "title": "Dimension-free Score Matching and Time Bootstrapping for Diffusion Models",
        "author": [
            "Syamantak Kumar",
            "Dheeraj Nagaraj",
            "Purnamrita Sarkar"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10354",
        "abstract": "Diffusion models generate samples by estimating the score function of the target distribution at various noise levels. The model is trained using samples drawn from the target distribution, progressively adding noise. In this work, we establish the first (nearly) dimension-free sample complexity bounds for learning these score functions, achieving a double exponential improvement in dimension over prior results. A key aspect of our analysis is the use of a single function approximator to jointly estimate scores across noise levels, a critical feature of diffusion models in practice which enables generalization across timesteps. Our analysis introduces a novel martingale-based error decomposition and sharp variance bounds, enabling efficient learning from dependent data generated by Markov processes, which may be of independent interest. Building on these insights, we propose Bootstrapped Score Matching (BSM), a variance reduction technique that utilizes previously learned scores to improve accuracy at higher noise levels. These results provide crucial insights into the efficiency and effectiveness of diffusion models for generative modeling.",
        "tags": [
            "Diffusion",
            "Score Matching"
        ]
    },
    {
        "id": "120",
        "title": "Enhancing Multilingual LLM Pretraining with Model-Based Data Selection",
        "author": [
            "Bettina Messmer",
            "Vinko SabolÄec",
            "Martin Jaggi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10361",
        "abstract": "Dataset curation has become a basis for strong large language model (LLM) performance. While various rule-based filtering heuristics exist for English and multilingual datasets, model-based filtering techniques have primarily focused on English. To address the disparity stemming from limited research on non-English languages, we propose a model-based filtering framework for multilingual datasets that aims to identify a diverse set of structured and knowledge-rich samples. Our approach emphasizes transparency, simplicity, and efficiency, leveraging Transformer- and FastText-based classifiers to ensure the broad accessibility of our technique and data. We conduct comprehensive ablation studies on the FineWeb-2 web crawl dataset across diverse language families, scripts, and resource availability to demonstrate the effectiveness of our method. Training a 1B-parameter Llama model for 70B and 119B tokens, our approach can match the baseline MMLU score with as little as 15% of the training tokens, while also improving across other benchmarks. These findings provide strong evidence for the generalizability of our approach to other languages. As a result, we extend our framework to 20 languages for which we release the refined pretraining datasets.",
        "tags": [
            "LLaMA",
            "Transformer"
        ]
    },
    {
        "id": "121",
        "title": "ReStyle3D: Scene-Level Appearance Transfer with Semantic Correspondences",
        "author": [
            "Liyuan Zhu",
            "Shengqu Cai",
            "Shengyu Huang",
            "Gordon Wetzstein",
            "Naji Khosravan",
            "Iro Armeni"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10377",
        "abstract": "We introduce ReStyle3D, a novel framework for scene-level appearance transfer from a single style image to a real-world scene represented by multiple views. The method combines explicit semantic correspondences with multi-view consistency to achieve precise and coherent stylization. Unlike conventional stylization methods that apply a reference style globally, ReStyle3D uses open-vocabulary segmentation to establish dense, instance-level correspondences between the style and real-world images. This ensures that each object is stylized with semantically matched textures. It first transfers the style to a single view using a training-free semantic-attention mechanism in a diffusion model. It then lifts the stylization to additional views via a learned warp-and-refine network guided by monocular depth and pixel-wise correspondences. Experiments show that ReStyle3D consistently outperforms prior methods in structure preservation, perceptual style similarity, and multi-view coherence. User studies further validate its ability to produce photo-realistic, semantically faithful results. Our code, pretrained models, and dataset will be publicly released, to support new applications in interior design, virtual staging, and 3D-consistent stylization.",
        "tags": [
            "3D",
            "Diffusion",
            "Segmentation"
        ]
    },
    {
        "id": "122",
        "title": "Unknown Word Detection for English as a Second Language (ESL) Learners Using Gaze and Pre-trained Language Models",
        "author": [
            "Jiexin Ding",
            "Bowen Zhao",
            "Yuntao Wang",
            "Xinyun Liu",
            "Rui Hao",
            "Ishan Chatterjee",
            "Yuanchun Shi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10378",
        "abstract": "English as a Second Language (ESL) learners often encounter unknown words that hinder their text comprehension. Automatically detecting these words as users read can enable computing systems to provide just-in-time definitions, synonyms, or contextual explanations, thereby helping users learn vocabulary in a natural and seamless manner. This paper presents EyeLingo, a transformer-based machine learning method that predicts the probability of unknown words based on text content and eye gaze trajectory in real time with high accuracy. A 20-participant user study revealed that our method can achieve an accuracy of 97.6%, and an F1-score of 71.1%. We implemented a real-time reading assistance prototype to show the effectiveness of EyeLingo. The user study shows improvement in willingness to use and usefulness compared to baseline methods.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "123",
        "title": "Aspect-Oriented Summarization for Psychiatric Short-Term Readmission Prediction",
        "author": [
            "WonJin Yoon",
            "Boyu Ren",
            "Spencer Thomas",
            "Chanwhi Kim",
            "Guergana Savova",
            "Mei-Hua Hall",
            "Timothy Miller"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10388",
        "abstract": "Recent progress in large language models (LLMs) has enabled the automated processing of lengthy documents even without supervised training on a task-specific dataset. Yet, their zero-shot performance in complex tasks as opposed to straightforward information extraction tasks remains suboptimal. One feasible approach for tasks with lengthy, complex input is to first summarize the document and then apply supervised fine-tuning to the summary. However, the summarization process inevitably results in some loss of information. In this study we present a method for processing the summaries of long documents aimed to capture different important aspects of the original document. We hypothesize that LLM summaries generated with different aspect-oriented prompts contain different \\textit{information signals}, and we propose methods to measure these differences. We introduce approaches to effectively integrate signals from these different summaries for supervised training of transformer models. We validate our hypotheses on a high-impact task -- 30-day readmission prediction from a psychiatric discharge -- using real-world data from four hospitals, and show that our proposed method increases the prediction performance for the complex task of predicting patient outcome.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "124",
        "title": "Region-Adaptive Sampling for Diffusion Transformers",
        "author": [
            "Ziming Liu",
            "Yifan Yang",
            "Chengruidong Zhang",
            "Yiqi Zhang",
            "Lili Qiu",
            "Yang You",
            "Yuqing Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10389",
        "abstract": "Diffusion models (DMs) have become the leading choice for generative tasks across diverse domains. However, their reliance on multiple sequential forward passes significantly limits real-time performance. Previous acceleration methods have primarily focused on reducing the number of sampling steps or reusing intermediate results, failing to leverage variations across spatial regions within the image due to the constraints of convolutional U-Net structures. By harnessing the flexibility of Diffusion Transformers (DiTs) in handling variable number of tokens, we introduce RAS, a novel, training-free sampling strategy that dynamically assigns different sampling ratios to regions within an image based on the focus of the DiT model. Our key observation is that during each sampling step, the model concentrates on semantically meaningful regions, and these areas of focus exhibit strong continuity across consecutive steps. Leveraging this insight, RAS updates only the regions currently in focus, while other regions are updated using cached noise from the previous step. The model's focus is determined based on the output from the preceding step, capitalizing on the temporal consistency we observed. We evaluate RAS on Stable Diffusion 3 and Lumina-Next-T2I, achieving speedups up to 2.36x and 2.51x, respectively, with minimal degradation in generation quality. Additionally, a user study reveals that RAS delivers comparable qualities under human evaluation while achieving a 1.6x speedup. Our approach makes a significant step towards more efficient diffusion transformers, enhancing their potential for real-time applications.",
        "tags": [
            "DiT",
            "Diffusion"
        ]
    },
    {
        "id": "125",
        "title": "MM-RLHF: The Next Step Forward in Multimodal LLM Alignment",
        "author": [
            "Yi-Fan Zhang",
            "Tao Yu",
            "Haochen Tian",
            "Chaoyou Fu",
            "Peiyan Li",
            "Jianshu Zeng",
            "Wulin Xie",
            "Yang Shi",
            "Huanyu Zhang",
            "Junkang Wu",
            "Xue Wang",
            "Yibo Hu",
            "Bin Wen",
            "Fan Yang",
            "Zhang Zhang",
            "Tingting Gao",
            "Di Zhang",
            "Liang Wang",
            "Rong Jin",
            "Tieniu Tan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10391",
        "abstract": "Despite notable advancements in Multimodal Large Language Models (MLLMs), most state-of-the-art models have not undergone thorough alignment with human preferences. This gap exists because current alignment research has primarily achieved progress in specific areas (e.g., hallucination reduction), while the broader question of whether aligning models with human preferences can systematically enhance MLLM capability remains largely unexplored. To this end, we introduce MM-RLHF, a dataset containing $\\mathbf{120k}$ fine-grained, human-annotated preference comparison pairs. This dataset represents a substantial advancement over existing resources, offering superior size, diversity, annotation granularity, and quality. Leveraging this dataset, we propose several key innovations to improve both the quality of reward models and the efficiency of alignment algorithms. Notably, we introduce a Critique-Based Reward Model, which generates critiques of model outputs before assigning scores, offering enhanced interpretability and more informative feedback compared to traditional scalar reward mechanisms. Additionally, we propose Dynamic Reward Scaling, a method that adjusts the loss weight of each sample according to the reward signal, thereby optimizing the use of high-quality comparison pairs. Our approach is rigorously evaluated across $\\mathbf{10}$ distinct dimensions and $\\mathbf{27}$ benchmarks, with results demonstrating significant and consistent improvements in model performance. Specifically, fine-tuning LLaVA-ov-7B with MM-RLHF and our alignment algorithm leads to a $\\mathbf{19.5}$% increase in conversational abilities and a $\\mathbf{60}$% improvement in safety.\nWe have open-sourced the preference dataset, reward model, training and evaluation code, as well as reward modeling and safety benchmarks. For more details, please visit our project page: https://mm-rlhf.github.io.",
        "tags": [
            "LLaVA",
            "Large Language Models"
        ]
    },
    {
        "id": "126",
        "title": "Transformer Based Time-Series Forecasting for Stock",
        "author": [
            "Shuozhe Li",
            "Zachery B Schulwol",
            "Risto Miikkulainen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09625",
        "abstract": "To the naked eye, stock prices are considered chaotic, dynamic, and unpredictable. Indeed, it is one of the most difficult forecasting tasks that hundreds of millions of retail traders and professional traders around the world try to do every second even before the market opens. With recent advances in the development of machine learning and the amount of data the market generated over years, applying machine learning techniques such as deep learning neural networks is unavoidable. In this work, we modeled the task as a multivariate forecasting problem, instead of a naive autoregression problem. The multivariate analysis is done using the attention mechanism via applying a mutated version of the Transformer, \"Stockformer\", which we created.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "127",
        "title": "Volumetric Temporal Texture Synthesis for Smoke Stylization using Neural Cellular Automata",
        "author": [
            "Dongqing Wang",
            "Ehsan Pajouheshgar",
            "Yitao Xu",
            "Tong Zhang",
            "Sabine SÃ¼sstrunk"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09631",
        "abstract": "Artistic stylization of 3D volumetric smoke data is still a challenge in computer graphics due to the difficulty of ensuring spatiotemporal consistency given a reference style image, and that within reasonable time and computational resources. In this work, we introduce Volumetric Neural Cellular Automata (VNCA), a novel model for efficient volumetric style transfer that synthesizes, in real-time, multi-view consistent stylizing features on the target smoke with temporally coherent transitions between stylized simulation frames. VNCA synthesizes a 3D texture volume with color and density stylization and dynamically aligns this volume with the intricate motion patterns of the smoke simulation under the Eulerian framework. Our approach replaces the explicit fluid advection modeling and the inter-frame smoothing terms with the self-emerging motion of the underlying cellular automaton, thus reducing the training time by over an order of magnitude. Beyond smoke simulations, we demonstrate the versatility of our approach by showcasing its applicability to mesh stylization.",
        "tags": [
            "3D",
            "Style Transfer"
        ]
    },
    {
        "id": "128",
        "title": "CellFlow: Simulating Cellular Morphology Changes via Flow Matching",
        "author": [
            "Yuhui Zhang",
            "Yuchang Su",
            "Chenyu Wang",
            "Tianhong Li",
            "Zoe Wefers",
            "Jeffrey Nirschl",
            "James Burgess",
            "Daisy Ding",
            "Alejandro Lozano",
            "Emma Lundberg",
            "Serena Yeung-Levy"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09775",
        "abstract": "Building a virtual cell capable of accurately simulating cellular behaviors in silico has long been a dream in computational biology. We introduce CellFlow, an image-generative model that simulates cellular morphology changes induced by chemical and genetic perturbations using flow matching. Unlike prior methods, CellFlow models distribution-wise transformations from unperturbed to perturbed cell states, effectively distinguishing actual perturbation effects from experimental artifacts such as batch effects -- a major challenge in biological data. Evaluated on chemical (BBBC021), genetic (RxRx1), and combined perturbation (JUMP) datasets, CellFlow generates biologically meaningful cell images that faithfully capture perturbation-specific morphological changes, achieving a 35% improvement in FID scores and a 12% increase in mode-of-action prediction accuracy over existing methods. Additionally, CellFlow enables continuous interpolation between cellular states, providing a potential tool for studying perturbation dynamics. These capabilities mark a significant step toward realizing virtual cell modeling for biomedical research.",
        "tags": [
            "Flow Matching"
        ]
    },
    {
        "id": "129",
        "title": "ExoMiner++ on TESS with Transfer Learning from Kepler: Transit Classification and Vetting Catalog for 2-min Data",
        "author": [
            "Hamed Valizadegan",
            "Miguel J. S. Martinho",
            "Jon M. Jenkins",
            "Joseph D. Twicken",
            "Douglas A. Caldwell",
            "Patrick Maynard",
            "Hongbo Wei",
            "William Zhong",
            "Charles Yates",
            "Sam Donald",
            "Karen A. Collins",
            "David Latham",
            "Khalid Barkaoui",
            "Perry Berlind",
            "Michael L. Calkins",
            "Kylee Carden",
            "Nikita Chazov",
            "Gilbert A. Esquerdo",
            "Tristan Guillot",
            "Vadim Krushinsky",
            "Grzegorz Nowak",
            "Benjamin V. Rackham",
            "Amaury Triaud",
            "Richard P. Schwarz",
            "Denise Stephens",
            "Chris Stockdale",
            "Jiaqi Wang",
            "Cristilyn N. Watkins",
            "Francis P. Wilkin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09790",
        "abstract": "We present ExoMiner++, an enhanced deep learning model that builds on the success of ExoMiner to improve transit signal classification in 2-minute TESS data. ExoMiner++ incorporates additional diagnostic inputs, including periodogram, flux trend, difference image, unfolded flux, and spacecraft attitude control data, all of which are crucial for effectively distinguishing transit signals from more challenging sources of false positives. To further enhance performance, we leverage transfer learning from high-quality labeled data from the Kepler space telescope, mitigating the impact of TESS's noisier and more ambiguous labels. ExoMiner++ achieves high accuracy across various classification and ranking metrics, significantly narrowing the search space for follow-up investigations to confirm new planets. To serve the exoplanet community, we introduce new TESS catalogs containing ExoMiner++ classifications and confidence scores for each transit signal. Among the 147,568 unlabeled TCEs, ExoMiner++ identifies 7,330 as planet candidates, with the remainder classified as false positives. These 7,330 planet candidates correspond to 1,868 existing TESS Objects of Interest (TOIs), 69 Community TESS Objects of Interest (CTOIs), and 50 newly introduced CTOIs. 1,797 out of the 2,506 TOIs previously labeled as planet candidates in ExoFOP are classified as planet candidates by ExoMiner++. This reduction in plausible candidates combined with the excellent ranking quality of ExoMiner++ allows the follow-up efforts to be focused on the most likely candidates, increasing the overall planet yield.",
        "tags": [
            "FLUX"
        ]
    },
    {
        "id": "130",
        "title": "$Î$CDM and early dark energy in latent space: a data-driven parametrization of the CMB temperature power spectrum",
        "author": [
            "Davide Piras",
            "Laura Herold",
            "Luisa Lucie-Smith",
            "Eiichiro Komatsu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09810",
        "abstract": "Finding the best parametrization for cosmological models in the absence of first-principle theories is an open question. We propose a data-driven parametrization of cosmological models given by the disentangled 'latent' representation of a variational autoencoder (VAE) trained to compress cosmic microwave background (CMB) temperature power spectra. We consider a broad range of $\\Lambda$CDM and beyond-$\\Lambda$CDM cosmologies with an additional early dark energy (EDE) component. We show that these spectra can be compressed into 5 ($\\Lambda$CDM) or 8 (EDE) independent latent parameters, as expected when using temperature power spectra alone, and which reconstruct spectra at an accuracy well within the Planck errors. These latent parameters have a physical interpretation in terms of well-known features of the CMB temperature spectrum: these include the position, height and even-odd modulation of the acoustic peaks, as well as the gravitational lensing effect. The VAE also discovers one latent parameter which entirely isolates the EDE effects from those related to $\\Lambda$CDM parameters, thus revealing a previously unknown degree of freedom in the CMB temperature power spectrum. We further showcase how to place constraints on the latent parameters using Planck data as typically done for cosmological parameters, obtaining latent values consistent with previous $\\Lambda$CDM and EDE cosmological constraints. Our work demonstrates the potential of a data-driven reformulation of current beyond-$\\Lambda$CDM phenomenological models into the independent degrees of freedom to which the data observables are sensitive.",
        "tags": [
            "VAE"
        ]
    },
    {
        "id": "131",
        "title": "Universal Machine Learning Interatomic Potentials are Ready for Solid Ion Conductors",
        "author": [
            "Hongwei Du",
            "Jian Hui",
            "Lanting Zhang",
            "Hong Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09970",
        "abstract": "With the rapid development of energy storage technology, high-performance solid-state electrolytes (SSEs) have become critical for next-generation lithium-ion batteries. These materials require high ionic conductivity, excellent electrochemical stability, and good mechanical properties to meet the demands of electric vehicles and portable electronics. However, traditional methods like density functional theory (DFT) and empirical force fields face challenges such as high computational costs, poor scalability, and limited accuracy across material systems. Universal machine learning interatomic potentials (uMLIPs) offer a promising solution with their efficiency and near-DFT-level http://accuracy.This study systematically evaluates six advanced uMLIP models (MatterSim, MACE, SevenNet, CHGNet, M3GNet, and ORBFF) in terms of energy, forces, thermodynamic properties, elastic moduli, and lithium-ion diffusion behavior. The results show that MatterSim outperforms others in nearly all metrics, particularly in complex material systems, demonstrating superior accuracy and physical consistency. Other models exhibit significant deviations due to issues like energy inconsistency or insufficient training data http://coverage.Further analysis reveals that MatterSim achieves excellent agreement with reference values in lithium-ion diffusivity calculations, especially at room temperature. Studies on Li3YCl6 and Li6PS5Cl uncover how crystal structure, anion disorder levels, and Na/Li arrangements influence ionic conductivity. Appropriate S/Cl disorder levels and optimized Na/Li arrangements enhance diffusion pathway connectivity, improving overall ionic transport performance.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "132",
        "title": "Generalised Parallel Tempering: Flexible Replica Exchange via Flows and Diffusions",
        "author": [
            "Leo Zhang",
            "Peter Potaptchik",
            "Arnaud Doucet",
            "Hai-Dang Dau",
            "Saifuddin Syed"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10328",
        "abstract": "Parallel Tempering (PT) is a classical MCMC algorithm designed for leveraging parallel computation to sample efficiently from high-dimensional, multimodal or otherwise complex distributions via annealing. One limitation of the standard formulation of PT is the growth of computational resources required to generate high-quality samples, as measured by effective sample size or round trip rate, for increasingly challenging distributions. To address this issue, we propose the framework: Generalised Parallel Tempering (GePT) which allows for the incorporation of recent advances in modern generative modelling, such as normalising flows and diffusion models, within Parallel Tempering, while maintaining the same theoretical guarantees as MCMC-based methods. For instance, we show that this allows us to utilise diffusion models in a parallelised manner, bypassing the usual computational cost of a large number of steps to generate quality samples. Further, we empirically demonstrate that GePT can improve sample quality and reduce the growth of computational resources required to handle complex distributions over the classical algorithm.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "133",
        "title": "Studying number theory with deep learning: a case study with the MÃ¶bius and squarefree indicator functions",
        "author": [
            "David Lowry-Duda"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10335",
        "abstract": "Building on work of Charton, we train small transformer models to calculate the MÃ¶bius function $\\mu(n)$ and the squarefree indicator function $\\mu^2(n)$. The models attain nontrivial predictive power. We then iteratively train additional models to understand how the model functions, ultimately finding a theoretical explanation.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "134",
        "title": "Learning Euler Factors of Elliptic Curves",
        "author": [
            "Angelica Babei",
            "FranÃ§ois Charton",
            "Edgar Costa",
            "Xiaoyu Huang",
            "Kyu-Hwan Lee",
            "David Lowry-Duda",
            "Ashvni Narayanan",
            "Alexey Pozdnyakov"
        ],
        "pdf": "https://arxiv.org/pdf/2502.10357",
        "abstract": "We apply transformer models and feedforward neural networks to predict Frobenius traces $a_p$ from elliptic curves given other traces $a_q$. We train further models to predict $a_p \\bmod 2$ from $a_q \\bmod 2$, and cross-analysis such as $a_p \\bmod 2$ from $a_q$. Our experiments reveal that these models achieve high accuracy, even in the absence of explicit number-theoretic tools like functional equations of $L$-functions. We also present partial interpretability findings.",
        "tags": [
            "Transformer"
        ]
    }
]