[
    {
        "id": "1",
        "title": "Prompt-Aware Scheduling for Efficient Text-to-Image Inferencing System",
        "author": [
            "Shubham Agarwal",
            "Saud Iqbal",
            "Subrata Mitra"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06798",
        "abstract": "Traditional ML models utilize controlled approximations during high loads, employing faster, but less accurate models in a process called accuracy scaling. However, this method is less effective for generative text-to-image models due to their sensitivity to input prompts and performance degradation caused by large model loading overheads. This work introduces a novel text-to-image inference system that optimally matches prompts across multiple instances of the same model operating at various approximation levels to deliver high-quality images under high loads and fixed budgets.",
        "tags": [
            "Text-to-Image"
        ]
    },
    {
        "id": "2",
        "title": "Efficient Diffusion Models: A Survey",
        "author": [
            "Hui Shen",
            "Jingxuan Zhang",
            "Boning Xiong",
            "Rui Hu",
            "Shoufa Chen",
            "Zhongwei Wan",
            "Xin Wang",
            "Yu Zhang",
            "Zixuan Gong",
            "Guangyin Bao",
            "Chaofan Tao",
            "Yongfeng Huang",
            "Ye Yuan",
            "Mi Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06805",
        "abstract": "Diffusion models have emerged as powerful generative models capable of producing high-quality contents such as images, videos, and audio, demonstrating their potential to revolutionize digital content creation. However, these capabilities come at the cost of their significant computational resources and lengthy generation time, underscoring the critical need to develop efficient techniques for practical deployment. In this survey, we provide a systematic and comprehensive review of research on efficient diffusion models. We organize the literature in a taxonomy consisting of three main categories, covering distinct yet interconnected efficient diffusion model topics from algorithm-level, system-level, and framework perspective, respectively. We have also created a GitHub repository where we organize the papers featured in this survey at https://github.com/AIoT-MLSys-Lab/Efficient-Diffusion-Model-Survey. We hope our survey can serve as a valuable resource to help researchers and practitioners gain a systematic understanding of efficient diffusion model research and inspire them to contribute to this important and exciting field.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "3",
        "title": "Logits are All We Need to Adapt Closed Models",
        "author": [
            "Gaurush Hiranandani",
            "Haolun Wu",
            "Subhojyoti Mukherjee",
            "Sanmi Koyejo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06806",
        "abstract": "Many commercial Large Language Models (LLMs) are often closed-source, limiting developers to prompt tuning for aligning content generation with specific applications. While these models currently do not provide access to token logits, we argue that if such access were available, it would enable more powerful adaptation techniques beyond prompt engineering. In this paper, we propose a token-level probability reweighting framework that, given access to logits and a small amount of task-specific data, can effectively steer black-box LLMs toward application-specific content generation. Our approach views next-token prediction through the lens of supervised classification. We show that aligning black-box LLMs with task-specific data can be formulated as a label noise correction problem, leading to \\emph{Plugin} model -- an autoregressive probability reweighting model that operates solely on logits. We provide theoretical justification for why reweighting logits alone is sufficient for task adaptation. Extensive experiments with multiple datasets, LLMs, and reweighting models demonstrate the effectiveness of our method, advocating for broader access to token logits in closed-source models.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "4",
        "title": "Competitive Programming with Large Reasoning Models",
        "author": [
            "OpenAI",
            "Ahmed El-Kishky",
            "Alexander Wei",
            "Andre Saraiva",
            "Borys Minaev",
            "Daniel Selsam",
            "David Dohan",
            "Francis Song",
            "Hunter Lightman",
            "Ignasi Clavera",
            "Jakub Pachocki",
            "Jerry Tworek",
            "Lorenz Kuhn",
            "Lukasz Kaiser",
            "Mark Chen",
            "Max Schwarzer",
            "Mostafa Rohaninejad",
            "Nat McAleese",
            "o3 contributors",
            "Oleg MÃ¼rk",
            "Rhythm Garg",
            "Rui Shu",
            "Szymon Sidor",
            "Vineet Kosaraju",
            "Wenda Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06807",
        "abstract": "We show that reinforcement learning applied to large language models (LLMs) significantly boosts performance on complex coding and reasoning tasks. Additionally, we compare two general-purpose reasoning models - OpenAI o1 and an early checkpoint of o3 - with a domain-specific system, o1-ioi, which uses hand-engineered inference strategies designed for competing in the 2024 International Olympiad in Informatics (IOI). We competed live at IOI 2024 with o1-ioi and, using hand-crafted test-time strategies, placed in the 49th percentile. Under relaxed competition constraints, o1-ioi achieved a gold medal. However, when evaluating later models such as o3, we find that o3 achieves gold without hand-crafted domain-specific strategies or relaxed constraints. Our findings show that although specialized pipelines such as o1-ioi yield solid improvements, the scaled-up, general-purpose o3 model surpasses those results without relying on hand-crafted inference heuristics. Notably, o3 achieves a gold medal at the 2024 IOI and obtains a Codeforces rating on par with elite human competitors. Overall, these results indicate that scaling general-purpose reinforcement learning, rather than relying on domain-specific techniques, offers a robust path toward state-of-the-art AI in reasoning domains, such as competitive programming.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "5",
        "title": "Neurons Speak in Ranges: Breaking Free from Discrete Neuronal Attribution",
        "author": [
            "Muhammad Umair Haider",
            "Hammad Rizwan",
            "Hassan Sajjad",
            "Peizhong Ju",
            "A.B. Siddique"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06809",
        "abstract": "Interpreting and controlling the internal mechanisms of large language models (LLMs) is crucial for improving their trustworthiness and utility. Recent efforts have primarily focused on identifying and manipulating neurons by establishing discrete mappings between neurons and semantic concepts. However, such mappings struggle to handle the inherent polysemanticity in LLMs, where individual neurons encode multiple, distinct concepts. This makes precise control challenging and complicates downstream interventions. Through an in-depth analysis of both encoder and decoder-based LLMs across multiple text classification datasets, we uncover that while individual neurons encode multiple concepts, their activation magnitudes vary across concepts in distinct, Gaussian-like patterns. Building on this insight, we introduce NeuronLens, a novel range-based interpretation and manipulation framework that provides a finer view of neuron activation distributions to localize concept attribution within a neuron. Extensive empirical evaluations demonstrate that NeuronLens significantly reduces unintended interference, while maintaining precise control for manipulation of targeted concepts, outperforming existing methods.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "6",
        "title": "Aligning Human and Machine Attention for Enhanced Supervised Learning",
        "author": [
            "Avihay Chriqui",
            "Inbal Yahav",
            "Dov Teeni",
            "Ahmed Abbasi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06811",
        "abstract": "Attention, or prioritization of certain information items over others, is a critical element of any learning process, for both humans and machines. Given that humans continue to outperform machines in certain learning tasks, it seems plausible that machine performance could be enriched by aligning machine attention with human attention mechanisms -- yet research on this topic is sparse and has achieved only limited success. This paper proposes a new approach to address this gap, called Human-Machine Attention Learning (HuMAL). This approach involves reliance on data annotated by humans to reflect their self-perceived attention during specific tasks. We evaluate several alternative strategies for integrating such human attention data into machine learning (ML) algorithms, using a sentiment analysis task (review data from Yelp) and a personality-type classification task (data from myPersonality). The best-performing HuMAL strategy significantly enhances the task performance of fine-tuned transformer models (BERT, as well as GPT-2 and XLNET), and the benefit is particularly pronounced under challenging conditions of imbalanced or sparse labeled data. This research contributes to a deeper understanding of strategies for integrating human attention into ML models and highlights the potential of leveraging human cognition to augment ML in real-world applications.",
        "tags": [
            "BERT",
            "GPT",
            "Transformer"
        ]
    },
    {
        "id": "7",
        "title": "Harness Local Rewards for Global Benefits: Effective Text-to-Video Generation Alignment with Patch-level Reward Models",
        "author": [
            "Shuting Wang",
            "Haihong Tang",
            "Zhicheng Dou",
            "Chenyan Xiong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06812",
        "abstract": "The emergence of diffusion models (DMs) has significantly improved the quality of text-to-video generation models (VGMs). However, current VGM optimization primarily emphasizes the global quality of videos, overlooking localized errors, which leads to suboptimal generation capabilities. To address this issue, we propose a post-training strategy for VGMs, HALO, which explicitly incorporates local feedback from a patch reward model, providing detailed and comprehensive training signals with the video reward model for advanced VGM optimization. To develop an effective patch reward model, we distill GPT-4o to continuously train our video reward model, which enhances training efficiency and ensures consistency between video and patch reward distributions. Furthermore, to harmoniously integrate patch rewards into VGM optimization, we introduce a granular DPO (Gran-DPO) algorithm for DMs, allowing collaborative use of both patch and video rewards during the optimization process. Experimental results indicate that our patch reward model aligns well with human annotations and HALO substantially outperforms the baselines across two evaluation methods. Further experiments quantitatively prove the existence of patch defects, and our proposed method could effectively alleviate this issue.",
        "tags": [
            "Diffusion",
            "GPT",
            "Text-to-Video",
            "Video Generation"
        ]
    },
    {
        "id": "8",
        "title": "Policy Guided Tree Search for Enhanced LLM Reasoning",
        "author": [
            "Yang Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06813",
        "abstract": "Despite their remarkable capabilities, large language models often struggle with tasks requiring complex reasoning and planning. While existing approaches like Chain-of-Thought prompting and tree search techniques show promise, they are limited by their reliance on predefined heuristics and computationally expensive exploration strategies. We propose Policy-Guided Tree Search (PGTS), a framework that combines reinforcement learning with structured tree exploration to efficiently navigate reasoning paths. Our key innovation is a learned policy that dynamically decides between expanding, branching, backtracking, or terminating exploration, eliminating the need for manual heuristics or exhaustive search. Experiments across mathematical reasoning, logical deduction, and planning benchmarks demonstrate that PGTS achieves superior reasoning performance while significantly reducing computational costs compared to existing methods. These results establish PGTS as a scalable and effective solution for tackling complex reasoning tasks with LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "9",
        "title": "Globality Strikes Back: Rethinking the Global Knowledge of CLIP in Training-Free Open-Vocabulary Semantic Segmentation",
        "author": [
            "Jingyun Wang",
            "Cilin Yan",
            "Guoliang Kang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06818",
        "abstract": "Recent works modify CLIP to perform open-vocabulary semantic segmentation in a training-free manner (TF-OVSS). In CLIP, patch-wise image representations mainly encode the homogeneous image-level properties and thus are not discriminative enough, hindering its application to the dense prediction task. Previous works make image features more distinct across patches, through making each patch mainly attend to itself or the neighboring patches within a narrow local window. However, with their modifications, the ability of CLIP to aggregate global context information, which is known to be useful for distinguishing confusing categories, is largely weakened. In this paper, we propose a new method named GCLIP, which mines the beneficial global knowledge of CLIP to facilitate the TF-OVSS task. Firstly, we aim to equip the last-block attention with image-level properties while not introducing homogeneous attention patterns across patches. In GCLIP, we merge the attention from the global token emerging blocks with the Query-Query attention to realize this goal. Secondly, we aim to make the Value embeddings of the last-block attention module more distinct and semantically correlated. To realize this, we design a novel channel suppression strategy. As the representation of each patch is finally determined by the attention weights and the Value embeddings, our method can generate more discriminative patch-level image features while absorbing global context information. Extensive experiments on five standard benchmarks demonstrate that our method consistently outperforms previous state-of-the-arts.",
        "tags": [
            "CLIP",
            "Segmentation"
        ]
    },
    {
        "id": "10",
        "title": "Functional 3D Scene Synthesis through Human-Scene Optimization",
        "author": [
            "Yao Wei",
            "Matteo Toso",
            "Pietro Morerio",
            "Michael Ying Yang",
            "Alessio Del Bue"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06819",
        "abstract": "This paper presents a novel generative approach that outputs 3D indoor environments solely from a textual description of the scene. Current methods often treat scene synthesis as a mere layout prediction task, leading to rooms with overlapping objects or overly structured scenes, with limited consideration of the practical usability of the generated environment. Instead, our approach is based on a simple, but effective principle: we condition scene synthesis to generate rooms that are usable by humans. This principle is implemented by synthesizing 3D humans that interact with the objects composing the scene. If this human-centric scene generation is viable, the room layout is functional and it leads to a more coherent 3D structure. To this end, we propose a novel method for functional 3D scene synthesis, which consists of reasoning, 3D assembling and optimization. We regard text guided 3D synthesis as a reasoning process by generating a scene graph via a graph diffusion network. Considering object functional co-occurrence, a new strategy is designed to better accommodate human-object interaction and avoidance, achieving human-aware 3D scene optimization. We conduct both qualitative and quantitative experiments to validate the effectiveness of our method in generating coherent 3D scene synthesis results.",
        "tags": [
            "3D",
            "Diffusion"
        ]
    },
    {
        "id": "11",
        "title": "LoCA: Location-Aware Cosine Adaptation for Parameter-Efficient Fine-Tuning",
        "author": [
            "Zhekai Du",
            "Yinjie Min",
            "Jingjing Li",
            "Ke Lu",
            "Changliang Zou",
            "Liuhua Peng",
            "Tingjin Chu",
            "Mingming Gong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06820",
        "abstract": "Low-rank adaptation (LoRA) has become a prevalent method for adapting pre-trained large language models to downstream tasks. However, the simple low-rank decomposition form may constrain the hypothesis space. To address this limitation, we introduce Location-aware Cosine Adaptation (LoCA), a novel frequency-domain parameter-efficient fine-tuning method based on inverse Discrete Cosine Transform (iDCT) with selective locations of learnable components. We begin with a comprehensive theoretical comparison between frequency-domain and low-rank decompositions for fine-tuning pre-trained large models. Our analysis reveals that frequency-domain approximation with carefully selected frequency components can surpass the expressivity of traditional low-rank-based methods. Furthermore, we demonstrate that iDCT offers a more efficient implementation compared to inverse Discrete Fourier Transform (iDFT), allowing for better selection and tuning of frequency components while maintaining equivalent expressivity to the optimal iDFT-based adaptation. By employing finite-difference approximation to estimate gradients for discrete locations of learnable coefficients on the DCT spectrum, LoCA dynamically selects the most informative frequency components during training. Experiments on diverse language and vision fine-tuning tasks demonstrate that LoCA offers enhanced parameter efficiency while maintains computational feasibility comparable to low-rank-based methods.",
        "tags": [
            "Large Language Models",
            "LoRA",
            "Low-Rank Adaptation"
        ]
    },
    {
        "id": "12",
        "title": "DiffListener: Discrete Diffusion Model for Listener Generation",
        "author": [
            "Siyeol Jung",
            "Taehwan Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06822",
        "abstract": "The listener head generation (LHG) task aims to generate natural nonverbal listener responses based on the speaker's multimodal cues. While prior work either rely on limited modalities (e.g. audio and facial information) or employ autoregressive approaches which have limitations such as accumulating prediction errors. To address these limitations, we propose DiffListener, a discrete diffusion based approach for non-autoregressive listener head generation. Our model takes the speaker's facial information, audio, and text as inputs, additionally incorporating facial differential information to represent the temporal dynamics of expressions and movements. With this explicit modeling of facial dynamics, DiffListener can generate coherent reaction sequences in a non-autoregressive manner. Through comprehensive experiments, DiffListener demonstrates state-of-the-art performance in both quantitative and qualitative evaluations. The user study shows that DiffListener generates natural context-aware listener reactions that are well synchronized with the speaker. The code and demo videos are available in https://siyeoljung.github.io/DiffListener",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "13",
        "title": "CTR-Driven Advertising Image Generation with Multimodal Large Language Models",
        "author": [
            "Xingye Chen",
            "Wei Feng",
            "Zhenbang Du",
            "Weizhen Wang",
            "Yanyin Chen",
            "Haohan Wang",
            "Linkai Liu",
            "Yaoyu Li",
            "Jinyuan Zhao",
            "Yu Li",
            "Zheng Zhang",
            "Jingjing Lv",
            "Junjie Shen",
            "Zhangang Lin",
            "Jingping Shao",
            "Yuanjie Shao",
            "Xinge You",
            "Changxin Gao",
            "Nong Sang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06823",
        "abstract": "In web data, advertising images are crucial for capturing user attention and improving advertising effectiveness. Most existing methods generate background for products primarily focus on the aesthetic quality, which may fail to achieve satisfactory online performance. To address this limitation, we explore the use of Multimodal Large Language Models (MLLMs) for generating advertising images by optimizing for Click-Through Rate (CTR) as the primary objective. Firstly, we build targeted pre-training tasks, and leverage a large-scale e-commerce multimodal dataset to equip MLLMs with initial capabilities for advertising image generation tasks. To further improve the CTR of generated images, we propose a novel reward model to fine-tune pre-trained MLLMs through Reinforcement Learning (RL), which can jointly utilize multimodal features and accurately reflect user click preferences. Meanwhile, a product-centric preference optimization strategy is developed to ensure that the generated background content aligns with the product characteristics after fine-tuning, enhancing the overall relevance and effectiveness of the advertising images. Extensive experiments have demonstrated that our method achieves state-of-the-art performance in both online and offline metrics. Our code and pre-trained models are publicly available at: https://github.com/Chenguoz/CAIG.",
        "tags": [
            "Large Language Models",
            "RL"
        ]
    },
    {
        "id": "14",
        "title": "Entropy Adaptive Decoding: Dynamic Model Switching for Efficient Inference",
        "author": [
            "Toby Simonds"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06833",
        "abstract": "We present Entropy Adaptive Decoding (EAD), a novel approach for efficient language model inference that dynamically switches between different-sized models based on prediction uncertainty. By monitoring rolling entropy in model logit distributions, our method identifies text regions where a smaller model suffices and switches to a larger model only when prediction uncertainty exceeds a threshold. Unlike speculative decoding approaches that maintain perfect output fidelity through verification, EAD accepts controlled output divergence in exchange for computational efficiency. Our experiments on the MATH benchmark demonstrate remarkable efficiency gains across different model families. Using the LLaMA family, we maintain 96.7\\% of the 11B model's performance (50.4\\% vs 52.1\\%) while using it for only 43\\% of tokens, decreasing computational cost by 41.5\\%. These gains become more pronounced with larger size differentials in the Qwen family, where we achieve 92.9\\% of the 14B model's performance (74.3\\% vs 80.0\\%) while using it for just 25\\% of tokens, decreasing computational cost by 67\\%. The consistency of these results across model pairs suggests that language model computation can be significantly optimized by selectively deploying model capacity based on local generation complexity. Our findings indicate that current approaches to model inference may be unnecessarily conservative in their pursuit of perfect output fidelity, and that accepting minor performance trade-offs can enable dramatic reductions in computational costs.",
        "tags": [
            "LLaMA",
            "Qwen"
        ]
    },
    {
        "id": "15",
        "title": "TorchResist: Open-Source Differentiable Resist Simulator",
        "author": [
            "Zixiao Wang",
            "Jieya Zhou",
            "Su Zheng",
            "Shuo Yin",
            "Kaichao Liang",
            "Shoubo Hu",
            "Xiao Chen",
            "Bei Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06838",
        "abstract": "Recent decades have witnessed remarkable advancements in artificial intelligence (AI), including large language models (LLMs), image and video generative models, and embodied AI systems. These advancements have led to an explosive increase in the demand for computational power, challenging the limits of Moore's Law. Optical lithography, a critical technology in semiconductor manufacturing, faces significant challenges due to its high costs. To address this, various lithography simulators have been developed. However, many of these simulators are limited by their inadequate photoresist modeling capabilities. This paper presents TorchResist, an open-source, differentiable photoresist http://simulator.TorchResist employs an analytical approach to model the photoresist process, functioning as a white-box system with at most twenty interpretable parameters. Leveraging modern differentiable programming techniques and parallel computing on GPUs, TorchResist enables seamless co-optimization with other tools across multiple related tasks. Our experimental results demonstrate that TorchResist achieves superior accuracy and efficiency compared to existing solutions. The source code is publicly available.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "16",
        "title": "Vision-Integrated LLMs for Autonomous Driving Assistance : Human Performance Comparison and Trust Evaluation",
        "author": [
            "Namhee Kim",
            "Woojin Park"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06843",
        "abstract": "Traditional autonomous driving systems often struggle with reasoning in complex, unexpected scenarios due to limited comprehension of spatial relationships. In response, this study introduces a Large Language Model (LLM)-based Autonomous Driving (AD) assistance system that integrates a vision adapter and an LLM reasoning module to enhance visual understanding and decision-making. The vision adapter, combining YOLOv4 and Vision Transformer (ViT), extracts comprehensive visual features, while GPT-4 enables human-like spatial reasoning and response generation. Experimental evaluations with 45 experienced drivers revealed that the system closely mirrors human performance in describing situations and moderately aligns with human decisions in generating appropriate responses.",
        "tags": [
            "GPT",
            "LLMs",
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "17",
        "title": "Exploring Model Invariance with Discrete Search for Ultra-Low-Bit Quantization",
        "author": [
            "Yuqiao Wen",
            "Yanshuai Cao",
            "Lili Mou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06844",
        "abstract": "Large language models have been increasing in size due to their success in a wide range of applications. This calls for a pressing need to reduce memory usage to make them more accessible. Post-training quantization is a popular technique which uses fewer bits (e.g., 4--8 bits) to represent the model without retraining it. However, it remains a challenging task to perform quantization in an ultra-low-bit setup (e.g., 2 bits). In this paper, we propose InvarExplore, a unified framework that systematically explores different model invariance at the same time, allowing us to take advantage of the synergy between each type of invariance. Importantly, InvarExplore features a discrete search algorithm that enables us to explore permutation invariance, which is under-studied as it cannot be optimized with gradient-based methods. Results show that InvarExplore is compatible with existing state-of-the-art methods, achieving an add-on performance improvement over strong competing methods.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "18",
        "title": "A Deep Learning Framework Integrating CNN and BiLSTM for Financial Systemic Risk Analysis and Prediction",
        "author": [
            "Yu Cheng",
            "Zhen Xu",
            "Yuan Chen",
            "Yuhan Wang",
            "Zhenghao Lin",
            "Jinsong Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06847",
        "abstract": "This study proposes a deep learning model based on the combination of convolutional neural network (CNN) and bidirectional long short-term memory network (BiLSTM) for discriminant analysis of financial systemic risk. The model first uses CNN to extract local patterns of multidimensional features of financial markets, and then models the bidirectional dependency of time series through BiLSTM, to comprehensively characterize the changing laws of systemic risk in spatial features and temporal dynamics. The experiment is based on real financial data sets. The results show that the model is significantly superior to traditional single models (such as BiLSTM, CNN, Transformer, and TCN) in terms of accuracy, recall, and F1 score. The F1-score reaches 0.88, showing extremely high discriminant ability. This shows that the joint strategy of combining CNN and BiLSTM can not only fully capture the complex patterns of market data but also effectively deal with the long-term dependency problem in time series data. In addition, this study also explores the robustness of the model in dealing with data noise and processing high-dimensional data, providing strong support for intelligent financial risk management. In the future, the research will further optimize the model structure, introduce methods such as reinforcement learning and multimodal data analysis, and improve the efficiency and generalization ability of the model to cope with a more complex financial environment.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "19",
        "title": "Survey on Vision-Language-Action Models",
        "author": [
            "Adilzhan Adilkhanov",
            "Amir Yelenov",
            "Assylkhan Seitzhanov",
            "Ayan Mazhitov",
            "Azamat Abdikarimov",
            "Danissa Sandykbayeva",
            "Daryn Kenzhebek",
            "Daulet Baimukashev",
            "Dinmukhammed Mukashev",
            "Ilyas Umurbekov",
            "Jabrail Chumakov",
            "Kamila Spanova",
            "Karina Burunchina",
            "Rasul Yermagambet",
            "Rustam Chibar",
            "Saltanat Seitzhan",
            "Soibkhon Khajikhanov",
            "Tasbolat Taunyazov",
            "Temirlan Galimzhanov",
            "Temirlan Kaiyrbay",
            "Tleukhan Mussin",
            "Togzhan Syrymova",
            "Valeriya Kostyukova",
            "Yermakhan Kassym",
            "Madina Yergibay",
            "Margulan Issa",
            "Moldir Zabirova",
            "Nurdaulet Zhuzbay",
            "Nurlan Kabdyshev",
            "Nurlan Zhaniyar",
            "Yerkebulan Massalim",
            "Zerde Nurbayeva",
            "Zhanat Kappassov"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06851",
        "abstract": "This paper presents an AI-generated review of Vision-Language-Action (VLA) models, summarizing key methodologies, findings, and future directions. The content is produced using large language models (LLMs) and is intended only for demonstration purposes. This work does not represent original research, but highlights how AI can help automate literature reviews. As AI-generated content becomes more prevalent, ensuring accuracy, reliability, and proper synthesis remains a challenge. Future research will focus on developing a structured framework for AI-assisted literature reviews, exploring techniques to enhance citation accuracy, source credibility, and contextual understanding. By examining the potential and limitations of LLM in academic writing, this study aims to contribute to the broader discussion of integrating AI into research workflows. This work serves as a preliminary step toward establishing systematic approaches for leveraging AI in literature review generation, making academic knowledge synthesis more efficient and scalable.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "20",
        "title": "EAP-GP: Mitigating Saturation Effect in Gradient-based Automated Circuit Identification",
        "author": [
            "Lin Zhang",
            "Wenshuo Dong",
            "Zhuoran Zhang",
            "Shu Yang",
            "Lijie Hu",
            "Ninghao Liu",
            "Pan Zhou",
            "Di Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06852",
        "abstract": "Understanding the internal mechanisms of transformer-based language models remains challenging. Mechanistic interpretability based on circuit discovery aims to reverse engineer neural networks by analyzing their internal processes at the level of computational subgraphs. In this paper, we revisit existing gradient-based circuit identification methods and find that their performance is either affected by the zero-gradient problem or saturation effects, where edge attribution scores become insensitive to input changes, resulting in noisy and unreliable attribution evaluations for circuit components. To address the saturation effect, we propose Edge Attribution Patching with GradPath (EAP-GP), EAP-GP introduces an integration path, starting from the input and adaptively following the direction of the difference between the gradients of corrupted and clean inputs to avoid the saturated region. This approach enhances attribution reliability and improves the faithfulness of circuit identification. We evaluate EAP-GP on 6 datasets using GPT-2 Small, GPT-2 Medium, and GPT-2 XL. Experimental results demonstrate that EAP-GP outperforms existing methods in circuit faithfulness, achieving improvements up to 17.7%. Comparisons with manually annotated ground-truth circuits demonstrate that EAP-GP achieves precision and recall comparable to or better than previous approaches, highlighting its effectiveness in identifying accurate circuits.",
        "tags": [
            "GPT",
            "Transformer"
        ]
    },
    {
        "id": "21",
        "title": "Native Fortran Implementation of TensorFlow-Trained Deep and Bayesian Neural Networks",
        "author": [
            "Aidan Furlong",
            "Xingang Zhao",
            "Bob Salko",
            "Xu Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06853",
        "abstract": "Over the past decade, the investigation of machine learning (ML) within the field of nuclear engineering has grown significantly. With many approaches reaching maturity, the next phase of investigation will determine the feasibility and usefulness of ML model implementation in a production setting. Several of the codes used for reactor design and assessment are primarily written in the Fortran language, which is not immediately compatible with TensorFlow-trained ML models. This study presents a framework for implementing deep neural networks (DNNs) and Bayesian neural networks (BNNs) in Fortran, allowing for native execution without TensorFlow's C API, Python runtime, or ONNX conversion. Designed for ease of use and computational efficiency, the framework can be implemented in any Fortran code, supporting iterative solvers and UQ via ensembles or BNNs. Verification was performed using a two-input, one-output test case composed of a noisy sinusoid to compare Fortran-based predictions to those from TensorFlow. The DNN predictions showed negligible differences and achieved a 19.6x speedup, whereas the BNN predictions exhibited minor disagreement, plausibly due to differences in random number generation. An 8.0x speedup was noted for BNN inference. The approach was then further verified on a nuclear-relevant problem predicting critical heat flux (CHF), which demonstrated similar behavior along with significant computational gains. Discussion regarding the framework's successful integration into the CTF thermal-hydraulics code is also included, outlining its practical usefulness. Overall, this framework was shown to be effective at implementing both DNN and BNN model inference within Fortran, allowing for the continued study of ML-based methods in real-world nuclear applications.",
        "tags": [
            "FLUX"
        ]
    },
    {
        "id": "22",
        "title": "Can Large Language Models Understand Intermediate Representations?",
        "author": [
            "Hailong Jiang",
            "Jianfeng Zhu",
            "Yao Wan",
            "Bo Fang",
            "Hongyu Zhang",
            "Ruoming Jin",
            "Qiang Guan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06854",
        "abstract": "Intermediate Representations (IRs) are essential in compiler design and program analysis, yet their comprehension by Large Language Models (LLMs) remains underexplored. This paper presents a pioneering empirical study to investigate the capabilities of LLMs, including GPT-4, GPT-3, Gemma 2, LLaMA 3.1, and Code Llama, in understanding IRs. We analyze their performance across four tasks: Control Flow Graph (CFG) reconstruction, decompilation, code summarization, and execution reasoning. Our results indicate that while LLMs demonstrate competence in parsing IR syntax and recognizing high-level structures, they struggle with control flow reasoning, execution semantics, and loop handling. Specifically, they often misinterpret branching instructions, omit critical IR operations, and rely on heuristic-based reasoning, leading to errors in CFG reconstruction, IR decompilation, and execution reasoning. The study underscores the necessity for IR-specific enhancements in LLMs, recommending fine-tuning on structured IR datasets and integration of explicit control flow models to augment their comprehension and handling of IR-related tasks.",
        "tags": [
            "GPT",
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "23",
        "title": "Self-Supervised Prompt Optimization",
        "author": [
            "Jinyu Xiang",
            "Jiayi Zhang",
            "Zhaoyang Yu",
            "Fengwei Teng",
            "Jinhao Tu",
            "Xinbing Liang",
            "Sirui Hong",
            "Chenglin Wu",
            "Yuyu Luo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06855",
        "abstract": "Well-designed prompts are crucial for enhancing Large language models' (LLMs) reasoning capabilities while aligning their outputs with task requirements across diverse domains. However, manually designed prompts require expertise and iterative experimentation. While existing prompt optimization methods aim to automate this process, they rely heavily on external references such as ground truth or by humans, limiting their applicability in real-world scenarios where such data is unavailable or costly to obtain. To address this, we propose Self-Supervised Prompt Optimization (SPO), a cost-efficient framework that discovers effective prompts for both closed and open-ended tasks without requiring external reference. Motivated by the observations that prompt quality manifests directly in LLM outputs and LLMs can effectively assess adherence to task requirements, we derive evaluation and optimization signals purely from output comparisons. Specifically, SPO selects superior prompts through pairwise output comparisons evaluated by an LLM evaluator, followed by an LLM optimizer that aligns outputs with task requirements. Extensive experiments demonstrate that SPO outperforms state-of-the-art prompt optimization methods, achieving comparable or superior results with significantly lower costs (e.g., 1.1% to 5.6% of existing methods) and fewer samples (e.g., three samples). The code is available at https://github.com/geekan/MetaGPT.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "24",
        "title": "LLM-Supported Natural Language to Bash Translation",
        "author": [
            "Finnian Westenfelder",
            "Erik Hemberg",
            "Miguel Tulla",
            "Stephen Moskal",
            "Una-May O'Reilly",
            "Silviu Chiricescu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06858",
        "abstract": "The Bourne-Again Shell (Bash) command-line interface for Linux systems has complex syntax and requires extensive specialized knowledge. Using the natural language to Bash command (NL2SH) translation capabilities of large language models (LLMs) for command composition circumvents these issues. However, the NL2SH performance of LLMs is difficult to assess due to inaccurate test data and unreliable heuristics for determining the functional equivalence of Bash commands. We present a manually verified test dataset of 600 instruction-command pairs and a training dataset of 40,939 pairs, increasing the size of previous datasets by 441% and 135%, respectively. Further, we present a novel functional equivalence heuristic that combines command execution with LLM evaluation of command outputs. Our heuristic can determine the functional equivalence of two Bash commands with 95% confidence, a 16% increase over previous heuristics. Evaluation of popular LLMs using our test dataset and heuristic demonstrates that parsing, in-context learning, in-weight learning, and constrained decoding can improve NL2SH accuracy by up to 32%. Our findings emphasize the importance of dataset quality, execution-based evaluation and translation method for advancing NL2SH translation. Our code is available at https://github.com/westenfelder/NL2SH",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "25",
        "title": "AutoSketch: VLM-assisted Style-Aware Vector Sketch Completion",
        "author": [
            "Hsiao-Yuan Chin",
            "I-Chao Shen",
            "Yi-Ting Chiu",
            "Bing-Yu Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06860",
        "abstract": "The ability to automatically complete a partial sketch that depicts a complex scene, e.g., \"a woman chatting with a man in the park\", is very useful. However, existing sketch generation methods create sketches from scratch; they do not complete a partial sketch in the style of the original. To address this challenge, we introduce AutoSketch, a styleaware vector sketch completion method that accommodates diverse sketch styles. Our key observation is that the style descriptions of a sketch in natural language preserve the style during automatic sketch completion. Thus, we use a pretrained vision-language model (VLM) to describe the styles of the partial sketches in natural language and replicate these styles using newly generated strokes. We initially optimize the strokes to match an input prompt augmented by style descriptions extracted from the VLM. Such descriptions allow the method to establish a diffusion prior in close alignment with that of the partial sketch. Next, we utilize the VLM to generate an executable style adjustment code that adjusts the strokes to conform to the desired style. We compare our method with existing methods across various sketch styles and prompts, performed extensive ablation studies and qualitative and quantitative evaluations, and demonstrate that AutoSketch can support various sketch scenarios.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "26",
        "title": "PoincarÃ© Inequality for Local Log-Polyak-Lojasiewicz Measures : Non-asymptotic Analysis in Low-temperature Regime",
        "author": [
            "Yun Gong",
            "Zebang Shen",
            "Niao He"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06862",
        "abstract": "Potential functions in highly pertinent applications, such as deep learning in over-parameterized regime, are empirically observed to admit non-isolated minima. To understand the convergence behavior of stochastic dynamics in such landscapes, we propose to study the class of \\logPLmeasure\\ measures $\\mu_\\epsilon \\propto \\exp(-V/\\epsilon)$, where the potential $V$ satisfies a local Polyak-Åojasiewicz (PÅ) inequality, and its set of local minima is provably \\emph{connected}. Notably, potentials in this class can exhibit local maxima and we characterize its optimal set S to be a compact $\\mathcal{C}^2$ \\emph{embedding submanifold} of $\\mathbb{R}^d$ without boundary. The \\emph{non-contractibility} of S distinguishes our function class from the classical convex setting topologically. Moreover, the embedding structure induces a naturally defined Laplacian-Beltrami operator on S, and we show that its first non-trivial eigenvalue provides an \\emph{$\\epsilon$-independent} lower bound for the \\Poincare\\ constant in the \\Poincare\\ inequality of $\\mu_\\epsilon$. As a direct consequence, Langevin dynamics with such non-convex potential $V$ and diffusion coefficient $\\epsilon$ converges to its equilibrium $\\mu_\\epsilon$ at a rate of $\\tilde{\\mathcal{O}}(1/\\epsilon)$, provided $\\epsilon$ is sufficiently small. Here $\\tilde{\\mathcal{O}}$ hides logarithmic terms.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "27",
        "title": "BF-GAN: Development of an AI-driven Bubbly Flow Image Generation Model Using Generative Adversarial Networks",
        "author": [
            "Wen Zhou",
            "Shuichiro Miwa",
            "Yang Liu",
            "Koji Okamoto"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06863",
        "abstract": "A generative AI architecture called bubbly flow generative adversarial networks (BF-GAN) is developed, designed to generate realistic and high-quality bubbly flow images through physically conditioned inputs, jg and jf. Initially, 52 sets of bubbly flow experiments under varying conditions are conducted to collect 140,000 bubbly flow images with physical labels of jg and jf for training data. A multi-scale loss function is then developed, incorporating mismatch loss and pixel loss to enhance the generative performance of BF-GAN further. Regarding evaluative metrics of generative AI, the BF-GAN has surpassed conventional GAN. Physically, key parameters of bubbly flow generated by BF-GAN are extracted and compared with measurement values and empirical correlations, validating BF-GAN's generative performance. The comparative analysis demonstrate that the BF-GAN can generate realistic and high-quality bubbly flow images with any given jg and jf within the research scope.\nBF-GAN offers a generative AI solution for two-phase flow research, substantially lowering the time and cost required to obtain high-quality data. In addition, it can function as a benchmark dataset generator for bubbly flow detection and segmentation algorithms, enhancing overall productivity in this research domain. The BF-GAN model is available online (https://github.com/zhouzhouwen/BF-GAN).",
        "tags": [
            "Detection",
            "GAN",
            "Segmentation"
        ]
    },
    {
        "id": "28",
        "title": "Knowledge Graph-Guided Retrieval Augmented Generation",
        "author": [
            "Xiangrong Zhu",
            "Yuexiang Xie",
            "Yi Liu",
            "Yaliang Li",
            "Wei Hu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06864",
        "abstract": "Retrieval-augmented generation (RAG) has emerged as a promising technology for addressing hallucination issues in the responses generated by large language models (LLMs). Existing studies on RAG primarily focus on applying semantic-based approaches to retrieve isolated relevant chunks, which ignore their intrinsic relationships. In this paper, we propose a novel Knowledge Graph-Guided Retrieval Augmented Generation (KG$^2$RAG) framework that utilizes knowledge graphs (KGs) to provide fact-level relationships between chunks, improving the diversity and coherence of the retrieved results. Specifically, after performing a semantic-based retrieval to provide seed chunks, KG$^2$RAG employs a KG-guided chunk expansion process and a KG-based chunk organization process to deliver relevant and important knowledge in well-organized paragraphs. Extensive experiments conducted on the HotpotQA dataset and its variants demonstrate the advantages of KG$^2$RAG compared to existing RAG-based approaches, in terms of both response quality and retrieval quality.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "29",
        "title": "Forbidden Science: Dual-Use AI Challenge Benchmark and Scientific Refusal Tests",
        "author": [
            "David Noever",
            "Forrest McKee"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06867",
        "abstract": "The development of robust safety benchmarks for large language models requires open, reproducible datasets that can measure both appropriate refusal of harmful content and potential over-restriction of legitimate scientific discourse. We present an open-source dataset and testing framework for evaluating LLM safety mechanisms across mainly controlled substance queries, analyzing four major models' responses to systematically varied prompts. Our results reveal distinct safety profiles: Claude-3.5-sonnet demonstrated the most conservative approach with 73% refusals and 27% allowances, while Mistral attempted to answer 100% of queries. GPT-3.5-turbo showed moderate restriction with 10% refusals and 90% allowances, and Grok-2 registered 20% refusals and 80% allowances. Testing prompt variation strategies revealed decreasing response consistency, from 85% with single prompts to 65% with five variations. This publicly available benchmark enables systematic evaluation of the critical balance between necessary safety restrictions and potential over-censorship of legitimate scientific inquiry, while providing a foundation for measuring progress in AI safety implementation. Chain-of-thought analysis reveals potential vulnerabilities in safety mechanisms, highlighting the complexity of implementing robust safeguards without unduly restricting desirable and valid scientific discourse.",
        "tags": [
            "GPT",
            "Large Language Models"
        ]
    },
    {
        "id": "30",
        "title": "Related Knowledge Perturbation Matters: Rethinking Multiple Pieces of Knowledge Editing in Same-Subject",
        "author": [
            "Zenghao Duan",
            "Wenbin Duan",
            "Zhiyi Yin",
            "Yinghan Shen",
            "Shaoling Jing",
            "Jie Zhang",
            "Huawei Shen",
            "Xueqi Cheng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06868",
        "abstract": "Knowledge editing has become a promising approach for efficiently and precisely updating knowledge embedded in large language models (LLMs). In this work, we focus on Same-Subject Editing, which involves modifying multiple attributes of a single entity to ensure comprehensive and consistent updates to entity-centric knowledge. Through preliminary observation, we identify a significant challenge: Current state-of-the-art editing methods struggle when tasked with editing multiple related knowledge pieces for the same subject. To address the lack of relevant editing data for identical subjects in traditional benchmarks, we introduce the $\\text{S}^2\\text{RKE}$(Same-Subject Related Knowledge Editing) benchmark. Our extensive experiments reveal that only mainstream locate-then-edit methods, such as ROME and MEMIT, exhibit \"related knowledge perturbation,\" where subsequent edits interfere with earlier ones. Further analysis reveals that these methods over-rely on subject information, neglecting other critical factors, resulting in reduced editing effectiveness.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "31",
        "title": "A Survey on Explainable Deep Reinforcement Learning",
        "author": [
            "Zelei Cheng",
            "Jiahao Yu",
            "Xinyu Xing"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06869",
        "abstract": "Deep Reinforcement Learning (DRL) has achieved remarkable success in sequential decision-making tasks across diverse domains, yet its reliance on black-box neural architectures hinders interpretability, trust, and deployment in high-stakes applications. Explainable Deep Reinforcement Learning (XRL) addresses these challenges by enhancing transparency through feature-level, state-level, dataset-level, and model-level explanation techniques. This survey provides a comprehensive review of XRL methods, evaluates their qualitative and quantitative assessment frameworks, and explores their role in policy refinement, adversarial robustness, and security. Additionally, we examine the integration of reinforcement learning with Large Language Models (LLMs), particularly through Reinforcement Learning from Human Feedback (RLHF), which optimizes AI alignment with human preferences. We conclude by highlighting open research challenges and future directions to advance the development of interpretable, reliable, and accountable DRL systems.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "32",
        "title": "Bridging Traffic State and Trajectory for Dynamic Road Network and Trajectory Representation Learning",
        "author": [
            "Chengkai Han",
            "Jingyuan Wang",
            "Yongyao Wang",
            "Xie Yu",
            "Hao Lin",
            "Chao Li",
            "Junjie Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06870",
        "abstract": "Effective urban traffic management is vital for sustainable city development, relying on intelligent systems with machine learning tasks such as traffic flow prediction and travel time estimation. Traditional approaches usually focus on static road network and trajectory representation learning, and overlook the dynamic nature of traffic states and trajectories, which is crucial for downstream tasks. To address this gap, we propose TRACK, a novel framework to bridge traffic state and trajectory data for dynamic road network and trajectory representation learning. TRACK leverages graph attention networks (GAT) to encode static and spatial road segment features, and introduces a transformer-based model for trajectory representation learning. By incorporating transition probabilities from trajectory data into GAT attention weights, TRACK captures dynamic spatial features of road segments. Meanwhile, TRACK designs a traffic transformer encoder to capture the spatial-temporal dynamics of road segments from traffic state data. To further enhance dynamic representations, TRACK proposes a co-attentional transformer encoder and a trajectory-traffic state matching task. Extensive experiments on real-life urban traffic datasets demonstrate the superiority of TRACK over state-of-the-art baselines. Case studies confirm TRACK's ability to capture spatial-temporal dynamics effectively.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "33",
        "title": "FlavorDiffusion: Predicting Food Pairings and Chemical Interactions Using Diffusion Models",
        "author": [
            "Seo Jun Pyo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06871",
        "abstract": "The study of food pairing has evolved beyond subjective expertise with the advent of machine learning. This paper presents FlavorDiffusion, a novel framework leveraging diffusion models to predict food-chemical interactions and ingredient pairings without relying on chromatography. By integrating graph-based embeddings, diffusion processes, and chemical property encoding, FlavorDiffusion addresses data imbalances and enhances clustering quality. Using a heterogeneous graph derived from datasets like Recipe1M and FlavorDB, our model demonstrates superior performance in reconstructing ingredient-ingredient relationships. The addition of a Chemical Structure Prediction (CSP) layer further refines the embedding space, achieving state-of-the-art NMI scores and enabling meaningful discovery of novel ingredient combinations. The proposed framework represents a significant step forward in computational gastronomy, offering scalable, interpretable, and chemically informed solutions for food science.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "34",
        "title": "Multimodal Cognitive Reframing Therapy via Multi-hop Psychotherapeutic Reasoning",
        "author": [
            "Subin Kim",
            "Hoonrae Kim",
            "Heejin Do",
            "Gary Geunbae Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06873",
        "abstract": "Previous research has revealed the potential of large language models (LLMs) to support cognitive reframing therapy; however, their focus was primarily on text-based methods, often overlooking the importance of non-verbal evidence crucial in real-life therapy. To alleviate this gap, we extend the textual cognitive reframing to multimodality, incorporating visual clues. Specifically, we present a new dataset called Multi Modal-Cognitive Support Conversation (M2CoSC), which pairs each GPT-4-generated dialogue with an image that reflects the virtual client's facial expressions. To better mirror real psychotherapy, where facial expressions lead to interpreting implicit emotional evidence, we propose a multi-hop psychotherapeutic reasoning approach that explicitly identifies and incorporates subtle evidence. Our comprehensive experiments with both LLMs and vision-language models (VLMs) demonstrate that the VLMs' performance as psychotherapists is significantly improved with the M2CoSC dataset. Furthermore, the multi-hop psychotherapeutic reasoning method enables VLMs to provide more thoughtful and empathetic suggestions, outperforming standard prompting methods.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "35",
        "title": "Group Reasoning Emission Estimation Networks",
        "author": [
            "Yanming Guo",
            "Xiao Qian",
            "Kevin Credit",
            "Jin Ma"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06874",
        "abstract": "Accurate greenhouse gas (GHG) emission reporting is critical for governments, businesses, and investors. However, adoption remains limited particularly among small and medium enterprises due to high implementation costs, fragmented emission factor databases, and a lack of robust sector classification methods. To address these challenges, we introduce Group Reasoning Emission Estimation Networks (GREEN), an AI-driven carbon accounting framework that standardizes enterprise-level emission estimation, constructs a large-scale benchmark dataset, and leverages a novel reasoning approach with large language models (LLMs). Specifically, we compile textual descriptions for 20,850 companies with validated North American Industry Classification System (NAICS) labels and align these with an economic model of carbon intensity factors. By reframing sector classification as an information retrieval task, we fine-tune Sentence-BERT models using a contrastive learning loss. To overcome the limitations of single-stage models in handling thousands of hierarchical categories, we propose a Group Reasoning method that ensembles LLM classifiers based on the natural NAICS ontology, decomposing the task into multiple sub-classification steps. We theoretically prove that this approach reduces classification uncertainty and computational complexity. Experiments on 1,114 NAICS categories yield state-of-the-art performance (83.68% Top-1, 91.47% Top-10 accuracy), and case studies on 20 companies report a mean absolute percentage error (MAPE) of 45.88%. The project is available at: https://huggingface.co/datasets/Yvnminc/ExioNAICS.",
        "tags": [
            "BERT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "36",
        "title": "Beyond Vision: How Large Language Models Interpret Facial Expressions from Valence-Arousal Values",
        "author": [
            "Vaibhav Mehra",
            "Guy Laban",
            "Hatice Gunes"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06875",
        "abstract": "Large Language Models primarily operate through text-based inputs and outputs, yet human emotion is communicated through both verbal and non-verbal cues, including facial expressions. While Vision-Language Models analyze facial expressions from images, they are resource-intensive and may depend more on linguistic priors than visual understanding. To address this, this study investigates whether LLMs can infer affective meaning from dimensions of facial expressions-Valence and Arousal values, structured numerical representations, rather than using raw visual input. VA values were extracted using Facechannel from images of facial expressions and provided to LLMs in two tasks: (1) categorizing facial expressions into basic (on the IIMI dataset) and complex emotions (on the Emotic dataset) and (2) generating semantic descriptions of facial expressions (on the Emotic dataset). Results from the categorization task indicate that LLMs struggle to classify VA values into discrete emotion categories, particularly for emotions beyond basic polarities (e.g., happiness, sadness). However, in the semantic description task, LLMs produced textual descriptions that align closely with human-generated interpretations, demonstrating a stronger capacity for free text affective inference of facial expressions.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "37",
        "title": "Mix Data or Merge Models? Balancing the Helpfulness, Honesty, and Harmlessness of Large Language Model via Model Merging",
        "author": [
            "Jinluan Yang",
            "Dingnan Jin",
            "Anke Tang",
            "Li Shen",
            "Didi Zhu",
            "Zhengyu Chen",
            "Daixin Wang",
            "Qing Cui",
            "Zhiqiang Zhang",
            "Jun Zhou",
            "Fei Wu",
            "Kun Kuang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06876",
        "abstract": "Achieving balanced alignment of large language models (LLMs) in terms of Helpfulness, Honesty, and Harmlessness (3H optimization) constitutes a cornerstone of responsible AI, with existing methods like data mixture strategies facing limitations including reliance on expert knowledge and conflicting optimization signals. While model merging offers a promising alternative by integrating specialized models, its potential for 3H optimization remains underexplored. This paper establishes the first comprehensive benchmark for model merging in 3H-aligned LLMs, systematically evaluating 15 methods (12 training-free merging and 3 data mixture techniques) across 10 datasets associated with 5 annotation dimensions, 2 LLM families, and 2 training paradigms. Our analysis reveals three pivotal insights: (i) previously overlooked collaborative/conflicting relationships among 3H dimensions, (ii) the consistent superiority of model merging over data mixture approaches in balancing alignment trade-offs, and (iii) the critical role of parameter-level conflict resolution through redundant component pruning and outlier mitigation. Building on these findings, we propose R-TSVM, a Reweighting-enhanced Task Singular Vector Merging method that incorporates outlier-aware parameter weighting and sparsity-adaptive rank selection strategies adapted to the heavy-tailed parameter distribution and sparsity for LLMs, further improving LLM alignment across multiple evaluations. Our models will be available at https://huggingface.co/Jinluan.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "38",
        "title": "Multi-Agent Simulator Drives Language Models for Legal Intensive Interaction",
        "author": [
            "Shengbin Yue",
            "Ting Huang",
            "Zheng Jia",
            "Siyuan Wang",
            "Shujun Liu",
            "Yun Song",
            "Xuanjing Huang",
            "Zhongyu Wei"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06882",
        "abstract": "Large Language Models (LLMs) have significantly advanced legal intelligence, but the scarcity of scenario data impedes the progress toward interactive legal scenarios. This paper introduces a Multi-agent Legal Simulation Driver (MASER) to scalably generate synthetic data by simulating interactive legal scenarios. Leveraging real-legal case sources, MASER ensures the consistency of legal attributes between participants and introduces a supervisory mechanism to align participants' characters and behaviors as well as addressing distractions. A Multi-stage Interactive Legal Evaluation (MILE) benchmark is further constructed to evaluate LLMs' performance in dynamic legal scenarios. Extensive experiments confirm the effectiveness of our framework.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "39",
        "title": "Learning Conformal Abstention Policies for Adaptive Risk Management in Large Language and Vision-Language Models",
        "author": [
            "Sina Tayebati",
            "Divake Kumar",
            "Nastaran Darabi",
            "Dinithi Jayasuriya",
            "Ranganath Krishnan",
            "Amit Ranjan Trivedi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06884",
        "abstract": "Large Language and Vision-Language Models (LLMs/VLMs) are increasingly used in safety-critical applications, yet their opaque decision-making complicates risk assessment and reliability. Uncertainty quantification (UQ) helps assess prediction confidence and enables abstention when uncertainty is high. Conformal prediction (CP), a leading UQ method, provides statistical guarantees but relies on static thresholds, which fail to adapt to task complexity and evolving data distributions, leading to suboptimal trade-offs in accuracy, coverage, and informativeness. To address this, we propose learnable conformal abstention, integrating reinforcement learning (RL) with CP to optimize abstention thresholds dynamically. By treating CP thresholds as adaptive actions, our approach balances multiple objectives, minimizing prediction set size while maintaining reliable coverage. Extensive evaluations across diverse LLM/VLM benchmarks show our method outperforms Least Ambiguous Classifiers (LAC) and Adaptive Prediction Sets (APS), improving accuracy by up to 3.2%, boosting AUROC for hallucination detection by 22.19%, enhancing uncertainty-guided selective generation (AUARC) by 21.17%, and reducing calibration error by 70%-85%. These improvements hold across multiple models and datasets while consistently meeting the 90% coverage target, establishing our approach as a more effective and flexible solution for reliable decision-making in safety-critical applications. The code is available at: {https://github.com/sinatayebati/vlm-uncertainty}.",
        "tags": [
            "Detection",
            "LLMs",
            "RL"
        ]
    },
    {
        "id": "40",
        "title": "Topological derivative approach for deep neural network architecture adaptation",
        "author": [
            "C G Krishnanunni",
            "Tan Bui-Thanh",
            "Clint Dawson"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06885",
        "abstract": "This work presents a novel algorithm for progressively adapting neural network architecture along the depth. In particular, we attempt to address the following questions in a mathematically principled way: i) Where to add a new capacity (layer) during the training process? ii) How to initialize the new capacity? At the heart of our approach are two key ingredients: i) the introduction of a ``shape functional\" to be minimized, which depends on neural network topology, and ii) the introduction of a topological derivative of the shape functional with respect to the neural network topology. Using an optimal control viewpoint, we show that the network topological derivative exists under certain conditions, and its closed-form expression is derived. In particular, we explore, for the first time, the connection between the topological derivative from a topology optimization framework with the Hamiltonian from optimal control theory. Further, we show that the optimality condition for the shape functional leads to an eigenvalue problem for deep neural architecture adaptation. Our approach thus determines the most sensitive location along the depth where a new layer needs to be inserted during the training phase and the associated parametric initialization for the newly added layer. We also demonstrate that our layer insertion strategy can be derived from an optimal transport viewpoint as a solution to maximizing a topological derivative in $p$-Wasserstein space, where $p>= 1$. Numerical investigations with fully connected network, convolutional neural network, and vision transformer on various regression and classification problems demonstrate that our proposed approach can outperform an ad-hoc baseline network and other architecture adaptation strategies. Further, we also demonstrate other applications of topological derivative in fields such as transfer learning.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "41",
        "title": "AI-Driven HSI: Multimodality, Fusion, Challenges, and the Deep Learning Revolution",
        "author": [
            "David S. Bhatti",
            "Yougin Choi",
            "Rahman S M Wahidur",
            "Maleeka Bakhtawar",
            "Sumin Kim",
            "Surin Lee",
            "Yongtae Lee",
            "Heung-No Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06894",
        "abstract": "Hyperspectral imaging (HSI) captures spatial and spectral data, enabling analysis of features invisible to conventional systems. The technology is vital in fields such as weather monitoring, food quality control, counterfeit detection, healthcare diagnostics, and extending into defense, agriculture, and industrial automation at the same time. HSI has advanced with improvements in spectral resolution, miniaturization, and computational methods. This study provides an overview of the HSI, its applications, challenges in data fusion and the role of deep learning models in processing HSI data. We discuss how integration of multimodal HSI with AI, particularly with deep learning, improves classification accuracy and operational efficiency. Deep learning enhances HSI analysis in areas like feature extraction, change detection, denoising unmixing, dimensionality reduction, landcover mapping, data augmentation, spectral construction and super resolution. An emerging focus is the fusion of hyperspectral cameras with large language models (LLMs), referred as highbrain LLMs, enabling the development of advanced applications such as low visibility crash detection and face antispoofing. We also highlight key players in HSI industry, its compound annual growth rate and the growing industrial significance. The purpose is to offer insight to both technical and non-technical audience, covering HSI's images, trends, and future directions, while providing valuable information on HSI datasets and software libraries.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models",
            "Super Resolution"
        ]
    },
    {
        "id": "42",
        "title": "PyPotteryInk: One-Step Diffusion Model for Sketch to Publication-ready Archaeological Drawings",
        "author": [
            "Lorenzo Cardarelli"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06897",
        "abstract": "Archaeological pottery documentation traditionally requires a time-consuming manual process of converting pencil sketches into publication-ready inked drawings. I present PyPotteryInk, an open-source automated pipeline that transforms archaeological pottery sketches into standardised publication-ready drawings using a one-step diffusion model. Built on a modified img2img-turbo architecture, the system processes drawings in a single forward pass while preserving crucial morphological details and maintaining archaeologic documentation standards and analytical value. The model employs an efficient patch-based approach with dynamic overlap, enabling high-resolution output regardless of input drawing size. I demonstrate the effectiveness of the approach on a dataset of Italian protohistoric pottery drawings, where it successfully captures both fine details like decorative patterns and structural elements like vessel profiles or handling elements. Expert evaluation confirms that the generated drawings meet publication standards while significantly reducing processing time from hours to seconds per drawing. The model can be fine-tuned to adapt to different archaeological contexts with minimal training data, making it versatile across various pottery documentation styles. The pre-trained models, the Python library and comprehensive documentation are provided to facilitate adoption within the archaeological research community.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "43",
        "title": "Large Language Models for In-File Vulnerability Localization Can Be \"Lost in the End\"",
        "author": [
            "Francesco Sovrano",
            "Adam Bauer",
            "Alberto Bacchelli"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06898",
        "abstract": "Recent advancements in artificial intelligence have enabled processing of larger inputs, leading everyday software developers to increasingly rely on chat-based large language models (LLMs) like GPT-3.5 and GPT-4 to detect vulnerabilities across entire files, not just within functions. This new development practice requires researchers to urgently investigate whether commonly used LLMs can effectively analyze large file-sized inputs, in order to provide timely insights for software developers and engineers about the pros and cons of this emerging technological trend. Hence, the goal of this paper is to evaluate the effectiveness of several state-of-the-art chat-based LLMs, including the GPT models, in detecting in-file vulnerabilities. We conducted a costly investigation into how the performance of LLMs varies based on vulnerability type, input size, and vulnerability location within the file. To give enough statistical power to our study, we could only focus on the three most common (as well as dangerous) vulnerabilities: XSS, SQL injection, and path traversal. Our findings indicate that the effectiveness of LLMs in detecting these vulnerabilities is strongly influenced by both the location of the vulnerability and the overall size of the input. Specifically, regardless of the vulnerability type, LLMs tend to significantly (p < .05) underperform when detecting vulnerabilities located toward the end of larger files, a pattern we call the 'lost-in-the-end' effect. Finally, to further support software developers and practitioners, we also explored the optimal input size for these LLMs and presented a simple strategy for identifying it, which can be applied to other models and vulnerability types. Eventually, we show how adjusting the input size can lead to significant improvements in LLM-based vulnerability detection, with an average recall increase of over 37% across all models.",
        "tags": [
            "Detection",
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "44",
        "title": "Enabling Autoregressive Models to Fill In Masked Tokens",
        "author": [
            "Daniel Israel",
            "Aditya Grover",
            "Guy Van den Broeck"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06901",
        "abstract": "Historically, LLMs have been trained using either autoregressive (AR) or masked language modeling (MLM) objectives, with AR models gaining dominance in recent years. However, AR models are inherently incapable of masked infilling, which is the ability to predict masked tokens between past and future context. In contrast, MLM models suffer from intrinsic computational inefficiencies during both training and inference that hinder their scalability. This work introduces MARIA (Masked and Autoregressive Infilling Architecture), a novel approach that leverages the strengths of both paradigms to achieve state-of-the-art masked infilling performance. MARIA combines a pre-trained MLM and AR model by training a linear decoder that takes their concatenated hidden states as input. This minimal modification enables the AR model to perform infilling while retaining its inherent advantages in terms of faster inference with KV caching. Our results demonstrate that MARIA significantly outperforms existing methods, namely discrete diffusion models, on masked infilling tasks.",
        "tags": [
            "Diffusion",
            "LLMs"
        ]
    },
    {
        "id": "45",
        "title": "Emergence of Episodic Memory in Transformers: Characterizing Changes in Temporal Structure of Attention Scores During Training",
        "author": [
            "Deven Mahesh Mistry",
            "Anooshka Bajaj",
            "Yash Aggarwal",
            "Sahaj Singh Maini",
            "Zoran Tiganj"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06902",
        "abstract": "We investigate in-context temporal biases in attention heads and transformer outputs. Using cognitive science methodologies, we analyze attention scores and outputs of the GPT-2 models of varying sizes. Across attention heads, we observe effects characteristic of human episodic memory, including temporal contiguity, primacy and recency. Transformer outputs demonstrate a tendency toward in-context serial recall. Importantly, this effect is eliminated after the ablation of the induction heads, which are the driving force behind the contiguity effect. Our findings offer insights into how transformers organize information temporally during in-context learning, shedding light on their similarities and differences with human memory and learning.",
        "tags": [
            "GPT",
            "Transformer"
        ]
    },
    {
        "id": "46",
        "title": "Hyper Compressed Fine-Tuning of Large Foundation Models with Quantum Inspired Adapters",
        "author": [
            "Snehal Raj",
            "Brian Coyle"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06916",
        "abstract": "Fine-tuning pre-trained large foundation models for specific tasks has become increasingly challenging due to the computational and storage demands associated with full parameter updates. Parameter-Efficient Fine-Tuning (PEFT) methods address this issue by updating only a small subset of model parameters using adapter modules. In this work, we propose \\emph{Quantum-Inspired Adapters}, a PEFT approach inspired by Hamming-weight preserving quantum circuits from quantum machine learning literature. These models can be both expressive and parameter-efficient by operating in a combinatorially large space while simultaneously preserving orthogonality in weight parameters. We test our proposed adapters by adapting large language models and large vision transformers on benchmark datasets. Our method can achieve 99.2\\% of the performance of existing fine-tuning methods such LoRA with a 44x parameter compression on language understanding datasets like GLUE and VTAB. Compared to existing orthogonal fine-tuning methods such as OFT or BOFT, we achieve 98\\% relative performance with 25x fewer parameters. This demonstrates competitive performance paired with a significant reduction in trainable parameters. Through ablation studies, we determine that combining multiple Hamming-weight orders with orthogonality and matrix compounding are essential for performant fine-tuning. Our findings suggest that Quantum-Inspired Adapters offer a promising direction for efficient adaptation of language and vision models in resource-constrained environments.",
        "tags": [
            "Large Language Models",
            "LoRA"
        ]
    },
    {
        "id": "47",
        "title": "XAMBA: Enabling Efficient State Space Models on Resource-Constrained Neural Processing Units",
        "author": [
            "Arghadip Das",
            "Arnab Raha",
            "Shamik Kundu",
            "Soumendu Kumar Ghosh",
            "Deepak Mathaikutty",
            "Vijay Raghunathan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06924",
        "abstract": "State-Space Models (SSMs) have emerged as efficient alternatives to transformers for sequential data tasks, offering linear or near-linear scalability with sequence length, making them ideal for long-sequence applications in NLP, vision, and edge AI, including real-time transcription, translation, and contextual search. These applications require lightweight, high-performance models for deployment on resource-constrained devices like laptops and PCs. Designing specialized accelerators for every emerging neural network is costly and impractical; instead, optimizing models for existing NPUs in AI PCs provides a scalable solution. To this end, we propose XAMBA, the first framework to enable and optimize SSMs on commercial off-the-shelf (COTS) state-of-the-art (SOTA) NPUs. XAMBA follows a three-step methodology: (1) enabling SSMs on NPUs, (2) optimizing performance to meet KPI requirements, and (3) trading accuracy for additional performance gains. After enabling SSMs on NPUs, XAMBA mitigates key bottlenecks using CumBA and ReduBA, replacing sequential CumSum and ReduceSum operations with matrix-based computations, significantly improving execution speed and memory efficiency. Additionally, ActiBA enhances performance by approximating expensive activation functions (e.g., Swish, Softplus) using piecewise linear mappings, reducing latency with minimal accuracy loss. Evaluations on an Intel Core Ultra Series 2 AI PC show that XAMBA achieves up to 2.6X speed-up over the baseline. Our implementation is available at https://github.com/arghadippurdue/XAMBA.",
        "tags": [
            "SSMs",
            "State Space Models"
        ]
    },
    {
        "id": "48",
        "title": "GAS: Generative Avatar Synthesis from a Single Image",
        "author": [
            "Yixing Lu",
            "Junting Dong",
            "Youngjoong Kwon",
            "Qin Zhao",
            "Bo Dai",
            "Fernando De la Torre"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06957",
        "abstract": "We introduce a generalizable and unified framework to synthesize view-consistent and temporally coherent avatars from a single image, addressing the challenging problem of single-image avatar generation. While recent methods employ diffusion models conditioned on human templates like depth or normal maps, they often struggle to preserve appearance information due to the discrepancy between sparse driving signals and the actual human subject, resulting in multi-view and temporal inconsistencies. Our approach bridges this gap by combining the reconstruction power of regression-based 3D human reconstruction with the generative capabilities of a diffusion model. The dense driving signal from the initial reconstructed human provides comprehensive conditioning, ensuring high-quality synthesis faithful to the reference appearance and structure. Additionally, we propose a unified framework that enables the generalization learned from novel pose synthesis on in-the-wild videos to naturally transfer to novel view synthesis. Our video-based diffusion model enhances disentangled synthesis with high-quality view-consistent renderings for novel views and realistic non-rigid deformations in novel pose animation. Results demonstrate the superior generalization ability of our method across in-domain and out-of-domain in-the-wild datasets. Project page: https://humansensinglab.github.io/GAS/",
        "tags": [
            "3D",
            "Diffusion"
        ]
    },
    {
        "id": "49",
        "title": "Model Diffusion for Certifiable Few-shot Transfer Learning",
        "author": [
            "Fady Rezk",
            "Royson Lee",
            "Henry Gouk",
            "Timothy Hospedales",
            "Minyoung Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06970",
        "abstract": "In modern large-scale deep learning, a prevalent and effective workflow for solving low-data problems is adapting powerful pre-trained foundation models (FMs) to new tasks via parameter-efficient fine-tuning (PEFT). However, while empirically effective, the resulting solutions lack generalisation guarantees to certify their accuracy - which may be required for ethical or legal reasons prior to deployment in high-importance applications. In this paper we develop a novel transfer learning approach that is designed to facilitate non-vacuous learning theoretic generalisation guarantees for downstream tasks, even in the low-shot regime. Specifically, we first use upstream tasks to train a distribution over PEFT parameters. We then learn the downstream task by a sample-and-evaluate procedure -- sampling plausible PEFTs from the trained diffusion model and selecting the one with the highest likelihood on the downstream data. Crucially, this confines our model hypothesis to a finite set of PEFT samples. In contrast to learning in the typical continuous hypothesis spaces of neural network weights, this facilitates tighter risk certificates. We instantiate our bound and show non-trivial generalization guarantees compared to existing learning approaches which lead to vacuous bounds in the low-shot regime.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "50",
        "title": "Position: Episodic Memory is the Missing Piece for Long-Term LLM Agents",
        "author": [
            "Mathis Pink",
            "Qinyuan Wu",
            "Vy Ai Vo",
            "Javier Turek",
            "Jianing Mu",
            "Alexander Huth",
            "Mariya Toneva"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06975",
        "abstract": "As Large Language Models (LLMs) evolve from text-completion tools into fully fledged agents operating in dynamic environments, they must address the challenge of continually learning and retaining long-term knowledge. Many biological systems solve these challenges with episodic memory, which supports single-shot learning of instance-specific contexts. Inspired by this, we present an episodic memory framework for LLM agents, centered around five key properties of episodic memory that underlie adaptive and context-sensitive behavior. With various research efforts already partially covering these properties, this position paper argues that now is the right time for an explicit, integrated focus on episodic memory to catalyze the development of long-term agents. To this end, we outline a roadmap that unites several research directions under the goal to support all five properties of episodic memory for more efficient long-term LLM agents.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "51",
        "title": "Investigating the Zone of Proximal Development of Language Models for In-Context Learning",
        "author": [
            "Peng Cui",
            "Mrinmaya Sachan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06990",
        "abstract": "In this paper, we introduce a learning analytics framework to analyze the in-context learning (ICL) behavior of large language models (LLMs) through the lens of the Zone of Proximal Development (ZPD), an established theory in educational psychology. ZPD delineates the space between what a learner is capable of doing unsupported and what the learner cannot do even with support. We adapt this concept to ICL, measuring the ZPD of LLMs based on model performance on individual examples with and without ICL. Furthermore, we propose an item response theory (IRT) model to predict the distribution of zones for LLMs. Our findings reveal a series of intricate and multifaceted behaviors of ICL, providing new insights into understanding and leveraging this technique. Finally, we demonstrate how our framework can enhance LLM in both inference and fine-tuning scenarios: (1) By predicting a model's zone of proximal development, we selectively apply ICL to queries that are most likely to benefit from demonstrations, achieving a better balance between inference cost and performance; (2) We propose a human-like curriculum for fine-tuning, which prioritizes examples within the model's ZPD. The curriculum results in improved performance, and we explain its effectiveness through an analysis of the training dynamics of LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "52",
        "title": "SyncMind: Measuring Agent Out-of-Sync Recovery in Collaborative Software Engineering",
        "author": [
            "Xuehang Guo",
            "Xingyao Wang",
            "Yangyi Chen",
            "Sha Li",
            "Chi Han",
            "Manling Li",
            "Heng Ji"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06994",
        "abstract": "Software engineering (SE) is increasingly collaborative, with developers working together on shared complex codebases. Effective collaboration in shared environments requires participants -- whether humans or AI agents -- to stay on the same page as their environment evolves. When a collaborator's understanding diverges from the current state -- what we term the out-of-sync challenge -- the collaborator's actions may fail, leading to integration issues. In this work, we introduce SyncMind, a framework that systematically defines the out-of-sync problem faced by large language model (LLM) agents in collaborative software engineering (CSE). Based on SyncMind, we create SyncBench, a benchmark featuring 24,332 instances of agent out-of-sync scenarios in real-world CSE derived from 21 popular GitHub repositories with executable verification tests. Experiments on SyncBench uncover critical insights into existing LLM agents' capabilities and limitations. Besides substantial performance gaps among agents (from Llama-3.1 agent <= 3.33% to Claude-3.5-Sonnet >= 28.18%), their consistently low collaboration willingness (<= 4.86%) suggests fundamental limitations of existing LLM in CSE. However, when collaboration occurs, it positively correlates with out-of-sync recovery success. Minimal performance differences in agents' resource-aware out-of-sync recoveries further reveal their significant lack of resource awareness and adaptability, shedding light on future resource-efficient collaborative systems. Code and data are openly available on our project website: https://xhguo7.github.io/SyncMind/.",
        "tags": [
            "LLaMA"
        ]
    },
    {
        "id": "53",
        "title": "From Image to Video: An Empirical Study of Diffusion Representations",
        "author": [
            "Pedro VÃ©lez",
            "Luisa F. PolanÃ­a",
            "Yi Yang",
            "Chuhan Zhang",
            "Rishab Kabra",
            "Anurag Arnab",
            "Mehdi S. M. Sajjadi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07001",
        "abstract": "Diffusion models have revolutionized generative modeling, enabling unprecedented realism in image and video synthesis. This success has sparked interest in leveraging their representations for visual understanding tasks. While recent works have explored this potential for image generation, the visual understanding capabilities of video diffusion models remain largely uncharted. To address this gap, we systematically compare the same model architecture trained for video versus image generation, analyzing the performance of their latent representations on various downstream tasks including image classification, action recognition, depth estimation, and tracking. Results show that video diffusion models consistently outperform their image counterparts, though we find a striking range in the extent of this superiority. We further analyze features extracted from different layers and with varying noise levels, as well as the effect of model size and training budget on representation and generation quality. This work marks the first direct comparison of video and image diffusion objectives for visual understanding, offering insights into the role of temporal information in representation learning.",
        "tags": [
            "Depth Estimation",
            "Diffusion"
        ]
    },
    {
        "id": "54",
        "title": "Demystifying Singular Defects in Large Language Models",
        "author": [
            "Haoqi Wang",
            "Tong Zhang",
            "Mathieu Salzmann"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07004",
        "abstract": "Large transformer models are known to produce high-norm tokens. In vision transformers (ViTs), such tokens have been mathematically modeled through the singular vectors of the linear approximations of layers. However, in large language models (LLMs), the underlying causes of high-norm tokens remain largely unexplored, and their different properties from those of ViTs require a new analysis framework. In this paper, we provide both theoretical insights and empirical validation across a range of recent models, leading to the following observations: i) The layer-wise singular direction predicts the abrupt explosion of token norms in LLMs. ii) The negative eigenvalues of a layer explain its sudden decay. iii) The computational pathways leading to high-norm tokens differ between initial and noninitial tokens. iv) High-norm tokens are triggered by the right leading singular vector of the matrix approximating the corresponding modules. We showcase two practical applications of these findings: the improvement of quantization schemes and the design of LLM signatures. Our findings not only advance the understanding of singular defects in LLMs but also open new avenues for their application. We expect that this work will stimulate further research into the internal mechanisms of LLMs and will therefore publicly release our code.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "55",
        "title": "Geometry-aware RL for Manipulation of Varying Shapes and Deformable Objects",
        "author": [
            "Tai Hoang",
            "Huy Le",
            "Philipp Becker",
            "Vien Anh Ngo",
            "Gerhard Neumann"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07005",
        "abstract": "Manipulating objects with varying geometries and deformable objects is a major challenge in robotics. Tasks such as insertion with different objects or cloth hanging require precise control and effective modelling of complex dynamics. In this work, we frame this problem through the lens of a heterogeneous graph that comprises smaller sub-graphs, such as actuators and objects, accompanied by different edge types describing their interactions. This graph representation serves as a unified structure for both rigid and deformable objects tasks, and can be extended further to tasks comprising multiple actuators. To evaluate this setup, we present a novel and challenging reinforcement learning benchmark, including rigid insertion of diverse objects, as well as rope and cloth manipulation with multiple end-effectors. These tasks present a large search space, as both the initial and target configurations are uniformly sampled in 3D space. To address this issue, we propose a novel graph-based policy model, dubbed Heterogeneous Equivariant Policy (HEPi), utilizing $SE(3)$\nequivariant message passing networks as the main backbone to exploit the geometric symmetry. In addition, by modeling explicit heterogeneity, HEPi can outperform Transformer-based and non-heterogeneous equivariant policies in terms of average returns, sample efficiency, and generalization to unseen objects.",
        "tags": [
            "3D",
            "RL",
            "Robotics",
            "Transformer"
        ]
    },
    {
        "id": "56",
        "title": "Grounding Creativity in Physics: A Brief Survey of Physical Priors in AIGC",
        "author": [
            "Siwei Meng",
            "Yawei Luo",
            "Ping Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07007",
        "abstract": "Recent advancements in AI-generated content have significantly improved the realism of 3D and 4D generation. However, most existing methods prioritize appearance consistency while neglecting underlying physical principles, leading to artifacts such as unrealistic deformations, unstable dynamics, and implausible objects interactions. Incorporating physics priors into generative models has become a crucial research direction to enhance structural integrity and motion realism. This survey provides a review of physics-aware generative methods, systematically analyzing how physical constraints are integrated into 3D and 4D generation. First, we examine recent works in incorporating physical priors into static and dynamic 3D generation, categorizing methods based on representation types, including vision-based, NeRF-based, and Gaussian Splatting-based approaches. Second, we explore emerging techniques in 4D generation, focusing on methods that model temporal dynamics with physical simulations. Finally, we conduct a comparative analysis of major methods, highlighting their strengths, limitations, and suitability for different materials and motion dynamics. By presenting an in-depth analysis of physics-grounded AIGC, this survey aims to bridge the gap between generative models and physical realism, providing insights that inspire future research in physically consistent content generation.",
        "tags": [
            "3D",
            "Gaussian Splatting",
            "NeRF"
        ]
    },
    {
        "id": "57",
        "title": "Finding Words Associated with DIF: Predicting Differential Item Functioning using LLMs and Explainable AI",
        "author": [
            "Hotaka Maeda",
            "Yikai Lu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07017",
        "abstract": "We fine-tuned and compared several encoder-based Transformer large language models (LLM) to predict differential item functioning (DIF) from the item text. We then applied explainable artificial intelligence (XAI) methods to these models to identify specific words associated with DIF. The data included 42,180 items designed for English language arts and mathematics summative state assessments among students in grades 3 to 11. Prediction $R^2$ ranged from .04 to .32 among eight focal and reference group pairs. Our findings suggest that many words associated with DIF reflect minor sub-domains included in the test blueprint by design, rather than construct-irrelevant item content that should be removed from assessments. This may explain why qualitative reviews of DIF items often yield confusing or inconclusive results. Our approach can be used to screen words associated with DIF during the item-writing process for immediate revision, or help review traditional DIF analysis results by highlighting key words in the text. Extensions of this research can enhance the fairness of assessment programs, especially those that lack resources to build high-quality items, and among smaller subpopulations where we do not have sufficient sample sizes for traditional DIF analyses.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "58",
        "title": "AIMS.au: A Dataset for the Analysis of Modern Slavery Countermeasures in Corporate Statements",
        "author": [
            "Adriana Eufrosiana Bora",
            "Pierre-Luc St-Charles",
            "Mirko Bronzi",
            "ArsÃ¨ne Fansi Tchango",
            "Bruno Rousseau",
            "Kerrie Mengersen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07022",
        "abstract": "Despite over a decade of legislative efforts to address modern slavery in the supply chains of large corporations, the effectiveness of government oversight remains hampered by the challenge of scrutinizing thousands of statements annually. While Large Language Models (LLMs) can be considered a well established solution for the automatic analysis and summarization of documents, recognizing concrete modern slavery countermeasures taken by companies and differentiating those from vague claims remains a challenging task. To help evaluate and fine-tune LLMs for the assessment of corporate statements, we introduce a dataset composed of 5,731 modern slavery statements taken from the Australian Modern Slavery Register and annotated at the sentence level. This paper details the construction steps for the dataset that include the careful design of annotation specifications, the selection and preprocessing of statements, and the creation of high-quality annotation subsets for effective model evaluations. To demonstrate our dataset's utility, we propose a machine learning methodology for the detection of sentences relevant to mandatory reporting requirements set by the Australian Modern Slavery Act. We then follow this methodology to benchmark modern language models under zero-shot and supervised learning settings.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "59",
        "title": "PrismAvatar: Real-time animated 3D neural head avatars on edge devices",
        "author": [
            "Prashant Raina",
            "Felix Taubner",
            "Mathieu Tuli",
            "Eu Wern Teh",
            "Kevin Ferreira"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07030",
        "abstract": "We present PrismAvatar: a 3D head avatar model which is designed specifically to enable real-time animation and rendering on resource-constrained edge devices, while still enjoying the benefits of neural volumetric rendering at training time. By integrating a rigged prism lattice with a 3D morphable head model, we use a hybrid rendering model to simultaneously reconstruct a mesh-based head and a deformable NeRF model for regions not represented by the 3DMM. We then distill the deformable NeRF into a rigged mesh and neural textures, which can be animated and rendered efficiently within the constraints of the traditional triangle rendering pipeline. In addition to running at 60 fps with low memory usage on mobile devices, we find that our trained models have comparable quality to state-of-the-art 3D avatar models on desktop devices.",
        "tags": [
            "3D",
            "NeRF"
        ]
    },
    {
        "id": "60",
        "title": "Automated Consistency Analysis of LLMs",
        "author": [
            "Aditya Patwardhan",
            "Vivek Vaidya",
            "Ashish Kundu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07036",
        "abstract": "Generative AI (Gen AI) with large language models (LLMs) are being widely adopted across the industry, academia and government. Cybersecurity is one of the key sectors where LLMs can be and/or are already being used. There are a number of problems that inhibit the adoption of trustworthy Gen AI and LLMs in cybersecurity and such other critical areas. One of the key challenge to the trustworthiness and reliability of LLMs is: how consistent an LLM is in its responses?\nIn this paper, we have analyzed and developed a formal definition of consistency of responses of LLMs. We have formally defined what is consistency of responses and then develop a framework for consistency evaluation. The paper proposes two approaches to validate consistency: self-validation, and validation across multiple LLMs. We have carried out extensive experiments for several LLMs such as GPT4oMini, GPT3.5, Gemini, Cohere, and Llama3, on a security benchmark consisting of several cybersecurity questions: informational and situational. Our experiments corroborate the fact that even though these LLMs are being considered and/or already being used for several cybersecurity tasks today, they are often inconsistent in their responses, and thus are untrustworthy and unreliable for cybersecurity.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "61",
        "title": "Scalable and Ethical Insider Threat Detection through Data Synthesis and Analysis by LLMs",
        "author": [
            "Haywood Gelman",
            "John D. Hastings"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07045",
        "abstract": "Insider threats wield an outsized influence on organizations, disproportionate to their small numbers. This is due to the internal access insiders have to systems, information, and infrastructure. %One example of this influence is where anonymous respondents submit web-based job search site reviews, an insider threat risk to organizations. Signals for such risks may be found in anonymous submissions to public web-based job search site reviews. This research studies the potential for large language models (LLMs) to analyze and detect insider threat sentiment within job site reviews. Addressing ethical data collection concerns, this research utilizes synthetic data generation using LLMs alongside existing job review datasets. A comparative analysis of sentiment scores generated by LLMs is benchmarked against expert human scoring. Findings reveal that LLMs demonstrate alignment with human evaluations in most cases, thus effectively identifying nuanced indicators of threat sentiment. The performance is lower on human-generated data than synthetic data, suggesting areas for improvement in evaluating real-world data. Text diversity analysis found differences between human-generated and LLM-generated datasets, with synthetic data exhibiting somewhat lower diversity. Overall, the results demonstrate the applicability of LLMs to insider threat detection, and a scalable solution for insider sentiment testing by overcoming ethical and logistical barriers tied to data acquisition.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "62",
        "title": "SnipGen: A Mining Repository Framework for Evaluating LLMs for Code",
        "author": [
            "Daniel Rodriguez-Cardenas",
            "Alejandro Velasco",
            "Denys Poshyvany"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07046",
        "abstract": "Language Models (LLMs), such as transformer-based neural networks trained on billions of parameters, have become increasingly prevalent in software engineering (SE). These models, trained on extensive datasets that include code repositories, exhibit remarkable capabilities for SE tasks. However, evaluating their effectiveness poses significant challenges, primarily due to the potential overlap between the datasets used for training and those employed for evaluation. To address this issue, we introduce SnipGen, a comprehensive repository mining framework designed to leverage prompt engineering across various downstream tasks for code generation. SnipGen aims to mitigate data contamination by generating robust testbeds and crafting tailored data points to assist researchers and practitioners in evaluating LLMs for code-related tasks. In our exploratory study, SnipGen mined approximately 227K data points from 338K recent code changes in GitHub commits, focusing on method-level granularity. SnipGen features a collection of prompt templates that can be combined to create a Chain-of-Thought-like sequence of prompts, enabling a nuanced assessment of LLMs' code generation quality. By providing the mining tool, the methodology, and the dataset, SnipGen empowers researchers and practitioners to rigorously evaluate and interpret LLMs' performance in software engineering contexts.",
        "tags": [
            "LLMs",
            "Transformer"
        ]
    },
    {
        "id": "63",
        "title": "Large Language Models in Software Security: A Survey of Vulnerability Detection Techniques and Insights",
        "author": [
            "Ze Sheng",
            "Zhicheng Chen",
            "Shuning Gu",
            "Heqing Huang",
            "Guofei Gu",
            "Jeff Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07049",
        "abstract": "Large Language Models (LLMs) are emerging as transformative tools for software vulnerability detection, addressing critical challenges in the security domain. Traditional methods, such as static and dynamic analysis, often falter due to inefficiencies, high false positive rates, and the growing complexity of modern software systems. By leveraging their ability to analyze code structures, identify patterns, and generate repair sugges- tions, LLMs, exemplified by models like GPT, BERT, and CodeBERT, present a novel and scalable approach to mitigating vulnerabilities. This paper provides a detailed survey of LLMs in vulnerability detection. It examines key aspects, including model architectures, application methods, target languages, fine-tuning strategies, datasets, and evaluation metrics. We also analyze the scope of current research problems, highlighting the strengths and weaknesses of existing approaches. Further, we address challenges such as cross-language vulnerability detection, multimodal data integration, and repository-level analysis. Based on these findings, we propose solutions for issues like dataset scalability, model interpretability, and applications in low-resource scenarios. Our contributions are threefold: (1) a systematic review of how LLMs are applied in vulnerability detection; (2) an analysis of shared patterns and differences across studies, with a unified framework for understanding the field; and (3) a summary of key challenges and future research directions. This work provides valuable insights for advancing LLM-based vulnerability detection. We also maintain and regularly update latest selected paper on https://github.com/OwenSanzas/LLM-For-Vulnerability-Detection",
        "tags": [
            "BERT",
            "Detection",
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "64",
        "title": "Tokenization Standards for Linguistic Integrity: Turkish as a Benchmark",
        "author": [
            "M. Ali Bayram",
            "Ali Arda Fincan",
            "Ahmet Semih GÃ¼mÃ¼Å",
            "Sercan KarakaÅ",
            "Banu Diri",
            "SavaÅ YÄ±ldÄ±rÄ±m"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07057",
        "abstract": "Tokenization is a fundamental preprocessing step in NLP, directly impacting large language models' (LLMs) ability to capture syntactic, morphosyntactic, and semantic structures. This paper introduces a novel framework for systematically evaluating tokenization strategies, addressing challenges in morphologically rich and low-resource languages. Using a Turkish dataset of 6,200 multiple-choice questions from the Massive Multitask Language Understanding (MMLU) benchmark, the framework assesses tokenizers across five key metrics: vocabulary size, token count, processing time, language-specific token percentages (\\%TR), and token purity. These metrics provide a structured approach to evaluating how well tokenizers preserve linguistic structures. While \\%TR measures the proportion of valid words in the target language, \\%Pure assesses the alignment of tokens with meaningful linguistic units, such as roots and valid morphemes, minimizing semantic fragmentation. The findings reveal that \\%TR, introduced as a critical metric, exhibits a stronger correlation with downstream performance (e.g., MMLU scores) than token purity, emphasizing its role in improving model accuracy. Additionally, larger model parameters do not necessarily yield better tokenization quality or enhanced results, highlighting the importance of tailored tokenization strategies that prioritize linguistic alignment. This framework sets a new standard for developing robust tokenization methods optimized for morphologically complex and low-resource languages. Future work will refine morphological analysis, explore domain-specific customizations, and conduct cross-linguistic evaluations to further enhance tokenization practices.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "65",
        "title": "Using Contextually Aligned Online Reviews to Measure LLMs' Performance Disparities Across Language Varieties",
        "author": [
            "Zixin Tang",
            "Chieh-Yang Huang",
            "Tsung-Chi Li",
            "Ho Yim Sam Ng",
            "Hen-Hsen Huang",
            "Ting-Hao 'Kenneth' Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07058",
        "abstract": "A language can have different varieties. These varieties can affect the performance of natural language processing (NLP) models, including large language models (LLMs), which are often trained on data from widely spoken varieties. This paper introduces a novel and cost-effective approach to benchmark model performance across language varieties. We argue that international online review platforms, such as http://Booking.com, can serve as effective data sources for constructing datasets that capture comments in different language varieties from similar real-world scenarios, like reviews for the same hotel with the same rating using the same language (e.g., Mandarin Chinese) but different language varieties (e.g., Taiwan Mandarin, Mainland Mandarin). To prove this concept, we constructed a contextually aligned dataset comprising reviews in Taiwan Mandarin and Mainland Mandarin and tested six LLMs in a sentiment analysis task. Our results show that LLMs consistently underperform in Taiwan Mandarin.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "66",
        "title": "Specializing Large Language Models to Simulate Survey Response Distributions for Global Populations",
        "author": [
            "Yong Cao",
            "Haijiang Liu",
            "Arnav Arora",
            "Isabelle Augenstein",
            "Paul RÃ¶ttger",
            "Daniel Hershcovich"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07068",
        "abstract": "Large-scale surveys are essential tools for informing social science research and policy, but running surveys is costly and time-intensive. If we could accurately simulate group-level survey results, this would therefore be very valuable to social science research. Prior work has explored the use of large language models (LLMs) for simulating human behaviors, mostly through prompting. In this paper, we are the first to specialize LLMs for the task of simulating survey response distributions. As a testbed, we use country-level results from two global cultural surveys. We devise a fine-tuning method based on first-token probabilities to minimize divergence between predicted and actual response distributions for a given question. Then, we show that this method substantially outperforms other methods and zero-shot classifiers, even on unseen questions, countries, and a completely unseen survey. While even our best models struggle with the task, especially on unseen questions, our results demonstrate the benefits of specialization for simulation, which may accelerate progress towards sufficiently accurate simulation in the future.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "67",
        "title": "IRepair: An Intent-Aware Approach to Repair Data-Driven Errors in Large Language Models",
        "author": [
            "Sayem Mohammad Imtiaz",
            "Astha Singh",
            "Fraol Batole",
            "Hridesh Rajan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07072",
        "abstract": "Not a day goes by without hearing about the impressive feats of large language models (LLMs), and equally, not a day passes without hearing about their challenges. LLMs are notoriously vulnerable to biases in their dataset, leading to issues such as toxicity. While domain-adaptive training has been employed to mitigate these issues, these techniques often address all model parameters indiscriminately during the repair process, resulting in poor repair quality and reduced model versatility. In this paper, we introduce a novel dynamic slicing-based intent-aware LLM repair strategy, IRepair. This approach selectively targets the most error-prone sections of the model for repair. Specifically, we propose dynamically slicing the model's most sensitive layers that require immediate attention, concentrating repair efforts on those areas. This method enables more effective repairs with potentially less impact on the model's overall performance by altering a smaller portion of the model. We evaluated our technique on three models from the GPT2 and GPT-Neo families, with parameters ranging from 800M to 1.6B, in a toxicity mitigation setup. Our results show that IRepair repairs errors 43.6% more effectively while causing 46% less disruption to general performance compared to the closest baseline, direct preference optimization. Our empirical analysis also reveals that errors are more concentrated in a smaller section of the model, with the top 20% of layers exhibiting 773% more error density than the remaining 80\\%. This highlights the need for selective repair. Additionally, we demonstrate that a dynamic selection approach is essential for addressing errors dispersed throughout the model, ensuring a robust and efficient repair.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "68",
        "title": "Multi-turn Evaluation of Anthropomorphic Behaviours in Large Language Models",
        "author": [
            "Lujain Ibrahim",
            "Canfer Akbulut",
            "Rasmi Elasmar",
            "Charvi Rastogi",
            "Minsuk Kahng",
            "Meredith Ringel Morris",
            "Kevin R. McKee",
            "Verena Rieser",
            "Murray Shanahan",
            "Laura Weidinger"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07077",
        "abstract": "The tendency of users to anthropomorphise large language models (LLMs) is of growing interest to AI developers, researchers, and policy-makers. Here, we present a novel method for empirically evaluating anthropomorphic LLM behaviours in realistic and varied settings. Going beyond single-turn static benchmarks, we contribute three methodological advances in state-of-the-art (SOTA) LLM evaluation. First, we develop a multi-turn evaluation of 14 anthropomorphic behaviours. Second, we present a scalable, automated approach by employing simulations of user interactions. Third, we conduct an interactive, large-scale human subject study (N=1101) to validate that the model behaviours we measure predict real users' anthropomorphic perceptions. We find that all SOTA LLMs evaluated exhibit similar behaviours, characterised by relationship-building (e.g., empathy and validation) and first-person pronoun use, and that the majority of behaviours only first occur after multiple turns. Our work lays an empirical foundation for investigating how design choices influence anthropomorphic model behaviours and for progressing the ethical debate on the desirability of these behaviours. It also showcases the necessity of multi-turn evaluations for complex social phenomena in human-AI interaction.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "69",
        "title": "Evaluating the Systematic Reasoning Abilities of Large Language Models through Graph Coloring",
        "author": [
            "Alex Heyman",
            "Joel Zylberberg"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07087",
        "abstract": "Contemporary large language models are powerful problem-solving tools, but they exhibit weaknesses in their reasoning abilities which ongoing research seeks to mitigate. We investigate graph coloring as a means of evaluating an LLM's capacities for systematic step-by-step reasoning and possibility space exploration, as well as effects of semantic problem framing. We test Claude 3.5 Sonnet, Llama 3.1 405B, Gemini 1.5 Pro, GPT-4o, o1-mini, and DeepSeek-R1 on a dataset of $k$-coloring problems with $2 \\leq k \\leq 4$ and vertex count $4 \\leq n \\leq 8$, using partial algorithmic solvers to further categorize problems by difficulty. In addition to substantial but varying framing effects, we find that all models except o1-mini and R1 exhibit $>60\\%$ error rates on difficult problem types in all frames ($>15\\%$ for o1-mini and $>10\\%$ for R1), and no model achieves perfect accuracy even in the simple domain of 2-coloring 4-vertex graphs. Our results highlight both the considerable recent progress in LLM systematic reasoning and the limits of its reliability, especially in relation to increasing computational costs. We expect that more complex graph coloring problems, and procedural generation of arbitrary-complexity reasoning problems more broadly, offer further untapped potential for LLM benchmarking.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "70",
        "title": "Kernels of Selfhood: GPT-4o shows humanlike patterns of cognitive consistency moderated by free choice",
        "author": [
            "Steven A. Lehr",
            "Ketan S. Saichandran",
            "Eddie Harmon-Jones",
            "Nykko Vitali",
            "Mahzarin R. Banaji"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07088",
        "abstract": "Large Language Models (LLMs) show emergent patterns that mimic human cognition. We explore whether they also mirror other, less deliberative human psychological processes. Drawing upon classical theories of cognitive consistency, two preregistered studies tested whether GPT-4o changed its attitudes toward Vladimir Putin in the direction of a positive or negative essay it wrote about the Russian leader. Indeed, GPT displayed patterns of attitude change mimicking cognitive consistency effects in humans. Even more remarkably, the degree of change increased sharply when the LLM was offered an illusion of choice about which essay (positive or negative) to write. This result suggests that GPT-4o manifests a functional analog of humanlike selfhood, although how faithfully the chatbot's behavior reflects the mechanisms of human attitude change remains to be understood.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "71",
        "title": "Online Scheduling for LLM Inference with KV Cache Constraints",
        "author": [
            "Patrick Jaillet",
            "Jiashuo Jiang",
            "Chara Podimata",
            "Zijie Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07115",
        "abstract": "Large Language Model (LLM) inference, where a trained model generates text one word at a time in response to user prompts, is a computationally intensive process requiring efficient scheduling to optimize latency and resource utilization. A key challenge in LLM inference is the management of the Key-Value (KV) cache, which reduces redundant computations but introduces memory constraints. In this work, we model LLM inference with KV cache constraints theoretically and propose novel batching and scheduling algorithms that minimize inference latency while effectively managing the KV cache's memory.\nWe analyze both semi-online and fully online scheduling models, and our results are threefold. First, we provide a polynomial-time algorithm that achieves exact optimality in terms of average latency in the semi-online prompt arrival model. Second, in the fully online case with a stochastic prompt arrival, we introduce an efficient online scheduling algorithm with constant regret. Third, we prove that no algorithm (deterministic or randomized) can achieve a constant competitive ratio in fully online adversarial settings. Our empirical evaluations on a public LLM inference dataset, using the Llama-70B model on A100 GPUs, show that our approach significantly outperforms benchmark algorithms used currently in practice, achieving lower latency while reducing energy consumption. Overall, our results offer a path toward more sustainable and cost-effective LLM deployment.",
        "tags": [
            "LLaMA"
        ]
    },
    {
        "id": "72",
        "title": "Cardiverse: Harnessing LLMs for Novel Card Game Prototyping",
        "author": [
            "Danrui Li",
            "Sen Zhang",
            "Sam S. Sohn",
            "Kaidong Hu",
            "Muhammad Usman",
            "Mubbasir Kapadia"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07128",
        "abstract": "The prototyping of computer games, particularly card games, requires extensive human effort in creative ideation and gameplay evaluation. Recent advances in Large Language Models (LLMs) offer opportunities to automate and streamline these processes. However, it remains challenging for LLMs to design novel game mechanics beyond existing databases, generate consistent gameplay environments, and develop scalable gameplay AI for large-scale evaluations. This paper addresses these challenges by introducing a comprehensive automated card game prototyping framework. The approach highlights a graph-based indexing method for generating novel game designs, an LLM-driven system for consistent game code generation validated by gameplay records, and a gameplay AI constructing method that uses an ensemble of LLM-generated action-value functions optimized through self-play. These contributions aim to accelerate card game prototyping, reduce human labor, and lower barriers to entry for game developers.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "73",
        "title": "Unconstrained Body Recognition at Altitude and Range: Comparing Four Approaches",
        "author": [
            "Blake A Myers",
            "Matthew Q Hill",
            "Veda Nandan Gandi",
            "Thomas M Metz",
            "Alice J O'Toole"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07130",
        "abstract": "This study presents an investigation of four distinct approaches to long-term person identification using body shape. Unlike short-term re-identification systems that rely on temporary features (e.g., clothing), we focus on learning persistent body shape characteristics that remain stable over time. We introduce a body identification model based on a Vision Transformer (ViT) (Body Identification from Diverse Datasets, BIDDS) and on a Swin-ViT model (Swin-BIDDS). We also expand on previous approaches based on the Linguistic and Non-linguistic Core ResNet Identity Models (LCRIM and NLCRIM), but with improved training. All models are trained on a large and diverse dataset of over 1.9 million images of approximately 5k identities across 9 databases. Performance was evaluated on standard re-identification benchmark datasets (MARS, MSMT17, Outdoor Gait, DeepChange) and on an unconstrained dataset that includes images at a distance (from close-range to 1000m), at altitude (from an unmanned aerial vehicle, UAV), and with clothing change. A comparative analysis across these models provides insights into how different backbone architectures and input image sizes impact long-term body identification performance across real-world conditions.",
        "tags": [
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "74",
        "title": "Language-TPP: Integrating Temporal Point Processes with Language Models for Event Analysis",
        "author": [
            "Quyu Kong",
            "Yixuan Zhang",
            "Yang Liu",
            "Panrong Tong",
            "Enqi Liu",
            "Feng Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07139",
        "abstract": "Temporal Point Processes (TPPs) have been widely used for event sequence modeling, but they often struggle to incorporate rich textual event descriptions effectively. Conversely, while Large Language Models (LLMs) have been shown remarkable capabilities in processing textual data, they lack mechanisms for handling temporal dynamics. To bridge this gap, we introduce Language-TPP, a unified framework that integrates TPPs with LLMs for enhanced event sequence modeling. Language-TPP introduces a novel temporal encoding mechanism that converts continuous time intervals into specialized byte-tokens, enabling seamless integration with standard LLM architectures. This approach allows Language-TPP to achieve state-of-the-art performance across multiple TPP tasks, including event time prediction, type prediction, and intensity estimation, on five datasets. Additionally, we demonstrate that incorporating temporal information significantly improves the quality of generated event descriptions.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "75",
        "title": "Conditional Distribution Quantization in Machine Learning",
        "author": [
            "Blaise Delattre",
            "Sylvain Delattre",
            "Alexandre VÃ©rine",
            "Alexandre Allauzen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07151",
        "abstract": "Conditional expectation \\mathbb{E}(Y \\mid X) often fails to capture the complexity of multimodal conditional distributions \\mathcal{L}(Y \\mid X). To address this, we propose using n-point conditional quantizations--functional mappings of X that are learnable via gradient descent--to approximate \\mathcal{L}(Y \\mid X). This approach adapts Competitive Learning Vector Quantization (CLVQ), tailored for conditional distributions. It goes beyond single-valued predictions by providing multiple representative points that better reflect multimodal structures. It enables the approximation of the true conditional law in the Wasserstein distance. The resulting framework is theoretically grounded and useful for uncertainty quantification and multimodal data generation tasks. For example, in computer vision inpainting tasks, multiple plausible reconstructions may exist for the same partially observed input image X. We demonstrate the effectiveness of our approach through experiments on synthetic and real-world datasets.",
        "tags": [
            "Inpainting",
            "Vector Quantization"
        ]
    },
    {
        "id": "76",
        "title": "Rethinking Fine-Tuning when Scaling Test-Time Compute: Limiting Confidence Improves Mathematical Reasoning",
        "author": [
            "Feng Chen",
            "Allan Raventos",
            "Nan Cheng",
            "Surya Ganguli",
            "Shaul Druckmann"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07154",
        "abstract": "Recent progress in large language models (LLMs) highlights the power of scaling test-time compute to achieve strong performance on complex tasks, such as mathematical reasoning and code generation. This raises a critical question: how should model training be modified to optimize performance under a subsequent test-time compute strategy and budget? To explore this, we focus on pass@N, a simple test-time strategy that searches for a correct answer in $N$ independent samples. We show, surprisingly, that training with cross-entropy (CE) loss can be ${\\it misaligned}$ with pass@N in that pass@N accuracy ${\\it decreases}$ with longer training. We explain the origins of this misalignment in terms of model overconfidence induced by CE, and experimentally verify our prediction of overconfidence as an impediment to scaling test-time compute via pass@N. Furthermore we suggest a principled, modified training loss that is better aligned to pass@N by limiting model confidence and rescuing pass@N test performance. Our algorithm demonstrates improved mathematical reasoning on MATH and MiniF2F benchmarks under several scenarios: (1) providing answers to math questions; and (2) proving theorems by searching over proof trees of varying shapes. Overall our work underscores the importance of co-designing two traditionally separate phases of LLM development: training-time protocols and test-time search and reasoning strategies.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "77",
        "title": "HDCompression: Hybrid-Diffusion Image Compression for Ultra-Low Bitrates",
        "author": [
            "Lei Lu",
            "Yize Li",
            "Yanzhi Wang",
            "Wei Wang",
            "Wei Jiang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07160",
        "abstract": "Image compression under ultra-low bitrates remains challenging for both conventional learned image compression (LIC) and generative vector-quantized (VQ) modeling. Conventional LIC suffers from severe artifacts due to heavy quantization, while generative VQ modeling gives poor fidelity due to the mismatch between learned generative priors and specific inputs. In this work, we propose Hybrid-Diffusion Image Compression (HDCompression), a dual-stream framework that utilizes both generative VQ-modeling and diffusion models, as well as conventional LIC, to achieve both high fidelity and high perceptual quality. Different from previous hybrid methods that directly use pre-trained LIC models to generate low-quality fidelity-preserving information from heavily quantized latent, we use diffusion models to extract high-quality complimentary fidelity information from the ground-truth input, which can enhance the system performance in several aspects: improving indices map prediction, enhancing the fidelity-preserving output of the LIC stream, and refining conditioned image reconstruction with VQ-latent correction. In addition, our diffusion model is based on a dense representative vector (DRV), which is lightweight with very simple sampling schedulers. Extensive experiments demonstrate that our HDCompression outperforms the previous conventional LIC, generative VQ-modeling, and hybrid frameworks in both quantitative metrics and qualitative visualization, providing balanced robust compression performance at ultra-low bitrates.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "78",
        "title": "A Survey on Mamba Architecture for Vision Applications",
        "author": [
            "Fady Ibrahim",
            "Guangjun Liu",
            "Guanghui Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07161",
        "abstract": "Transformers have become foundational for visual tasks such as object detection, semantic segmentation, and video understanding, but their quadratic complexity in attention mechanisms presents scalability challenges. To address these limitations, the Mamba architecture utilizes state-space models (SSMs) for linear scalability, efficient processing, and improved contextual awareness. This paper investigates Mamba architecture for visual domain applications and its recent advancements, including Vision Mamba (ViM) and VideoMamba, which introduce bidirectional scanning, selective scanning mechanisms, and spatiotemporal processing to enhance image and video understanding. Architectural innovations like position embeddings, cross-scan modules, and hierarchical designs further optimize the Mamba framework for global and local feature extraction. These advancements position Mamba as a promising architecture in computer vision research and applications.",
        "tags": [
            "Detection",
            "Mamba",
            "SSMs",
            "Segmentation",
            "State Space Models"
        ]
    },
    {
        "id": "79",
        "title": "Does Training on Synthetic Data Make Models Less Robust?",
        "author": [
            "Lingze Zhang",
            "Ellie Pavlick"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07164",
        "abstract": "An increasingly common practice is to train large language models (LLMs) using synthetic data. Often this synthetic data is produced by the same or similar LLMs as those it is being used to train. This raises the question of whether the synthetic data might in fact exacerbate certain \"blindspots\" by reinforcing heuristics that the LLM already encodes. In this paper, we conduct simulated experiments on the natural language inference (NLI) task with Llama-2-7B-hf models. We use MultiNLI as the general task and HANS, a targeted evaluation set designed to measure the presence of specific heuristic strategies for NLI, as our \"blindspot\" task. Our goal is to determine whether performance disparities between the general and blind spot tasks emerge. Our results indicate that synthetic data does not reinforce blindspots in the way we expected. Specifically, we see that, while fine-tuning with synthetic data doesn't necessarily reduce the use of the heuristic, it also does not make it worse as we hypothesized.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "80",
        "title": "Don't Just Demo, Teach Me the Principles: A Principle-Based Multi-Agent Prompting Strategy for Text Classification",
        "author": [
            "Peipei Wei",
            "Dimitris Dimitriadis",
            "Yan Xu",
            "Mingwei Shen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07165",
        "abstract": "We present PRINCIPLE-BASED PROMPTING, a simple but effective multi-agent prompting strategy for text classification. It first asks multiple LLM agents to independently generate candidate principles based on analysis of demonstration samples with or without labels, consolidates them into final principles via a finalizer agent, and then sends them to a classifier agent to perform downstream classification tasks. Extensive experiments on binary and multi-class classification datasets with different sizes of LLMs show that our approach not only achieves substantial performance gains (1.55% - 19.37%) over zero-shot prompting on macro-F1 score but also outperforms other strong baselines (CoT and stepback prompting). Principles generated by our approach help LLMs perform better on classification tasks than human crafted principles on two private datasets. Our multi-agent PRINCIPLE-BASED PROMPTING approach also shows on-par or better performance compared to demonstration-based few-shot prompting approaches, yet with substantially lower inference costs. Ablation studies show that label information and the multi-agent cooperative LLM framework play an important role in generating high-quality principles to facilitate downstream classification tasks.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "81",
        "title": "MatrixKAN: Parallelized Kolmogorov-Arnold Network",
        "author": [
            "Cale Coffman",
            "Lizhong Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07176",
        "abstract": "Kolmogorov-Arnold Networks (KAN) are a new class of neural network architecture representing a promising alternative to the Multilayer Perceptron (MLP), demonstrating improved expressiveness and interpretability. However, KANs suffer from slow training and inference speeds relative to MLPs due in part to the recursive nature of the underlying B-spline calculations. This issue is particularly apparent with respect to KANs utilizing high-degree B-splines, as the number of required non-parallelizable recursions is proportional to B-spline degree. We solve this issue by proposing MatrixKAN, a novel optimization that parallelizes B-spline calculations with matrix representation and operations, thus significantly improving effective computation time for models utilizing high-degree B-splines. In this paper, we demonstrate the superior scaling of MatrixKAN's computation time relative to B-spline degree. Further, our experiments demonstrate speedups of approximately 40x relative to KAN, with significant additional speedup potential for larger datasets or higher spline degrees.",
        "tags": [
            "KAN",
            "Kolmogorov-Arnold Networks"
        ]
    },
    {
        "id": "82",
        "title": "Refine Knowledge of Large Language Models via Adaptive Contrastive Learning",
        "author": [
            "Yinghui Li",
            "Haojing Huang",
            "Jiayi Kuang",
            "Yangning Li",
            "Shu-Yu Guo",
            "Chao Qu",
            "Xiaoyu Tan",
            "Hai-Tao Zheng",
            "Ying Shen",
            "Philip S. Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07184",
        "abstract": "How to alleviate the hallucinations of Large Language Models (LLMs) has always been the fundamental goal pursued by the LLMs research community. Looking through numerous hallucination-related studies, a mainstream category of methods is to reduce hallucinations by optimizing the knowledge representation of LLMs to change their output. Considering that the core focus of these works is the knowledge acquired by models, and knowledge has long been a central theme in human societal progress, we believe that the process of models refining knowledge can greatly benefit from the way humans learn. In our work, by imitating the human learning process, we design an Adaptive Contrastive Learning strategy. Our method flexibly constructs different positive and negative samples for contrastive learning based on LLMs' actual mastery of knowledge. This strategy helps LLMs consolidate the correct knowledge they already possess, deepen their understanding of the correct knowledge they have encountered but not fully grasped, forget the incorrect knowledge they previously learned, and honestly acknowledge the knowledge they lack. Extensive experiments and detailed analyses on widely used datasets demonstrate the effectiveness of our method.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "83",
        "title": "Perceived Confidence Scoring for Data Annotation with Zero-Shot LLMs",
        "author": [
            "Sina Salimian",
            "Gias Uddin",
            "Most Husne Jahan",
            "Shaina Raza"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07186",
        "abstract": "Zero-shot LLMs are now also used for textual classification tasks, e.g., sentiment/emotion detection of a given input as a sentence/article. However, their performance can be suboptimal in such data annotation tasks. We introduce a novel technique Perceived Confidence Scoring (PCS) that evaluates LLM's confidence for its classification of an input by leveraging Metamorphic Relations (MRs). The MRs generate semantically equivalent yet textually mutated versions of the input. Following the principles of Metamorphic Testing (MT), the mutated versions are expected to have annotation labels similar to the input. By analyzing the consistency of LLM responses across these variations, PCS computes a confidence score based on the frequency of predicted labels. PCS can be used both for single LLM and multiple LLM settings (e.g., majority voting). We introduce an algorithm Perceived Differential Evolution (PDE) that determines the optimal weights assigned to the MRs and the LLMs for a classification task. Empirical evaluation shows PCS significantly improves zero-shot accuracy for Llama-3-8B-Instruct (4.96%) and Mistral-7B-Instruct-v0.3 (10.52%), with Gemma-2-9b-it showing a 9.39% gain. When combining all three models, PCS significantly outperforms majority voting by 7.75%.",
        "tags": [
            "Detection",
            "LLMs",
            "LLaMA"
        ]
    },
    {
        "id": "84",
        "title": "A Large-Scale Benchmark for Vietnamese Sentence Paraphrases",
        "author": [
            "Sang Quang Nguyen",
            "Kiet Van Nguyen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07188",
        "abstract": "This paper presents ViSP, a high-quality Vietnamese dataset for sentence paraphrasing, consisting of 1.2M original-paraphrase pairs collected from various domains. The dataset was constructed using a hybrid approach that combines automatic paraphrase generation with manual evaluation to ensure high quality. We conducted experiments using methods such as back-translation, EDA, and baseline models like BART and T5, as well as large language models (LLMs), including GPT-4o, Gemini-1.5, Aya, Qwen-2.5, and Meta-Llama-3.1 variants. To the best of our knowledge, this is the first large-scale study on Vietnamese paraphrasing. We hope that our dataset and findings will serve as a valuable foundation for future research and applications in Vietnamese paraphrase tasks.",
        "tags": [
            "GPT",
            "LLMs",
            "LLaMA",
            "Large Language Models",
            "Qwen"
        ]
    },
    {
        "id": "85",
        "title": "Exploring Neural Network Pruning with Screening Methods",
        "author": [
            "Mingyuan Wang",
            "Yangzi Guo",
            "Sida Liu",
            "Yanwen Xiao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07189",
        "abstract": "Deep neural networks (DNNs) such as convolutional neural networks (CNNs) for visual tasks, recurrent neural networks (RNNs) for sequence data, and transformer models for rich linguistic or multimodal tasks, achieved unprecedented performance on a wide range of tasks. The impressive performance of modern DNNs is partially attributed to their sheer scale. The latest deep learning models have tens to hundreds of millions of parameters which makes the inference processes resource-intensive. The high computational complexity of these networks prevents their deployment on resource-limited devices such as mobile platforms, IoT devices, and edge computing systems because these devices require energy-efficient and real-time processing capabilities. This paper proposes and evaluates a network pruning framework that eliminates non-essential parameters based on a statistical analysis of network component significance across classification categories. The proposed method uses screening methods coupled with a weighted scheme to assess connection and channel contributions for unstructured and structured pruning which allows for the elimination of unnecessary network elements without significantly degrading model performance. Extensive experimental validation on real-world vision datasets for both fully connected neural networks (FNNs) and CNNs has shown that the proposed framework produces competitive lean networks compared to the original networks. Moreover, the proposed framework outperforms state-of-art network pruning methods in two out of three cases.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "86",
        "title": "Understanding LLMs' Fluid Intelligence Deficiency: An Analysis of the ARC Task",
        "author": [
            "Junjie Wu",
            "Mo Yu",
            "Lemao Liu",
            "Dit-Yan Yeung",
            "Jie Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07190",
        "abstract": "While LLMs have exhibited strong performance on various NLP tasks, it is noteworthy that most of these tasks rely on utilizing the vast amount of knowledge encoded in LLMs' parameters, rather than solving new problems without prior knowledge. In cognitive research, the latter ability is referred to as fluid intelligence, which is considered to be critical for assessing human intelligence. Recent research on fluid intelligence assessments has highlighted significant deficiencies in LLMs' abilities. In this paper, we analyze the challenges LLMs face in demonstrating fluid intelligence through controlled experiments, using the most representative ARC task as an example. Our study revealed three major limitations in existing LLMs: limited ability for skill composition, unfamiliarity with abstract input formats, and the intrinsic deficiency of left-to-right decoding. Our data and code can be found in https://wujunjie1998.github.io/araoc-benchmark.github.io/.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "87",
        "title": "Bag of Tricks for Inference-time Computation of LLM Reasoning",
        "author": [
            "Fan Liu",
            "Wenshuo Chao",
            "Naiqiang Tan",
            "Hao Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07191",
        "abstract": "With the advancement of large language models (LLMs), solving complex reasoning tasks has gained increasing attention. Inference-time computation methods (e.g., Best-of-N, beam search, et al.) are particularly valuable as they can enhance reasoning performance without modifying model parameters or requiring additional training. However, these techniques come with implementation challenges, and most existing methods remain at the proof-of-concept stage with limited practical adoption due to their computational complexity and varying effectiveness across different tasks. In this paper, we investigate and benchmark diverse inference-time computation strategies across reasoning tasks of varying complexity. Since most current methods rely on a proposer-verifier pipeline that first generates candidate solutions (e.g., reasoning solutions) and then selects the best one based on reward signals (e.g., RLHF rewards, process rewards), our research focuses on optimizing both candidate solution generation (e.g., instructing prompts, hyperparameters such as temperature and top-p) and reward mechanisms (e.g., self-evaluation, reward types). Through extensive experiments (more than 20,000 A100-80G GPU hours with over 1,000 experiments) across a variety of models (e.g., Llama, Qwen, and Mistral families) of various sizes, our ablation studies reveal that previously overlooked strategies can significantly enhance performance (e.g., tuning temperature can improve reasoning task performance by up to 5%). Furthermore, we establish a standardized benchmark for inference-time computation by systematically evaluating six representative methods across eight reasoning tasks. These findings provide a stronger foundation for future research. The code is available at https://github.com/usail-hkust/benchmark_inference_time_computation_LL",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models",
            "Qwen"
        ]
    },
    {
        "id": "88",
        "title": "Provably Efficient RLHF Pipeline: A Unified View from Contextual Bandits",
        "author": [
            "Long-Fei Li",
            "Yu-Yang Qian",
            "Peng Zhao",
            "Zhi-Hua Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07193",
        "abstract": "Reinforcement Learning from Human Feedback (RLHF) is a widely used approach for aligning Large Language Models (LLMs) with human preferences. While recent advancements have provided valuable insights into various stages and settings of RLHF, a comprehensive theoretical understanding of the entire RLHF pipeline remains lacking. Towards this end, we propose a unified framework for the RLHF pipeline from the view of contextual bandits and provide provable efficiency guarantees. In particular, we decompose the RLHF process into two distinct stages: (post-)training and deployment, exploring both passive and active data collection strategies during the training phase. By employing the Bradley-Terry preference model with a linearly parameterized reward function, we reformulate RLHF as a contextual preference bandit problem. We then develop novel algorithms for each stage, demonstrating significant improvements over existing approaches in both statistical and computational efficiency. Finally, we apply our method to train and deploy Llama-3-8B-Instruct on the Ultrafeedback-binarized dataset, and empirical results confirm the effectiveness of our approach.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "89",
        "title": "Dense Object Detection Based on De-homogenized Queries",
        "author": [
            "Yueming Huang",
            "Chenrui Ma",
            "Hao Zhou",
            "Hao Wu",
            "Guowu Yuan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07194",
        "abstract": "Dense object detection is widely used in automatic driving, video surveillance, and other fields. This paper focuses on the challenging task of dense object detection. Currently, detection methods based on greedy algorithms, such as non-maximum suppression (NMS), often produce many repetitive predictions or missed detections in dense scenarios, which is a common problem faced by NMS-based algorithms. Through the end-to-end DETR (DEtection TRansformer), as a type of detector that can incorporate the post-processing de-duplication capability of NMS, etc., into the network, we found that homogeneous queries in the query-based detector lead to a reduction in the de-duplication capability of the network and the learning efficiency of the encoder, resulting in duplicate prediction and missed detection problems. To solve this problem, we propose learnable differentiated encoding to de-homogenize the queries, and at the same time, queries can communicate with each other via differentiated encoding information, replacing the previous self-attention among the queries. In addition, we used joint loss on the output of the encoder that considered both location and confidence prediction to give a higher-quality initialization for queries. Without cumbersome decoder stacking and guaranteeing accuracy, our proposed end-to-end detection framework was more concise and reduced the number of parameters by about 8% compared to deformable DETR. Our method achieved excellent results on the challenging CrowdHuman dataset with 93.6% average precision (AP), 39.2% MR-2, and 84.3% JI. The performance overperformed previous SOTA methods, such as Iter-E2EDet (Progressive End-to-End Object Detection) and MIP (One proposal, Multiple predictions). In addition, our method is more robust in various scenarios with different densities.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "90",
        "title": "Monte Carlo Tree Diffusion for System 2 Planning",
        "author": [
            "Jaesik Yoon",
            "Hyeonseo Cho",
            "Doojin Baek",
            "Yoshua Bengio",
            "Sungjin Ahn"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07202",
        "abstract": "Diffusion models have recently emerged as a powerful tool for planning. However, unlike Monte Carlo Tree Search (MCTS)-whose performance naturally improves with additional test-time computation (TTC), standard diffusion-based planners offer only limited avenues for TTC scalability. In this paper, we introduce Monte Carlo Tree Diffusion (MCTD), a novel framework that integrates the generative strength of diffusion models with the adaptive search capabilities of MCTS. Our method reconceptualizes denoising as a tree-structured process, allowing partially denoised plans to be iteratively evaluated, pruned, and refined. By selectively expanding promising trajectories while retaining the flexibility to revisit and improve suboptimal branches, MCTD achieves the benefits of MCTS such as controlling exploration-exploitation trade-offs within the diffusion framework. Empirical results on challenging long-horizon tasks show that MCTD outperforms diffusion baselines, yielding higher-quality solutions as TTC increases.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "91",
        "title": "Playmate: Flexible Control of Portrait Animation via 3D-Implicit Space Guided Diffusion",
        "author": [
            "Xingpei Ma",
            "Jiaran Cai",
            "Yuansheng Guan",
            "Shenneng Huang",
            "Qiang Zhang",
            "Shunsi Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07203",
        "abstract": "Recent diffusion-based talking face generation models have demonstrated impressive potential in synthesizing videos that accurately match a speech audio clip with a given reference identity. However, existing approaches still encounter significant challenges due to uncontrollable factors, such as inaccurate lip-sync, inappropriate head posture and the lack of fine-grained control over facial expressions. In order to introduce more face-guided conditions beyond speech audio clips, a novel two-stage training framework Playmate is proposed to generate more lifelike facial expressions and talking faces. In the first stage, we introduce a decoupled implicit 3D representation along with a meticulously designed motion-decoupled module to facilitate more accurate attribute disentanglement and generate expressive talking videos directly from audio cues. Then, in the second stage, we introduce an emotion-control module to encode emotion control information into the latent space, enabling fine-grained control over emotions and thereby achieving the ability to generate talking videos with desired emotion. Extensive experiments demonstrate that Playmate outperforms existing state-of-the-art methods in terms of video quality and lip-synchronization, and improves flexibility in controlling emotion and head pose. The code will be available at https://playmate111.github.io.",
        "tags": [
            "3D",
            "CLIP",
            "Diffusion",
            "Talking Face"
        ]
    },
    {
        "id": "92",
        "title": "Improve the Training Efficiency of DRL for Wireless Communication Resource Allocation: The Role of Generative Diffusion Models",
        "author": [
            "Xinren Zhang",
            "Jiadong Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07211",
        "abstract": "Dynamic resource allocation in mobile wireless networks involves complex, time-varying optimization problems, motivating the adoption of deep reinforcement learning (DRL). However, most existing works rely on pre-trained policies, overlooking dynamic environmental changes that rapidly invalidate the policies. Periodic retraining becomes inevitable but incurs prohibitive computational costs and energy consumption-critical concerns for resource-constrained wireless systems. We identify three root causes of inefficient retraining: high-dimensional state spaces, suboptimal action spaces exploration-exploitation trade-offs, and reward design limitations. To overcome these limitations, we propose Diffusion-based Deep Reinforcement Learning (D2RL), which leverages generative diffusion models (GDMs) to holistically enhance all three DRL components. Iterative refinement process and distribution modelling of GDMs enable (1) the generation of diverse state samples to improve environmental understanding, (2) balanced action space exploration to escape local optima, and (3) the design of discriminative reward functions that better evaluate action quality. Our framework operates in two modes: Mode I leverages GDMs to explore reward spaces and design discriminative reward functions that rigorously evaluate action quality, while Mode II synthesizes diverse state samples to enhance environmental understanding and generalization. Extensive experiments demonstrate that D2RL achieves faster convergence and reduced computational costs over conventional DRL methods for resource allocation in wireless communications while maintaining competitive policy performance. This work underscores the transformative potential of GDMs in overcoming fundamental DRL training bottlenecks for wireless networks, paving the way for practical, real-time deployments.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "93",
        "title": "SparseFormer: Detecting Objects in HRW Shots via Sparse Vision Transformer",
        "author": [
            "Wenxi Li",
            "Yuchen Guo",
            "Jilai Zheng",
            "Haozhe Lin",
            "Chao Ma",
            "Lu Fang",
            "Xiaokang Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07216",
        "abstract": "Recent years have seen an increase in the use of gigapixel-level image and video capture systems and benchmarks with high-resolution wide (HRW) shots. However, unlike close-up shots in the MS COCO dataset, the higher resolution and wider field of view raise unique challenges, such as extreme sparsity and huge scale changes, causing existing close-up detectors inaccuracy and inefficiency. In this paper, we present a novel model-agnostic sparse vision transformer, dubbed SparseFormer, to bridge the gap of object detection between close-up and HRW shots. The proposed SparseFormer selectively uses attentive tokens to scrutinize the sparsely distributed windows that may contain objects. In this way, it can jointly explore global and local attention by fusing coarse- and fine-grained features to handle huge scale changes. SparseFormer also benefits from a novel Cross-slice non-maximum suppression (C-NMS) algorithm to precisely localize objects from noisy windows and a simple yet effective multi-scale strategy to improve accuracy. Extensive experiments on two HRW benchmarks, PANDA and DOTA-v1.0, demonstrate that the proposed SparseFormer significantly improves detection accuracy (up to 5.8%) and speed (up to 3x) over the state-of-the-art approaches.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "94",
        "title": "MLLM4PUE: Toward Universal Embeddings in Computational Pathology through Multimodal LLMs",
        "author": [
            "Qifeng Zhou",
            "Thao M. Dang",
            "Wenliang Zhong",
            "Yuzhi Guo",
            "Hehuan Ma",
            "Saiyang Na",
            "Junzhou Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07221",
        "abstract": "Pathology plays a critical role in diagnosing a wide range of diseases, yet existing approaches often rely heavily on task-specific models trained on extensive, well-labeled datasets. These methods face sustainability challenges due to the diversity of pathologies and the labor-intensive nature of data collection. To address these limitations, we highlight the need for universal multimodal embeddings that can support multiple downstream tasks. Previous approaches often involve fine-tuning CLIP-based models, which handle images and text separately, limiting their ability to capture complex multimodal relationships. Additionally, these models are evaluated across diverse datasets without a unified benchmark for assessing multimodal embeddings in pathology. To address these challenges, we propose MLLM4PUE, a novel framework that leverages Multimodal Large Language Models (MLLMs) to generate Pathology Universal Embeddings. The MLLM4PUE framework not only facilitates robust integration of images and text but also enhances understanding and fusion capabilities across various tasks. We further introduce the Pathology Multimodal Embedding Benchmark (PMEB), a comprehensive benchmark designed to assess the quality of pathology multimodal embeddings. PMEB comprises 15 original tasks drawn from 14 datasets, organized into three meta-tasks: retrieval, classification, and composed retrieval. Experimental results demonstrate the superiority of MLLM4PUE, illustrating MLLM-based models can effectively support a wide range of downstream tasks and unify the research direction for foundation models in pathology.",
        "tags": [
            "CLIP",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "95",
        "title": "A Memory Efficient Randomized Subspace Optimization Method for Training Large Language Models",
        "author": [
            "Yiming Chen",
            "Yuan Zhang",
            "Yin Liu",
            "Kun Yuan",
            "Zaiwen Wen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07222",
        "abstract": "The memory challenges associated with training Large Language Models (LLMs) have become a critical concern, particularly when using the Adam optimizer. To address this issue, numerous memory-efficient techniques have been proposed, with GaLore standing out as a notable example designed to reduce the memory footprint of optimizer states. However, these approaches do not alleviate the memory burden imposed by activations, rendering them unsuitable for scenarios involving long context sequences or large mini-batches. Moreover, their convergence properties are still not well-understood in the literature. In this work, we introduce a Randomized Subspace Optimization framework for pre-training and fine-tuning LLMs. Our approach decomposes the high-dimensional training problem into a series of lower-dimensional subproblems. At each iteration, a random subspace is selected, and the parameters within that subspace are optimized. This structured reduction in dimensionality allows our method to simultaneously reduce memory usage for both activations and optimizer states. We establish comprehensive convergence guarantees and derive rates for various scenarios, accommodating different optimization strategies to solve the subproblems. Extensive experiments validate the superior memory and communication efficiency of our method, achieving performance comparable to GaLore and Adam.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "96",
        "title": "CAT: Contrastive Adversarial Training for Evaluating the Robustness of Protective Perturbations in Latent Diffusion Models",
        "author": [
            "Sen Peng",
            "Mingyue Wang",
            "Jianfei He",
            "Jijia Yang",
            "Xiaohua Jia"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07225",
        "abstract": "Latent diffusion models have recently demonstrated superior capabilities in many downstream image synthesis tasks. However, customization of latent diffusion models using unauthorized data can severely compromise the privacy and intellectual property rights of data owners. Adversarial examples as protective perturbations have been developed to defend against unauthorized data usage by introducing imperceptible noise to customization samples, preventing diffusion models from effectively learning them. In this paper, we first reveal that the primary reason adversarial examples are effective as protective perturbations in latent diffusion models is the distortion of their latent representations, as demonstrated through qualitative and quantitative experiments. We then propose the Contrastive Adversarial Training (CAT) utilizing adapters as an adaptive attack against these protection methods, highlighting their lack of robustness. Extensive experiments demonstrate that our CAT method significantly reduces the effectiveness of protective perturbations in customization configurations, urging the community to reconsider and enhance the robustness of existing protective perturbation methods. Code is available at \\hyperlink{here}{https://github.com/senp98/CAT}.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "97",
        "title": "Diffusion Suction Grasping with Large-Scale Parcel Dataset",
        "author": [
            "Ding-Tao Huang",
            "Xinyi He",
            "Debei Hua",
            "Dongfang Yu",
            "En-Te Lin",
            "Long Zeng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07238",
        "abstract": "While recent advances in object suction grasping have shown remarkable progress, significant challenges persist particularly in cluttered and complex parcel handling scenarios. Two fundamental limitations hinder current approaches: (1) the lack of a comprehensive suction grasp dataset tailored for parcel manipulation tasks, and (2) insufficient adaptability to diverse object characteristics including size variations, geometric complexity, and textural diversity. To address these challenges, we present Parcel-Suction-Dataset, a large-scale synthetic dataset containing 25 thousand cluttered scenes with 410 million precision-annotated suction grasp poses. This dataset is generated through our novel geometric sampling algorithm that enables efficient generation of optimal suction grasps incorporating both physical constraints and material properties. We further propose Diffusion-Suction, an innovative framework that reformulates suction grasp prediction as a conditional generation task through denoising diffusion probabilistic models. Our method iteratively refines random noise into suction grasp score maps through visual-conditioned guidance from point cloud observations, effectively learning spatial point-wise affordances from our synthetic dataset. Extensive experiments demonstrate that the simple yet efficient Diffusion-Suction achieves new state-of-the-art performance compared to previous models on both Parcel-Suction-Dataset and the public SuctionNet-1Billion benchmark.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "98",
        "title": "Contextual Gesture: Co-Speech Gesture Video Generation through Context-aware Gesture Representation",
        "author": [
            "Pinxin Liu",
            "Pengfei Zhang",
            "Hyeongwoo Kim",
            "Pablo Garrido",
            "Ari Sharpio",
            "Kyle Olszewski"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07239",
        "abstract": "Co-speech gesture generation is crucial for creating lifelike avatars and enhancing human-computer interactions by synchronizing gestures with speech. Despite recent advancements, existing methods struggle with accurately identifying the rhythmic or semantic triggers from audio for generating contextualized gesture patterns and achieving pixel-level realism. To address these challenges, we introduce Contextual Gesture, a framework that improves co-speech gesture video generation through three innovative components: (1) a chronological speech-gesture alignment that temporally connects two modalities, (2) a contextualized gesture tokenization that incorporate speech context into motion pattern representation through distillation, and (3) a structure-aware refinement module that employs edge connection to link gesture keypoints to improve video generation. Our extensive experiments demonstrate that Contextual Gesture not only produces realistic and speech-aligned gesture videos but also supports long-sequence generation and video gesture editing applications, shown in Fig.1 Project Page: https://andypinxinliu.github.io/Contextual-Gesture/.",
        "tags": [
            "Video Generation"
        ]
    },
    {
        "id": "99",
        "title": "Vevo: Controllable Zero-Shot Voice Imitation with Self-Supervised Disentanglement",
        "author": [
            "Xueyao Zhang",
            "Xiaohui Zhang",
            "Kainan Peng",
            "Zhenyu Tang",
            "Vimal Manohar",
            "Yingru Liu",
            "Jeff Hwang",
            "Dangna Li",
            "Yuhao Wang",
            "Julian Chan",
            "Yuan Huang",
            "Zhizheng Wu",
            "Mingbo Ma"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07243",
        "abstract": "The imitation of voice, targeted on specific speech attributes such as timbre and speaking style, is crucial in speech generation. However, existing methods rely heavily on annotated data, and struggle with effectively disentangling timbre and style, leading to challenges in achieving controllable generation, especially in zero-shot scenarios. To address these issues, we propose Vevo, a versatile zero-shot voice imitation framework with controllable timbre and style. Vevo operates in two core stages: (1) Content-Style Modeling: Given either text or speech's content tokens as input, we utilize an autoregressive transformer to generate the content-style tokens, which is prompted by a style reference; (2) Acoustic Modeling: Given the content-style tokens as input, we employ a flow-matching transformer to produce acoustic representations, which is prompted by a timbre reference. To obtain the content and content-style tokens of speech, we design a fully self-supervised approach that progressively decouples the timbre, style, and linguistic content of speech. Specifically, we adopt VQ-VAE as the tokenizer for the continuous hidden features of HuBERT. We treat the vocabulary size of the VQ-VAE codebook as the information bottleneck, and adjust it carefully to obtain the disentangled speech representations. Solely self-supervised trained on 60K hours of audiobook speech data, without any fine-tuning on style-specific corpora, Vevo matches or surpasses existing methods in accent and emotion conversion tasks. Additionally, Vevo's effectiveness in zero-shot voice conversion and text-to-speech tasks further demonstrates its strong generalization and versatility. Audio samples are available at https://versavoice.github.io.",
        "tags": [
            "Flow Matching",
            "Transformer",
            "VAE"
        ]
    },
    {
        "id": "100",
        "title": "Linear Transformers as VAR Models: Aligning Autoregressive Attention Mechanisms with Autoregressive Forecasting",
        "author": [
            "Jiecheng Lu",
            "Shihao Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07244",
        "abstract": "Autoregressive attention-based time series forecasting (TSF) has drawn increasing interest, with mechanisms like linear attention sometimes outperforming vanilla attention. However, deeper Transformer architectures frequently misalign with autoregressive objectives, obscuring the underlying VAR structure embedded within linear attention and hindering their ability to capture the data generative processes in TSF. In this work, we first show that a single linear attention layer can be interpreted as a dynamic vector autoregressive (VAR) structure. We then explain that existing multi-layer Transformers have structural mismatches with the autoregressive forecasting objective, which impair interpretability and generalization ability. To address this, we show that by rearranging the MLP, attention, and input-output flow, multi-layer linear attention can also be aligned as a VAR model. Then, we propose Structural Aligned Mixture of VAR (SAMoVAR), a linear Transformer variant that integrates interpretable dynamic VAR weights for multivariate TSF. By aligning the Transformer architecture with autoregressive objectives, SAMoVAR delivers improved performance, interpretability, and computational efficiency, comparing to SOTA TSF models.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "101",
        "title": "NARCE: A Mamba-Based Neural Algorithmic Reasoner Framework for Online Complex Event Detection",
        "author": [
            "Liying Han",
            "Gaofeng Dong",
            "Xiaomin Ouyang",
            "Lance Kaplan",
            "Federico Cerutti",
            "Mani Srivastava"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07250",
        "abstract": "Current machine learning models excel in short-span perception tasks but struggle to derive high-level insights from long-term observation, a capability central to understanding complex events (CEs). CEs, defined as sequences of short-term atomic events (AEs) governed by spatiotemporal rules, are challenging to detect online due to the need to extract meaningful patterns from long and noisy sensor data while ignoring irrelevant events. We hypothesize that state-based methods are well-suited for CE detection, as they capture event progression through state transitions without requiring long-term memory. Baseline experiments validate this, demonstrating that the state-space model Mamba outperforms existing architectures. However, Mamba's reliance on extensive labeled data, which are difficult to obtain, motivates our second hypothesis: decoupling CE rule learning from noisy sensor data can reduce data requirements. To address this, we propose NARCE, a framework that combines Neural Algorithmic Reasoning (NAR) to split the task into two components: (i) learning CE rules independently of sensor data using synthetic concept traces generated by LLMs and (ii) mapping sensor inputs to these rules via an adapter. Our results show that NARCE outperforms baselines in accuracy, generalization to unseen and longer sensor data, and data efficiency, significantly reducing annotation costs while advancing robust CE detection.",
        "tags": [
            "Detection",
            "LLMs",
            "Mamba"
        ]
    },
    {
        "id": "102",
        "title": "When More is Less: Understanding Chain-of-Thought Length in LLMs",
        "author": [
            "Yuyang Wu",
            "Yifei Wang",
            "Tianqi Du",
            "Stefanie Jegelka",
            "Yisen Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07266",
        "abstract": "Chain-of-thought (CoT) reasoning enhances the multi-step reasoning capabilities of large language models (LLMs) by breaking complex tasks into smaller, manageable sub-tasks. Researchers have been exploring ways to guide models to generate more complex CoT processes to improve the reasoning ability of LLMs, such as long CoT and the test-time scaling law. However, for most models and tasks, does an increase in CoT length consistently lead to improved reasoning accuracy? In this paper, we observe a nuanced relationship: as the number of reasoning steps increases, performance initially improves but eventually decreases. To understand this phenomenon, we provide a piece of evidence that longer reasoning processes are increasingly susceptible to noise. We theoretically prove the existence of an optimal CoT length and derive a scaling law for this optimal length based on model capability and task difficulty. Inspired by our theory, we conduct experiments on both synthetic and real world datasets and propose Length-filtered Vote to alleviate the effects of excessively long or short CoTs. Our findings highlight the critical need to calibrate CoT length to align with model capabilities and task demands, offering a principled framework for optimizing multi-step reasoning in LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "103",
        "title": "Articulate That Object Part (ATOP): 3D Part Articulation from Text and Motion Personalization",
        "author": [
            "Aditya Vora",
            "Sauradip Nag",
            "Hao Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07278",
        "abstract": "We present ATOP (Articulate That Object Part), a novel method based on motion personalization to articulate a 3D object with respect to a part and its motion as prescribed in a text prompt. Specifically, the text input allows us to tap into the power of modern-day video diffusion to generate plausible motion samples for the right object category and part. In turn, the input 3D object provides image prompting to personalize the generated video to that very object we wish to articulate. Our method starts with a few-shot finetuning for category-specific motion generation, a key first step to compensate for the lack of articulation awareness by current video diffusion models. For this, we finetune a pre-trained multi-view image generation model for controllable multi-view video generation, using a small collection of video samples obtained for the target object category. This is followed by motion video personalization that is realized by multi-view rendered images of the target 3D object. At last, we transfer the personalized video motion to the target 3D object via differentiable rendering to optimize part motion parameters by a score distillation sampling loss. We show that our method is capable of generating realistic motion videos and predict 3D motion parameters in a more accurate and generalizable way, compared to prior works.",
        "tags": [
            "3D",
            "Diffusion",
            "Video Generation"
        ]
    },
    {
        "id": "104",
        "title": "Exploratory Diffusion Policy for Unsupervised Reinforcement Learning",
        "author": [
            "Chengyang Ying",
            "Huayu Chen",
            "Xinning Zhou",
            "Zhongkai Hao",
            "Hang Su",
            "Jun Zhu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07279",
        "abstract": "Unsupervised reinforcement learning (RL) aims to pre-train agents by exploring states or skills in reward-free environments, facilitating the adaptation to downstream tasks. However, existing methods often overlook the fitting ability of pre-trained policies and struggle to handle the heterogeneous pre-training data, which are crucial for achieving efficient exploration and fast fine-tuning. To address this gap, we propose Exploratory Diffusion Policy (EDP), which leverages the strong expressive ability of diffusion models to fit the explored data, both boosting exploration and obtaining an efficient initialization for downstream tasks. Specifically, we estimate the distribution of collected data in the replay buffer with the diffusion policy and propose a score intrinsic reward, encouraging the agent to explore unseen states. For fine-tuning the pre-trained diffusion policy on downstream tasks, we provide both theoretical analyses and practical algorithms, including an alternating method of Q function optimization and diffusion policy distillation. Extensive experiments demonstrate the effectiveness of EDP in efficient exploration during pre-training and fast adaptation during fine-tuning.",
        "tags": [
            "Diffusion",
            "RL"
        ]
    },
    {
        "id": "105",
        "title": "MIGT: Memory Instance Gated Transformer Framework for Financial Portfolio Management",
        "author": [
            "Fengchen Gu",
            "Angelos Stefanidis",
            "Ãngel GarcÃ­a-FernÃ¡ndez",
            "Jionglong Su",
            "Huakang Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07280",
        "abstract": "Deep reinforcement learning (DRL) has been applied in financial portfolio management to improve returns in changing market conditions. However, unlike most fields where DRL is widely used, the stock market is more volatile and dynamic as it is affected by several factors such as global events and investor sentiment. Therefore, it remains a challenge to construct a DRL-based portfolio management framework with strong return capability, stable training, and generalization ability. This study introduces a new framework utilizing the Memory Instance Gated Transformer (MIGT) for effective portfolio management. By incorporating a novel Gated Instance Attention module, which combines a transformer variant, instance normalization, and a Lite Gate Unit, our approach aims to maximize investment returns while ensuring the learning process's stability and reducing outlier impacts. Tested on the Dow Jones Industrial Average 30, our framework's performance is evaluated against fifteen other strategies using key financial metrics like the cumulative return and risk-return ratios (Sharpe, Sortino, and Omega ratios). The results highlight MIGT's advantage, showcasing at least a 9.75% improvement in cumulative returns and a minimum 2.36% increase in risk-return ratios over competing strategies, marking a significant advancement in DRL for portfolio management.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "106",
        "title": "Small Language Model Makes an Effective Long Text Extractor",
        "author": [
            "Yelin Chen",
            "Fanjin Zhang",
            "Jie Tang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07286",
        "abstract": "Named Entity Recognition (NER) is a fundamental problem in natural language processing (NLP). However, the task of extracting longer entity spans (e.g., awards) from extended texts (e.g., homepages) is barely explored. Current NER methods predominantly fall into two categories: span-based methods and generation-based methods. Span-based methods require the enumeration of all possible token-pair spans, followed by classification on each span, resulting in substantial redundant computations and excessive GPU memory usage. In contrast, generation-based methods involve prompting or fine-tuning large language models (LLMs) to adapt to downstream NER tasks. However, these methods struggle with the accurate generation of longer spans and often incur significant time costs for effective fine-tuning. To address these challenges, this paper introduces a lightweight span-based NER method called SeNER, which incorporates a bidirectional arrow attention mechanism coupled with LogN-Scaling on the [CLS] token to embed long texts effectively, and comprises a novel bidirectional sliding-window plus-shaped attention (BiSPA) mechanism to reduce redundant candidate token-pair spans significantly and model interactions between token-pair spans simultaneously. Extensive experiments demonstrate that our method achieves state-of-the-art extraction accuracy on three long NER datasets and is capable of extracting entities from long texts in a GPU-memory-friendly manner. Code: https://github.com/THUDM/scholar-profiling/tree/main/sener",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "107",
        "title": "Generation of Drug-Induced Cardiac Reactions towards Virtual Clinical Trials",
        "author": [
            "Qian Shao",
            "Bang Du",
            "Zepeng Li",
            "Qiyuan Chen",
            "Hongxia Xu",
            "Jimeng Sun",
            "Jian Wu",
            "Jintai Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07297",
        "abstract": "Clinical trials are pivotal in cardiac drug development, yet they often fail due to inadequate efficacy and unexpected safety issues, leading to significant financial losses. Using in-silico trials to replace a part of physical clinical trials, e.g., leveraging advanced generative models to generate drug-influenced electrocardiograms (ECGs), seems an effective method to reduce financial risk and potential harm to trial participants. While existing generative models have demonstrated progress in ECG generation, they fall short in modeling drug reactions due to limited fidelity and inability to capture individualized drug response patterns. In this paper, we propose a Drug-Aware Diffusion Model (DADM), which could simulate individualized drug reactions while ensuring fidelity. To ensure fidelity, we construct a set of ordinary differential equations to provide external physical knowledge (EPK) of the realistic ECG morphology. The EPK is used to adaptively constrain the morphology of the generated ECGs through a dynamic cross-attention (DCA) mechanism. Furthermore, we propose an extension of ControlNet to incorporate demographic and drug data, simulating individual drug reactions. We compare DADM with the other eight state-of-the-art ECG generative models on two real-world databases covering 8 types of drug regimens. The results demonstrate that DADM can more accurately simulate drug-induced changes in ECGs, improving the accuracy by at least 5.79% and recall by 8%.",
        "tags": [
            "ControlNet",
            "Diffusion"
        ]
    },
    {
        "id": "108",
        "title": "TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation",
        "author": [
            "Navid Rajabi",
            "Jana Kosecka"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07306",
        "abstract": "In this work, we propose a modular approach for the Vision-Language Navigation (VLN) task by decomposing the problem into four sub-modules that use state-of-the-art Large Language Models (LLMs) and Vision-Language Models (VLMs) in a zero-shot setting. Given navigation instruction in natural language, we first prompt LLM to extract the landmarks and the order in which they are visited. Assuming the known model of the environment, we retrieve the top-k locations of the last landmark and generate $k$ path hypotheses from the starting location to the last landmark using the shortest path algorithm on the topological map of the environment. Each path hypothesis is represented by a sequence of panoramas. We then use dynamic programming to compute the alignment score between the sequence of panoramas and the sequence of landmark names, which match scores obtained from VLM. Finally, we compute the nDTW metric between the hypothesis that yields the highest alignment score to evaluate the path fidelity. We demonstrate superior performance compared to other approaches that use joint semantic maps like VLMaps \\cite{vlmaps} on the complex R2R-Habitat \\cite{r2r} instruction dataset and quantify in detail the effect of visual grounding on navigation performance.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "109",
        "title": "OpenGrok: Enhancing SNS Data Processing with Distilled Knowledge and Mask-like Mechanisms",
        "author": [
            "Lumen AI",
            "Zaozhuang No.28 Middle School",
            "Shihao Ji",
            "Zihui Song",
            "Fucheng Zhong",
            "Jisen Jia",
            "Zhaobo Wu",
            "Zheyi Cao",
            "Tianhao Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07312",
        "abstract": "This report details Lumen Labs' novel approach to processing Social Networking Service (SNS) data. We leverage knowledge distillation, specifically a simple distillation method inspired by DeepSeek-R1's CoT acquisition, combined with prompt hacking, to extract valuable training data from the Grok model. This data is then used to fine-tune a Phi-3-mini model, augmented with a mask-like mechanism specifically designed for handling the nuances of SNS data. Our method demonstrates state-of-the-art (SOTA) performance on several SNS data processing tasks, outperforming existing models like Grok, Phi-3, and GPT-4. We provide a comprehensive analysis of our approach, including mathematical formulations, engineering details, ablation studies, and comparative evaluations.",
        "tags": [
            "DeepSeek",
            "GPT"
        ]
    },
    {
        "id": "110",
        "title": "Prompt-Based Document Modifications In Ranking Competitions",
        "author": [
            "Niv Bardas",
            "Tommy Mordo",
            "Oren Kurland",
            "Moshe Tennenholtz",
            "Gal Zur"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07315",
        "abstract": "We study prompting-based approaches with Large Language Models (LLMs) for modifying documents so as to promote their ranking in a competitive search setting. Our methods are inspired by prior work on leveraging LLMs as rankers. We evaluate our approach by deploying it as a bot in previous ranking competitions and in competitions we organized. Our findings demonstrate that our approach effectively improves document ranking while preserving high levels of faithfulness to the original content and maintaining overall document quality.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "111",
        "title": "CodeI/O: Condensing Reasoning Patterns via Code Input-Output Prediction",
        "author": [
            "Junlong Li",
            "Daya Guo",
            "Dejian Yang",
            "Runxin Xu",
            "Yu Wu",
            "Junxian He"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07316",
        "abstract": "Reasoning is a fundamental capability of Large Language Models. While prior research predominantly focuses on enhancing narrow skills like math or code generation, improving performance on many other reasoning tasks remains challenging due to sparse and fragmented training data. To address this issue, we propose CodeI/O, a novel approach that systematically condenses diverse reasoning patterns inherently embedded in contextually-grounded codes, through transforming the original code into a code input-output prediction format. By training models to predict inputs/outputs given code and test cases entirely in natural language as Chain-of-Thought (CoT) rationales, we expose them to universal reasoning primitives -- like logic flow planning, state-space searching, decision tree traversal, and modular decomposition -- while decoupling structured reasoning from code-specific syntax and preserving procedural rigor. Experimental results demonstrate CodeI/O leads to consistent improvements across symbolic, scientific, logic, math & numerical, and commonsense reasoning tasks. By matching the existing ground-truth outputs or re-executing the code with predicted inputs, we can verify each prediction and further enhance the CoTs through multi-turn revision, resulting in CodeI/O++ and achieving higher performance. Our data and models are available at https://github.com/hkust-nlp/CodeIO.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "112",
        "title": "MEMIT-Merge: Addressing MEMIT's Key-Value Conflicts in Same-Subject Batch Editing for LLMs",
        "author": [
            "Zilu Dong",
            "Xiangqing Shen",
            "Rui Xia"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07322",
        "abstract": "As large language models continue to scale up, knowledge editing techniques that modify models' internal knowledge without full retraining have gained significant attention. MEMIT, a prominent batch editing algorithm, stands out for its capability to perform mass knowledge modifications. However, we uncover a critical limitation that MEMIT's editing efficacy significantly deteriorates when processing batches containing multiple edits sharing the same subject. Our analysis reveals that the root cause lies in MEMIT's key value modeling framework: When multiple facts with the same subject in a batch are modeled through MEMIT's key value mechanism, identical keys (derived from the shared subject) are forced to represent different values (corresponding to different knowledge), resulting in updates conflicts during editing. Addressing this issue, we propose MEMIT-Merge, an enhanced approach that merges value computation processes for facts sharing the same subject, effectively resolving the performance degradation in same-subject batch editing scenarios. Experimental results demonstrate that when MEMIT's edit success rate drops to around 50% at larger batch sizes, MEMIT-Merge maintains a success rate exceeding 90%, showcasing remarkable robustness to subject entity collisions.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "113",
        "title": "Semantic to Structure: Learning Structural Representations for Infringement Detection",
        "author": [
            "Chuanwei Huang",
            "Zexi Jia",
            "Hongyan Fei",
            "Yeshuang Zhu",
            "Zhiqiang Yuan",
            "Jinchao Zhang",
            "Jie Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07323",
        "abstract": "Structural information in images is crucial for aesthetic assessment, and it is widely recognized in the artistic field that imitating the structure of other works significantly infringes on creators' rights. The advancement of diffusion models has led to AI-generated content imitating artists' structural creations, yet effective detection methods are still lacking. In this paper, we define this phenomenon as \"structural infringement\" and propose a corresponding detection method. Additionally, we develop quantitative metrics and create manually annotated datasets for evaluation: the SIA dataset of synthesized data, and the SIR dataset of real data. Due to the current lack of datasets for structural infringement detection, we propose a new data synthesis strategy based on diffusion models and LLM, successfully training a structural infringement detection model. Experimental results show that our method can successfully detect structural infringements and achieve notable improvements on annotated test sets.",
        "tags": [
            "Detection",
            "Diffusion"
        ]
    },
    {
        "id": "114",
        "title": "Generative Ghost: Investigating Ranking Bias Hidden in AI-Generated Videos",
        "author": [
            "Haowen Gao",
            "Liang Pang",
            "Shicheng Xu",
            "Leigang Qu",
            "Tat-Seng Chua",
            "Huawei Shen",
            "Xueqi Cheng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07327",
        "abstract": "With the rapid development of AI-generated content (AIGC), the creation of high-quality AI-generated videos has become faster and easier, resulting in the Internet being flooded with all kinds of video content. However, the impact of these videos on the content ecosystem remains largely unexplored. Video information retrieval remains a fundamental approach for accessing video content. Building on the observation that retrieval models often favor AI-generated content in ad-hoc and image retrieval tasks, we investigate whether similar biases emerge in the context of challenging video retrieval, where temporal and visual factors may further influence model behavior. To explore this, we first construct a comprehensive benchmark dataset containing both real and AI-generated videos, along with a set of fair and rigorous metrics to assess bias. This benchmark consists of 13,000 videos generated by two state-of-the-art open-source video generation models. We meticulously design a suite of rigorous metrics to accurately measure this preference, accounting for potential biases arising from the limited frame rate and suboptimal quality of AIGC videos. We then applied three off-the-shelf video retrieval models to perform retrieval tasks on this hybrid dataset. Our findings reveal a clear preference for AI-generated videos in retrieval. Further investigation shows that incorporating AI-generated videos into the training set of retrieval models exacerbates this bias. Unlike the preference observed in image modalities, we find that video retrieval bias arises from both unseen visual and temporal information, making the root causes of video bias a complex interplay of these two factors. To mitigate this bias, we fine-tune the retrieval models using a contrastive learning approach. The results of this study highlight the potential implications of AI-generated videos on retrieval systems.",
        "tags": [
            "Video Generation"
        ]
    },
    {
        "id": "115",
        "title": "Aligning Large Language Models to Follow Instructions and Hallucinate Less via Effective Data Filtering",
        "author": [
            "Shuzheng Si",
            "Haozhe Zhao",
            "Gang Chen",
            "Cheng Gao",
            "Yuzhuo Bai",
            "Zhitong Wang",
            "Kaikai An",
            "Kangyang Luo",
            "Chen Qian",
            "Fanchao Qi",
            "Baobao Chang",
            "Maosong Sun"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07340",
        "abstract": "Training LLMs on data that contains unfamiliar knowledge during the instruction tuning stage can make LLMs overconfident and encourage hallucinations. To address this challenge, we introduce a novel framework, NOVA, which identifies high-quality data that aligns well with the LLM's learned knowledge to reduce hallucinations. NOVA includes Internal Consistency Probing (ICP) and Semantic Equivalence Identification (SEI) to measure how familiar the LLM is with instruction data. Specifically, ICP evaluates the LLM's understanding of the given instruction by calculating the tailored consistency among multiple self-generated responses. SEI further assesses the familiarity of the LLM with the target response by comparing it to the generated responses, using the proposed semantic clustering and well-designed voting strategy. Finally, we introduce an expert-aligned reward model, considering characteristics beyond just familiarity to enhance data quality. By considering data quality and avoiding unfamiliar data, we can utilize the selected data to effectively align LLMs to follow instructions and hallucinate less. Extensive experiments and analysis show that NOVA significantly reduces hallucinations and allows LLMs to maintain a strong ability to follow instructions.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "116",
        "title": "BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models",
        "author": [
            "Xu Huang",
            "Wenhao Zhu",
            "Hanxu Hu",
            "Conghui He",
            "Lei Li",
            "Shujian Huang",
            "Fei Yuan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07346",
        "abstract": "Previous multilingual benchmarks focus primarily on simple understanding tasks, but for large language models(LLMs), we emphasize proficiency in instruction following, reasoning, long context understanding, code generation, and so on. However, measuring these advanced capabilities across languages is underexplored. To address the disparity, we introduce BenchMAX, a multi-way multilingual evaluation benchmark that allows for fair comparisons of these important abilities across languages. To maintain high quality, three distinct native-speaking annotators independently annotate each sample within all tasks after the data was machine-translated from English into 16 other languages. Additionally, we present a novel translation challenge stemming from dataset construction. Extensive experiments on BenchMAX reveal varying effectiveness of core capabilities across languages, highlighting performance gaps that cannot be bridged by simply scaling up model size. BenchMAX serves as a comprehensive multilingual evaluation platform, providing a promising test bed to promote the development of multilingual language models. The dataset and code are publicly accessible.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "117",
        "title": "KABB: Knowledge-Aware Bayesian Bandits for Dynamic Expert Coordination in Multi-Agent Systems",
        "author": [
            "Jusheng Zhang",
            "Zimeng Huang",
            "Yijia Fan",
            "Ningyuan Liu",
            "Mingyan Li",
            "Zhuojie Yang",
            "Jiawei Yao",
            "Jian Wang",
            "Keze Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07350",
        "abstract": "As scaling large language models faces prohibitive costs, multi-agent systems emerge as a promising alternative, though challenged by static knowledge assumptions and coordination inefficiencies. We introduces Knowledge-Aware Bayesian Bandits (KABB), a novel framework that enhances multi-agent system coordination through semantic understanding and dynamic adaptation. The framework features three key innovations: a three-dimensional knowledge distance model for deep semantic understanding, a dual-adaptation mechanism for continuous expert optimization, and a knowledge-aware Thompson Sampling strategy for efficient expert selection. Extensive evaluation demonstrates KABB achieves an optimal cost-performance balance, maintaining high performance while keeping computational demands relatively low in multi-agent coordination.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "118",
        "title": "Bridging the Evaluation Gap: Leveraging Large Language Models for Topic Model Evaluation",
        "author": [
            "Zhiyin Tan",
            "Jennifer D'Souza"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07352",
        "abstract": "This study presents a framework for automated evaluation of dynamically evolving topic taxonomies in scientific literature using Large Language Models (LLMs). In digital library systems, topic modeling plays a crucial role in efficiently organizing and retrieving scholarly content, guiding researchers through complex knowledge landscapes. As research domains proliferate and shift, traditional human centric and static evaluation methods struggle to maintain relevance. The proposed approach harnesses LLMs to measure key quality dimensions, such as coherence, repetitiveness, diversity, and topic-document alignment, without heavy reliance on expert annotators or narrow statistical metrics. Tailored prompts guide LLM assessments, ensuring consistent and interpretable evaluations across various datasets and modeling techniques. Experiments on benchmark corpora demonstrate the method's robustness, scalability, and adaptability, underscoring its value as a more holistic and dynamic alternative to conventional evaluation strategies.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "119",
        "title": "LongReD: Mitigating Short-Text Degradation of Long-Context Large Language Models via Restoration Distillation",
        "author": [
            "Zican Dong",
            "Junyi Li",
            "Jinhao Jiang",
            "Mingyu Xu",
            "Wayne Xin Zhao",
            "Bingning Wang",
            "Weipeng Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07365",
        "abstract": "Large language models (LLMs) have gained extended context windows through scaling positional encodings and lightweight continual pre-training. However, this often leads to degraded performance on short-text tasks, while the reasons for this degradation remain insufficiently explored. In this work, we identify two primary factors contributing to this issue: distribution drift in hidden states and attention scores, and catastrophic forgetting during continual pre-training. To address these challenges, we propose Long Context Pre-training with Restoration Distillation (LongReD), a novel approach designed to mitigate short-text performance degradation through minimizing the distribution discrepancy between the extended and original models. Besides training on long texts, LongReD distills the hidden state of selected layers from the original model on short texts. Additionally, LongReD also introduces a short-to-long distillation, aligning the output distribution on short texts with that on long texts by leveraging skipped positional indices. Experiments on common text benchmarks demonstrate that LongReD effectively preserves the model's short-text performance while maintaining comparable or even better capacity to handle long texts than baselines.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "120",
        "title": "LLMs Can Easily Learn to Reason from Demonstrations Structure, not content, is what matters!",
        "author": [
            "Dacheng Li",
            "Shiyi Cao",
            "Tyler Griggs",
            "Shu Liu",
            "Xiangxi Mo",
            "Shishir G. Patil",
            "Matei Zaharia",
            "Joseph E. Gonzalez",
            "Ion Stoica"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07374",
        "abstract": "Large reasoning models (LRMs) tackle complex reasoning problems by following long chain-of-thoughts (Long CoT) that incorporate reflection, backtracking, and self-validation. However, the training techniques and data requirements to elicit Long CoT remain poorly understood. In this work, we find that a Large Language model (LLM) can effectively learn Long CoT reasoning through data-efficient supervised fine-tuning (SFT) and parameter-efficient low-rank adaptation (LoRA). With just 17k long CoT training samples, the Qwen2.5-32B-Instruct model achieves significant improvements on a wide range of math and coding benchmarks, including 56.7% (+40.0%) on AIME 2024 and 57.0% (+8.1%) on LiveCodeBench, competitive to the proprietary o1-preview model's score of 44.6% and 59.1%. More importantly, we find that the structure of Long CoT is critical to the learning process, whereas the content of individual reasoning steps has minimal impact. Perturbations affecting content, such as training on incorrect samples or removing reasoning keywords, have little impact on performance. In contrast, structural modifications that disrupt logical consistency in the Long CoT, such as shuffling or deleting reasoning steps, significantly degrade accuracy. For example, a model trained on Long CoT samples with incorrect answers still achieves only 3.2% lower accuracy compared to training with fully correct samples. These insights deepen our understanding of how to elicit reasoning capabilities in LLMs and highlight key considerations for efficiently training the next generation of reasoning models. This is the academic paper of our previous released Sky-T1-32B-Preview model. Codes are available at https://github.com/NovaSky-AI/SkyThought.",
        "tags": [
            "LLMs",
            "LoRA",
            "Low-Rank Adaptation"
        ]
    },
    {
        "id": "121",
        "title": "Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution",
        "author": [
            "Hongyu An",
            "Xinfeng Zhang",
            "Shijie Zhao",
            "Li Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07381",
        "abstract": "Due to limitations of storage and bandwidth, videos stored and transmitted on the Internet are usually low-quality with low-resolution and compression noise. Although video super-resolution (VSR) is an efficient technique to enhance video resolution, relatively VSR methods focus on compressed videos. Directly applying general VSR approaches leads to the failure of improving practical videos, especially when frames are highly compressed at a low bit rate. Recently, diffusion models have achieved superior performance in low-level visual tasks, and their high-realism generation capability enables them to be applied in VSR. To synthesize more compression-lost details and refine temporal consistency, we propose a novel Spatial Degradation-Aware and Temporal Consistent (SDATC) diffusion model for compressed VSR. Specifically, we introduce a distortion Control module (DCM) to modulate diffusion model inputs and guide the generation. Next, the diffusion model executes the denoising process for texture generation with fine-tuned spatial prompt-based compression-aware module (PCAM) and spatio-temporal attention module (STAM). PCAM extracts features to encode specific compression information dynamically. STAM extends the spatial attention mechanism to a spatio-temporal dimension for capturing temporal correlation. Extensive experimental results on benchmark datasets demonstrate the effectiveness of the proposed modules in enhancing compressed videos.",
        "tags": [
            "Diffusion",
            "Super Resolution"
        ]
    },
    {
        "id": "122",
        "title": "Target-Augmented Shared Fusion-based Multimodal Sarcasm Explanation Generation",
        "author": [
            "Palaash Goel",
            "Dushyant Singh Chauhan",
            "Md Shad Akhtar"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07391",
        "abstract": "Sarcasm is a linguistic phenomenon that intends to ridicule a target (e.g., entity, event, or person) in an inherent way. Multimodal Sarcasm Explanation (MuSE) aims at revealing the intended irony in a sarcastic post using a natural language explanation. Though important, existing systems overlooked the significance of the target of sarcasm in generating explanations. In this paper, we propose a Target-aUgmented shaRed fusion-Based sarcasm explanatiOn model, aka. TURBO. We design a novel shared-fusion mechanism to leverage the inter-modality relationships between an image and its caption. TURBO assumes the target of the sarcasm and guides the multimodal shared fusion mechanism in learning intricacies of the intended irony for explanations. We evaluate our proposed TURBO model on the MORE+ dataset. Comparison against multiple baselines and state-of-the-art models signifies the performance improvement of TURBO by an average margin of $+3.3\\%$. Moreover, we explore LLMs in zero and one-shot settings for our task and observe that LLM-generated explanation, though remarkable, often fails to capture the critical nuances of the sarcasm. Furthermore, we supplement our study with extensive human evaluation on TURBO's generated explanations and find them out to be comparatively better than other systems.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "123",
        "title": "On Iterative Evaluation and Enhancement of Code Quality Using GPT-4o",
        "author": [
            "Rundong Liu",
            "Andre Frade",
            "Amal Vaidya",
            "Maxime Labonne",
            "Marcus Kaiser",
            "Bismayan Chakrabarti",
            "Jonathan Budd",
            "Sean Moran"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07399",
        "abstract": "This paper introduces CodeQUEST, a novel framework leveraging Large Language Models (LLMs) to iteratively evaluate and enhance code quality across multiple dimensions, including readability, maintainability, efficiency, and security. The framework is divided into two main components: an Evaluator that assesses code quality across ten dimensions, providing both quantitative scores and qualitative summaries, and an Optimizer that iteratively improves the code based on the Evaluator's feedback. Our study demonstrates that CodeQUEST can effectively and robustly evaluate code quality, with its assessments aligning closely with established code quality metrics. Through a series of experiments using a curated dataset of Python and JavaScript examples, CodeQUEST demonstrated significant improvements in code quality, achieving a mean relative percentage improvement of 52.6%. The framework's evaluations were validated against a set of proxy metrics comprising of Pylint Score, Radon Maintainability Index, and Bandit output logs, showing a meaningful correlation. This highlights the potential of LLMs in automating code quality evaluation and improvement processes, presenting a significant advancement toward enhancing software development practices. The code implementation of the framework is available at: https://github.com/jpmorganchase/CodeQuest.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "124",
        "title": "Enhancing Higher Education with Generative AI: A Multimodal Approach for Personalised Learning",
        "author": [
            "Johnny Chan",
            "Yuming Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07401",
        "abstract": "This research explores the opportunities of Generative AI (GenAI) in the realm of higher education through the design and development of a multimodal chatbot for an undergraduate course. Leveraging the ChatGPT API for nuanced text-based interactions and Google Bard for advanced image analysis and diagram-to-code conversions, we showcase the potential of GenAI in addressing a broad spectrum of educational queries. Additionally, the chatbot presents a file-based analyser designed for educators, offering deep insights into student feedback via sentiment and emotion analysis, and summarising course evaluations with key metrics. These combinations highlight the crucial role of multimodal conversational AI in enhancing teaching and learning processes, promising significant advancements in educational adaptability, engagement, and feedback analysis. By demonstrating a practical web application, this research underlines the imperative for integrating GenAI technologies to foster more dynamic and responsive educational environments, ultimately contributing to improved educational outcomes and pedagogical strategies.",
        "tags": [
            "ChatGPT"
        ]
    },
    {
        "id": "125",
        "title": "EgoTextVQA: Towards Egocentric Scene-Text Aware Video Question Answering",
        "author": [
            "Sheng Zhou",
            "Junbin Xiao",
            "Qingyun Li",
            "Yicong Li",
            "Xun Yang",
            "Dan Guo",
            "Meng Wang",
            "Tat-Seng Chua",
            "Angela Yao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07411",
        "abstract": "We introduce EgoTextVQA, a novel and rigorously constructed benchmark for egocentric QA assistance involving scene text. EgoTextVQA contains 1.5K ego-view videos and 7K scene-text aware questions that reflect real-user needs in outdoor driving and indoor house-keeping activities. The questions are designed to elicit identification and reasoning on scene text in an egocentric and dynamic environment. With EgoTextVQA, we comprehensively evaluate 10 prominent multimodal large language models. Currently, all models struggle, and the best results (Gemini 1.5 Pro) are around 33% accuracy, highlighting the severe deficiency of these techniques in egocentric QA assistance. Our further investigations suggest that precise temporal grounding and multi-frame reasoning, along with high resolution and auxiliary scene-text inputs, are key for better performance. With thorough analyses and heuristic suggestions, we hope EgoTextVQA can serve as a solid testbed for research in egocentric scene-text QA assistance.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "126",
        "title": "Fast-COS: A Fast One-Stage Object Detector Based on Reparameterized Attention Vision Transformer for Autonomous Driving",
        "author": [
            "Novendra Setyawan",
            "Ghufron Wahyu Kurniawan",
            "Chi-Chia Sun",
            "Wen-Kai Kuo",
            "Jun-Wei Hsieh"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07417",
        "abstract": "The perception system is a a critical role of an autonomous driving system for ensuring safety. The driving scene perception system fundamentally represents an object detection task that requires achieving a balance between accuracy and processing speed. Many contemporary methods focus on improving detection accuracy but often overlook the importance of real-time detection capabilities when computational resources are limited. Thus, it is vital to investigate efficient object detection strategies for driving scenes. This paper introduces Fast-COS, a novel single-stage object detection framework crafted specifically for driving scene applications. The research initiates with an analysis of the backbone, considering both macro and micro architectural designs, yielding the Reparameterized Attention Vision Transformer (RAViT). RAViT utilizes Reparameterized Multi-Scale Depth-Wise Convolution (RepMSDW) and Reparameterized Self-Attention (RepSA) to enhance computational efficiency and feature extraction. In extensive tests across GPU, edge, and mobile platforms, RAViT achieves 81.4% Top-1 accuracy on the ImageNet-1K dataset, demonstrating significant throughput improvements over comparable backbone models such as ResNet, FastViT, RepViT, and EfficientFormer. Additionally, integrating RepMSDW into a feature pyramid network forms RepFPN, enabling fast and multi-scale feature fusion. Fast-COS enhances object detection in driving scenes, attaining an AP50 score of 57.2% on the BDD100K dataset and 80.0% on the TJU-DHD Traffic dataset. It surpasses leading models in efficiency, delivering up to 75.9% faster GPU inference and 1.38 higher throughput on edge devices compared to FCOS, YOLOF, and RetinaNet. These findings establish Fast-COS as a highly scalable and reliable solution suitable for real-time applications, especially in resource-limited environments like autonomous driving systems",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "127",
        "title": "Entity Linking using LLMs for Automated Product Carbon Footprint Estimation",
        "author": [
            "Steffen Castle",
            "Julian Moreno Schneider",
            "Leonhard Hennig",
            "Georg Rehm"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07418",
        "abstract": "Growing concerns about climate change and sustainability are driving manufacturers to take significant steps toward reducing their carbon footprints. For these manufacturers, a first step towards this goal is to identify the environmental impact of the individual components of their products. We propose a system leveraging large language models (LLMs) to automatically map components from manufacturer Bills of Materials (BOMs) to Life Cycle Assessment (LCA) database entries by using LLMs to expand on available component information. Our approach reduces the need for manual data processing, paving the way for more accessible sustainability practices.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "128",
        "title": "RomanLens: Latent Romanization and its role in Multilinguality in LLMs",
        "author": [
            "Alan Saji",
            "Jaavid Aktar Husain",
            "Thanmay Jayakumar",
            "Raj Dabre",
            "Anoop Kunchukuttan",
            "Mitesh M. Khapra",
            "Ratish Puduppully"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07424",
        "abstract": "Large Language Models (LLMs) exhibit remarkable multilingual generalization despite being predominantly trained on English-centric corpora. A fundamental question arises: how do LLMs achieve such robust multilingual capabilities? For non-Latin script languages, we investigate the role of romanization - the representation of non-Latin scripts using Latin characters - as a bridge in multilingual processing. Using mechanistic interpretability techniques, we analyze next-token generation and find that intermediate layers frequently represent target words in romanized form before transitioning to native script, a phenomenon we term Latent Romanization. Further, through activation patching experiments, we demonstrate that LLMs encode semantic concepts similarly across native and romanized scripts, suggesting a shared underlying representation. Additionally in translation towards non Latin languages, our findings reveal that when the target language is in romanized form, its representations emerge earlier in the model's layers compared to native script. These insights contribute to a deeper understanding of multilingual representation in LLMs and highlight the implicit role of romanization in facilitating language transfer. Our work provides new directions for potentially improving multilingual language modeling and interpretability.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "129",
        "title": "ArthroPhase: A Novel Dataset and Method for Phase Recognition in Arthroscopic Video",
        "author": [
            "Ali Bahari Malayeri",
            "Matthias Seibold",
            "Nicola Cavalcanti",
            "Jonas Hein",
            "Sascha Jecklin",
            "Lazaros Vlachopoulos",
            "Sandro Fucentese",
            "Sandro Hodel",
            "Philipp Furnstahl"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07431",
        "abstract": "This study aims to advance surgical phase recognition in arthroscopic procedures, specifically Anterior Cruciate Ligament (ACL) reconstruction, by introducing the first arthroscopy dataset and developing a novel transformer-based model. We aim to establish a benchmark for arthroscopic surgical phase recognition by leveraging spatio-temporal features to address the specific challenges of arthroscopic videos including limited field of view, occlusions, and visual distortions. We developed the ACL27 dataset, comprising 27 videos of ACL surgeries, each labeled with surgical phases. Our model employs a transformer-based architecture, utilizing temporal-aware frame-wise feature extraction through a ResNet-50 and transformer layers. This approach integrates spatio-temporal features and introduces a Surgical Progress Index (SPI) to quantify surgery progression. The model's performance was evaluated using accuracy, precision, recall, and Jaccard Index on the ACL27 and Cholec80 datasets. The proposed model achieved an overall accuracy of 72.91% on the ACL27 dataset. On the Cholec80 dataset, the model achieved a comparable performance with the state-of-the-art methods with an accuracy of 92.4%. The SPI demonstrated an output error of 10.6% and 9.86% on ACL27 and Cholec80 datasets respectively, indicating reliable surgery progression estimation. This study introduces a significant advancement in surgical phase recognition for arthroscopy, providing a comprehensive dataset and a robust transformer-based model. The results validate the model's effectiveness and generalizability, highlighting its potential to improve surgical training, real-time assistance, and operational efficiency in orthopedic surgery. The publicly available dataset and code will facilitate future research and development in this critical field.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "130",
        "title": "Optimizing Knowledge Distillation in Transformers: Enabling Multi-Head Attention without Alignment Barriers",
        "author": [
            "Zhaodong Bing",
            "Linze Li",
            "Jiajun Liang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07436",
        "abstract": "Knowledge distillation (KD) in transformers often faces challenges due to misalignment in the number of attention heads between teacher and student models. Existing methods either require identical head counts or introduce projectors to bridge dimensional gaps, limiting flexibility and efficiency. We propose Squeezing-Heads Distillation (SHD), a novel approach that enables seamless knowledge transfer between models with varying head counts by compressing multi-head attention maps via efficient linear approximation. Unlike prior work, SHD eliminates alignment barriers without additional parameters or architectural modifications. Our method dynamically approximates the combined effect of multiple teacher heads into fewer student heads, preserving fine-grained attention patterns while reducing redundancy. Experiments across language (LLaMA, GPT) and vision (DiT, MDT) generative and vision (DeiT) discriminative tasks demonstrate SHD's effectiveness: it outperforms logit-based and feature-alignment KD baselines, achieving state-of-the-art results in image classification, image generation language fine-tuning, and language pre-training. The key innovations of flexible head compression, projector-free design, and linear-time complexity make SHD a versatile and scalable solution for distilling modern transformers. This work bridges a critical gap in KD, enabling efficient deployment of compact models without compromising performance.",
        "tags": [
            "DiT",
            "GPT",
            "LLaMA"
        ]
    },
    {
        "id": "131",
        "title": "SensPS: Sensing Personal Space Comfortable Distance between Human-Human Using Multimodal Sensors",
        "author": [
            "Ko Watanabe",
            "Nico FÃ¶rster",
            "Shoya Ishimaru"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07441",
        "abstract": "Personal space, also known as peripersonal space, is crucial in human social interaction, influencing comfort, communication, and social stress. Estimating and respecting personal space is essential for enhancing human-computer interaction (HCI) and smart environments. Personal space preferences vary due to individual traits, cultural background, and contextual factors. Advanced multimodal sensing technologies, including eye-tracking and wristband sensors, offer opportunities to develop adaptive systems that dynamically adjust to user comfort levels. Integrating physiological and behavioral data enables a deeper understanding of spatial interactions. This study develops a sensor-based model to estimate comfortable personal space and identifies key features influencing spatial preferences. Our findings show that multimodal sensors, particularly eye-tracking and physiological wristband data, can effectively predict personal space preferences, with eye-tracking data playing a more significant role. An experimental study involving controlled human interactions demonstrates that a Transformer-based model achieves the highest predictive accuracy (F1 score: 0.87) for estimating personal space. Eye-tracking features, such as gaze point and pupil diameter, emerge as the most significant predictors, while physiological signals from wristband sensors contribute marginally. These results highlight the potential for AI-driven personalization of social space in adaptive environments, suggesting that multimodal sensing can be leveraged to develop intelligent systems that optimize spatial arrangements in workplaces, educational institutions, and public settings. Future work should explore larger datasets, real-world applications, and additional physiological markers to enhance model robustness.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "132",
        "title": "Approximating Human Strategic Reasoning with LLM-Enhanced Recursive Reasoners Leveraging Multi-agent Hypergames",
        "author": [
            "Vince Trencsenyi",
            "Agnieszka Mensfelt",
            "Kostas Stathis"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07443",
        "abstract": "LLM-driven multi-agent-based simulations have been gaining traction with applications in game-theoretic and social simulations. While most implementations seek to exploit or evaluate LLM-agentic reasoning, they often do so with a weak notion of agency and simplified architectures. We implement a role-based multi-agent strategic interaction framework tailored to sophisticated recursive reasoners, providing the means for systematic in-depth development and evaluation of strategic reasoning. Our game environment is governed by the umpire responsible for facilitating games, from matchmaking through move validation to environment management. Players incorporate state-of-the-art LLMs in their decision mechanism, relying on a formal hypergame-based model of hierarchical beliefs. We use one-shot, 2-player beauty contests to evaluate the recursive reasoning capabilities of the latest LLMs, providing a comparison to an established baseline model from economics and data from human experiments. Furthermore, we introduce the foundations of an alternative semantic measure of reasoning to the k-level theory. Our experiments show that artificial reasoners can outperform the baseline model in terms of both approximating human behaviour and reaching the optimal solution.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "133",
        "title": "Forget What You Know about LLMs Evaluations - LLMs are Like a Chameleon",
        "author": [
            "Nurit Cohen-Inger",
            "Yehonatan Elisha",
            "Bracha Shapira",
            "Lior Rokach",
            "Seffi Cohen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07445",
        "abstract": "Large language models (LLMs) often appear to excel on public benchmarks, but these high scores may mask an overreliance on dataset-specific surface cues rather than true language understanding. We introduce the Chameleon Benchmark Overfit Detector (C-BOD), a meta-evaluation framework that systematically distorts benchmark prompts via a parametric transformation and detects overfitting of LLMs. By rephrasing inputs while preserving their semantic content and labels, C-BOD exposes whether a model's performance is driven by memorized patterns. Evaluated on the MMLU benchmark using 26 leading LLMs, our method reveals an average performance degradation of 2.15% under modest perturbations, with 20 out of 26 models exhibiting statistically significant differences. Notably, models with higher baseline accuracy exhibit larger performance differences under perturbation, and larger LLMs tend to be more sensitive to rephrasings indicating that both cases may overrely on fixed prompt patterns. In contrast, the Llama family and models with lower baseline accuracy show insignificant degradation, suggesting reduced dependency on superficial cues. Moreover, C-BOD's dataset- and model-agnostic design allows easy integration into training pipelines to promote more robust language understanding. Our findings challenge the community to look beyond leaderboard scores and prioritize resilience and generalization in LLM evaluation.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "134",
        "title": "RusCode: Russian Cultural Code Benchmark for Text-to-Image Generation",
        "author": [
            "Viacheslav Vasilev",
            "Julia Agafonova",
            "Nikolai Gerasimenko",
            "Alexander Kapitanov",
            "Polina Mikhailova",
            "Evelina Mironova",
            "Denis Dimitrov"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07455",
        "abstract": "Text-to-image generation models have gained popularity among users around the world. However, many of these models exhibit a strong bias toward English-speaking cultures, ignoring or misrepresenting the unique characteristics of other language groups, countries, and nationalities. The lack of cultural awareness can reduce the generation quality and lead to undesirable consequences such as unintentional insult, and the spread of prejudice. In contrast to the field of natural language processing, cultural awareness in computer vision has not been explored as extensively. In this paper, we strive to reduce this gap. We propose a RusCode benchmark for evaluating the quality of text-to-image generation containing elements of the Russian cultural code. To do this, we form a list of 19 categories that best represent the features of Russian visual culture. Our final dataset consists of 1250 text prompts in Russian and their translations into English. The prompts cover a wide range of topics, including complex concepts from art, popular culture, folk traditions, famous people's names, natural objects, scientific achievements, etc. We present the results of a human evaluation of the side-by-side comparison of Russian visual concepts representations using popular generative models.",
        "tags": [
            "Text-to-Image"
        ]
    },
    {
        "id": "135",
        "title": "PerCul: A Story-Driven Cultural Evaluation of LLMs in Persian",
        "author": [
            "Erfan Moosavi Monazzah",
            "Vahid Rahimzadeh",
            "Yadollah Yaghoobzadeh",
            "Azadeh Shakery",
            "Mohammad Taher Pilehvar"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07459",
        "abstract": "Large language models predominantly reflect Western cultures, largely due to the dominance of English-centric training data. This imbalance presents a significant challenge, as LLMs are increasingly used across diverse contexts without adequate evaluation of their cultural competence in non-English languages, including Persian. To address this gap, we introduce PerCul, a carefully constructed dataset designed to assess the sensitivity of LLMs toward Persian culture. PerCul features story-based, multiple-choice questions that capture culturally nuanced scenarios. Unlike existing benchmarks, PerCul is curated with input from native Persian annotators to ensure authenticity and to prevent the use of translation as a shortcut. We evaluate several state-of-the-art multilingual and Persian-specific LLMs, establishing a foundation for future research in cross-cultural NLP evaluation. Our experiments demonstrate a 11.3% gap between best closed source model and layperson baseline while the gap increases to 21.3% by using the best open-weight model. You can access the dataset from here: https://huggingface.co/datasets/teias-ai/percul",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "136",
        "title": "Logarithmic Regret for Online KL-Regularized Reinforcement Learning",
        "author": [
            "Heyang Zhao",
            "Chenlu Ye",
            "Wei Xiong",
            "Quanquan Gu",
            "Tong Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07460",
        "abstract": "Recent advances in Reinforcement Learning from Human Feedback (RLHF) have shown that KL-regularization plays a pivotal role in improving the efficiency of RL fine-tuning for large language models (LLMs). Despite its empirical advantage, the theoretical difference between KL-regularized RL and standard RL remains largely under-explored. While there is a recent line of work on the theoretical analysis of KL-regularized objective in decision making \\citep{xiong2024iterative, xie2024exploratory,zhao2024sharp}, these analyses either reduce to the traditional RL setting or rely on strong coverage assumptions. In this paper, we propose an optimism-based KL-regularized online contextual bandit algorithm, and provide a novel analysis of its regret. By carefully leveraging the benign optimization landscape induced by the KL-regularization and the optimistic reward estimation, our algorithm achieves an $\\mathcal{O}\\big(\\eta\\log (N_{\\mathcal R} T)\\cdot d_{\\mathcal R}\\big)$ logarithmic regret bound, where $\\eta, N_{\\mathcal R},T,d_{\\mathcal R}$ denote the KL-regularization parameter, the cardinality of the reward function class, number of rounds, and the complexity of the reward function class. Furthermore, we extend our algorithm and analysis to reinforcement learning by developing a novel decomposition over transition steps and also obtain a similar logarithmic regret bound.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RL"
        ]
    },
    {
        "id": "137",
        "title": "Less is More: Masking Elements in Image Condition Features Avoids Content Leakages in Style Transfer Diffusion Models",
        "author": [
            "Lin Zhu",
            "Xinbing Wang",
            "Chenghu Zhou",
            "Qinying Gu",
            "Nanyang Ye"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07466",
        "abstract": "Given a style-reference image as the additional image condition, text-to-image diffusion models have demonstrated impressive capabilities in generating images that possess the content of text prompts while adopting the visual style of the reference image. However, current state-of-the-art methods often struggle to disentangle content and style from style-reference images, leading to issues such as content leakages. To address this issue, we propose a masking-based method that efficiently decouples content from style without the need of tuning any model parameters. By simply masking specific elements in the style reference's image features, we uncover a critical yet under-explored principle: guiding with appropriately-selected fewer conditions (e.g., dropping several image feature elements) can efficiently avoid unwanted content flowing into the diffusion models, enhancing the style transfer performances of text-to-image diffusion models. In this paper, we validate this finding both theoretically and experimentally. Extensive experiments across various styles demonstrate the effectiveness of our masking-based method and support our theoretical results.",
        "tags": [
            "Diffusion",
            "Style Transfer",
            "Text-to-Image"
        ]
    },
    {
        "id": "138",
        "title": "Multi-Agent Collaboration for Multilingual Code Instruction Tuning",
        "author": [
            "Jian Yang",
            "Wei Zhang",
            "Jiaxi Yang",
            "Yibo Miao",
            "Shanghaoran Quan",
            "Zhenhe Wu",
            "Qiyao Peng",
            "Liqun Yang",
            "Tianyu Liu",
            "Zeyu Cui",
            "Binyuan Hui",
            "Junyang Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07487",
        "abstract": "Recent advancement in code understanding and generation demonstrates that code LLMs fine-tuned on a high-quality instruction dataset can gain powerful capabilities to address wide-ranging code-related tasks. However, most previous existing methods mainly view each programming language in isolation and ignore the knowledge transfer among different programming languages. To bridge the gap among different programming languages, we introduce a novel multi-agent collaboration framework to enhance multilingual instruction tuning for code LLMs, where multiple language-specific intelligent agent components with generation memory work together to transfer knowledge from one language to another efficiently and effectively. Specifically, we first generate the language-specific instruction data from the code snippets and then provide the generated data as the seed data for language-specific agents. Multiple language-specific agents discuss and collaborate to formulate a new instruction and its corresponding solution (A new programming language or existing programming language), To further encourage the cross-lingual transfer, each agent stores its generation history as memory and then summarizes its merits and faults. Finally, the high-quality multilingual instruction data is used to encourage knowledge transfer among different programming languages to train Qwen2.5-xCoder. Experimental results on multilingual programming benchmarks demonstrate the superior performance of Qwen2.5-xCoder in sharing common knowledge, highlighting its potential to reduce the cross-lingual gap.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "139",
        "title": "Improving Adaptive Moment Optimization via Preconditioner Diagonalization",
        "author": [
            "Son Nguyen",
            "Bo Liu",
            "Lizhang Chen",
            "Qiang Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07488",
        "abstract": "Modern adaptive optimization methods, such as Adam and its variants, have emerged as the most widely used tools in deep learning over recent years. These algorithms offer automatic mechanisms for dynamically adjusting the update step based on estimates of gradient statistics. Compared to traditional algorithms like Stochastic Gradient Descent, these adaptive methods are typically more robust to model scale and hyperparameter tuning. However, the gradient statistics employed by these methods often do not leverage sufficient gradient covariance information, leading to suboptimal updates in certain directions of the parameter space and potentially slower convergence. In this work, we keep track of such covariance statistics in the form of a structured preconditioner matrix. Unlike other works, our approach does not apply direct approximations to estimate this matrix. We instead implement an invertible transformation that maps the preconditioner matrix into a new space where it becomes approximately diagonal. This enables a diagonal approximation of the preconditioner matrix in the transformed space, offering several computational advantages. Empirical results show that our approach can substantially enhance the convergence speed of modern adaptive optimizers. Notably, for large language models like LLaMA, we can achieve a speedup of 2x compared to the baseline Adam. Additionally, our method can be integrated with memory-efficient optimizers like Adafactor to manage computational overhead.",
        "tags": [
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "140",
        "title": "Mask-Enhanced Autoregressive Prediction: Pay Less Attention to Learn More",
        "author": [
            "Xialie Zhuang",
            "Zhikai Jia",
            "Jianjin Li",
            "Zhenyu Zhang",
            "Li Shen",
            "Zheng Cao",
            "Shiwei Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07490",
        "abstract": "Large Language Models (LLMs) are discovered to suffer from accurately retrieving key information. To address this, we propose Mask-Enhanced Autoregressive Prediction (MEAP), a simple yet effective training paradigm that seamlessly integrates Masked Language Modeling (MLM) into Next-Token Prediction (NTP) to enhance the latter's in-context retrieval capabilities. Specifically, MEAP first randomly masks a small fraction of input tokens and then directly performs the standard next-token prediction autoregressive using a decoder-only Transformer. MEAP eliminates the need for bidirectional attention or encoder-decoder architectures for MLM, incurring no additional computational overhead during pre-training or inference. Intensive experiments demonstrate that MEAP substantially outperforms NTP on key information retrieval and long-context reasoning tasks, while performing on par or better on commonsense reasoning tasks. The benefits of MEAP also extend to supervised fine-tuning, where it shows remarkable advantages in lost-in-the-middle scenarios, outperforming NTP by 11.77 percentage points. Our analysis indicates that MEAP's effectiveness arises from its ability to promote more distinguishable attention scores by concentrating on a reduced set of non-masked tokens. This mechanism improves the model's focus on task-relevant signals while mitigating the influence of peripheral context. These findings position MEAP as a promising training paradigm for large language models.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "141",
        "title": "LLM-Sketch: Enhancing Network Sketches with LLM",
        "author": [
            "Yuanpeng Li",
            "Zhen Xu",
            "Zongwei Lv",
            "Yannan Hu",
            "Yong Cui",
            "Tong Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07495",
        "abstract": "Network stream mining is fundamental to many network operations. Sketches, as compact data structures that offer low memory overhead with bounded accuracy, have emerged as a promising solution for network stream mining. Recent studies attempt to optimize sketches using machine learning; however, these approaches face the challenges of lacking adaptivity to dynamic networks and incurring high training costs. In this paper, we propose LLM-Sketch, based on the insight that fields beyond the flow IDs in packet headers can also help infer flow sizes. By using a two-tier data structure and separately recording large and small flows, LLM-Sketch improves accuracy while minimizing memory usage. Furthermore, it leverages fine-tuned large language models (LLMs) to reliably estimate flow sizes. We evaluate LLM-Sketch on three representative tasks, and the results demonstrate that LLM-Sketch outperforms state-of-the-art methods by achieving a $7.5\\times$ accuracy improvement.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "142",
        "title": "Enhance-A-Video: Better Generated Video for Free",
        "author": [
            "Yang Luo",
            "Xuanlei Zhao",
            "Mengzhao Chen",
            "Kaipeng Zhang",
            "Wenqi Shao",
            "Kai Wang",
            "Zhangyang Wang",
            "Yang You"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07508",
        "abstract": "DiT-based video generation has achieved remarkable results, but research into enhancing existing models remains relatively unexplored. In this work, we introduce a training-free approach to enhance the coherence and quality of DiT-based generated videos, named Enhance-A-Video. The core idea is enhancing the cross-frame correlations based on non-diagonal temporal attention distributions. Thanks to its simple design, our approach can be easily applied to most DiT-based video generation frameworks without any retraining or fine-tuning. Across various DiT-based video generation models, our approach demonstrates promising improvements in both temporal consistency and visual quality. We hope this research can inspire future explorations in video generation enhancement.",
        "tags": [
            "DiT",
            "Video Generation"
        ]
    },
    {
        "id": "143",
        "title": "Compact Runge-Kutta Flux Reconstruction for Hyperbolic Conservation Laws with admissibility preservation",
        "author": [
            "Arpit Babbar",
            "Qifan Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07517",
        "abstract": "Compact Runge-Kutta (cRK) Discontinuous Galerkin (DG) methods, recently introduced in [Q. Chen, Z. Sun, and Y. Xing, SIAM J. Sci. Comput. SIAM J. Sci. Comput., 46: A1327-A1351, 2024], are a variant of RKDG methods for solving hyperbolic conservation laws and are characterized by their compact stencil including only immediate neighboring finite elements. This article proposes a cRK Flux Reconstruction (FR) method by interpreting cRK as a procedure to approximate time-averaged fluxes, which requires computing only a single numerical flux for each time step and further reduces data communication. The numerical flux is carefully constructed to maintain the same Courant-Friedrichs-Lewy (CFL) numbers as cRKDG methods and achieve optimal accuracy uniformly across all polynomial degrees, even for problems with sonic points. A subcell-based blending limiter is then applied for problems with nonsmooth solutions, which uses Gauss-Legendre solution points and performs MUSCL-Hancock reconstruction on subcells to mitigate the additional dissipation errors. Additionally, to achieve a fully admissibility-preserving cRKFR scheme, a flux limiter is applied to the time-averaged numerical flux to ensure admissibility preservation in the means, combined with a positivity-preserving scaling limiter. The method is further extended to handle source terms by incorporating their contributions as additional time averages. Numerical experiments including Euler equations and the ten-moment problem are provided to validate the claims regarding the method's accuracy, robustness, and admissibility preservation.",
        "tags": [
            "FLUX"
        ]
    },
    {
        "id": "144",
        "title": "VidCRAFT3: Camera, Object, and Lighting Control for Image-to-Video Generation",
        "author": [
            "Sixiao Zheng",
            "Zimian Peng",
            "Yanpeng Zhou",
            "Yi Zhu",
            "Hang Xu",
            "Xiangru Huang",
            "Yanwei Fu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07531",
        "abstract": "Recent image-to-video generation methods have demonstrated success in enabling control over one or two visual elements, such as camera trajectory or object motion. However, these methods are unable to offer control over multiple visual elements due to limitations in data and network efficacy. In this paper, we introduce VidCRAFT3, a novel framework for precise image-to-video generation that enables control over camera motion, object motion, and lighting direction simultaneously. To better decouple control over each visual element, we propose the Spatial Triple-Attention Transformer, which integrates lighting direction, text, and image in a symmetric way. Since most real-world video datasets lack lighting annotations, we construct a high-quality synthetic video dataset, the VideoLightingDirection (VLD) dataset. This dataset includes lighting direction annotations and objects of diverse appearance, enabling VidCRAFT3 to effectively handle strong light transmission and reflection effects. Additionally, we propose a three-stage training strategy that eliminates the need for training data annotated with multiple visual elements (camera motion, object motion, and lighting direction) simultaneously. Extensive experiments on benchmark datasets demonstrate the efficacy of VidCRAFT3 in producing high-quality video content, surpassing existing state-of-the-art methods in terms of control granularity and visual coherence. All code and data will be publicly available. Project page: https://sixiaozheng.github.io/VidCRAFT3/.",
        "tags": [
            "Transformer",
            "Video Generation"
        ]
    },
    {
        "id": "145",
        "title": "Diffusion-LAM: Probabilistic Limited Area Weather Forecasting with Diffusion",
        "author": [
            "Erik Larsson",
            "Joel Oskarsson",
            "Tomas Landelius",
            "Fredrik Lindsten"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07532",
        "abstract": "Machine learning methods have been shown to be effective for weather forecasting, based on the speed and accuracy compared to traditional numerical models. While early efforts primarily concentrated on deterministic predictions, the field has increasingly shifted toward probabilistic forecasting to better capture the forecast uncertainty. Most machine learning-based models have been designed for global-scale predictions, with only limited work targeting regional or limited area forecasting, which allows more specialized and flexible modeling for specific locations. This work introduces Diffusion-LAM, a probabilistic limited area weather model leveraging conditional diffusion. By conditioning on boundary data from surrounding regions, our approach generates forecasts within a defined area. Experimental results on the MEPS limited area dataset demonstrate the potential of Diffusion-LAM to deliver accurate probabilistic forecasts, highlighting its promise for limited-area weather prediction.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "146",
        "title": "Grammar Control in Dialogue Response Generation for Language Learning Chatbots",
        "author": [
            "Dominik Glandorf",
            "Peng Cui",
            "Detmar Meurers",
            "Mrinmaya Sachan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07544",
        "abstract": "Chatbots based on large language models offer cheap conversation practice opportunities for language learners. However, they are hard to control for linguistic forms that correspond to learners' current needs, such as grammar. We control grammar in chatbot conversation practice by grounding a dialogue response generation model in a pedagogical repository of grammar skills. We also explore how this control helps learners to produce specific grammar. We comprehensively evaluate prompting, fine-tuning, and decoding strategies for grammar-controlled dialogue response generation. Strategically decoding Llama3 outperforms GPT-3.5 when tolerating minor response quality losses. Our simulation predicts grammar-controlled responses to support grammar acquisition adapted to learner proficiency. Existing language learning chatbots and research on second language acquisition benefit from these affordances. Code available on GitHub.",
        "tags": [
            "GPT",
            "Large Language Models"
        ]
    },
    {
        "id": "147",
        "title": "O1 Embedder: Let Retrievers Think Before Action",
        "author": [
            "Ruin Yan",
            "Zheng Liu",
            "Defu Lian"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07555",
        "abstract": "The growing power of large language models (LLMs) has revolutionized how people access and utilize information. Notably, the LLMs excel at performing fine-grained data representation, which facilitates precise retrieval of information. They also generate high-quality answers based on external references, enabling the production of useful knowledge. The recent introduction of reasoning models, like OpenAI O1 and DeepSeek R1, marks another leap forward, highlighting LLMs' ability to think progressively before delivering final answers. This breakthrough significantly improves the ability to address complex tasks, e.g., coding and math proofs.\nInspired by this progress, we aim to develop similar capabilities for retrieval models, which hold great promise for tackling critical challenges in the field, including multi-task retrieval, zero-shot retrieval, and tasks requiring intensive reasoning of complex relationships. With this motivation, we propose a novel approach called O1 Embedder, which generates useful thoughts for the input query before making retrieval for the target documents. To realize this objective, we conquer two technical difficulties. First, we design a data synthesis workflow, creating training signals for O1 Embedder by generating initial thoughts from an LLM-expert and subsequently refining them using a retrieval committee. Second, we optimize the training process, enabling a pre-trained model to be jointly fine-tuned to generate retrieval thoughts via behavior cloning and perform dense retrieval through contrastive learning. Our approach is evaluated by comprehensive experiments, where substantial improvements are achieved across 12 popular datasets, spanning both in-domain and out-of-domain scenarios. These results highlight O1 Embedder's remarkable accuracy and generalizability, paving the way for the development of next-generation IR foundation models.",
        "tags": [
            "DeepSeek",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "148",
        "title": "SketchFlex: Facilitating Spatial-Semantic Coherence in Text-to-Image Generation with Region-Based Sketches",
        "author": [
            "Haichuan Lin",
            "Yilin Ye",
            "Jiazhi Xia",
            "Wei Zeng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07556",
        "abstract": "Text-to-image models can generate visually appealing images from text descriptions. Efforts have been devoted to improving model controls with prompt tuning and spatial conditioning. However, our formative study highlights the challenges for non-expert users in crafting appropriate prompts and specifying fine-grained spatial conditions (e.g., depth or canny references) to generate semantically cohesive images, especially when multiple objects are involved. In response, we introduce SketchFlex, an interactive system designed to improve the flexibility of spatially conditioned image generation using rough region sketches. The system automatically infers user prompts with rational descriptions within a semantic space enriched by crowd-sourced object attributes and relationships. Additionally, SketchFlex refines users' rough sketches into canny-based shape anchors, ensuring the generation quality and alignment of user intentions. Experimental results demonstrate that SketchFlex achieves more cohesive image generations than end-to-end models, meanwhile significantly reducing cognitive load and better matching user intentions compared to region-based generation baseline.",
        "tags": [
            "Text-to-Image"
        ]
    },
    {
        "id": "149",
        "title": "JBShield: Defending Large Language Models from Jailbreak Attacks through Activated Concept Analysis and Manipulation",
        "author": [
            "Shenyi Zhang",
            "Yuchen Zhai",
            "Keyan Guo",
            "Hongxin Hu",
            "Shengnan Guo",
            "Zheng Fang",
            "Lingchen Zhao",
            "Chao Shen",
            "Cong Wang",
            "Qian Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07557",
        "abstract": "Despite the implementation of safety alignment strategies, large language models (LLMs) remain vulnerable to jailbreak attacks, which undermine these safety guardrails and pose significant security threats. Some defenses have been proposed to detect or mitigate jailbreaks, but they are unable to withstand the test of time due to an insufficient understanding of jailbreak mechanisms. In this work, we investigate the mechanisms behind jailbreaks based on the Linear Representation Hypothesis (LRH), which states that neural networks encode high-level concepts as subspaces in their hidden representations. We define the toxic semantics in harmful and jailbreak prompts as toxic concepts and describe the semantics in jailbreak prompts that manipulate LLMs to comply with unsafe requests as jailbreak concepts. Through concept extraction and analysis, we reveal that LLMs can recognize the toxic concepts in both harmful and jailbreak prompts. However, unlike harmful prompts, jailbreak prompts activate the jailbreak concepts and alter the LLM output from rejection to compliance. Building on our analysis, we propose a comprehensive jailbreak defense framework, JBShield, consisting of two key components: jailbreak detection JBShield-D and mitigation JBShield-M. JBShield-D identifies jailbreak prompts by determining whether the input activates both toxic and jailbreak concepts. When a jailbreak prompt is detected, JBShield-M adjusts the hidden representations of the target LLM by enhancing the toxic concept and weakening the jailbreak concept, ensuring LLMs produce safe content. Extensive experiments demonstrate the superior performance of JBShield, achieving an average detection accuracy of 0.95 and reducing the average attack success rate of various jailbreak attacks to 2% from 61% across distinct LLMs.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "150",
        "title": "LoRP-TTS: Low-Rank Personalized Text-To-Speech",
        "author": [
            "Åukasz Bondaruk",
            "Jakub Kubiak"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07562",
        "abstract": "Speech synthesis models convert written text into natural-sounding audio. While earlier models were limited to a single speaker, recent advancements have led to the development of zero-shot systems that generate realistic speech from a wide range of speakers using their voices as additional prompts. However, they still struggle with imitating non-studio-quality samples that differ significantly from the training datasets. In this work, we demonstrate that utilizing Low-Rank Adaptation (LoRA) allows us to successfully use even single recordings of spontaneous speech in noisy environments as prompts. This approach enhances speaker similarity by up to $30pp$ while preserving content and naturalness. It represents a significant step toward creating truly diverse speech corpora, that is crucial in all speech-related tasks.",
        "tags": [
            "LoRA",
            "Low-Rank Adaptation"
        ]
    },
    {
        "id": "151",
        "title": "LASP-2: Rethinking Sequence Parallelism for Linear Attention and Its Hybrid",
        "author": [
            "Weigao Sun",
            "Disen Lan",
            "Yiran Zhong",
            "Xiaoye Qu",
            "Yu Cheng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07563",
        "abstract": "Linear sequence modeling approaches, such as linear attention, provide advantages like linear-time training and constant-memory inference over sequence lengths. However, existing sequence parallelism (SP) methods are either not optimized for the right-product-first feature of linear attention or use a ring-style communication strategy, which results in lower computation parallelism, limits their scalability for longer sequences in distributed systems. In this paper, we introduce LASP-2, a new SP method to enhance both communication and computation parallelism when training linear attention transformer models with very-long input sequences. Compared to previous work LASP, LASP-2 rethinks the minimal communication requirement for SP on linear attention layers, reorganizes the whole communication-computation workflow of LASP. In this way, only one single AllGather collective communication is needed on intermediate memory states, whose sizes are independent of the sequence length, leading to significant improvements of both communication and computation parallelism, as well as their overlap. Additionally, we extend LASP-2 to LASP-2H by applying similar communication redesign to standard attention modules, offering an efficient SP solution for hybrid models that blend linear and standard attention layers. Our evaluation on a Linear-Llama3 model, a variant of Llama3 with linear attention replacing standard attention, demonstrates the effectiveness of LASP-2 and LASP-2H. Specifically, LASP-2 achieves training speed improvements of 15.2% over LASP and 36.6% over Ring Attention, with a sequence length of 2048K across 64 GPUs. The Code is released as a part of: https://github.com/OpenSparseLLMs/Linear-MoE.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "152",
        "title": "Automated Capability Discovery via Model Self-Exploration",
        "author": [
            "Cong Lu",
            "Shengran Hu",
            "Jeff Clune"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07577",
        "abstract": "Foundation models have become general-purpose assistants, exhibiting diverse capabilities across numerous domains through training on web-scale data. It remains challenging to precisely characterize even a fraction of the full spectrum of capabilities and potential risks in any new model. Existing evaluation approaches often require significant human effort, and it is taking increasing effort to design ever harder challenges for more capable models. We introduce Automated Capability Discovery (ACD), a framework that designates one foundation model as a scientist to systematically propose open-ended tasks probing the abilities of a subject model (potentially itself). By combining frontier models with ideas from the field of open-endedness, ACD automatically and systematically uncovers both surprising capabilities and failures in the subject model. We demonstrate ACD across a range of foundation models (including the GPT, Claude, and Llama series), showing that it automatically reveals thousands of capabilities that would be challenging for any single team to uncover. We further validate our method's automated scoring with extensive human surveys, observing high agreement between model-generated and human evaluations. By leveraging foundation models' ability to both create tasks and self-evaluate, ACD is a significant step toward scalable, automated evaluation of novel AI systems. All code and evaluation logs are open-sourced at https://github.com/conglu1997/ACD.",
        "tags": [
            "GPT",
            "LLaMA"
        ]
    },
    {
        "id": "153",
        "title": "PIM Is All You Need: A CXL-Enabled GPU-Free System for Large Language Model Inference",
        "author": [
            "Yufeng Gu",
            "Alireza Khadem",
            "Sumanth Umesh",
            "Ning Liang",
            "Xavier Servot",
            "Onur Mutlu",
            "Ravi Iyer",
            "Reetuparna Das"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07578",
        "abstract": "Large Language Model (LLM) inference uses an autoregressive manner to generate one token at a time, which exhibits notably lower operational intensity compared to earlier Machine Learning (ML) models such as encoder-only transformers and Convolutional Neural Networks. At the same time, LLMs possess large parameter sizes and use key-value caches to store context information. Modern LLMs support context windows with up to 1 million tokens to generate versatile text, audio, and video content. A large key-value cache unique to each prompt requires a large memory capacity, limiting the inference batch size. Both low operational intensity and limited batch size necessitate a high memory bandwidth. However, contemporary hardware systems for ML model deployment, such as GPUs and TPUs, are primarily optimized for compute throughput. This mismatch challenges the efficient deployment of advanced LLMs and makes users to pay for expensive compute resources that are poorly utilized for the memory-bound LLM inference tasks.\nWe propose CENT, a CXL-ENabled GPU-Free sysTem for LLM inference, which harnesses CXL memory expansion capabilities to accommodate substantial LLM sizes, and utilizes near-bank processing units to deliver high memory bandwidth, eliminating the need for expensive GPUs. CENT exploits a scalable CXL network to support peer-to-peer and collective communication primitives across CXL devices. We implement various parallelism strategies to distribute LLMs across these devices. Compared to GPU baselines with maximum supported batch sizes and similar average power, CENT achieves 2.3$\\times$ higher throughput and consumes 2.3$\\times$ less energy. CENT enhances the Total Cost of Ownership (TCO), generating 5.2$\\times$ more tokens per dollar than GPUs.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "154",
        "title": "Single-Step Consistent Diffusion Samplers",
        "author": [
            "Pascal Jutras-DubÃ©",
            "Patrick Pynadath",
            "Ruqi Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07579",
        "abstract": "Sampling from unnormalized target distributions is a fundamental yet challenging task in machine learning and statistics. Existing sampling algorithms typically require many iterative steps to produce high-quality samples, leading to high computational costs that limit their practicality in time-sensitive or resource-constrained settings. In this work, we introduce consistent diffusion samplers, a new class of samplers designed to generate high-fidelity samples in a single step. We first develop a distillation algorithm to train a consistent diffusion sampler from a pretrained diffusion model without pre-collecting large datasets of samples. Our algorithm leverages incomplete sampling trajectories and noisy intermediate states directly from the diffusion process. We further propose a method to train a consistent diffusion sampler from scratch, fully amortizing exploration by training a single model that both performs diffusion sampling and skips intermediate steps using a self-consistency loss. Through extensive experiments on a variety of unnormalized distributions, we show that our approach yields high-fidelity samples using less than 1% of the network evaluations required by traditional diffusion samplers.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "155",
        "title": "Generative Modeling with Bayesian Sample Inference",
        "author": [
            "Marten Lienen",
            "Marcel Kollovieh",
            "Stephan GÃ¼nnemann"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07580",
        "abstract": "We derive a novel generative model from the simple act of Gaussian posterior inference. Treating the generated sample as an unknown variable to infer lets us formulate the sampling process in the language of Bayesian probability. Our model uses a sequence of prediction and posterior update steps to narrow down the unknown sample from a broad initial belief. In addition to a rigorous theoretical analysis, we establish a connection between our model and diffusion models and show that it includes Bayesian Flow Networks (BFNs) as a special case. In our experiments, we demonstrate improved performance over both BFNs and Variational Diffusion Models, achieving competitive likelihood scores on CIFAR10 and ImageNet.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "156",
        "title": "DSV: Exploiting Dynamic Sparsity to Accelerate Large-Scale Video DiT Training",
        "author": [
            "Xin Tan",
            "Yuetao Chen",
            "Yimin Jiang",
            "Xing Chen",
            "Kun Yan",
            "Nan Duan",
            "Yibo Zhu",
            "Daxin Jiang",
            "Hong Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07590",
        "abstract": "Diffusion Transformers (DiTs) have shown remarkable performance in modeling and generating high-quality videos. However, the quadratic computational complexity of 3D full attention mechanism presents significant challenges in scaling video DiT training, especially for high-definition and lengthy videos, where attention can dominate up to 95% of the end-to-end time and necessitate specialized communication paradigms to handle large input sizes.\nThis paper introduces DSV, a novel framework designed to accelerate and scale the training of video DiTs by leveraging the inherent dynamic attention sparsity throughout the training process. DSV employs a two-stage training algorithm that exploits sparsity patterns, focusing on critical elements supported by efficient, tailored kernels. To accommodate the new sparsity dimension, we develop a hybrid sparsity-aware context parallelism that effectively scales to large inputs by addressing the heterogeneity of sparsity across attention heads and blocks, resulting in optimized sparse computation and communication. Extensive evaluations demonstrate that DSV achieves up to 3.02x gain in training throughput with nearly no quality degradation.",
        "tags": [
            "3D",
            "DiT",
            "Diffusion"
        ]
    },
    {
        "id": "157",
        "title": "Towards spatial computing: recent advances in multimodal natural interaction for XR headsets",
        "author": [
            "Zhimin Wang",
            "Maohang Rao",
            "Shanghua Ye",
            "Weitao Song",
            "Feng Lu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07598",
        "abstract": "With the widespread adoption of Extended Reality (XR) headsets, spatial computing technologies are gaining increasing attention. Spatial computing enables interaction with virtual elements through natural input methods such as eye tracking, hand gestures, and voice commands, thus placing natural human-computer interaction at its core. While previous surveys have reviewed conventional XR interaction techniques, recent advancements in natural interaction, particularly driven by artificial intelligence (AI) and large language models (LLMs), have introduced new paradigms and technologies. In this paper, we review research on multimodal natural interaction for wearable XR, focusing on papers published between 2022 and 2024 in six top venues: ACM CHI, UIST, IMWUT (Ubicomp), IEEE VR, ISMAR, and TVCG. We classify and analyze these studies based on application scenarios, operation types, and interaction modalities. This analysis provides a structured framework for understanding how researchers are designing advanced natural interaction techniques in XR. Based on these findings, we discuss the challenges in natural interaction techniques and suggest potential directions for future research. This review provides valuable insights for researchers aiming to design natural and efficient interaction systems for XR, ultimately contributing to the advancement of spatial computing.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "158",
        "title": "Flow Distillation Sampling: Regularizing 3D Gaussians with Pre-trained Matching Priors",
        "author": [
            "Lin-Zhuo Chen",
            "Kangjie Liu",
            "Youtian Lin",
            "Siyu Zhu",
            "Zhihao Li",
            "Xun Cao",
            "Yao Yao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07615",
        "abstract": "3D Gaussian Splatting (3DGS) has achieved excellent rendering quality with fast training and rendering speed. However, its optimization process lacks explicit geometric constraints, leading to suboptimal geometric reconstruction in regions with sparse or no observational input views. In this work, we try to mitigate the issue by incorporating a pre-trained matching prior to the 3DGS optimization process. We introduce Flow Distillation Sampling (FDS), a technique that leverages pre-trained geometric knowledge to bolster the accuracy of the Gaussian radiance field. Our method employs a strategic sampling technique to target unobserved views adjacent to the input views, utilizing the optical flow calculated from the matching model (Prior Flow) to guide the flow analytically calculated from the 3DGS geometry (Radiance Flow). Comprehensive experiments in depth rendering, mesh reconstruction, and novel view synthesis showcase the significant advantages of FDS over state-of-the-art methods. Additionally, our interpretive experiments and analysis aim to shed light on the effects of FDS on geometric accuracy and rendering quality, potentially providing readers with insights into its performance. Project page: https://nju-3dv.github.io/projects/fds",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "159",
        "title": "Tractable Transformers for Flexible Conditional Generation",
        "author": [
            "Anji Liu",
            "Xuejie Liu",
            "Dayuan Zhao",
            "Mathias Niepert",
            "Yitao Liang",
            "Guy Van den Broeck"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07616",
        "abstract": "Non-autoregressive (NAR) generative models are valuable because they can handle diverse conditional generation tasks in a more principled way than their autoregressive (AR) counterparts, which are constrained by sequential dependency requirements. Recent advancements in NAR models, such as diffusion language models, have demonstrated superior performance in unconditional generation compared to AR models (e.g., GPTs) of similar sizes. However, such improvements do not always lead to improved conditional generation performance. We show that a key reason for this gap is the difficulty in generalizing to conditional probability queries unseen during training. As a result, strong unconditional generation performance does not guarantee high-quality conditional generation. This paper proposes Tractable Transformers (Tracformer), a Transformer-based generative model that is more robust to different conditional generation tasks. Unlike existing models that rely solely on global contextual features derived from full inputs, Tracformers incorporate a sparse Transformer encoder to capture both local and global contextual information. This information is routed through a decoder for conditional generation. Empirical results demonstrate that Tracformers achieve state-of-the-art conditional generation performance on text modeling compared to recent diffusion and AR model baselines.",
        "tags": [
            "Diffusion",
            "Transformer"
        ]
    },
    {
        "id": "160",
        "title": "Scaling Pre-training to One Hundred Billion Data for Vision Language Models",
        "author": [
            "Xiao Wang",
            "Ibrahim Alabdulmohsin",
            "Daniel Salz",
            "Zhe Li",
            "Keran Rong",
            "Xiaohua Zhai"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07617",
        "abstract": "We provide an empirical investigation of the potential of pre-training vision-language models on an unprecedented scale: 100 billion examples. We find that model performance tends to saturate at this scale on many common Western-centric classification and retrieval benchmarks, such as COCO Captions. Nevertheless, tasks of cultural diversity achieve more substantial gains from the 100-billion scale web data, thanks to its coverage of long-tail concepts. Furthermore, we analyze the model's multilinguality and show gains in low-resource languages as well. In addition, we observe that reducing the size of the pretraining dataset via quality filters like using CLIP, typically used to enhance performance, may inadvertently reduce the cultural diversity represented even in large-scale datasets. Our results highlight that while traditional benchmarks may not benefit significantly from scaling noisy, raw web data to 100 billion examples, this data scale is vital for building truly inclusive multimodal systems.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "161",
        "title": "Exploring Mobile Touch Interaction with Large Language Models",
        "author": [
            "Tim Zindulka",
            "Jannek Sekowski",
            "Florian Lehmann",
            "Daniel Buschek"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07629",
        "abstract": "Interacting with Large Language Models (LLMs) for text editing on mobile devices currently requires users to break out of their writing environment and switch to a conversational AI interface. In this paper, we propose to control the LLM via touch gestures performed directly on the text. We first chart a design space that covers fundamental touch input and text transformations. In this space, we then concretely explore two control mappings: spread-to-generate and pinch-to-shorten, with visual feedback loops. We evaluate this concept in a user study (N=14) that compares three feedback designs: no visualisation, text length indicator, and length + word indicator. The results demonstrate that touch-based control of LLMs is both feasible and user-friendly, with the length + word indicator proving most effective for managing text generation. This work lays the foundation for further research into gesture-based interaction with LLMs on touch devices.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "162",
        "title": "Consistency Training with Physical Constraints",
        "author": [
            "Che-Chia Chang",
            "Chen-Yang Dai",
            "Te-Sheng Lin",
            "Ming-Chih Lai",
            "Chieh-Hsin Lai"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07636",
        "abstract": "We propose a physics-aware Consistency Training (CT) method that accelerates sampling in Diffusion Models with physical constraints. Our approach leverages a two-stage strategy: (1) learning the noise-to-data mapping via CT, and (2) incorporating physics constraints as a regularizer. Experiments on toy examples show that our method generates samples in a single step while adhering to the imposed constraints. This approach has the potential to efficiently solve partial differential equations (PDEs) using deep generative modeling.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "163",
        "title": "Goedel-Prover: A Frontier Model for Open-Source Automated Theorem Proving",
        "author": [
            "Yong Lin",
            "Shange Tang",
            "Bohan Lyu",
            "Jiayun Wu",
            "Hongzhou Lin",
            "Kaiyu Yang",
            "Jia Li",
            "Mengzhou Xia",
            "Danqi Chen",
            "Sanjeev Arora",
            "Chi Jin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07640",
        "abstract": "We introduce Goedel-Prover, an open-source large language model (LLM) that achieves the state-of-the-art (SOTA) performance in automated formal proof generation for mathematical problems. The key challenge in this field is the scarcity of formalized math statements and proofs, which we tackle in the following ways. We train statement formalizers to translate the natural language math problems from Numina into formal language (Lean 4), creating a dataset of 1.64 million formal statements. LLMs are used to check that the formal statements accurately preserve the content of the original natural language problems. We then iteratively build a large dataset of formal proofs by training a series of provers. Each prover succeeds in proving many statements that the previous ones could not, and these new proofs are added to the training set for the next prover. The final prover outperforms all existing open-source models in whole-proof generation. On the miniF2F benchmark, it achieves a 57.6% success rate (Pass@32), exceeding the previous best open-source model by 7.6%. On PutnamBench, Goedel-Prover successfully solves 7 problems (Pass@512), ranking first on the leaderboard. Furthermore, it generates 29.7K formal proofs for Lean Workbook problems, nearly doubling the 15.7K produced by earlier works.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "164",
        "title": "FoQA: A Faroese Question-Answering Dataset",
        "author": [
            "Annika Simonsen",
            "Dan Saattrup Nielsen",
            "Hafsteinn Einarsson"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07642",
        "abstract": "We present FoQA, a Faroese extractive question-answering (QA) dataset with 2,000 samples, created using a semi-automated approach combining Large Language Models (LLMs) and human validation. The dataset was generated from Faroese Wikipedia articles using GPT-4-turbo for initial QA generation, followed by question rephrasing to increase complexity and native speaker validation to ensure quality. We provide baseline performance metrics for FoQA across multiple models, including LLMs and BERT, demonstrating its effectiveness in evaluating Faroese QA performance. The dataset is released in three versions: a validated set of 2,000 samples, a complete set of all 10,001 generated samples, and a set of 2,395 rejected samples for error analysis.",
        "tags": [
            "BERT",
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "165",
        "title": "SymGPT: Auditing Smart Contracts via Combining Symbolic Execution with Large Language Models",
        "author": [
            "Shihao Xia",
            "Mengting He",
            "Shuai Shao",
            "Tingting Yu",
            "Yiying Zhang",
            "Linhai Song"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07644",
        "abstract": "To govern smart contracts running on Ethereum, multiple Ethereum Request for Comment (ERC) standards have been developed, each having a set of rules to guide the behaviors of smart contracts. Violating the ERC rules could cause serious security issues and financial loss, signifying the importance of verifying smart contracts follow ERCs. Today's practices of such verification are to manually audit each single contract, use expert-developed program-analysis tools, or use large language models (LLMs), all of which are far from effective in identifying ERC rule violations. This paper introduces SymGPT, a tool that combines the natural language understanding of large language models (LLMs) with the formal guarantees of symbolic execution to automatically verify smart contracts' compliance with ERC rules. To develop SymGPT, we conduct an empirical study of 132 ERC rules from three widely used ERC standards, examining their content, security implications, and natural language descriptions. Based on this study, we design SymGPT by first instructing an LLM to translate ERC rules into a defined EBNF grammar. We then synthesize constraints from the formalized rules to represent scenarios where violations may occur and use symbolic execution to detect them. Our evaluation shows that SymGPT identifies 5,783 ERC rule violations in 4,000 real-world contracts, including 1,375 violations with clear attack paths for stealing financial assets, demonstrating its effectiveness. Furthermore, SymGPT outperforms six automated techniques and a security-expert auditing service, underscoring its superiority over current smart contract analysis methods.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "166",
        "title": "Beyond Behavior Cloning: Robustness through Interactive Imitation and Contrastive Learning",
        "author": [
            "Zhaoting Li",
            "Rodrigo PÃ©rez-Dattari",
            "Robert Babuska",
            "Cosimo Della Santina",
            "Jens Kober"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07645",
        "abstract": "Behavior cloning (BC) traditionally relies on demonstration data, assuming the demonstrated actions are optimal. This can lead to overfitting under noisy data, particularly when expressive models are used (e.g., the energy-based model in Implicit BC). To address this, we extend behavior cloning into an iterative process of optimal action estimation within the Interactive Imitation Learning framework. Specifically, we introduce Contrastive policy Learning from Interactive Corrections (CLIC). CLIC leverages human corrections to estimate a set of desired actions and optimizes the policy to select actions from this set. We provide theoretical guarantees for the convergence of the desired action set to optimal actions in both single and multiple optimal action cases. Extensive simulation and real-robot experiments validate CLIC's advantages over existing state-of-the-art methods, including stable training of energy-based models, robustness to feedback noise, and adaptability to diverse feedback types beyond demonstrations. Our code will be publicly available soon.",
        "tags": [
            "Energy-Based Models",
            "Robot"
        ]
    },
    {
        "id": "167",
        "title": "Matrix3D: Large Photogrammetry Model All-in-One",
        "author": [
            "Yuanxun Lu",
            "Jingyang Zhang",
            "Tian Fang",
            "Jean-Daniel Nahmias",
            "Yanghai Tsin",
            "Long Quan",
            "Xun Cao",
            "Yao Yao",
            "Shiwei Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07685",
        "abstract": "We present Matrix3D, a unified model that performs several photogrammetry subtasks, including pose estimation, depth prediction, and novel view synthesis using just the same model. Matrix3D utilizes a multi-modal diffusion transformer (DiT) to integrate transformations across several modalities, such as images, camera parameters, and depth maps. The key to Matrix3D's large-scale multi-modal training lies in the incorporation of a mask learning strategy. This enables full-modality model training even with partially complete data, such as bi-modality data of image-pose and image-depth pairs, thus significantly increases the pool of available training data. Matrix3D demonstrates state-of-the-art performance in pose estimation and novel view synthesis tasks. Additionally, it offers fine-grained control through multi-round interactions, making it an innovative tool for 3D content creation. Project page: https://nju-3dv.github.io/projects/matrix3d.",
        "tags": [
            "3D",
            "DiT",
            "Diffusion",
            "Diffusion Transformer",
            "Pose Estimation",
            "Transformer"
        ]
    },
    {
        "id": "168",
        "title": "Large Language Models as Proxies for Theories of Human Linguistic Cognition",
        "author": [
            "Imry Ziv",
            "Nur Lan",
            "Emmanuel Chemla",
            "Roni Katzir"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07687",
        "abstract": "We consider the possible role of current large language models (LLMs) in the study of human linguistic cognition. We focus on the use of such models as proxies for theories of cognition that are relatively linguistically-neutral in their representations and learning but differ from current LLMs in key ways. We illustrate this potential use of LLMs as proxies for theories of cognition in the context of two kinds of questions: (a) whether the target theory accounts for the acquisition of a given pattern from a given corpus; and (b) whether the target theory makes a given typologically-attested pattern easier to acquire than another, typologically-unattested pattern. For each of the two questions we show, building on recent literature, how current LLMs can potentially be of help, but we note that at present this help is quite limited.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "169",
        "title": "A Framework for LLM-powered Design Assistants",
        "author": [
            "Swaroop Panda"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07698",
        "abstract": "Design assistants are frameworks, tools or applications intended to facilitate both the creative and technical facets of design processes. Large language models (LLMs) are AI systems engineered to analyze and produce text resembling human language, leveraging extensive datasets. This study introduces a framework wherein LLMs are employed as Design Assistants, focusing on three key modalities within the Design Process: Idea Exploration, Dialogue with Designers, and Design Evaluation. Importantly, our framework is not confined to a singular design process but is adaptable across various processes.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "170",
        "title": "Magic 1-For-1: Generating One Minute Video Clips within One Minute",
        "author": [
            "Hongwei Yi",
            "Shitong Shao",
            "Tian Ye",
            "Jiantong Zhao",
            "Qingyu Yin",
            "Michael Lingelbach",
            "Li Yuan",
            "Yonghong Tian",
            "Enze Xie",
            "Daquan Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07701",
        "abstract": "In this technical report, we present Magic 1-For-1 (Magic141), an efficient video generation model with optimized memory consumption and inference latency. The key idea is simple: factorize the text-to-video generation task into two separate easier tasks for diffusion step distillation, namely text-to-image generation and image-to-video generation. We verify that with the same optimization algorithm, the image-to-video task is indeed easier to converge over the text-to-video task. We also explore a bag of optimization tricks to reduce the computational cost of training the image-to-video (I2V) models from three aspects: 1) model convergence speedup by using a multi-modal prior condition injection; 2) inference latency speed up by applying an adversarial step distillation, and 3) inference memory cost optimization with parameter sparsification. With those techniques, we are able to generate 5-second video clips within 3 seconds. By applying a test time sliding window, we are able to generate a minute-long video within one minute with significantly improved visual quality and motion dynamics, spending less than 1 second for generating 1 second video clips on average. We conduct a series of preliminary explorations to find out the optimal tradeoff between computational cost and video quality during diffusion step distillation and hope this could be a good foundation model for open-source explorations. The code and the model weights are available at https://github.com/DA-Group-PKU/Magic-1-For-1.",
        "tags": [
            "Diffusion",
            "Text-to-Image",
            "Text-to-Video",
            "Video Generation"
        ]
    },
    {
        "id": "171",
        "title": "Making Language Models Robust Against Negation",
        "author": [
            "MohammadHossein Rezaei",
            "Eduardo Blanco"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07717",
        "abstract": "Negation has been a long-standing challenge for language models. Previous studies have shown that they struggle with negation in many natural language understanding tasks. In this work, we propose a self-supervised method to make language models more robust against negation. We introduce a novel task, Next Sentence Polarity Prediction (NSPP), and a variation of the Next Sentence Prediction (NSP) task. We show that BERT and RoBERTa further pre-trained on our tasks outperform the off-the-shelf versions on nine negation-related benchmarks. Most notably, our pre-training tasks yield between 1.8% and 9.1% improvement on CondaQA, a large question-answering corpus requiring reasoning over negation.",
        "tags": [
            "BERT"
        ]
    },
    {
        "id": "172",
        "title": "A BDDC Preconditioner for the Cardiac EMI Model in three Dimensions",
        "author": [
            "Fritz Goebel",
            "Ngoc Mai Monica Huynh",
            "Fatemeh Chegini",
            "Luca Pavarino",
            "Martin Weiser",
            "Simone Scacchi",
            "Hartwig Anzt"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07722",
        "abstract": "We analyze a Balancing Domain Decomposition by Constraints (BDDC) preconditioner for the solution of three dimensional composite Discontinuous Galerkin discretizations of reaction-diffusion systems of ordinary and partial differential equations arising in cardiac cell-by-cell models like the Extracellular space, Membrane and Intracellular space (EMI) Model. These microscopic models are essential for the understanding of events in aging and structurally diseased hearts which macroscopic models relying on homogenized descriptions of the cardiac tissue, like Monodomain and Bidomain models, fail to adequately represent. The modeling of each individual cardiac cell results in discontinuous global solutions across cell boundaries, requiring the careful construction of dual and primal spaces for the BDDC preconditioner. We provide a scalable condition number bound for the precondition operator and validate the theoretical results with extensive numerical experiments.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "173",
        "title": "Verifying LLM-Generated Code in the Context of Software Verification with Ada/SPARK",
        "author": [
            "Marcos Cramer",
            "Lucian McIntyre"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07728",
        "abstract": "Large language models (LLMs) have demonstrated remarkable code generation capabilities, but the correctness of the generated code cannot be inherently trusted. This paper explores the feasibility of using formal software verification, specifically the SPARK framework for Ada, to ensure the reliability of LLM-generated code. We present Marmaragan, a tool that leverages an LLM in order to generate SPARK annotations for existing programs, enabling formal verification of the code. The tool is benchmarked on a curated set of SPARK programs, with annotations selectively removed to test specific capabilities. The performance of Marmaragan with GPT-4o on the benchmark is promising, with correct annotations having been generated for 50.7% of the benchmark cases. The results establish a foundation for future work on combining the power of LLMs with the reliability of formal software verification.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "174",
        "title": "Economics of Sourcing Human Data",
        "author": [
            "Sebastin Santy",
            "Prasanta Bhattacharya",
            "Manoel Horta Ribeiro",
            "Kelsey Allen",
            "Sewoong Oh"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07732",
        "abstract": "Progress in AI has relied on human-generated data, from annotator marketplaces to the wider Internet. However, the widespread use of large language models now threatens the quality and integrity of human-generated data on these very platforms. We argue that this issue goes beyond the immediate challenge of filtering AI-generated content--it reveals deeper flaws in how data collection systems are designed. Existing systems often prioritize speed, scale, and efficiency at the cost of intrinsic human motivation, leading to declining engagement and data quality. We propose that rethinking data collection systems to align with contributors' intrinsic motivations--rather than relying solely on external incentives--can help sustain high-quality data sourcing at scale while maintaining contributor trust and long-term participation.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "175",
        "title": "EdgeEar: Efficient and Accurate Ear Recognition for Edge Devices",
        "author": [
            "Camile Lendering",
            "Bernardo Perrone Ribeiro",
            "Å½iga EmerÅ¡iÄ",
            "Peter Peer"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07734",
        "abstract": "Ear recognition is a contactless and unobtrusive biometric technique with applications across various domains. However, deploying high-performing ear recognition models on resource-constrained devices is challenging, limiting their applicability and widespread adoption. This paper introduces EdgeEar, a lightweight model based on a proposed hybrid CNN-transformer architecture to solve this problem. By incorporating low-rank approximations into specific linear layers, EdgeEar reduces its parameter count by a factor of 50 compared to the current state-of-the-art, bringing it below two million while maintaining competitive accuracy. Evaluation on the Unconstrained Ear Recognition Challenge (UERC2023) benchmark shows that EdgeEar achieves the lowest EER while significantly reducing computational costs. These findings demonstrate the feasibility of efficient and accurate ear recognition, which we believe will contribute to the wider adoption of ear biometrics.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "176",
        "title": "Next Block Prediction: Video Generation via Semi-Auto-Regressive Modeling",
        "author": [
            "Shuhuai Ren",
            "Shuming Ma",
            "Xu Sun",
            "Furu Wei"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07737",
        "abstract": "Next-Token Prediction (NTP) is a de facto approach for autoregressive (AR) video generation, but it suffers from suboptimal unidirectional dependencies and slow inference speed. In this work, we propose a semi-autoregressive (semi-AR) framework, called Next-Block Prediction (NBP), for video generation. By uniformly decomposing video content into equal-sized blocks (e.g., rows or frames), we shift the generation unit from individual tokens to blocks, allowing each token in the current block to simultaneously predict the corresponding token in the next block. Unlike traditional AR modeling, our framework employs bidirectional attention within each block, enabling tokens to capture more robust spatial dependencies. By predicting multiple tokens in parallel, NBP models significantly reduce the number of generation steps, leading to faster and more efficient inference. Our model achieves FVD scores of 103.3 on UCF101 and 25.5 on K600, outperforming the vanilla NTP model by an average of 4.4. Furthermore, thanks to the reduced number of inference steps, the NBP model generates 8.89 frames (128x128 resolution) per second, achieving an 11x speedup. We also explored model scales ranging from 700M to 3B parameters, observing significant improvements in generation quality, with FVD scores dropping from 103.3 to 55.3 on UCF101 and from 25.5 to 19.5 on K600, demonstrating the scalability of our approach.",
        "tags": [
            "Video Generation"
        ]
    },
    {
        "id": "177",
        "title": "HRP: High-Rank Preheating for Superior LoRA Initialization",
        "author": [
            "Yuzhu Chen",
            "Yingjie Wang",
            "Shi Fu",
            "Li Shen",
            "Yongcheng Jing",
            "Xinmei Tian",
            "Dacheng Tao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07739",
        "abstract": "This paper studies the crucial impact of initialization on the convergence properties of Low-Rank Adaptation (LoRA). We theoretically demonstrate that random initialization, a widely used schema, will likely lead LoRA to random low-rank results, rather than the best low-rank result. While this issue can be mitigated by adjusting initialization towards a well-informed direction, it relies on prior knowledge of the target, which is typically unknown in real-world scenarios. To approximate this well-informed initial direction, we propose High-Rank Preheating (HRP), which fine-tunes high-rank LoRA for a few steps and uses the singular value decomposition of the preheated result as a superior initialization. HRP initialization is theory-supported to combine the convergence strengths of high-rank LoRA and the generalization strengths of low-rank LoRA. Extensive experiments demonstrate that HRP significantly enhances LoRA's effectiveness across various models and tasks, achieving performance comparable to full-parameter fine-tuning and outperforming other initialization strategies.",
        "tags": [
            "LoRA",
            "Low-Rank Adaptation"
        ]
    },
    {
        "id": "178",
        "title": "WHODUNIT: Evaluation benchmark for culprit detection in mystery stories",
        "author": [
            "Kshitij Gupta"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07747",
        "abstract": "We present a novel data set, WhoDunIt, to assess the deductive reasoning capabilities of large language models (LLM) within narrative contexts. Constructed from open domain mystery novels and short stories, the dataset challenges LLMs to identify the perpetrator after reading and comprehending the story. To evaluate model robustness, we apply a range of character-level name augmentations, including original names, name swaps, and substitutions with well-known real and/or fictional entities from popular discourse. We further use various prompting styles to investigate the influence of prompting on deductive reasoning accuracy.\nWe conduct evaluation study with state-of-the-art models, specifically GPT-4o, GPT-4-turbo, and GPT-4o-mini, evaluated through multiple trials with majority response selection to ensure reliability. The results demonstrate that while LLMs perform reliably on unaltered texts, accuracy diminishes with certain name substitutions, particularly those with wide recognition. This dataset is publicly available here.",
        "tags": [
            "Detection",
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "179",
        "title": "CausalGeD: Blending Causality and Diffusion for Spatial Gene Expression Generation",
        "author": [
            "Rabeya Tus Sadia",
            "Md Atik Ahamed",
            "Qiang Cheng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07751",
        "abstract": "The integration of single-cell RNA sequencing (scRNA-seq) and spatial transcriptomics (ST) data is crucial for understanding gene expression in spatial context. Existing methods for such integration have limited performance, with structural similarity often below 60\\%, We attribute this limitation to the failure to consider causal relationships between genes. We present CausalGeD, which combines diffusion and autoregressive processes to leverage these relationships. By generalizing the Causal Attention Transformer from image generation to gene expression data, our model captures regulatory mechanisms without predefined relationships. Across 10 tissue datasets, CausalGeD outperformed state-of-the-art baselines by 5- 32\\% in key metrics, including Pearson's correlation and structural similarity, advancing both technical and biological insights.",
        "tags": [
            "Diffusion",
            "Transformer"
        ]
    },
    {
        "id": "180",
        "title": "Towards Efficient Optimizer Design for LLM via Structured Fisher Approximation with a Low-Rank Extension",
        "author": [
            "Wenbo Gong",
            "Meyer Scetbon",
            "Chao Ma",
            "Edward Meeds"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07752",
        "abstract": "Designing efficient optimizers for large language models (LLMs) with low-memory requirements and fast convergence is an important and challenging problem. This paper makes a step towards the systematic design of such optimizers through the lens of structured Fisher information matrix (FIM) approximation. We show that many state-of-the-art efficient optimizers can be viewed as solutions to FIM approximation (under the Frobenius norm) with specific structural assumptions. Building on these insights, we propose two design recommendations of practical efficient optimizers for LLMs, involving the careful selection of structural assumptions to balance generality and efficiency, and enhancing memory efficiency of optimizers with general structures through a novel low-rank extension framework. We demonstrate how to use each design approach by deriving new memory-efficient optimizers: Row and Column Scaled SGD (RACS) and Adaptive low-dimensional subspace estimation (Alice). Experiments on LLaMA pre-training (up to 1B parameters) validate the effectiveness, showing faster and better convergence than existing memory-efficient baselines and Adam with little memory overhead. Notably, Alice achieves better than 2x faster convergence over Adam, while RACS delivers strong performance on the 1B model with SGD-like memory.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "181",
        "title": "Direct Ascent Synthesis: Revealing Hidden Generative Capabilities in Discriminative Models",
        "author": [
            "Stanislav Fort",
            "Jonathan Whitaker"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07753",
        "abstract": "We demonstrate that discriminative models inherently contain powerful generative capabilities, challenging the fundamental distinction between discriminative and generative architectures. Our method, Direct Ascent Synthesis (DAS), reveals these latent capabilities through multi-resolution optimization of CLIP model representations. While traditional inversion attempts produce adversarial patterns, DAS achieves high-quality image synthesis by decomposing optimization across multiple spatial scales (1x1 to 224x224), requiring no additional training. This approach not only enables diverse applications -- from text-to-image generation to style transfer -- but maintains natural image statistics ($1/f^2$ spectrum) and guides the generation away from non-robust adversarial patterns. Our results demonstrate that standard discriminative models encode substantially richer generative knowledge than previously recognized, providing new perspectives on model interpretability and the relationship between adversarial examples and natural image synthesis.",
        "tags": [
            "CLIP",
            "Style Transfer",
            "Text-to-Image"
        ]
    },
    {
        "id": "182",
        "title": "MeshSplats: Mesh-Based Rendering with Gaussian Splatting Initialization",
        "author": [
            "RafaÅ Tobiasz",
            "Grzegorz WilczyÅski",
            "Marcin Mazur",
            "SÅawomir Tadeja",
            "PrzemysÅaw Spurek"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07754",
        "abstract": "Gaussian Splatting (GS) is a recent and pivotal technique in 3D computer graphics. GS-based algorithms almost always bypass classical methods such as ray tracing, which offers numerous inherent advantages for rendering. For example, ray tracing is able to handle incoherent rays for advanced lighting effects, including shadows and reflections. To address this limitation, we introduce MeshSplats, a method which converts GS to a mesh-like format. Following the completion of training, MeshSplats transforms Gaussian elements into mesh faces, enabling rendering using ray tracing methods with all their associated benefits. Our model can be utilized immediately following transformation, yielding a mesh of slightly reduced quality without additional training. Furthermore, we can enhance the reconstruction quality through the application of a dedicated optimization algorithm that operates on mesh faces rather than Gaussian components. The efficacy of our method is substantiated by experimental results, underscoring its extensive applications in computer graphics and image processing.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "183",
        "title": "Scalable Fingerprinting of Large Language Models",
        "author": [
            "Anshul Nasery",
            "Jonathan Hayase",
            "Creston Brooks",
            "Peiyao Sheng",
            "Himanshu Tyagi",
            "Pramod Viswanath",
            "Sewoong Oh"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07760",
        "abstract": "Model fingerprinting has emerged as a powerful tool for model owners to identify their shared model given API access. However, to lower false discovery rate, fight fingerprint leakage, and defend against coalitions of model users attempting to bypass detection, we argue that {\\em scalability} is critical, i.e., scaling up the number of fingerprints one can embed into a model. Hence, we pose scalability as a crucial requirement for fingerprinting schemes. We experiment with fingerprint design at a scale significantly larger than previously considered, and introduce a new method, dubbed Perinucleus sampling, to generate scalable, persistent, and harmless fingerprints. We demonstrate that this scheme can add 24,576 fingerprints to a Llama-3.1-8B model -- two orders of magnitude more than existing schemes -- without degrading the model's utility. Our inserted fingerprints persist even after supervised fine-tuning on standard post-training data. We further address security risks for fingerprinting, and theoretically and empirically show how a scalable fingerprinting scheme like ours can mitigate these risks.",
        "tags": [
            "Detection",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "184",
        "title": "Great Power Brings Great Responsibility: Personalizing Conversational AI for Diverse Problem-Solvers",
        "author": [
            "Italo Santos",
            "Katia Romero Felizardo",
            "Igor Steinmacher",
            "Marco A. Gerosa"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07763",
        "abstract": "Newcomers onboarding to Open Source Software (OSS) projects face many challenges. Large Language Models (LLMs), like ChatGPT, have emerged as potential resources for answering questions and providing guidance, with many developers now turning to ChatGPT over traditional Q&A sites like Stack Overflow. Nonetheless, LLMs may carry biases in presenting information, which can be especially impactful for newcomers whose problem-solving styles may not be broadly represented. This raises important questions about the accessibility of AI-driven support for newcomers to OSS projects. This vision paper outlines the potential of adapting AI responses to various problem-solving styles to avoid privileging a particular subgroup. We discuss the potential of AI persona-based prompt engineering as a strategy for interacting with AI. This study invites further research to refine AI-based tools to better support contributions to OSS projects.",
        "tags": [
            "ChatGPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "185",
        "title": "Breaking Down Bias: On The Limits of Generalizable Pruning Strategies",
        "author": [
            "Sibo Ma",
            "Alejandro Salinas",
            "Peter Henderson",
            "Julian Nyarko"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07771",
        "abstract": "We employ model pruning to examine how LLMs conceptualize racial biases, and whether a generalizable mitigation strategy for such biases appears feasible. Our analysis yields several novel insights. We find that pruning can be an effective method to reduce bias without significantly increasing anomalous model behavior. Neuron-based pruning strategies generally yield better results than approaches pruning entire attention heads. However, our results also show that the effectiveness of either approach quickly deteriorates as pruning strategies become more generalized. For instance, a model that is trained on removing racial biases in the context of financial decision-making poorly generalizes to biases in commercial transactions. Overall, our analysis suggests that racial biases are only partially represented as a general concept within language models. The other part of these biases is highly context-specific, suggesting that generalizable mitigation strategies may be of limited effectiveness. Our findings have important implications for legal frameworks surrounding AI. In particular, they suggest that an effective mitigation strategy should include the allocation of legal responsibility on those that deploy models in a specific use case.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "186",
        "title": "Auditing Prompt Caching in Language Model APIs",
        "author": [
            "Chenchen Gu",
            "Xiang Lisa Li",
            "Rohith Kuditipudi",
            "Percy Liang",
            "Tatsunori Hashimoto"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07776",
        "abstract": "Prompt caching in large language models (LLMs) results in data-dependent timing variations: cached prompts are processed faster than non-cached prompts. These timing differences introduce the risk of side-channel timing attacks. For example, if the cache is shared across users, an attacker could identify cached prompts from fast API response times to learn information about other users' prompts. Because prompt caching may cause privacy leakage, transparency around the caching policies of API providers is important. To this end, we develop and conduct statistical audits to detect prompt caching in real-world LLM API providers. We detect global cache sharing across users in seven API providers, including OpenAI, resulting in potential privacy leakage about users' prompts. Timing variations due to prompt caching can also result in leakage of information about model architecture. Namely, we find evidence that OpenAI's embedding model is a decoder-only Transformer, which was previously not publicly known.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "187",
        "title": "DarwinLM: Evolutionary Structured Pruning of Large Language Models",
        "author": [
            "Shengkun Tang",
            "Oliver Sieberling",
            "Eldar Kurtic",
            "Zhiqiang Shen",
            "Dan Alistarh"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07780",
        "abstract": "Large Language Models (LLMs) have achieved significant success across various NLP tasks. However, their massive computational costs limit their widespread use, particularly in real-time applications. Structured pruning offers an effective solution by compressing models and directly providing end-to-end speed improvements, regardless of the hardware environment. Meanwhile, different components of the model exhibit varying sensitivities towards pruning, calling for \\emph{non-uniform} model compression. However, a pruning method should not only identify a capable substructure, but also account for post-compression training. To this end, we propose \\sysname, a method for \\emph{training-aware} structured pruning. \\sysname builds upon an evolutionary search process, generating multiple offspring models in each generation through mutation, and selecting the fittest for survival. To assess the effect of post-training, we incorporate a lightweight, multistep training process within the offspring population, progressively increasing the number of tokens and eliminating poorly performing models in each selection stage. We validate our method through extensive experiments on Llama-2-7B, Llama-3.1-8B and Qwen-2.5-14B-Instruct, achieving state-of-the-art performance for structured pruning. For instance, \\sysname surpasses ShearedLlama while requiring $5\\times$ less training data during post-compression training.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models",
            "Qwen"
        ]
    },
    {
        "id": "188",
        "title": "MatSwap: Light-aware material transfers in images",
        "author": [
            "Ivan Lopes",
            "Valentin Deschaintre",
            "Yannick Hold-Geoffroy",
            "Raoul de Charette"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07784",
        "abstract": "We present MatSwap, a method to transfer materials to designated surfaces in an image photorealistically. Such a task is non-trivial due to the large entanglement of material appearance, geometry, and lighting in a photograph. In the literature, material editing methods typically rely on either cumbersome text engineering or extensive manual annotations requiring artist knowledge and 3D scene properties that are impractical to obtain. In contrast, we propose to directly learn the relationship between the input material -- as observed on a flat surface -- and its appearance within the scene, without the need for explicit UV mapping. To achieve this, we rely on a custom light- and geometry-aware diffusion model. We fine-tune a large-scale pre-trained text-to-image model for material transfer using our synthetic dataset, preserving its strong priors to ensure effective generalization to real images. As a result, our method seamlessly integrates a desired material into the target location in the photograph while retaining the identity of the scene. We evaluate our method on synthetic and real images and show that it compares favorably to recent work both qualitatively and quantitatively. We will release our code and data upon publication.",
        "tags": [
            "3D",
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "189",
        "title": "Pippo: High-Resolution Multi-View Humans from a Single Image",
        "author": [
            "Yash Kant",
            "Ethan Weber",
            "Jin Kyu Kim",
            "Rawal Khirodkar",
            "Su Zhaoen",
            "Julieta Martinez",
            "Igor Gilitschenski",
            "Shunsuke Saito",
            "Timur Bagautdinov"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07785",
        "abstract": "We present Pippo, a generative model capable of producing 1K resolution dense turnaround videos of a person from a single casually clicked photo. Pippo is a multi-view diffusion transformer and does not require any additional inputs - e.g., a fitted parametric model or camera parameters of the input image. We pre-train Pippo on 3B human images without captions, and conduct multi-view mid-training and post-training on studio captured humans. During mid-training, to quickly absorb the studio dataset, we denoise several (up to 48) views at low-resolution, and encode target cameras coarsely using a shallow MLP. During post-training, we denoise fewer views at high-resolution and use pixel-aligned controls (e.g., Spatial anchor and Plucker rays) to enable 3D consistent generations. At inference, we propose an attention biasing technique that allows Pippo to simultaneously generate greater than 5 times as many views as seen during training. Finally, we also introduce an improved metric to evaluate 3D consistency of multi-view generations, and show that Pippo outperforms existing works on multi-view human generation from a single image.",
        "tags": [
            "3D",
            "Diffusion",
            "Diffusion Transformer",
            "Transformer"
        ]
    },
    {
        "id": "190",
        "title": "Generalizable automated ischaemic stroke lesion segmentation with vision transformers",
        "author": [
            "Chris Foulon",
            "Robert Gray",
            "James K. Ruffle",
            "Jonathan Best",
            "Tianbo Xu",
            "Henry Watkins",
            "Jane Rondina",
            "Guilherme Pombo",
            "Dominic Giles",
            "Paul Wright",
            "Marcela Ovando-Tellez",
            "H. Rolf JÃ¤ger",
            "Jorge Cardoso",
            "Sebastien Ourselin",
            "Geraint Rees",
            "Parashkev Nachev"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06939",
        "abstract": "Ischaemic stroke, a leading cause of death and disability, critically relies on neuroimaging for characterising the anatomical pattern of injury. Diffusion-weighted imaging (DWI) provides the highest expressivity in ischemic stroke but poses substantial challenges for automated lesion segmentation: susceptibility artefacts, morphological heterogeneity, age-related comorbidities, time-dependent signal dynamics, instrumental variability, and limited labelled data. Current U-Net-based models therefore underperform, a problem accentuated by inadequate evaluation metrics that focus on mean performance, neglecting anatomical, subpopulation, and acquisition-dependent variability. Here, we present a high-performance DWI lesion segmentation tool addressing these challenges through optimized vision transformer-based architectures, integration of 3563 annotated lesions from multi-site data, and algorithmic enhancements, achieving state-of-the-art results. We further propose a novel evaluative framework assessing model fidelity, equity (across demographics and lesion subtypes), anatomical precision, and robustness to instrumental variability, promoting clinical and research utility. This work advances stroke imaging by reconciling model expressivity with domain-specific challenges and redefining performance benchmarks to prioritize equity and generalizability, critical for personalized medicine and mechanistic research.",
        "tags": [
            "Diffusion",
            "Segmentation",
            "Transformer"
        ]
    },
    {
        "id": "191",
        "title": "TRADES: Generating Realistic Market Simulations with Diffusion Models",
        "author": [
            "Leonardo Berti",
            "Bardh Prenkaj",
            "Paola Velardi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07071",
        "abstract": "Financial markets are complex systems characterized by high statistical noise, nonlinearity, volatility, and constant evolution. Thus, modeling them is extremely hard. Here, we address the task of generating realistic and responsive Limit Order Book (LOB) market simulations, which are fundamental for calibrating and testing trading strategies, performing market impact experiments, and generating synthetic market data. Previous works lack realism, usefulness, and responsiveness of the generated simulations. To bridge this gap, we propose a novel TRAnsformer-based Denoising Diffusion Probabilistic Engine for LOB Simulations (TRADES). TRADES generates realistic order flows as time series conditioned on the state of the market, leveraging a transformer-based architecture that captures the temporal and spatial characteristics of high-frequency market data. There is a notable absence of quantitative metrics for evaluating generative market simulation models in the literature. To tackle this problem, we adapt the predictive score, a metric measured as an MAE, by training a stock price predictive model on synthetic data and testing it on real data. We compare TRADES with previous works on two stocks, reporting an x3.27 and x3.47 improvement over SoTA according to the predictive score, demonstrating that we generate useful synthetic market data for financial downstream tasks. Furthermore, we assess TRADES's market simulation realism and responsiveness, showing that it effectively learns the conditional data distribution and successfully reacts to an experimental agent, giving sprout to possible calibrations and evaluations of trading strategies and market impact experiments. We developed DeepMarket, the first open-source Python framework for market simulation with deep learning. In our repository, we include a synthetic LOB dataset composed of the TRADES's generated simulations.",
        "tags": [
            "Diffusion",
            "Transformer"
        ]
    },
    {
        "id": "192",
        "title": "5D Neural Surrogates for Nonlinear Gyrokinetic Simulations of Plasma Turbulence",
        "author": [
            "Gianluca Galletti",
            "Fabian Paischer",
            "Paul Setinek",
            "William Hornsby",
            "Lorenzo Zanisi",
            "Naomi Carey",
            "Stanislas Pamela",
            "Johannes Brandstetter"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07469",
        "abstract": "Nuclear fusion plays a pivotal role in the quest for reliable and sustainable energy production. A major roadblock to achieving commercially viable fusion power is understanding plasma turbulence, which can significantly degrade plasma confinement. Modelling turbulence is crucial to design performing plasma scenarios for next-generation reactor-class devices and current experimental machines. The nonlinear gyrokinetic equation underpinning turbulence modelling evolves a 5D distribution function over time. Solving this equation numerically is extremely expensive, requiring up to weeks for a single run to converge, making it unfeasible for iterative optimisation and control studies. In this work, we propose a method for training neural surrogates for 5D gyrokinetic simulations. Our method extends a hierarchical vision transformer to five dimensions and is trained on the 5D distribution function for the adiabatic electron approximation. We demonstrate that our model can accurately infer downstream physical quantities such as heat flux time trace and electrostatic potentials for single-step predictions two orders of magnitude faster than numerical codes. Our work paves the way towards neural surrogates for plasma turbulence simulations to accelerate deployment of commercial energy production via nuclear fusion.",
        "tags": [
            "FLUX",
            "Transformer"
        ]
    },
    {
        "id": "193",
        "title": "Exoplanet Transit Candidate Identification in TESS Full-Frame Images via a Transformer-Based Algorithm",
        "author": [
            "Helem Salinas",
            "Rafael Brahm",
            "Greg Olmschenk",
            "Richard K. Barry",
            "Karim Pichara",
            "Stela Ishitani Silva",
            "Vladimir Araujo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07542",
        "abstract": "The Transiting Exoplanet Survey Satellite (TESS) is surveying a large fraction of the sky, generating a vast database of photometric time series data that requires thorough analysis to identify exoplanetary transit signals. Automated learning approaches have been successfully applied to identify transit signals. However, most existing methods focus on the classification and validation of candidates, while few efforts have explored new techniques for the search of candidates. To search for new exoplanet transit candidates, we propose an approach to identify exoplanet transit signals without the need for phase folding or assuming periodicity in the transit signals, such as those observed in multi-transit light curves. To achieve this, we implement a new neural network inspired by Transformers to directly process Full Frame Image (FFI) light curves to detect exoplanet transits. Transformers, originally developed for natural language processing, have recently demonstrated significant success in capturing long-range dependencies compared to previous approaches focused on sequential data. This ability allows us to employ multi-head self-attention to identify exoplanet transit signals directly from the complete light curves, combined with background and centroid time series, without requiring prior transit parameters. The network is trained to learn characteristics of the transit signal, like the dip shape, which helps distinguish planetary transits from other variability sources. Our model successfully identified 214 new planetary system candidates, including 122 multi-transit light curves, 88 single-transit and 4 multi-planet systems from TESS sectors 1-26 with a radius > 0.27 $R_{\\mathrm{Jupiter}}$, demonstrating its ability to detect transits regardless of their periodicity.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "194",
        "title": "RenderBox: Expressive Performance Rendering with Text Control",
        "author": [
            "Huan Zhang",
            "Akira Maezawa",
            "Simon Dixon"
        ],
        "pdf": "https://arxiv.org/pdf/2502.07711",
        "abstract": "Expressive music performance rendering involves interpreting symbolic scores with variations in timing, dynamics, articulation, and instrument-specific techniques, resulting in performances that capture musical can emotional intent. We introduce RenderBox, a unified framework for text-and-score controlled audio performance generation across multiple instruments, applying coarse-level controls through natural language descriptions and granular-level controls using music scores. Based on a diffusion transformer architecture and cross-attention joint conditioning, we propose a curriculum-based paradigm that trains from plain synthesis to expressive performance, gradually incorporating controllable factors such as speed, mistakes, and style diversity.\nRenderBox achieves high performance compared to baseline models across key metrics such as FAD and CLAP, and also tempo and pitch accuracy under different prompting tasks. Subjective evaluation further demonstrates that RenderBox is able to generate controllable expressive performances that sound natural and musically engaging, aligning well with prompts and intent.",
        "tags": [
            "Diffusion",
            "Diffusion Transformer",
            "Transformer"
        ]
    }
]