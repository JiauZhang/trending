[
    {
        "id": "1",
        "title": "Using Large Language Models for Solving Thermodynamic Problems",
        "author": [
            "Rebecca Loubet",
            "Pascal Zittlau",
            "Luisa Vollmer",
            "Marco Hoffmann",
            "Sophie Fellenz",
            "Fabian Jirasek",
            "Heike Leitte",
            "Hans Hasse"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05195",
        "abstract": "Large Language Models (LLMs) have made significant progress in reasoning, demonstrating their capability to generate human-like responses. This study analyzes the problem-solving capabilities of LLMs in the domain of thermodynamics. A benchmark of 22 thermodynamic problems to evaluate LLMs is presented that contains both simple and advanced problems. Five different LLMs are assessed: GPT-3.5, GPT-4, and GPT-4o from OpenAI, Llama 3.1 from Meta, and le Chat from MistralAI. The answers of these LLMs were evaluated by trained human experts, following a methodology akin to the grading of academic exam responses. The scores and the consistency of the answers are discussed, together with the analytical skills of the LLMs. Both strengths and weaknesses of the LLMs become evident. They generally yield good results for the simple problems, but also limitations become clear: The LLMs do not provide consistent results, they often fail to fully comprehend the context and make wrong assumptions. Given the complexity and domain-specific nature of the problems, the statistical language modeling approach of the LLMs struggles with the accurate interpretation and the required reasoning. The present results highlight the need for more systematic integration of thermodynamic knowledge with LLMs, for example, by using knowledge-based methods.",
        "tags": [
            "GPT",
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "2",
        "title": "LLMs Provide Unstable Answers to Legal Questions",
        "author": [
            "Andrew Blair-Stanek",
            "Benjamin Van Durme"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05196",
        "abstract": "An LLM is stable if it reaches the same conclusion when asked the identical question multiple times. We find leading LLMs like gpt-4o, claude-3.5, and gemini-1.5 are unstable when providing answers to hard legal questions, even when made as deterministic as possible by setting temperature to 0. We curate and release a novel dataset of 500 legal questions distilled from real cases, involving two parties, with facts, competing legal arguments, and the question of which party should prevail. When provided the exact same question, we observe that LLMs sometimes say one party should win, while other times saying the other party should win. This instability has implications for the increasing numbers of legal AI products, legal processes, and lawyers relying on these LLMs.",
        "tags": [
            "GPT",
            "LLMs"
        ]
    },
    {
        "id": "3",
        "title": "Accelerating LLM Inference with Lossless Speculative Decoding Algorithms for Heterogeneous Vocabularies",
        "author": [
            "Nadav Timor",
            "Jonathan Mamou",
            "Daniel Korat",
            "Moshe Berchansky",
            "Oren Pereg",
            "Gaurav Jain",
            "Roy Schwartz",
            "Moshe Wasserblat",
            "David Harel"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05202",
        "abstract": "Accelerating the inference of large language models (LLMs) is a critical challenge in generative AI. Speculative decoding (SD) methods offer substantial efficiency gains by generating multiple tokens using a single target forward pass. However, existing SD approaches require the drafter and target models to share the same vocabulary, thus limiting the pool of possible drafters, often necessitating the training of a drafter from scratch. We present three new SD methods that remove this shared-vocabulary constraint. All three methods preserve the target distribution (i.e., they are lossless) and work with off-the-shelf models without requiring additional training or modifications. Empirically, on summarization, programming, and long-context tasks, our algorithms achieve significant speedups over standard autoregressive decoding. By enabling any off-the-shelf model to serve as drafter and requiring no retraining, this work substantially broadens the applicability of the SD framework in practice.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "4",
        "title": "Model Tampering Attacks Enable More Rigorous Evaluations of LLM Capabilities",
        "author": [
            "Zora Che",
            "Stephen Casper",
            "Robert Kirk",
            "Anirudh Satheesh",
            "Stewart Slocum",
            "Lev E McKinney",
            "Rohit Gandikota",
            "Aidan Ewart",
            "Domenic Rosati",
            "Zichu Wu",
            "Zikui Cai",
            "Bilal Chughtai",
            "Yarin Gal",
            "Furong Huang",
            "Dylan Hadfield-Menell"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05209",
        "abstract": "Evaluations of large language model (LLM) risks and capabilities are increasingly being incorporated into AI risk management and governance frameworks. Currently, most risk evaluations are conducted by designing inputs that elicit harmful behaviors from the system. However, a fundamental limitation of this approach is that the harmfulness of the behaviors identified during any particular evaluation can only lower bound the model's worst-possible-case behavior. As a complementary method for eliciting harmful behaviors, we propose evaluating LLMs with model tampering attacks which allow for modifications to latent activations or weights. We pit state-of-the-art techniques for removing harmful LLM capabilities against a suite of 5 input-space and 6 model tampering attacks. In addition to benchmarking these methods against each other, we show that (1) model resilience to capability elicitation attacks lies on a low-dimensional robustness subspace; (2) the attack success rate of model tampering attacks can empirically predict and offer conservative estimates for the success of held-out input-space attacks; and (3) state-of-the-art unlearning methods can easily be undone within 16 steps of fine-tuning. Together these results highlight the difficulty of removing harmful LLM capabilities and show that model tampering attacks enable substantially more rigorous evaluations than input-space attacks alone. We release models at https://huggingface.co/LLM-GAT",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "5",
        "title": "Watermarking across Modalities for Content Tracing and Generative AI",
        "author": [
            "Pierre Fernandez"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05215",
        "abstract": "Watermarking embeds information into digital content like images, audio, or text, imperceptible to humans but robustly detectable by specific algorithms. This technology has important applications in many challenges of the industry such as content moderation, tracing AI-generated content, and monitoring the usage of AI models. The contributions of this thesis include the development of new watermarking techniques for images, audio, and text. We first introduce methods for active moderation of images on social platforms. We then develop specific techniques for AI-generated content. We specifically demonstrate methods to adapt latent generative models to embed watermarks in all generated content, identify watermarked sections in speech, and improve watermarking in large language models with tests that ensure low false positive rates. Furthermore, we explore the use of digital watermarking to detect model misuse, including the detection of watermarks in language models fine-tuned on watermarked text, and introduce training-free watermarks for the weights of large transformers. Through these contributions, the thesis provides effective solutions for the challenges posed by the increasing use of generative AI models and the need for model monitoring and content moderation. It finally examines the challenges and limitations of watermarking techniques and discuss potential future directions for research in this area.",
        "tags": [
            "Detection",
            "Large Language Models"
        ]
    },
    {
        "id": "6",
        "title": "KDA: A Knowledge-Distilled Attacker for Generating Diverse Prompts to Jailbreak LLMs",
        "author": [
            "Buyun Liang",
            "Kwan Ho Ryan Chan",
            "Darshan Thaker",
            "Jinqi Luo",
            "RenÃ© Vidal"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05223",
        "abstract": "Jailbreak attacks exploit specific prompts to bypass LLM safeguards, causing the LLM to generate harmful, inappropriate, and misaligned content. Current jailbreaking methods rely heavily on carefully designed system prompts and numerous queries to achieve a single successful attack, which is costly and impractical for large-scale red-teaming. To address this challenge, we propose to distill the knowledge of an ensemble of SOTA attackers into a single open-source model, called Knowledge-Distilled Attacker (KDA), which is finetuned to automatically generate coherent and diverse attack prompts without the need for meticulous system prompt engineering. Compared to existing attackers, KDA achieves higher attack success rates and greater cost-time efficiency when targeting multiple SOTA open-source and commercial black-box LLMs. Furthermore, we conducted a quantitative diversity analysis of prompts generated by baseline methods and KDA, identifying diverse and ensemble attacks as key factors behind KDA's effectiveness and efficiency.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "7",
        "title": "Aligner-Encoders: Self-Attention Transformers Can Be Self-Transducers",
        "author": [
            "Adam Stooke",
            "Rohit Prabhavalkar",
            "Khe Chai Sim",
            "Pedro Moreno Mengibar"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05232",
        "abstract": "Modern systems for automatic speech recognition, including the RNN-Transducer and Attention-based Encoder-Decoder (AED), are designed so that the encoder is not required to alter the time-position of information from the audio sequence into the embedding; alignment to the final text output is processed during decoding. We discover that the transformer-based encoder adopted in recent years is actually capable of performing the alignment internally during the forward pass, prior to decoding. This new phenomenon enables a simpler and more efficient model, the \"Aligner-Encoder\". To train it, we discard the dynamic programming of RNN-T in favor of the frame-wise cross-entropy loss of AED, while the decoder employs the lighter text-only recurrence of RNN-T without learned cross-attention -- it simply scans embedding frames in order from the beginning, producing one token each until predicting the end-of-message. We conduct experiments demonstrating performance remarkably close to the state of the art, including a special inference configuration enabling long-form recognition. In a representative comparison, we measure the total inference time for our model to be 2x faster than RNN-T and 16x faster than AED. Lastly, we find that the audio-text alignment is clearly visible in the self-attention weights of a certain layer, which could be said to perform \"self-transduction\".",
        "tags": [
            "RNN",
            "Transformer"
        ]
    },
    {
        "id": "8",
        "title": "Efficient Knowledge Feeding to Language Models: A Novel Integrated Encoder-Decoder Architecture",
        "author": [
            "S Santosh Kumar",
            "Rishi Gottimukkala",
            "Supriya Devidutta",
            "Karthikeyan S"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05233",
        "abstract": "This paper introduces a novel approach to efficiently feeding knowledge to language models (LLMs) during prediction by integrating retrieval and generation processes within a unified framework. While the Retrieval-Augmented Generation (RAG) model addresses gaps in LLMs' training data and knowledge limits, it is hindered by token limit restrictions and dependency on the retrieval system's accuracy. Our proposed architecture incorporates in-context vectors (ICV) to overcome these challenges. ICV recasts in-context learning by using latent embeddings of LLMs to create a vector that captures essential task information. This vector is then used to shift the latent states of the LLM, enhancing the generation process without adding demonstration examples to the prompt. ICV directly integrates information into the model, enabling it to process this information more effectively. Our extensive experimental evaluation demonstrates that ICV outperforms standard in-context learning and fine-tuning across question-answering, information retrieval, and other tasks. This approach mitigates the limitations of current RAG models and offers a more robust solution for handling extensive and diverse datasets. Despite leveraging a fraction of the parameters, our ICV-enhanced model achieves competitive performance against models like LLaMA-3, Gemma, and Phi-3, significantly reducing computational costs and memory requirements. ICV reduces prompt length, is easy to control, surpasses token limitations, and is computationally efficient compared to fine-tuning.",
        "tags": [
            "LLMs",
            "LLaMA",
            "RAG"
        ]
    },
    {
        "id": "9",
        "title": "Optimizing Temperature for Language Models with Multi-Sample Inference",
        "author": [
            "Weihua Du",
            "Yiming Yang",
            "Sean Welleck"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05234",
        "abstract": "Multi-sample aggregation strategies, such as majority voting and best-of-N sampling, are widely used in contemporary large language models (LLMs) to enhance predictive accuracy across various tasks. A key challenge in this process is temperature selection, which significantly impacts model performance. Existing approaches either rely on a fixed default temperature or require labeled validation data for tuning, which are often scarce and difficult to obtain. This paper addresses the challenge of automatically identifying the (near)-optimal temperature for different LLMs using multi-sample aggregation strategies, without relying on task-specific validation data. We provide a comprehensive analysis of temperature's role in performance optimization, considering variations in model architectures, datasets, task types, model sizes, and predictive accuracy. Furthermore, we propose a novel entropy-based metric for automated temperature optimization, which consistently outperforms fixed-temperature baselines. Additionally, we incorporate a stochastic process model to enhance interpretability, offering deeper insights into the relationship between temperature and model performance.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "10",
        "title": "Koel-TTS: Enhancing LLM based Speech Generation with Preference Alignment and Classifier Free Guidance",
        "author": [
            "Shehzeen Hussain",
            "Paarth Neekhara",
            "Xuesong Yang",
            "Edresson Casanova",
            "Subhankar Ghosh",
            "Mikyas T. Desta",
            "Roy Fejgin",
            "Rafael Valle",
            "Jason Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05236",
        "abstract": "While autoregressive speech token generation models produce speech with remarkable variety and naturalness, their inherent lack of controllability often results in issues such as hallucinations and undesired vocalizations that do not conform to conditioning inputs. We introduce Koel-TTS, a suite of enhanced encoder-decoder Transformer TTS models that address these challenges by incorporating preference alignment techniques guided by automatic speech recognition and speaker verification models. Additionally, we incorporate classifier-free guidance to further improve synthesis adherence to the transcript and reference speaker audio. Our experiments demonstrate that these optimizations significantly enhance target speaker similarity, intelligibility, and naturalness of synthesized speech. Notably, Koel-TTS directly maps text and context audio to acoustic tokens, and on the aforementioned metrics, outperforms state-of-the-art TTS models, despite being trained on a significantly smaller dataset. Audio samples and demos are available on our website.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "11",
        "title": "Enhancing Knowledge Graph Construction: Evaluating with Emphasis on Hallucination, Omission, and Graph Similarity Metrics",
        "author": [
            "Hussam Ghanem",
            "Christophe Cruz"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05239",
        "abstract": "Recent advancements in large language models have demonstrated significant potential in the automated construction of knowledge graphs from unstructured text. This paper builds upon our previous work [16], which evaluated various models using metrics like precision, recall, F1 score, triple matching, and graph matching, and introduces a refined approach to address the critical issues of hallucination and omission. We propose an enhanced evaluation framework incorporating BERTScore for graph similarity, setting a practical threshold of 95% for graph matching. Our experiments focus on the Mistral model, comparing its original and fine-tuned versions in zero-shot and few-shot settings. We further extend our experiments using examples from the KELM-sub training dataset, illustrating that the fine-tuned model significantly improves knowledge graph construction accuracy while reducing the exact hallucination and omission. However, our findings also reveal that the fine-tuned models perform worse in generalization tasks on the KELM-sub dataset. This study underscores the importance of comprehensive evaluation metrics in advancing the state-of-the-art in knowledge graph construction from textual data.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "12",
        "title": "Survey on AI-Generated Media Detection: From Non-MLLM to MLLM",
        "author": [
            "Yueying Zou",
            "Peipei Li",
            "Zekun Li",
            "Huaibo Huang",
            "Xing Cui",
            "Xuannan Liu",
            "Chenghanyu Zhang",
            "Ran He"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05240",
        "abstract": "The proliferation of AI-generated media poses significant challenges to information authenticity and social trust, making reliable detection methods highly demanded. Methods for detecting AI-generated media have evolved rapidly, paralleling the advancement of Multimodal Large Language Models (MLLMs). Current detection approaches can be categorized into two main groups: Non-MLLM-based and MLLM-based methods. The former employs high-precision, domain-specific detectors powered by deep learning techniques, while the latter utilizes general-purpose detectors based on MLLMs that integrate authenticity verification, explainability, and localization capabilities. Despite significant progress in this field, there remains a gap in literature regarding a comprehensive survey that examines the transition from domain-specific to general-purpose detection methods. This paper addresses this gap by providing a systematic review of both approaches, analyzing them from single-modal and multi-modal perspectives. We present a detailed comparative analysis of these categories, examining their methodological similarities and differences. Through this analysis, we explore potential hybrid approaches and identify key challenges in forgery detection, providing direction for future research. Additionally, as MLLMs become increasingly prevalent in detection tasks, ethical and security considerations have emerged as critical global concerns. We examine the regulatory landscape surrounding Generative AI (GenAI) across various jurisdictions, offering valuable insights for researchers and practitioners in this field.",
        "tags": [
            "Detection",
            "Large Language Models"
        ]
    },
    {
        "id": "13",
        "title": "SEER: Self-Explainability Enhancement of Large Language Models' Representations",
        "author": [
            "Guanxu Chen",
            "Dongrui Liu",
            "Tao Luo",
            "Jing Shao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05242",
        "abstract": "Explaining the hidden representations of Large Language Models (LLMs) is a perspective to understand LLMs' underlying inference logic and improve their reliability in application scenarios. However, previous methods introduce external ''black-box'' modules to explain ''black-box'' LLMs, increasing the potential uncertainty and failing to provide faithful explanations. In this paper, we propose a self-explaining method SEER, enhancing LLMs' explainability by aggregating the same concept and disentangling the different concepts in the representation space. In this way, SEER provides faithful explanations carried by representations synchronously with the LLMs' output. Additionally, we showcase the applications of SEER on trustworthiness-related tasks (e.g., the safety risks classification and detoxification tasks), where self-explained LLMs achieve consistent improvement in explainability and performance. More crucially, we theoretically analyze the improvement of SEER on LLMs' generalization ability through optimal transport theory.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "14",
        "title": "Evaluating Personality Traits in Large Language Models: Insights from Psychological Questionnaires",
        "author": [
            "Pranav Bhandari",
            "Usman Naseem",
            "Amitava Datta",
            "Nicolas Fay",
            "Mehwish Nasim"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05248",
        "abstract": "Psychological assessment tools have long helped humans understand behavioural patterns. While Large Language Models (LLMs) can generate content comparable to that of humans, we explore whether they exhibit personality traits. To this end, this work applies psychological tools to LLMs in diverse scenarios to generate personality profiles. Using established trait-based questionnaires such as the Big Five Inventory and by addressing the possibility of training data contamination, we examine the dimensional variability and dominance of LLMs across five core personality dimensions: Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism. Our findings reveal that LLMs exhibit unique dominant traits, varying characteristics, and distinct personality profiles even within the same family of models.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "15",
        "title": "GSM-Infinite: How Do Your LLMs Behave over Infinitely Increasing Context Length and Reasoning Complexity?",
        "author": [
            "Yang Zhou",
            "Hongyi Liu",
            "Zhuoming Chen",
            "Yuandong Tian",
            "Beidi Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05252",
        "abstract": "Long-context large language models (LLMs) have recently shown strong performance in information retrieval and long-document QA. However, to tackle the most challenging intellectual problems, LLMs must reason effectively in long and complex contexts (e.g., frontier mathematical research). Studying how LLMs handle increasing reasoning complexity and context length is essential, yet existing benchmarks lack a solid basis for quantitative evaluation. Inspired by the abstraction of GSM-8K problems as computational graphs, and the ability to introduce noise by adding unnecessary nodes and edges, we develop a grade school math problem generator capable of producing arithmetic problems with infinite difficulty and context length under fine-grained control. Using our newly synthesized GSM-Infinite benchmark, we comprehensively evaluate existing LLMs. We find a consistent sigmoid decline in reasoning performance as complexity increases, along with a systematic inference scaling trend: exponentially increasing inference computation yields only linear performance gains. These findings underscore the fundamental limitations of current long-context LLMs and the key challenges in scaling reasoning capabilities. Our GSM-Infinite benchmark provides a scalable and controllable testbed for systematically studying and advancing LLM reasoning in long and complex contexts.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "16",
        "title": "LLMs Can Teach Themselves to Better Predict the Future",
        "author": [
            "Benjamin Turtel",
            "Danny Franklin",
            "Philipp Schoenegger"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05253",
        "abstract": "We present an outcome-driven fine-tuning framework that enhances the forecasting capabilities of large language models (LLMs) without relying on human-curated reasoning samples. Our method leverages model self-play to generate pairs of diverse reasoning trajectories and probabilistic forecasts for a set of diverse questions that resolve after the models' knowledge cutoff date. We then rank pairs of these reasoning traces by their distance to the actual outcomes before fine-tuning the model via Direct Preference Optimization (DPO). On a separate test set, our approach increases prediction accuracy of Phi-4 14B and DeepSeek-R1 14B by between 7--10\\% over a base model and a DPO fine-tuned control model with randomized labels, bringing them on par with forecasting capabilities of much larger frontier models like GPT-4o.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "17",
        "title": "Invizo: Arabic Handwritten Document Optical Character Recognition Solution",
        "author": [
            "Alhossien Waly",
            "Bassant Tarek",
            "Ali Feteha",
            "Rewan Yehia",
            "Gasser Amr",
            "Walid Gomaa",
            "Ahmed Fares"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05277",
        "abstract": "Converting images of Arabic text into plain text is a widely researched topic in academia and industry. However, recognition of Arabic handwritten and printed text presents difficult challenges due to the complex nature of variations of the Arabic script. This work proposes an end-to-end solution for recognizing Arabic handwritten, printed, and Arabic numbers and presents the data in a structured manner. We reached 81.66% precision, 78.82% Recall, and 79.07% F-measure on a Text Detection task that powers the proposed solution. The proposed recognition model incorporates state-of-the-art CNN-based feature extraction, and Transformer-based sequence modeling to accommodate variations in handwriting styles, stroke thicknesses, alignments, and noise conditions. The evaluation of the model suggests its strong performances on both printed and handwritten texts, yielding 0.59% CER and & 1.72% WER on printed text, and 7.91% CER and 31.41% WER on handwritten text. The overall proposed solution has proven to be relied on in real-life OCR tasks. Equipped with both detection and recognition models as well as other Feature Extraction and Matching helping algorithms. With the general purpose implementation, making the solution valid for any given document or receipt that is Arabic handwritten or printed. Thus, it is practical and useful for any given context.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "18",
        "title": "Can LLMs Rank the Harmfulness of Smaller LLMs? We are Not There Yet",
        "author": [
            "Berk Atil",
            "Vipul Gupta",
            "Sarkar Snigdha Sarathi Das",
            "Rebecca J. Passonneau"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05291",
        "abstract": "Large language models (LLMs) have become ubiquitous, thus it is important to understand their risks and limitations. Smaller LLMs can be deployed where compute resources are constrained, such as edge devices, but with different propensity to generate harmful output. Mitigation of LLM harm typically depends on annotating the harmfulness of LLM output, which is expensive to collect from humans. This work studies two questions: How do smaller LLMs rank regarding generation of harmful content? How well can larger LLMs annotate harmfulness? We prompt three small LLMs to elicit harmful content of various types, such as discriminatory language, offensive content, privacy invasion, or negative influence, and collect human rankings of their outputs. Then, we evaluate three state-of-the-art large LLMs on their ability to annotate the harmfulness of these responses. We find that the smaller models differ with respect to harmfulness. We also find that large LLMs show low to moderate agreement with humans. These findings underline the need for further work on harm mitigation in LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "19",
        "title": "Oracular Programming: A Modular Foundation for Building LLM-Enabled Software",
        "author": [
            "Jonathan Laurent",
            "AndrÃ© Platzer"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05310",
        "abstract": "Large Language Models have proved surprisingly effective at solving a wide range of tasks from just a handful of examples. However, their lack of reliability and modularity limits their capacity to tackle large problems that require many steps of reasoning. In response, researchers have proposed advanced pipelines that leverage domain-specific knowledge to chain smaller prompts, provide intermediate feedback and improve performance through search. However, the current complexity of writing, tuning, maintaining and improving such pipelines has limited their sophistication. We propose oracular programming, a foundational paradigm for building LLM-enabled applications that lets domain experts express high-level problem-solving strategies as programs with unresolved choice points. These choice points are resolved at runtime by LLMs, which generalize from user-provided examples of correct and incorrect decisions. An oracular program is composed of three orthogonal components: a strategy that consists in a nondeterministic program with choice points that can be reified into a search tree, a policy that specifies how to navigate this tree with the help of LLM oracles, and a set of demonstrations that describe successful and unsuccessful search tree navigation scenarios across diverse problem instances. Each component is expressed in a dedicated programming language and can be independently improved or substituted. We address the key programming language design challenges of modularly composing oracular programs and enforcing consistency between their components as they evolve.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "20",
        "title": "Fine-Tuned LLMs are \"Time Capsules\" for Tracking Societal Bias Through Books",
        "author": [
            "Sangmitra Madhusudan",
            "Robert Morabito",
            "Skye Reid",
            "Nikta Gohari Sadr",
            "Ali Emami"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05331",
        "abstract": "Books, while often rich in cultural insights, can also mirror societal biases of their eras - biases that Large Language Models (LLMs) may learn and perpetuate during training. We introduce a novel method to trace and quantify these biases using fine-tuned LLMs. We develop BookPAGE, a corpus comprising 593 fictional books across seven decades (1950-2019), to track bias evolution. By fine-tuning LLMs on books from each decade and using targeted prompts, we examine shifts in biases related to gender, sexual orientation, race, and religion. Our findings indicate that LLMs trained on decade-specific books manifest biases reflective of their times, with both gradual trends and notable shifts. For example, model responses showed a progressive increase in the portrayal of women in leadership roles (from 8% to 22%) from the 1950s to 2010s, with a significant uptick in the 1990s (from 4% to 12%), possibly aligning with third-wave feminism. Same-sex relationship references increased markedly from the 1980s to 2000s (from 0% to 10%), mirroring growing LGBTQ+ visibility. Concerningly, negative portrayals of Islam rose sharply in the 2000s (26% to 38%), likely reflecting post-9/11 sentiments. Importantly, we demonstrate that these biases stem mainly from the books' content and not the models' architecture or initial training. Our study offers a new perspective on societal bias trends by bridging AI, literary studies, and social science research.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "21",
        "title": "Removing Neural Signal Artifacts with Autoencoder-Targeted Adversarial Transformers (AT-AT)",
        "author": [
            "Benjamin J. Choi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05332",
        "abstract": "Electromyogenic (EMG) noise is a major contamination source in EEG data that can impede accurate analysis of brain-specific neural activity. Recent literature on EMG artifact removal has moved beyond traditional linear algorithms in favor of machine learning-based systems. However, existing deep learning-based filtration methods often have large compute footprints and prohibitively long training times. In this study, we present a new machine learning-based system for filtering EMG interference from EEG data using an autoencoder-targeted adversarial transformer (AT-AT). By leveraging the lightweight expressivity of an autoencoder to determine optimal time-series transformer application sites, our AT-AT architecture achieves a >90% model size reduction compared to published artifact removal models. The addition of adversarial training ensures that filtered signals adhere to the fundamental characteristics of EEG data. We trained AT-AT using published neural data from 67 subjects and found that the system was able to achieve comparable test performance to larger models; AT-AT posted a mean reconstructive correlation coefficient above 0.95 at an initial signal-to-noise ratio (SNR) of 2 dB and 0.70 at -7 dB SNR. Further research generalizing these results to broader sample sizes beyond these isolated test cases will be crucial; while outside the scope of this study, we also include results from a real-world deployment of AT-AT in the Appendix.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "22",
        "title": "RAG-Verus: Repository-Level Program Verification with LLMs using Retrieval Augmented Generation",
        "author": [
            "Sicheng Zhong",
            "Jiading Zhu",
            "Yifang Tian",
            "Xujie Si"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05344",
        "abstract": "Scaling automated formal verification to real-world projects requires resolving cross-module dependencies and global contexts, which are challenges overlooked by existing function-centric methods. We introduce RagVerus, a framework that synergizes retrieval-augmented generation with context-aware prompting to automate proof synthesis for multi-module repositories, achieving a 27% relative improvement on our novel RepoVBench benchmark -- the first repository-level dataset for Verus with 383 proof completion tasks. RagVerus triples proof pass rates on existing benchmarks under constrained language model budgets, demonstrating a scalable and sample-efficient verification.",
        "tags": [
            "LLMs",
            "RAG"
        ]
    },
    {
        "id": "23",
        "title": "Probabilistic Subspace Manifolds for Contextual Inference in Large Language Models",
        "author": [
            "Christopher Nightingale",
            "Dominic Lavington",
            "Jonathan Thistlethwaite",
            "Sebastian Penhaligon",
            "Thomas Belinski",
            "David Boldo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05346",
        "abstract": "Representing token embeddings as probability distributions over learned manifolds allows for more flexible contextual inference, reducing representational rigidity while enhancing semantic granularity. Comparative evaluations demonstrate that probabilistic embeddings improve neighborhood consistency and decrease redundancy, ensuring that token relationships remain more structurally coherent across fine-tuning iterations. The integration of probabilistic subspaces within attention mechanisms facilitates more adaptive contextual weighting, enabling models to capture latent dependencies that would otherwise be obscured in conventional embeddings. Experimental results highlight increased robustness against adversarial modifications, with probabilistic embeddings preserving contextual integrity even under perturbation-based evaluation scenarios. Performance assessments indicate that probabilistic representations achieve greater adaptability in domain-specific applications, mitigating the need for extensive retraining when shifting across linguistic domains. Computational trade-offs remain within operationally feasible limits, with marginal increases in inference latency balanced against the benefits of enhanced representation stability and contextual expressiveness. The capacity to encode structured uncertainty provides advantages in generative modeling tasks, particularly where maintaining coherence across extended sequences requires a representation framework capable of handling ambiguous or context-dependent linguistic constructs.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "24",
        "title": "Otter: Generating Tests from Issues to Validate SWE Patches",
        "author": [
            "Toufique Ahmed",
            "Jatin Ganhotra",
            "Rangeet Pan",
            "Avraham Shinnar",
            "Saurabh Sinha",
            "Martin Hirzel"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05368",
        "abstract": "While there has been plenty of work on generating tests from existing code, there has been limited work on generating tests from issues. A correct test must validate the code patch that resolves the issue. In this work, we focus on the scenario where the code patch does not exist yet. This approach supports two major use-cases. First, it supports TDD (test-driven development), the discipline of \"test first, write code later\" that has well-documented benefits for human software engineers. Second, it also validates SWE (software engineering) agents, which generate code patches for resolving issues. This paper introduces Otter, an LLM-based solution for generating tests from issues. Otter augments LLMs with rule-based analysis to check and repair their outputs, and introduces a novel self-reflective action planning stage. Experiments show Otter outperforming state-of-the-art systems for generating tests from issues, in addition to enhancing systems that generate patches from issues. We hope that Otter helps make developers more productive at resolving issues and leads to more robust, well-tested code.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "25",
        "title": "Active Learning of Model Discrepancy with Bayesian Experimental Design",
        "author": [
            "Huchen Yang",
            "Chuanqi Chen",
            "Jin-Long Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05372",
        "abstract": "Digital twins have been actively explored in many engineering applications, such as manufacturing and autonomous systems. However, model discrepancy is ubiquitous in most digital twin models and has significant impacts on the performance of using those models. In recent years, data-driven modeling techniques have been demonstrated promising in characterizing the model discrepancy in existing models, while the training data for the learning of model discrepancy is often obtained in an empirical way and an active approach of gathering informative data can potentially benefit the learning of model discrepancy. On the other hand, Bayesian experimental design (BED) provides a systematic approach to gathering the most informative data, but its performance is often negatively impacted by the model discrepancy. In this work, we build on sequential BED and propose an efficient approach to iteratively learn the model discrepancy based on the data from the BED. The performance of the proposed method is validated by a classical numerical example governed by a convection-diffusion equation, for which full BED is still feasible. The proposed method is then further studied in the same numerical example with a high-dimensional model discrepancy, which serves as a demonstration for the scenarios where full BED is not practical anymore. An ensemble-based approximation of information gain is further utilized to assess the data informativeness and to enhance learning model discrepancy. The results show that the proposed method is efficient and robust to the active learning of high-dimensional model discrepancy, using data suggested by the sequential BED. We also demonstrate that the proposed method is compatible with both classical numerical solvers and modern auto-differentiable solvers.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "26",
        "title": "BCQ: Block Clustered Quantization for 4-bit (W4A4) LLM Inference",
        "author": [
            "Reena Elangovan",
            "Charbel Sakr",
            "Anand Raghunathan",
            "Brucek Khailany"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05376",
        "abstract": "Post-training quantization (PTQ) is a promising approach to reducing the storage and computational requirements of large language models (LLMs) without additional training cost. Recent PTQ studies have primarily focused on quantizing only weights to sub-8-bits while maintaining activations at 8-bits or higher. Accurate sub-8-bit quantization for both weights and activations without relying on quantization-aware training remains a significant challenge. We propose a novel quantization method called block clustered quantization (BCQ) wherein each operand tensor is decomposed into blocks (a block is a group of contiguous scalars), blocks are clustered based on their statistics, and a dedicated optimal quantization codebook is designed for each cluster. As a specific embodiment of this approach, we propose a PTQ algorithm called Locally-Optimal BCQ (LO-BCQ) that iterates between the steps of block clustering and codebook design to greedily minimize the quantization mean squared error. When weight and activation scalars are encoded to W4A4 format (with 0.5-bits of overhead for storing scaling factors and codebook selectors), we advance the current state-of-the-art by demonstrating <1% loss in inference accuracy across several LLMs and downstream tasks.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "27",
        "title": "Coarse-to-Fine Structure-Aware Artistic Style Transfer",
        "author": [
            "Kunxiao Liu",
            "Guowu Yuan",
            "Hao Wu",
            "Wenhua Qian"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05387",
        "abstract": "Artistic style transfer aims to use a style image and a content image to synthesize a target image that retains the same artistic expression as the style image while preserving the basic content of the content image. Many recently proposed style transfer methods have a common problem; that is, they simply transfer the texture and color of the style image to the global structure of the content image. As a result, the content image has a local structure that is not similar to the local structure of the style image. In this paper, we present an effective method that can be used to transfer style patterns while fusing the local style structure into the local content structure. In our method, dif-ferent levels of coarse stylized features are first reconstructed at low resolution using a Coarse Network, in which style color distribution is roughly transferred, and the content structure is combined with the style structure. Then, the reconstructed features and the content features are adopted to synthesize high-quality structure-aware stylized images with high resolution using a Fine Network with three structural selective fusion (SSF) modules. The effectiveness of our method is demonstrated through the generation of appealing high-quality stylization results and a com-parison with some state-of-the-art style transfer methods.",
        "tags": [
            "Style Transfer"
        ]
    },
    {
        "id": "28",
        "title": "Learning Task Representations from In-Context Learning",
        "author": [
            "Baturay Saglam",
            "Zhuoran Yang",
            "Dionysis Kalogerias",
            "Amin Karbasi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05390",
        "abstract": "Large language models (LLMs) have demonstrated remarkable proficiency in in-context learning (ICL), where models adapt to new tasks through example-based prompts without requiring parameter updates. However, understanding how tasks are internally encoded and generalized remains a challenge. To address some of the empirical and technical gaps in the literature, we introduce an automated formulation for encoding task information in ICL prompts as a function of attention heads within the transformer architecture. This approach computes a single task vector as a weighted sum of attention heads, with the weights optimized causally via gradient descent. Our findings show that existing methods fail to generalize effectively to modalities beyond text. In response, we also design a benchmark to evaluate whether a task vector can preserve task fidelity in functional regression tasks. The proposed method successfully extracts task-specific information from in-context demonstrations and excels in both text and regression tasks, demonstrating its generalizability across modalities. Moreover, ablation studies show that our method's effectiveness stems from aligning the distribution of the last hidden state with that of an optimally performing in-context-learned model.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "29",
        "title": "Beyond and Free from Diffusion: Invertible Guided Consistency Training",
        "author": [
            "Chia-Hong Hsu",
            "Shiu-hong Kao",
            "Randall Balestriero"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05391",
        "abstract": "Guidance in image generation steers models towards higher-quality or more targeted outputs, typically achieved in Diffusion Models (DMs) via Classifier-free Guidance (CFG). However, recent Consistency Models (CMs), which offer fewer function evaluations, rely on distilling CFG knowledge from pretrained DMs to achieve guidance, making them costly and inflexible. In this work, we propose invertible Guided Consistency Training (iGCT), a novel training framework for guided CMs that is entirely data-driven. iGCT, as a pioneering work, contributes to fast and guided image generation and editing without requiring the training and distillation of DMs, greatly reducing the overall compute requirements. iGCT addresses the saturation artifacts seen in CFG under high guidance scales. Our extensive experiments on CIFAR-10 and ImageNet64 show that iGCT significantly improves FID and precision compared to CFG. At a guidance of 13, iGCT improves precision to 0.8, while DM's drops to 0.47. Our work takes the first step toward enabling guidance and inversion for CMs without relying on DMs.",
        "tags": [
            "Consistency Models",
            "Diffusion"
        ]
    },
    {
        "id": "30",
        "title": "Hierarchical Lexical Manifold Projection in Large Language Models: A Novel Mechanism for Multi-Scale Semantic Representation",
        "author": [
            "Natasha Martus",
            "Sebastian Crowther",
            "Maxwell Dorrington",
            "Jonathan Applethwaite",
            "Edgar Tillinghurst",
            "Quentin Birkenshaw",
            "Lukas Petrov",
            "Constance Willoughby"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05395",
        "abstract": "The integration of structured hierarchical embeddings into transformer-based architectures introduces a refined approach to lexical representation, ensuring that multi-scale semantic relationships are preserved without compromising computational efficiency. A projection mechanism that maps tokens onto a structured manifold provides improved lexical alignment, enhancing the adaptability of word representations across diverse linguistic tasks. The structured encoding framework ensures that hierarchical embeddings maintain coherence across varying abstraction levels, allowing for stable transitions between localized syntactic features and global semantic structures. Experimental evaluations indicate that hierarchical embeddings consistently outperform conventional token representations, improving accuracy in linguistic benchmarks while maintaining lower computational overhead. Comparative analysis across multiple domains highlights the ability of hierarchical embeddings to retain contextual consistency, particularly in specialized language applications where structured lexical alignment is essential. Statistical assessments further demonstrate that hierarchical embeddings exhibit enhanced robustness under perturbation conditions, ensuring that linguistic structures remain stable across adversarial text modifications. The integration of hierarchical projections with transformer attention mechanisms enables improved contextual adaptation, ensuring that token representations are dynamically adjusted based on varying linguistic distributions. The refined hierarchical organization of embeddings provides greater interpretability in lexical modeling, facilitating enhanced generalization capabilities across diverse text processing tasks.",
        "tags": [
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "31",
        "title": "Dynamic Noise Preference Optimization for LLM Self-Improvement via Synthetic Data",
        "author": [
            "Haoyan Yang",
            "Ting Hua",
            "Shangqian Gao",
            "Binfeng Xu",
            "Zheng Tang",
            "Jie Xu",
            "Hongxia Jin",
            "Vijay Srinivasan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05400",
        "abstract": "Although LLMs have achieved significant success, their reliance on large volumes of human-annotated data has limited their potential for further scaling. In this situation, utilizing self-generated synthetic data has become crucial for fine-tuning LLMs without extensive human annotation. However, current methods often fail to ensure consistent improvements across iterations, with performance stagnating after only minimal updates. To overcome these challenges, we introduce Dynamic Noise Preference Optimization (DNPO). DNPO employs a dynamic sample labeling mechanism to construct preference pairs for training and introduces controlled, trainable noise into the preference optimization process. Our approach effectively prevents stagnation and enables continuous improvement. In experiments with Zephyr-7B, DNPO consistently outperforms existing methods, showing an average performance boost of 2.6% across multiple benchmarks. Additionally, DNPO shows a significant improvement in model-generated data quality, with a 29.4% win-loss rate gap compared to the baseline in GPT-4 evaluations. This highlights its effectiveness in enhancing model performance through iterative refinement.",
        "tags": [
            "GPT",
            "LLMs"
        ]
    },
    {
        "id": "32",
        "title": "The Complexity of Learning Sparse Superposed Features with Feedback",
        "author": [
            "Akash Kumar"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05407",
        "abstract": "The success of deep networks is crucially attributed to their ability to capture latent features within a representation space. In this work, we investigate whether the underlying learned features of a model can be efficiently retrieved through feedback from an agent, such as a large language model (LLM), in the form of relative \\textit{triplet comparisons}. These features may represent various constructs, including dictionaries in LLMs or components of a covariance matrix of Mahalanobis distances. We analyze the feedback complexity associated with learning a feature matrix in sparse settings. Our results establish tight bounds when the agent is permitted to construct activations and demonstrate strong upper bounds in sparse scenarios when the agent's feedback is limited to distributional information. We validate our theoretical findings through experiments on two distinct applications: feature recovery from Recursive Feature Machine-trained models and dictionary extraction from sparse autoencoders trained on Large Language Models.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "33",
        "title": "Vision-in-the-loop Simulation for Deep Monocular Pose Estimation of UAV in Ocean Environment",
        "author": [
            "Maneesha Wickramasuriya",
            "Beomyeol Yu",
            "Taeyoung Lee",
            "Murray Snyder"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05409",
        "abstract": "This paper proposes a vision-in-the-loop simulation environment for deep monocular pose estimation of a UAV operating in an ocean environment. Recently, a deep neural network with a transformer architecture has been successfully trained to estimate the pose of a UAV relative to the flight deck of a research vessel, overcoming several limitations of GPS-based approaches. However, validating the deep pose estimation scheme in an actual ocean environment poses significant challenges due to the limited availability of research vessels and the associated operational costs. To address these issues, we present a photo-realistic 3D virtual environment leveraging recent advancements in Gaussian splatting, a novel technique that represents 3D scenes by modeling image pixels as Gaussian distributions in 3D space, creating a lightweight and high-quality visual model from multiple viewpoints. This approach enables the creation of a virtual environment integrating multiple real-world images collected in situ. The resulting simulation enables the indoor testing of flight maneuvers while verifying all aspects of flight software, hardware, and the deep monocular pose estimation scheme. This approach provides a cost-effective solution for testing and validating the autonomous flight of shipboard UAVs, specifically focusing on vision-based control and estimation algorithms.",
        "tags": [
            "3D",
            "Gaussian Splatting",
            "Pose Estimation",
            "Transformer"
        ]
    },
    {
        "id": "34",
        "title": "XPUTimer: Anomaly Diagnostics for Divergent LLM Training in GPU Clusters of Thousand-Plus Scale",
        "author": [
            "Weihao Cui",
            "Ji Zhang",
            "Han Zhao",
            "Chao Liu",
            "Wenhao Zhang",
            "Jian Sha",
            "Quan Chen",
            "Bingsheng He",
            "Minyi Guo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05413",
        "abstract": "The rapid proliferation of large language models has driven the need for efficient GPU training clusters. However, ensuring high-performance training in these clusters is challenging due to the complexity of software-hardware interactions and the frequent occurrence of training anomalies. Since existing diagnostic tools are narrowly tailored to specific issues, there are gaps in their ability to address anomalies spanning the entire training stack. In response, we introduce XPUTimer, a real-time diagnostic framework designed for distributed LLM training at scale. XPUTimer first integrates a lightweight tracing daemon to monitor key code segments with minimal overhead. Additionally, it features a diagnostic engine that employs novel intra-kernel tracing and holistic aggregated metrics to efficiently identify and resolve anomalies. Deployment of XPUTimer across 6,000 GPUs over eight months demonstrated significant improvements across the training stack, validating its effectiveness in real-world scenarios.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "35",
        "title": "Show-o Turbo: Towards Accelerated Unified Multimodal Understanding and Generation",
        "author": [
            "Chenkai Xu",
            "Xu Wang",
            "Zhenyi Liao",
            "Yishun Li",
            "Tianqi Hou",
            "Zhijie Deng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05415",
        "abstract": "There has been increasing research interest in building unified multimodal understanding and generation models, among which Show-o stands as a notable representative, demonstrating great promise for both text-to-image and image-to-text generation. The inference of Show-o involves progressively denoising image tokens and autoregressively decoding text tokens, and hence, unfortunately, suffers from inefficiency issues from both sides. This paper introduces Show-o Turbo to bridge the gap. We first identify a unified denoising perspective for the generation of images and text in Show-o based on the parallel decoding of text tokens. We then propose to extend consistency distillation (CD), a qualified approach for shortening the denoising process of diffusion models, to the multimodal denoising trajectories of Show-o. We introduce a trajectory segmentation strategy and a curriculum learning procedure to improve the training convergence. Empirically, in text-to-image generation, Show-o Turbo displays a GenEval score of 0.625 at 4 sampling steps without using classifier-free guidance (CFG), outperforming that of the original Show-o with 8 steps and CFG; in image-to-text generation, Show-o Turbo exhibits a 1.5x speedup without significantly sacrificing performance. The code is available at https://github.com/zhijie-group/Show-o-Turbo.",
        "tags": [
            "Diffusion",
            "Segmentation",
            "Text-to-Image"
        ]
    },
    {
        "id": "36",
        "title": "SAMGPT: Text-free Graph Foundation Model for Multi-domain Pre-training and Cross-domain Adaptation",
        "author": [
            "Xingtong Yu",
            "Zechuan Gong",
            "Chang Zhou",
            "Yuan Fang",
            "Hui Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05424",
        "abstract": "Graphs are able to model interconnected entities in many online services, supporting a wide range of applications on the Web. This raises an important question: How can we train a graph foundational model on multiple source domains and adapt to an unseen target domain? A major obstacle is that graphs from different domains often exhibit divergent characteristics. Some studies leverage large language models to align multiple domains based on textual descriptions associated with the graphs, limiting their applicability to text-attributed graphs. For text-free graphs, a few recent works attempt to align different feature distributions across domains, while generally neglecting structural differences. In this work, we propose a novel Structure Alignment framework for text-free Multi-domain Graph Pre-Training and cross-domain adaptation (SAMGPT). It is designed to learn multi-domain knowledge from graphs originating in multiple source domains, which can then be adapted to address applications in an unseen target domain. Specifically, we introduce a set of structure tokens to harmonize structure-based aggregation across source domains during the pre-training phase. Next, for cross-domain adaptation, we design dual prompts, namely, holistic prompts and specific prompts, which adapt unified multi-domain structural knowledge and fine-grained, domain-specific information, respectively, to a target domain. Finally, we conduct comprehensive experiments on seven public datasets to evaluate and analyze the effectiveness of SAMGPT.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "37",
        "title": "MoFM: A Large-Scale Human Motion Foundation Model",
        "author": [
            "Mohammadreza Baharani",
            "Ghazal Alinezhad Noghre",
            "Armin Danesh Pazho",
            "Gabriel Maldonado",
            "Hamed Tabkhi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05432",
        "abstract": "AFoundation Models (FM) have increasingly drawn the attention of researchers due to their scalability and generalization across diverse tasks. Inspired by the success of FMs and the principles that have driven advancements in Large Language Models (LLMs), we introduce MoFM as a novel Motion Foundation Model. MoFM is designed for the semantic understanding of complex human motions in both time and space. To facilitate large-scale training, MotionBook, a comprehensive human motion dictionary of discretized motions is designed and employed. MotionBook utilizes Thermal Cubes to capture spatio-temporal motion heatmaps, applying principles from discrete variational models to encode human movements into discrete units for a more efficient and scalable representation. MoFM, trained on a large corpus of motion data, provides a foundational backbone adaptable to diverse downstream tasks, supporting paradigms such as one-shot, unsupervised, and supervised tasks. This versatility makes MoFM well-suited for a wide range of motion-based applications.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "38",
        "title": "AdaFlow: Efficient Long Video Editing via Adaptive Attention Slimming And Keyframe Selection",
        "author": [
            "Shuheng Zhang",
            "Yuqi Liu",
            "Hongbo Zhou",
            "Jun Peng",
            "Yiyi Zhou",
            "Xiaoshuai Sun",
            "Rongrong Ji"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05433",
        "abstract": "Despite great progress, text-driven long video editing is still notoriously challenging mainly due to excessive memory overhead. Although recent efforts have simplified this task into a two-step process of keyframe translation and interpolation generation, the token-wise keyframe translation still plagues the upper limit of video length. In this paper, we propose a novel and training-free approach towards efficient and effective long video editing, termed AdaFlow. We first reveal that not all tokens of video frames hold equal importance for keyframe translation, based on which we propose an Adaptive Attention Slimming scheme for AdaFlow to squeeze the $KV$ sequence, thus increasing the number of keyframes for translations by an order of magnitude. In addition, an Adaptive Keyframe Selection scheme is also equipped to select the representative frames for joint editing, further improving generation quality. With these innovative designs, AdaFlow achieves high-quality long video editing of minutes in one inference, i.e., more than 1$k$ frames on one A800 GPU, which is about ten times longer than the compared methods, e.g., TokenFlow. To validate AdaFlow, we also build a new benchmark for long video editing with high-quality annotations, termed LongV-EVAL. Our code is released at: https://github.com/jidantang55/AdaFlow.",
        "tags": [
            "Video Editing"
        ]
    },
    {
        "id": "39",
        "title": "Agentic AI Systems Applied to tasks in Financial Services: Modeling and model risk management crews",
        "author": [
            "Izunna Okpala",
            "Ashkan Golgoon",
            "Arjun Ravi Kannan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05439",
        "abstract": "The advent of large language models has ushered in a new era of agentic systems, where artificial intelligence programs exhibit remarkable autonomous decision-making capabilities across diverse domains. This paper explores agentic system workflows in the financial services industry. In particular, we build agentic crews that can effectively collaborate to perform complex modeling and model risk management (MRM) tasks. The modeling crew consists of a manager and multiple agents who perform specific tasks such as exploratory data analysis, feature engineering, model selection, hyperparameter tuning, model training, model evaluation, and writing documentation. The MRM crew consists of a manager along with specialized agents who perform tasks such as checking compliance of modeling documentation, model replication, conceptual soundness, analysis of outcomes, and writing documentation. We demonstrate the effectiveness and robustness of modeling and MRM crews by presenting a series of numerical examples applied to credit card fraud detection, credit card approval, and portfolio credit risk modeling datasets.",
        "tags": [
            "Detection",
            "Large Language Models"
        ]
    },
    {
        "id": "40",
        "title": "The Odyssey of the Fittest: Can Agents Survive and Still Be Good?",
        "author": [
            "Dylan Waldner",
            "Risto Miikkulainen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05442",
        "abstract": "As AI models grow in power and generality, understanding how agents learn and make decisions in complex environments is critical to promoting ethical behavior. This paper examines the ethical implications of implementing biological drives, specifically, self preservation, into three different agents. A Bayesian agent optimized with NEAT, a Bayesian agent optimized with stochastic variational inference, and a GPT 4o agent play a simulated, LLM generated text based adventure game. The agents select actions at each scenario to survive, adapting to increasingly challenging scenarios. Post simulation analysis evaluates the ethical scores of the agent's decisions, uncovering the tradeoffs they navigate to survive. Specifically, analysis finds that when danger increases, agents ignore ethical considerations and opt for unethical behavior. The agents' collective behavior, trading ethics for survival, suggests that prioritizing survival increases the risk of unethical behavior. In the context of AGI, designing agents to prioritize survival may amplify the likelihood of unethical decision making and unintended emergent behaviors, raising fundamental questions about goal design in AI safety research.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "41",
        "title": "Stochastic Forward-Backward Deconvolution: Training Diffusion Models with Finite Noisy Datasets",
        "author": [
            "Haoye Lu",
            "Qifan Wu",
            "Yaoliang Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05446",
        "abstract": "Recent diffusion-based generative models achieve remarkable results by training on massive datasets, yet this practice raises concerns about memorization and copyright infringement. A proposed remedy is to train exclusively on noisy data with potential copyright issues, ensuring the model never observes original content. However, through the lens of deconvolution theory, we show that although it is theoretically feasible to learn the data distribution from noisy samples, the practical challenge of collecting sufficient samples makes successful learning nearly unattainable. To overcome this limitation, we propose to pretrain the model with a small fraction of clean data to guide the deconvolution process. Combined with our Stochastic Forward--Backward Deconvolution (SFBD) method, we attain an FID of $6.31$ on CIFAR-10 with just $4\\%$ clean images (and $3.58$ with $10\\%$). Theoretically, we prove that SFBD guides the model to learn the true data distribution. The result also highlights the importance of pretraining on limited but clean data or the alternative from similar datasets. Empirical studies further support these findings and offer additional insights.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "42",
        "title": "Iterative Deepening Sampling for Large Language Models",
        "author": [
            "Weizhe Chen",
            "Sven Koenig",
            "Bistra Dilkina"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05449",
        "abstract": "The recent release of OpenAI's o1 models and other similar frameworks showcasing test-time scaling laws has demonstrated their exceptional capability to tackle complex reasoning tasks. Inspired by this, subsequent research has revealed that such test-time scaling laws hinge on the model's ability to search both within a single response (intra-response) and across multiple responses (inter-response) during training. Crucially, beyond selecting a single optimal response, the model must also develop robust self-correction capabilities within its own outputs. However, training models to achieve effective self-evaluation and self-correction remains a significant challenge, heavily dependent on the quality of self-reflection data. In this paper, we address this challenge by focusing on enhancing the quality of self-reflection data generation for complex problem-solving, which can subsequently improve the training of next-generation large language models (LLMs). Specifically, we explore how manually triggering a model's self-correction mechanisms can improve performance on challenging reasoning tasks. To this end, we propose a novel iterative deepening sampling algorithm framework designed to enhance self-correction and generate higher-quality samples. Through extensive experiments on Math500 and AIME benchmarks, we demonstrate that our method achieves a higher success rate on difficult tasks and provide detailed ablation studies to analyze its effectiveness across diverse settings.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "43",
        "title": "LLM-Powered Decentralized Generative Agents with Adaptive Hierarchical Knowledge Graph for Cooperative Planning",
        "author": [
            "Hanqing Yang",
            "Jingdi Chen",
            "Marie Siew",
            "Tania Lorido-Botran",
            "Carlee Joe-Wong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05453",
        "abstract": "Developing intelligent agents for long-term cooperation in dynamic open-world scenarios is a major challenge in multi-agent systems. Traditional Multi-agent Reinforcement Learning (MARL) frameworks like centralized training decentralized execution (CTDE) struggle with scalability and flexibility. They require centralized long-term planning, which is difficult without custom reward functions, and face challenges in processing multi-modal data. CTDE approaches also assume fixed cooperation strategies, making them impractical in dynamic environments where agents need to adapt and plan independently. To address decentralized multi-agent cooperation, we propose Decentralized Adaptive Knowledge Graph Memory and Structured Communication System (DAMCS) in a novel Multi-agent Crafter environment. Our generative agents, powered by Large Language Models (LLMs), are more scalable than traditional MARL agents by leveraging external knowledge and language for long-term planning and reasoning. Instead of fully sharing information from all past experiences, DAMCS introduces a multi-modal memory system organized as a hierarchical knowledge graph and a structured communication protocol to optimize agent cooperation. This allows agents to reason from past interactions and share relevant information efficiently. Experiments on novel multi-agent open-world tasks show that DAMCS outperforms both MARL and LLM baselines in task efficiency and collaboration. Compared to single-agent scenarios, the two-agent scenario achieves the same goal with 63% fewer steps, and the six-agent scenario with 74% fewer steps, highlighting the importance of adaptive memory and structured communication in achieving long-term goals. We publicly release our project at: https://happyeureka.github.io/damcs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "44",
        "title": "IllusionCAPTCHA: A CAPTCHA based on Visual Illusion",
        "author": [
            "Ziqi Ding",
            "Gelei Deng",
            "Yi Liu",
            "Junchen Ding",
            "Jieshan Chen",
            "Yulei Sui",
            "Yuekang Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05461",
        "abstract": "CAPTCHAs have long been essential tools for protecting applications from automated bots. Initially designed as simple questions to distinguish humans from bots, they have become increasingly complex to keep pace with the proliferation of CAPTCHA-cracking techniques employed by malicious actors. However, with the advent of advanced large language models (LLMs), the effectiveness of existing CAPTCHAs is now being undermined.\nTo address this issue, we have conducted an empirical study to evaluate the performance of multimodal LLMs in solving CAPTCHAs and to assess how many attempts human users typically need to pass them. Our findings reveal that while LLMs can solve most CAPTCHAs, they struggle with those requiring complex reasoning type of CAPTCHA that also presents significant challenges for human users. Interestingly, our user study shows that the majority of human participants require a second attempt to pass these reasoning CAPTCHAs, a finding not reported in previous research.\nBased on empirical findings, we present IllusionCAPTCHA, a novel security mechanism employing the \"Human-Easy but AI-Hard\" paradigm. This new CAPTCHA employs visual illusions to create tasks that are intuitive for humans but highly confusing for AI models. Furthermore, we developed a structured, step-by-step method that generates misleading options, which particularly guide LLMs towards making incorrect choices and reduce their chances of successfully solving CAPTCHAs. Our evaluation shows that IllusionCAPTCHA can effectively deceive LLMs 100% of the time. Moreover, our structured design significantly increases the likelihood of AI errors when attempting to solve these challenges. Results from our user study indicate that 86.95% of participants successfully passed the CAPTCHA on their first attempt, outperforming other CAPTCHA systems.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "45",
        "title": "Position: LLMs Can be Good Tutors in Foreign Language Education",
        "author": [
            "Jingheng Ye",
            "Shen Wang",
            "Deqing Zou",
            "Yibo Yan",
            "Kun Wang",
            "Hai-Tao Zheng",
            "Zenglin Xu",
            "Irwin King",
            "Philip S. Yu",
            "Qingsong Wen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05467",
        "abstract": "While recent efforts have begun integrating large language models (LLMs) into foreign language education (FLE), they often rely on traditional approaches to learning tasks without fully embracing educational methodologies, thus lacking adaptability to language learning. To address this gap, we argue that LLMs have the potential to serve as effective tutors in FLE. Specifically, LLMs can play three critical roles: (1) as data enhancers, improving the creation of learning materials or serving as student simulations; (2) as task predictors, serving as learner assessment or optimizing learning pathway; and (3) as agents, enabling personalized and inclusive education. We encourage interdisciplinary research to explore these roles, fostering innovation while addressing challenges and risks, ultimately advancing FLE through the thoughtful integration of LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "46",
        "title": "Enhancing Expressive Voice Conversion with Discrete Pitch-Conditioned Flow Matching Model",
        "author": [
            "Jialong Zuo",
            "Shengpeng Ji",
            "Minghui Fang",
            "Ziyue Jiang",
            "Xize Cheng",
            "Qian Yang",
            "Wenrui Liu",
            "Guangyan Zhang",
            "Zehai Tu",
            "Yiwen Guo",
            "Zhou Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05471",
        "abstract": "This paper introduces PFlow-VC, a conditional flow matching voice conversion model that leverages fine-grained discrete pitch tokens and target speaker prompt information for expressive voice conversion (VC). Previous VC works primarily focus on speaker conversion, with further exploration needed in enhancing expressiveness (such as prosody and emotion) for timbre conversion. Unlike previous methods, we adopt a simple and efficient approach to enhance the style expressiveness of voice conversion models. Specifically, we pretrain a self-supervised pitch VQVAE model to discretize speaker-irrelevant pitch information and leverage a masked pitch-conditioned flow matching model for Mel-spectrogram synthesis, which provides in-context pitch modeling capabilities for the speaker conversion model, effectively improving the voice style transfer capacity. Additionally, we improve timbre similarity by combining global timbre embeddings with time-varying timbre tokens. Experiments on unseen LibriTTS test-clean and emotional speech dataset ESD show the superiority of the PFlow-VC model in both timbre conversion and style transfer. Audio samples are available on the demo page https://speechai-demo.github.io/PFlow-VC/.",
        "tags": [
            "Flow Matching",
            "Style Transfer"
        ]
    },
    {
        "id": "47",
        "title": "Mechanistic Interpretability of Emotion Inference in Large Language Models",
        "author": [
            "Ala N. Tak",
            "Amin Banayeeanzade",
            "Anahita Bolourani",
            "Mina Kian",
            "Robin Jia",
            "Jonathan Gratch"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05489",
        "abstract": "Large language models (LLMs) show promising capabilities in predicting human emotions from text. However, the mechanisms through which these models process emotional stimuli remain largely unexplored. Our study addresses this gap by investigating how autoregressive LLMs infer emotions, showing that emotion representations are functionally localized to specific regions in the model. Our evaluation includes diverse model families and sizes and is supported by robustness checks. We then show that the identified representations are psychologically plausible by drawing on cognitive appraisal theory, a well-established psychological framework positing that emotions emerge from evaluations (appraisals) of environmental stimuli. By causally intervening on construed appraisal concepts, we steer the generation and show that the outputs align with theoretical and intuitive expectations. This work highlights a novel way to causally intervene and precisely shape emotional text generation, potentially benefiting safety and alignment in sensitive affective domains.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "48",
        "title": "DeepThink: Aligning Language Models with Domain-Specific User Intents",
        "author": [
            "Yang Li",
            "Mingxuan Luo",
            "Yeyun Gong",
            "Chen Lin",
            "Jian Jiao",
            "Yi Liu",
            "Kaili Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05497",
        "abstract": "Supervised fine-tuning with synthesized instructions has been a common practice for adapting LLMs to domain-specific QA tasks. However, the synthesized instructions deviate from real user questions and expected answers. This study proposes a novel framework called DeepThink to generate high-quality instructions. DeepThink first generates a few seed questions to mimic actual user questions, simulates conversations to uncover the hidden user needs, and refines the answer by conversational contexts and the retrieved documents for more comprehensive answers. Experiments demonstrate that DeepThink achieves an average performance improvement of 7.92% compared to a GPT-4-turbo+RAG-based assistant on the real user test set in the advertising domain across dimensions such as relevance, completeness, clarity, accuracy, and actionability.",
        "tags": [
            "GPT",
            "LLMs",
            "RAG"
        ]
    },
    {
        "id": "49",
        "title": "Riemannian Manifold Learning for Stackelberg Games with Neural Flow Representations",
        "author": [
            "Larkin Liu",
            "Kashif Rasul",
            "Yutong Chao",
            "Jalal Etesami"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05498",
        "abstract": "We present a novel framework for online learning in Stackelberg general-sum games, where two agents, the leader and follower, engage in sequential turn-based interactions. At the core of this approach is a learned diffeomorphism that maps the joint action space to a smooth Riemannian manifold, referred to as the Stackelberg manifold. This mapping, facilitated by neural normalizing flows, ensures the formation of tractable isoplanar subspaces, enabling efficient techniques for online learning. By assuming linearity between the agents' reward functions on the Stackelberg manifold, our construct allows the application of standard bandit algorithms. We then provide a rigorous theoretical basis for regret minimization on convex manifolds and establish finite-time bounds on simple regret for learning Stackelberg equilibria. This integration of manifold learning into game theory uncovers a previously unrecognized potential for neural normalizing flows as an effective tool for multi-agent learning. We present empirical results demonstrating the effectiveness of our approach compared to standard baselines, with applications spanning domains such as cybersecurity and economic supply chain optimization.",
        "tags": [
            "Normalizing Flows"
        ]
    },
    {
        "id": "50",
        "title": "A Physical Coherence Benchmark for Evaluating Video Generation Models via Optical Flow-guided Frame Prediction",
        "author": [
            "Yongfan Chen",
            "Xiuwen Zhu",
            "Tianyu Li",
            "Hao Chen",
            "Chunhua Shen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05503",
        "abstract": "Recent advances in video generation models demonstrate their potential as world simulators, but they often struggle with videos deviating from physical laws, a key concern overlooked by most text-to-video benchmarks. We introduce a benchmark designed specifically to assess the Physical Coherence of generated videos, PhyCoBench. Our benchmark includes 120 prompts covering 7 categories of physical principles, capturing key physical laws observable in video content. We evaluated four state-of-the-art (SoTA) T2V models on PhyCoBench and conducted manual assessments. Additionally, we propose an automated evaluation model: PhyCoPredictor, a diffusion model that generates optical flow and video frames in a cascade manner. Through a consistency evaluation comparing automated and manual sorting, the experimental results show that PhyCoPredictor currently aligns most closely with human evaluation. Therefore, it can effectively evaluate the physical coherence of videos, providing insights for future model optimization. Our benchmark, which includes physical coherence prompts, automatic evaluation tool PhyCoPredictor, and generated video dataset, will all be released on GitHub shortly.",
        "tags": [
            "Diffusion",
            "Text-to-Video",
            "Video Generation"
        ]
    },
    {
        "id": "51",
        "title": "IndexTTS: An Industrial-Level Controllable and Efficient Zero-Shot Text-To-Speech System",
        "author": [
            "Wei Deng",
            "Siyi Zhou",
            "Jingchen Shu",
            "Jinchao Wang",
            "Lu Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05512",
        "abstract": "Recently, large language model (LLM) based text-to-speech (TTS) systems have gradually become the mainstream in the industry due to their high naturalness and powerful zero-shot voice cloning http://capabilities.Here, we introduce the IndexTTS system, which is mainly based on the XTTS and Tortoise model. We add some novel improvements. Specifically, in Chinese scenarios, we adopt a hybrid modeling method that combines characters and pinyin, making the pronunciations of polyphonic characters and long-tail characters controllable. We also performed a comparative analysis of the Vector Quantization (VQ) with Finite-Scalar Quantization (FSQ) for codebook utilization of acoustic speech tokens. To further enhance the effect and stability of voice cloning, we introduce a conformer-based speech conditional encoder and replace the speechcode decoder with BigVGAN2. Compared with XTTS, it has achieved significant improvements in naturalness, content consistency, and zero-shot voice cloning. As for the popular TTS systems in the open-source, such as Fish-Speech, CosyVoice2, FireRedTTS and F5-TTS, IndexTTS has a relatively simple training process, more controllable usage, and faster inference speed. Moreover, its performance surpasses that of these systems. Our demos are available at https://index-tts.github.io.",
        "tags": [
            "Vector Quantization"
        ]
    },
    {
        "id": "52",
        "title": "Fg-T2M++: LLMs-Augmented Fine-Grained Text Driven Human Motion Generation",
        "author": [
            "Yin Wang",
            "Mu Li",
            "Jiapeng Liu",
            "Zhiying Leng",
            "Frederick W. B. Li",
            "Ziyao Zhang",
            "Xiaohui Liang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05534",
        "abstract": "We address the challenging problem of fine-grained text-driven human motion generation. Existing works generate imprecise motions that fail to accurately capture relationships specified in text due to: (1) lack of effective text parsing for detailed semantic cues regarding body parts, (2) not fully modeling linguistic structures between words to comprehend text comprehensively. To tackle these limitations, we propose a novel fine-grained framework Fg-T2M++ that consists of: (1) an LLMs semantic parsing module to extract body part descriptions and semantics from text, (2) a hyperbolic text representation module to encode relational information between text units by embedding the syntactic dependency graph into hyperbolic space, and (3) a multi-modal fusion module to hierarchically fuse text and motion features. Extensive experiments on HumanML3D and KIT-ML datasets demonstrate that Fg-T2M++ outperforms SOTA methods, validating its ability to accurately generate motions adhering to comprehensive text semantics.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "53",
        "title": "SSH: Sparse Spectrum Adaptation via Discrete Hartley Transformation",
        "author": [
            "Yixian Shen",
            "Qi Bi",
            "Jia-Hong Huang",
            "Hongyi Zhu",
            "Andy D. Pimentel",
            "Anuj Pathania"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05539",
        "abstract": "Low-rank adaptation (LoRA) has been demonstrated effective in reducing the trainable parameter number when fine-tuning a large foundation model (LLM). However, it still encounters computational and memory challenges when scaling to larger models or addressing more complex task adaptation.\nIn this work, we introduce Sparse Spectrum Adaptation via Discrete Hartley Transformation (SSH), a novel approach that significantly reduces the number of trainable parameters while enhancing model performance. It selects the most informative spectral components across all layers, under the guidance of the initial weights after a discrete Hartley transformation (DHT). The lightweight inverse DHT then projects the spectrum back into the spatial domain for updates.\nExtensive experiments across both single-modality tasks such as language understanding and generation and multi-modality tasks such as video-text understanding demonstrate that SSH outperforms existing parameter-efficient fine-tuning (PEFT) methods while achieving substantial reductions in computational cost and memory requirements.",
        "tags": [
            "LoRA",
            "Low-Rank Adaptation"
        ]
    },
    {
        "id": "54",
        "title": "FRAMES: Boosting LLMs with A Four-Quadrant Multi-Stage Pretraining Strategy",
        "author": [
            "Xuemiao Zhang",
            "Feiyu Duan",
            "Liangyu Xu",
            "Yongwei Zhou",
            "Sirui Wang",
            "Rongxiang Weng",
            "Jingang Wang",
            "Xunliang Cai"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05551",
        "abstract": "Large language models (LLMs) have significantly advanced human language understanding and generation, with pretraining data quality and organization being crucial to their performance. Multi-stage pretraining is a promising approach, but existing methods often lack quantitative criteria for data partitioning and instead rely on intuitive heuristics. In this paper, we propose the novel Four-quadRAnt Multi-stage prEtraining Strategy (FRAMES), guided by the established principle of organizing the pretraining process into four stages to achieve significant loss reductions four times. This principle is grounded in two key findings: first, training on high Perplexity (PPL) data followed by low PPL data, and second, training on low PPL difference (PD) data followed by high PD data, both causing the loss to drop significantly twice and performance enhancements. By partitioning data into four quadrants and strategically organizing them, FRAMES achieves a remarkable 16.8% average improvement over random sampling across MMLU and CMMLU, effectively boosting LLM performance.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "55",
        "title": "Latent Structure Modulation in Large Language Models Through Stochastic Concept Embedding Transitions",
        "author": [
            "Stefan Whitaker",
            "Colin Sisate",
            "Marcel Windsor",
            "Nikolai Fairweather",
            "Tarquin Goldborough",
            "Oskar Lindenfeld"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05553",
        "abstract": "Stochastic embedding transitions introduce a probabilistic mechanism for adjusting token representations dynamically during inference, mitigating the constraints imposed through static or deterministic embeddings. A transition framework was proposed in which each token embedding evolved through probabilistic updates, ensuring adaptability while preserving semantic integrity across linguistic contexts. Empirical evaluations demonstrated that models incorporating stochastic transitions exhibited greater lexical diversity, improved generative coherence, and enhanced retention of low-frequency vocabulary, contributing to more varied sentence structures and reduced reliance on high-probability token selections. Statistical analyses of embedding drift across transformer layers indicated that representations evolved more flexibly without losing coherence, supporting the hypothesis that controlled stochasticity facilitated context-sensitive representation learning. Experimental results revealed that probabilistic embeddings introduced minor computational overhead while maintaining generative efficiency, reinforcing their feasibility in large-scale applications. A comparative study with traditional embedding approaches highlighted measurable gains in text completion accuracy, dialogue coherence, and structural complexity, confirming the effectiveness of stochastic transitions in enhancing representation expressiveness. Clustering patterns in the embedding space suggested that probabilistic updates preserved meaningful semantic groupings while enabling context-driven shifts, further validating the stability of the transition mechanism. Performance metrics indicated that stochastic transitions balanced adaptability and control, ensuring that generative outputs remained linguistically coherent without excessive randomness.",
        "tags": [
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "56",
        "title": "Knowledge is Power: Harnessing Large Language Models for Enhanced Cognitive Diagnosis",
        "author": [
            "Zhiang Dong",
            "Jingyuan Chen",
            "Fei Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05556",
        "abstract": "Cognitive Diagnosis Models (CDMs) are designed to assess students' cognitive states by analyzing their performance across a series of exercises. However, existing CDMs often struggle with diagnosing infrequent students and exercises due to a lack of rich prior knowledge. With the advancement in large language models (LLMs), which possess extensive domain knowledge, their integration into cognitive diagnosis presents a promising opportunity. Despite this potential, integrating LLMs with CDMs poses significant challenges. LLMs are not well-suited for capturing the fine-grained collaborative interactions between students and exercises, and the disparity between the semantic space of LLMs and the behavioral space of CDMs hinders effective integration. To address these issues, we propose a novel Knowledge-enhanced Cognitive Diagnosis (KCD) framework, which is a model-agnostic framework utilizing LLMs to enhance CDMs and compatible with various CDM architectures. The KCD framework operates in two stages: LLM Diagnosis and Cognitive Level Alignment. In the LLM Diagnosis stage, both students and exercises are diagnosed to achieve comprehensive and detailed modeling. In the Cognitive Level Alignment stage, we bridge the gap between the CDMs' behavioral space and the LLMs' semantic space using contrastive learning and mask-reconstruction approaches. Experiments on several real-world datasets demonstrate the effectiveness of our proposed framework.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "57",
        "title": "MMHMER:Multi-viewer and Multi-task for Handwritten Mathematical Expression Recognition",
        "author": [
            "Kehua Chen",
            "Haoyang Shen",
            "Lifan Zhong",
            "Mingyi Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05557",
        "abstract": "Handwritten Mathematical Expression Recognition (HMER) methods have made remarkable progress, with most existing HMER approaches based on either a hybrid CNN/RNN-based with GRU architecture or Transformer architectures. Each of these has its strengths and weaknesses. Leveraging different model structures as viewers and effectively integrating their diverse capabilities presents an intriguing avenue for exploration. This involves addressing two key challenges: 1) How to fuse these two methods effectively, and 2) How to achieve higher performance under an appropriate level of complexity. This paper proposes an efficient CNN-Transformer multi-viewer, multi-task approach to enhance the model's recognition performance. Our MMHMER model achieves 63.96%, 62.51%, and 65.46% ExpRate on CROHME14, CROHME16, and CROHME19, outperforming Posformer with an absolute gain of 1.28%, 1.48%, and 0.58%. The main contribution of our approach is that we propose a new multi-view, multi-task framework that can effectively integrate the strengths of CNN and Transformer. By leveraging the feature extraction capabilities of CNN and the sequence modeling capabilities of Transformer, our model can better handle the complexity of handwritten mathematical expressions.",
        "tags": [
            "RNN",
            "Transformer"
        ]
    },
    {
        "id": "58",
        "title": "Can Large Language Models Be Query Optimizer for Relational Databases?",
        "author": [
            "Jie Tan",
            "Kangfei Zhao",
            "Rui Li",
            "Jeffrey Xu Yu",
            "Chengzhi Piao",
            "Hong Cheng",
            "Helen Meng",
            "Deli Zhao",
            "Yu Rong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05562",
        "abstract": "Query optimization, which finds the optimized execution plan for a given query, is a complex planning and decision-making problem within the exponentially growing plan space in database management systems (DBMS). Traditional optimizers heavily rely on a certain cost model constructed by various heuristics and empirical tuning, probably leading to generating suboptimal plans. Recent developments of Large Language Models (LLMs) have demonstrated their potential in solving complex planning and decision-making problems, such as arithmetic and programmatic tasks. In this paper, we try to explore the potential of LLMs in handling query optimization and propose a tentative LLM-based query optimizer dubbed LLM-QO, established on PostgreSQL's execution engine. In LLM-QO, we formulate query optimization in an autoregressive fashion which directly generates the execution plan without explicit plan enumeration. To investigate the essential input of LLM-QO, we design a customized data recipe named QInstruct to collect the training data from various optimizers and serialize the database's meta data, queries and corresponding plans into a textual format. Based on QInstruct, we implement a two-stage fine-tuning pipeline, Query Instruction Tuning (QIT) and Query Direct Preference Optimization (QDPO), to empower the capability of general-purpose LLMs in handling query optimization. In our experiments, LLM-QO can generate valid and high-quality plans and consistently outperforms both traditional and learned optimizers on three query workloads. Our findings verify that LLMs can be derived as query optimizers where generalization, efficiency and adaptivity deserve further research efforts.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "59",
        "title": "ATLAS: Autoformalizing Theorems through Lifting, Augmentation, and Synthesis of Data",
        "author": [
            "Xiaoyang Liu",
            "Kangjie Bao",
            "Jiashuo Zhang",
            "Yunqi Liu",
            "Yu Chen",
            "Yuntian Liu",
            "Yang Jiao",
            "Tao Luo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05567",
        "abstract": "Autoformalization, the process of automatically translating natural language mathematics into machine-verifiable formal language, has demonstrated advancements with the progress of large language models (LLMs). However, a key obstacle to further advancements is the scarcity of paired datasets that align natural language with formal language. To address this challenge, we introduce ATLAS (Autoformalizing Theorems through Lifting, Augmentation, and Synthesis of Data), an iterative data generation framework designed to produce large-scale, high-quality parallel theorem statements. With the proposed ATLAS running for 10 iterations, we construct an undergraduate-level dataset comprising 300k theorem statements and develop the ATLAS translator, achieving accuracies of 80.59% (pass@8) and 92.99% (pass@128) on ProofNet, significantly outperforming the base model (23.99% and 47.17%) and InternLM2-Math-Plus-7B (50.94% and 80.32%). Furthermore, the ATLAS translator also achieves state-of-the-art performance on both the high-school-level miniF2F dataset and the graduate-level MathQual dataset introduced in this work. The datasets, model, and code will be released to the public soon.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "60",
        "title": "Low-Rank Agent-Specific Adaptation (LoRASA) for Multi-Agent Policy Learning",
        "author": [
            "Beining Zhang",
            "Aditya Kapoor",
            "Mingfei Sun"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05573",
        "abstract": "Multi-agent reinforcement learning (MARL) often relies on \\emph{parameter sharing (PS)} to scale efficiently. However, purely shared policies can stifle each agent's unique specialization, reducing overall performance in heterogeneous environments. We propose \\textbf{Low-Rank Agent-Specific Adaptation (LoRASA)}, a novel approach that treats each agent's policy as a specialized ``task'' fine-tuned from a shared backbone. Drawing inspiration from parameter-efficient transfer methods, LoRASA appends small, low-rank adaptation matrices to each layer of the shared policy, naturally inducing \\emph{parameter-space sparsity} that promotes both specialization and scalability. We evaluate LoRASA on challenging benchmarks including the StarCraft Multi-Agent Challenge (SMAC) and Multi-Agent MuJoCo (MAMuJoCo), implementing it atop widely used algorithms such as MAPPO and A2PO. Across diverse tasks, LoRASA matches or outperforms existing baselines \\emph{while reducing memory and computational overhead}. Ablation studies on adapter rank, placement, and timing validate the method's flexibility and efficiency. Our results suggest LoRASA's potential to establish a new norm for MARL policy parameterization: combining a shared foundation for coordination with low-rank agent-specific refinements for individual specialization.",
        "tags": [
            "Low-Rank Adaptation"
        ]
    },
    {
        "id": "61",
        "title": "Event Stream-based Visual Object Tracking: HDETrack V2 and A High-Definition Benchmark",
        "author": [
            "Shiao Wang",
            "Xiao Wang",
            "Chao Wang",
            "Liye Jin",
            "Lin Zhu",
            "Bo Jiang",
            "Yonghong Tian",
            "Jin Tang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05574",
        "abstract": "We then introduce a novel hierarchical knowledge distillation strategy that incorporates the similarity matrix, feature representation, and response map-based distillation to guide the learning of the student Transformer network. We also enhance the model's ability to capture temporal dependencies by applying the temporal Fourier transform to establish temporal relationships between video frames. We adapt the network model to specific target objects during testing via a newly proposed test-time tuning strategy to achieve high performance and flexibility in target tracking. Recognizing the limitations of existing event-based tracking datasets, which are predominantly low-resolution, we propose EventVOT, the first large-scale high-resolution event-based tracking dataset. It comprises 1141 videos spanning diverse categories such as pedestrians, vehicles, UAVs, ping pong, etc. Extensive experiments on both low-resolution (FE240hz, VisEvent, FELT), and our newly proposed high-resolution EventVOT dataset fully validated the effectiveness of our proposed method. Both the benchmark dataset and source code have been released on https://github.com/Event-AHU/EventVOT_Benchmark",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "62",
        "title": "UbiMoE: A Ubiquitous Mixture-of-Experts Vision Transformer Accelerator With Hybrid Computation Pattern on FPGA",
        "author": [
            "Jiale Dong",
            "Wenqi Lou",
            "Zhendong Zheng",
            "Yunji Qin",
            "Lei Gong",
            "Chao Wang",
            "Xuehai Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05602",
        "abstract": "Compared to traditional Vision Transformers (ViT), Mixture-of-Experts Vision Transformers (MoE-ViT) are introduced to scale model size without a proportional increase in computational complexity, making them a new research focus. Given the high performance and reconfigurability, FPGA-based accelerators for MoE-ViT emerge, delivering substantial gains over general-purpose processors. However, existing accelerators often fall short of fully exploring the design space, leading to suboptimal trade-offs between resource utilization and performance. To overcome this problem, we introduce UbiMoE, a novel end-to-end FPGA accelerator tailored for MoE-ViT. Leveraging the unique computational and memory access patterns of MoE-ViTs, we develop a latency-optimized streaming attention kernel and a resource-efficient reusable linear kernel, effectively balancing performance and resource consumption. To further enhance design efficiency, we propose a two-stage heuristic search algorithm that optimally tunes hardware parameters for various FPGA resource constraints. Compared to state-of-the-art (SOTA) FPGA designs, UbiMoE achieves 1.34x and 3.35x throughput improvements for MoE-ViT on Xilinx ZCU102 and Alveo U280 platforms, respectively, while enhancing energy efficiency by 1.75x and 1.54x. Our implementation is available at https://github.com/DJ000011/UbiMoE.",
        "tags": [
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "63",
        "title": "ARIES: Stimulating Self-Refinement of Large Language Models by Iterative Preference Optimization",
        "author": [
            "Yongcheng Zeng",
            "Xinyu Cui",
            "Xuanfa Jin",
            "Guoqing Liu",
            "Zexu Sun",
            "Quan He",
            "Dong Li",
            "Ning Yang",
            "Jianye Hao",
            "Haifeng Zhang",
            "Jun Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05605",
        "abstract": "A truly intelligent Large Language Model (LLM) should be capable of correcting errors in its responses through external interactions. However, even the most advanced models often face challenges in improving their outputs. In this paper, we explore how to cultivate LLMs with the self-refinement capability through iterative preference training, and how this ability can be leveraged to improve model performance during inference. To this end, we introduce a novel post-training and inference framework, called ARIES: Adaptive Refinement and Iterative Enhancement Structure. This method iteratively performs preference training and self-refinement-based data collection. During training, ARIES strengthen the model's direct question-answering capability while simultaneously unlocking its self-refinement potential. During inference, ARIES harnesses this self-refinement capability to generate a series of progressively refined responses, which are then filtered using either the Reward Model Scoring or a simple yet effective Rule-Based Selection mechanism, specifically tailored to our approach, to construct a dataset for the next round of preference training. Experimental results demonstrate the remarkable performance of ARIES. When applied to the Llama-3.1-8B model and under the self-refinement setting, ARIES surpasses powerful models such as GPT-4o, achieving 62.3% length-controlled (LC) and a 63.3% raw win rates on AlpacaEval 2, outperforming Iterative DPO by 27.8% and 35.5% respectively, as well as a 50.3% win rate on Arena-Hard, surpassing Iterative DPO by 26.6%. Furthermore, ARIES consistently enhances performance on mathematical reasoning tasks like GSM8K and MATH.",
        "tags": [
            "GPT",
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "64",
        "title": "FreeBlend: Advancing Concept Blending with Staged Feedback-Driven Interpolation Diffusion",
        "author": [
            "Yufan Zhou",
            "Haoyu Shen",
            "Huan Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05606",
        "abstract": "Concept blending is a promising yet underexplored area in generative models. While recent approaches, such as embedding mixing and latent modification based on structural sketches, have been proposed, they often suffer from incompatible semantic information and discrepancies in shape and appearance. In this work, we introduce FreeBlend, an effective, training-free framework designed to address these challenges. To mitigate cross-modal loss and enhance feature detail, we leverage transferred image embeddings as conditional inputs. The framework employs a stepwise increasing interpolation strategy between latents, progressively adjusting the blending ratio to seamlessly integrate auxiliary features. Additionally, we introduce a feedback-driven mechanism that updates the auxiliary latents in reverse order, facilitating global blending and preventing rigid or unnatural outputs. Extensive experiments demonstrate that our method significantly improves both the semantic coherence and visual quality of blended images, yielding compelling and coherent results.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "65",
        "title": "Lossless Acceleration of Large Language Models with Hierarchical Drafting based on Temporal Locality in Speculative Decoding",
        "author": [
            "Sukmin Cho",
            "Sangjin Choi",
            "Taeho Hwang",
            "Jeongyeon Seo",
            "Soyeong Jeong",
            "Huije Lee",
            "Hoyun Song",
            "Jong C. Park",
            "Youngjin Kwon"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05609",
        "abstract": "Accelerating inference in Large Language Models (LLMs) is critical for real-time interactions, as they have been widely incorporated into real-world services. Speculative decoding, a fully algorithmic solution, has gained attention for improving inference speed by drafting and verifying tokens, thereby generating multiple tokens in a single forward pass. However, current drafting strategies usually require significant fine-tuning or have inconsistent performance across tasks. To address these challenges, we propose Hierarchy Drafting (HD), a novel lossless drafting approach that organizes various token sources into multiple databases in a hierarchical framework based on temporal locality. In the drafting step, HD sequentially accesses multiple databases to obtain draft tokens from the highest to the lowest locality, ensuring consistent acceleration across diverse tasks and minimizing drafting latency. Our experiments on Spec-Bench using LLMs with 7B and 13B parameters demonstrate that HD outperforms existing database drafting methods, achieving robust inference speedups across model sizes, tasks, and temperatures.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "66",
        "title": "Towards Sustainable NLP: Insights from Benchmarking Inference Energy in Large Language Models",
        "author": [
            "Soham Poddar",
            "Paramita Koley",
            "Janardan Misra",
            "Niloy Ganguly",
            "Saptarshi Ghosh"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05610",
        "abstract": "Large language models (LLMs) are increasingly recognized for their exceptional generative capabilities and versatility across various tasks. However, the high inference costs associated with these models have not received adequate attention, particularly when compared to the focus on training costs in existing research. In response to this gap, our study conducts a comprehensive benchmarking of LLM inference energy across a wide range of NLP tasks, where we analyze the impact of different models, tasks, prompts, and system-related factors on inference energy. Specifically, our experiments reveal several interesting insights, including strong correlation of inference energy with output token length and response time. Also, we find that quantization and optimal batch sizes, along with targeted prompt phrases, can significantly reduce energy usage. This study is the first to thoroughly benchmark LLM inference across such a diverse range of aspects, providing insights and offering several recommendations for improving energy efficiency in model deployment.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "67",
        "title": "XiHeFusion: Harnessing Large Language Models for Science Communication in Nuclear Fusion",
        "author": [
            "Xiao Wang",
            "Qingquan Yang",
            "Fuling Wang",
            "Qiang Chen",
            "Wentao Wu",
            "Yu Jin",
            "Jingtao Jiang",
            "Liye Jin",
            "Bo Jiang",
            "Dengdi Sun",
            "Wanli Lv",
            "Meiwen Chen",
            "Zehua Chen",
            "Guosheng Xu",
            "Jin Tang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05615",
        "abstract": "Nuclear fusion is one of the most promising ways for humans to obtain infinite energy. Currently, with the rapid development of artificial intelligence, the mission of nuclear fusion has also entered a critical period of its development. How to let more people to understand nuclear fusion and join in its research is one of the effective means to accelerate the implementation of fusion. This paper proposes the first large model in the field of nuclear fusion, XiHeFusion, which is obtained through supervised fine-tuning based on the open-source large model Qwen2.5-14B. We have collected multi-source knowledge about nuclear fusion tasks to support the training of this model, including the common crawl, eBooks, arXiv, dissertation, etc. After the model has mastered the knowledge of the nuclear fusion field, we further used the chain of thought to enhance its logical reasoning ability, making XiHeFusion able to provide more accurate and logical answers. In addition, we propose a test questionnaire containing 180+ questions to assess the conversational ability of this science popularization large model. Extensive experimental results show that our nuclear fusion dialogue model, XiHeFusion, can perform well in answering science popularization knowledge. The pre-trained XiHeFusion model is released on https://github.com/Event-AHU/XiHeFusion.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "68",
        "title": "Training-Free Constrained Generation With Stable Diffusion Models",
        "author": [
            "Stefano Zampini",
            "Jacob Christopher",
            "Luca Oneto",
            "Davide Anguita",
            "Ferdinando Fioretto"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05625",
        "abstract": "Stable diffusion models represent the state-of-the-art in data synthesis across diverse domains and hold transformative potential for applications in science and engineering, e.g., by facilitating the discovery of novel solutions and simulating systems that are computationally intractable to model explicitly. However, their current utility in these fields is severely limited by an inability to enforce strict adherence to physical laws and domain-specific constraints. Without this grounding, the deployment of such models in critical applications, ranging from material science to safety-critical systems, remains impractical. This paper addresses this fundamental limitation by proposing a novel approach to integrate stable diffusion models with constrained optimization frameworks, enabling them to generate outputs that satisfy stringent physical and functional requirements. We demonstrate the effectiveness of this approach through material science experiments requiring adherence to precise morphometric properties, inverse design problems involving the generation of stress-strain responses using video generation with a simulator in the loop, and safety settings where outputs must avoid copyright infringement.",
        "tags": [
            "Diffusion",
            "Video Generation"
        ]
    },
    {
        "id": "69",
        "title": "AnyEdit: Edit Any Knowledge Encoded in Language Models",
        "author": [
            "Houcheng Jiang",
            "Junfeng Fang",
            "Ningyu Zhang",
            "Guojun Ma",
            "Mingyang Wan",
            "Xiang Wang",
            "Xiangnan He",
            "Tat-seng Chua"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05628",
        "abstract": "Large language models (LLMs) often produce incorrect or outdated information, necessitating efficient and precise knowledge updates. Current model editing methods, however, struggle with long-form knowledge in diverse formats, such as poetry, code snippets, and mathematical derivations. These limitations arise from their reliance on editing a single token's hidden state, a limitation we term \"efficacy barrier\". To solve this, we propose AnyEdit, a new autoregressive editing paradigm. It decomposes long-form knowledge into sequential chunks and iteratively edits the key token in each chunk, ensuring consistent and accurate outputs. Theoretically, we ground AnyEdit in the Chain Rule of Mutual Information, showing its ability to update any knowledge within LLMs. Empirically, it outperforms strong baselines by 21.5% on benchmarks including UnKEBench, AKEW, and our new EditEverything dataset for long-form diverse-formatted knowledge. Additionally, AnyEdit serves as a plug-and-play framework, enabling current editing methods to update knowledge with arbitrary length and format, significantly advancing the scope and practicality of LLM knowledge editing.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "70",
        "title": "TrackDiffuser: Nearly Model-Free Bayesian Filtering with Diffusion Model",
        "author": [
            "Yangguang He",
            "Wenhao Li",
            "Minzhe Li",
            "Juan Zhang",
            "Xiangfeng Wang",
            "Bo Jin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05629",
        "abstract": "State estimation remains a fundamental challenge across numerous domains, from autonomous driving, aircraft tracking to quantum system control. Although Bayesian filtering has been the cornerstone solution, its classical model-based paradigm faces two major limitations: it struggles with inaccurate state space model (SSM) and requires extensive prior knowledge of noise characteristics. We present TrackDiffuser, a generative framework addressing both challenges by reformulating Bayesian filtering as a conditional diffusion model. Our approach implicitly learns system dynamics from data to mitigate the effects of inaccurate SSM, while simultaneously circumventing the need for explicit measurement models and noise priors by establishing a direct relationship between measurements and states. Through an implicit predict-and-update mechanism, TrackDiffuser preserves the interpretability advantage of traditional model-based filtering methods. Extensive experiments demonstrate that our framework substantially outperforms both classical and contemporary hybrid methods, especially in challenging non-linear scenarios involving non-Gaussian noises. Notably, TrackDiffuser exhibits remarkable robustness to SSM inaccuracies, offering a practical solution for real-world state estimation problems where perfect models and prior knowledge are unavailable.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "71",
        "title": "ELMTEX: Fine-Tuning Large Language Models for Structured Clinical Information Extraction. A Case Study on Clinical Reports",
        "author": [
            "Aynur Guluzade",
            "Naguib Heiba",
            "Zeyd Boukhers",
            "Florim Hamiti",
            "Jahid Hasan Polash",
            "Yehya Mohamad",
            "Carlos A Velasco"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05638",
        "abstract": "Europe's healthcare systems require enhanced interoperability and digitalization, driving a demand for innovative solutions to process legacy clinical data. This paper presents the results of our project, which aims to leverage Large Language Models (LLMs) to extract structured information from unstructured clinical reports, focusing on patient history, diagnoses, treatments, and other predefined categories. We developed a workflow with a user interface and evaluated LLMs of varying sizes through prompting strategies and fine-tuning. Our results show that fine-tuned smaller models match or surpass larger counterparts in performance, offering efficiency for resource-limited settings. A new dataset of 60,000 annotated English clinical summaries and 24,000 German translations was validated with automated and manual checks. The evaluations used ROUGE, BERTScore, and entity-level metrics. The work highlights the approach's viability and outlines future improvements.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "72",
        "title": "Incongruence Identification in Eyewitness Testimony",
        "author": [
            "Akshara Nair",
            "Zeba Afroz",
            "Md Shad Akhtar"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05650",
        "abstract": "Incongruence detection in eyewitness narratives is critical for understanding the reliability of testimonies, yet traditional approaches often fail to address the nuanced inconsistencies inherent in such accounts. In this paper, we introduce a novel task of incongruence detection in eyewitness testimonies. Given a pair of testimonies containing of multiple pairs of question and answer by two subjects, we identify contextually related incongruence between the two subjects. We also mark the span of incongruences in the utterances. To achieve this, we developed MIND(MultI-EyewitNess Deception) - a comprehensive dataset consisting of 2927 pairs of contextually related answers designed to capture both explicit and implicit contradictions. INstruction - TunEd iNcongruity Detection framework based on 6W and multi-hop reasoning approach, aka. INTEND. Drawing from investigative techniques, INTEND address the task as a close-style problem, contradicting on the who, what, when, where and why aspect of the content. Our findings shows that prompt tuning, especially when utilizing our framework, enhances the detection of incongruences by a margin of +5.63 percent. We compare our approach with multiple fine-tuning and prompt tuning techniques on MLMs and LLMs. Emperical results demonstrate convincing performance improvement in F1-score over fine-tuned and regular prompt-tuning techniques, highlighting the effectiveness of our approach.",
        "tags": [
            "Detection",
            "LLMs"
        ]
    },
    {
        "id": "73",
        "title": "Flowing Through Layers: A Continuous Dynamical Systems Perspective on Transformers",
        "author": [
            "Jacob Fein-Ashley"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05656",
        "abstract": "We show that the standard discrete update rule of transformer layers can be naturally interpreted as a forward Euler discretization of a continuous dynamical system. Our Transformer Flow Approximation Theorem demonstrates that, under standard Lipschitz continuity assumptions, token representations converge uniformly to the unique solution of an ODE as the number of layers grows. Moreover, if the underlying mapping satisfies a one-sided Lipschitz condition with a negative constant, the resulting dynamics are contractive, causing perturbations to decay exponentially across layers. Beyond clarifying the empirical stability and expressivity of transformer models, these insights link transformer updates to a broader iterative reasoning framework, suggesting new avenues for accelerated convergence and architectural innovations inspired by dynamical systems theory.",
        "tags": [
            "ODE",
            "Transformer"
        ]
    },
    {
        "id": "74",
        "title": "Towards AI-driven Sign Language Generation with Non-manual Markers",
        "author": [
            "Han Zhang",
            "Rotem Shalev-Arkushin",
            "Vasileios Baltatzis",
            "Connor Gillis",
            "Gierad Laput",
            "Raja Kushalnagar",
            "Lorna Quandt",
            "Leah Findlater",
            "Abdelkareem Bedri",
            "Colin Lea"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05661",
        "abstract": "Sign languages are essential for the Deaf and Hard-of-Hearing (DHH) community. Sign language generation systems have the potential to support communication by translating from written languages, such as English, into signed videos. However, current systems often fail to meet user needs due to poor translation of grammatical structures, the absence of facial cues and body language, and insufficient visual and motion fidelity. We address these challenges by building on recent advances in LLMs and video generation models to translate English sentences into natural-looking AI ASL signers. The text component of our model extracts information for manual and non-manual components of ASL, which are used to synthesize skeletal pose sequences and corresponding video frames. Our findings from a user study with 30 DHH participants and thorough technical evaluations demonstrate significant progress and identify critical areas necessary to meet user needs.",
        "tags": [
            "LLMs",
            "Video Generation"
        ]
    },
    {
        "id": "75",
        "title": "CODESIM: Multi-Agent Code Generation and Problem Solving through Simulation-Driven Planning and Debugging",
        "author": [
            "Md. Ashraful Islam",
            "Mohammed Eunus Ali",
            "Md Rizwan Parvez"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05664",
        "abstract": "Large Language Models (LLMs) have made significant strides in code generation and problem solving. Current approaches employ external tool-based iterative debuggers that use compiler or other tool-based runtime feedback to refine coarse programs generated by various methods. However, the effectiveness of these approaches heavily relies on the quality of the initial code generation, which remains an open challenge. In this paper, we introduce CodeSim, a novel multi-agent code generation framework that comprehensively addresses the stages of program synthesis-planning, coding, and debugging-through a human-like perception approach. As human verifies their understanding of any algorithms through visual simulation, CodeSim uniquely features a method of plan verification and internal debugging through the step-by-step simulation of input/output. Extensive experiments across seven challenging competitive problem-solving and program synthesis benchmarks demonstrate CodeSim's remarkable code generation capabilities. Our framework achieves new state-of-the-art (pass@1) results-(HumanEval 95.1%, MBPP 90.7%, APPS 22%, and CodeContests 29.1%). Furthermore, our method shows potential for even greater enhancement when cascaded with external debuggers. To facilitate further research and development in this area, we have open-sourced our framework in this link (https://kagnlp.github.io/codesim.github.io/).",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "76",
        "title": "Language Models Largely Exhibit Human-like Constituent Ordering Preferences",
        "author": [
            "Ada Defne Tur",
            "Gaurav Kamath",
            "Siva Reddy"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05670",
        "abstract": "Though English sentences are typically inflexible vis-Ã -vis word order, constituents often show far more variability in ordering. One prominent theory presents the notion that constituent ordering is directly correlated with constituent weight: a measure of the constituent's length or complexity. Such theories are interesting in the context of natural language processing (NLP), because while recent advances in NLP have led to significant gains in the performance of large language models (LLMs), much remains unclear about how these models process language, and how this compares to human language processing. In particular, the question remains whether LLMs display the same patterns with constituent movement, and may provide insights into existing theories on when and how the shift occurs in human language. We compare a variety of LLMs with diverse properties to evaluate broad LLM performance on four types of constituent movement: heavy NP shift, particle movement, dative alternation, and multiple PPs. Despite performing unexpectedly around particle movement, LLMs generally align with human preferences around constituent ordering.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "77",
        "title": "Investigating the Shortcomings of LLMs in Step-by-Step Legal Reasoning",
        "author": [
            "Venkatesh Mishra",
            "Bimsara Pathiraja",
            "Mihir Parmar",
            "Sat Chidananda",
            "Jayanth Srinivasa",
            "Gaowen Liu",
            "Ali Payani",
            "Chitta Baral"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05675",
        "abstract": "Reasoning abilities of LLMs have been a key focus in recent years. One challenging reasoning domain with interesting nuances is legal reasoning, which requires careful application of rules, and precedents while balancing deductive and analogical reasoning, and conflicts between rules. Although there have been a few works on using LLMs for legal reasoning, their focus has been on overall accuracy. In this paper, we dig deeper to do a step-by-step analysis and figure out where they commit errors. We use the college-level Multiple Choice Question-Answering (MCQA) task from the \\textit{Civil Procedure} dataset and propose a new error taxonomy derived from initial manual analysis of reasoning chains with respect to several LLMs, including two objective measures: soundness and correctness scores. We then develop an LLM-based automated evaluation framework to identify reasoning errors and evaluate the performance of LLMs. The computation of soundness and correctness on the dataset using the auto-evaluator framework reveals several interesting insights. Furthermore, we show that incorporating the error taxonomy as feedback in popular prompting techniques marginally increases LLM performance. Our work will also serve as an evaluation framework that can be used in detailed error analysis of reasoning chains for logic-intensive complex tasks.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "78",
        "title": "Zero-Shot End-to-End Relation Extraction in Chinese: A Comparative Study of Gemini, LLaMA and ChatGPT",
        "author": [
            "Shaoshuai Du",
            "Yiyi Tao",
            "Yixian Shen",
            "Hang Zhang",
            "Yanxin Shen",
            "Xinyu Qiu",
            "Chuanqi Shi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05694",
        "abstract": "This study investigates the performance of various large language models (LLMs) on zero-shot end-to-end relation extraction (RE) in Chinese, a task that integrates entity recognition and relation extraction without requiring annotated data. While LLMs show promise for RE, most prior work focuses on English or assumes pre-annotated entities, leaving their effectiveness in Chinese RE largely unexplored. To bridge this gap, we evaluate ChatGPT, Gemini, and LLaMA based on accuracy, efficiency, and adaptability. ChatGPT demonstrates the highest overall performance, balancing precision and recall, while Gemini achieves the fastest inference speed, making it suitable for real-time applications. LLaMA underperforms in both accuracy and latency, highlighting the need for further adaptation. Our findings provide insights into the strengths and limitations of LLMs for zero-shot Chinese RE, shedding light on trade-offs between accuracy and efficiency. This study serves as a foundation for future research aimed at improving LLM adaptability to complex linguistic tasks in Chinese NLP.",
        "tags": [
            "ChatGPT",
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "79",
        "title": "Semantic-Aware Adaptive Video Streaming Using Latent Diffusion Models for Wireless Networks",
        "author": [
            "Zijiang Yan",
            "Jianhua Pei",
            "Hongda Wu",
            "Hina Tabassum",
            "Ping Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05695",
        "abstract": "This paper proposes a novel framework for real-time adaptive-bitrate video streaming by integrating latent diffusion models (LDMs) within the FFmpeg techniques. This solution addresses the challenges of high bandwidth usage, storage inefficiencies, and quality of experience (QoE) degradation associated with traditional constant bitrate streaming (CBS) and adaptive bitrate streaming (ABS). The proposed approach leverages LDMs to compress I-frames into a latent space, offering significant storage and semantic transmission savings without sacrificing high visual quality. While it keeps B-frames and P-frames as adjustment metadata to ensure efficient video reconstruction at the user side, the proposed framework is complemented with the most state-of-the-art denoising and video frame interpolation (VFI) techniques. These techniques mitigate semantic ambiguity and restore temporal coherence between frames, even in noisy wireless communication environments. Experimental results demonstrate the proposed method achieves high-quality video streaming with optimized bandwidth usage, outperforming state-of-the-art solutions in terms of QoE and resource efficiency. This work opens new possibilities for scalable real-time video streaming in 5G and future post-5G networks.",
        "tags": [
            "Diffusion",
            "LDMs"
        ]
    },
    {
        "id": "80",
        "title": "Context information can be more important than reasoning for time series forecasting with a large language model",
        "author": [
            "Janghoon Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05699",
        "abstract": "With the evolution of large language models (LLMs), there is growing interest in leveraging LLMs for time series tasks. In this paper, we explore the characteristics of LLMs for time series forecasting by considering various existing and proposed prompting techniques. Forecasting for both short and long time series was evaluated. Our findings indicate that no single prompting method is universally applicable. It was also observed that simply providing proper context information related to the time series, without additional reasoning prompts, can achieve performance comparable to the best-performing prompt for each case. From this observation, it is expected that providing proper context information can be more crucial than a prompt for specific reasoning in time series forecasting. Several weaknesses in prompting for time series forecasting were also identified. First, LLMs often fail to follow the procedures described by the prompt. Second, when reasoning steps involve simple algebraic calculations with several operands, LLMs often fail to calculate accurately. Third, LLMs sometimes misunderstand the semantics of prompts, resulting in incomplete responses.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "81",
        "title": "TOKON: TOKenization-Optimized Normalization for time series analysis with a large language model",
        "author": [
            "Janghoon Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05701",
        "abstract": "While large language models have rapidly evolved towards general artificial intelligence, their versatility in analyzing time series data remains limited. To address this limitation, we propose a novel normalization technique that considers the inherent nature of tokenization. The proposed Tokenization-Optimized Normalization (TOKON) simplifies time series data by representing each element with a single token, effectively reducing the number of tokens by 2 to 3 times. Additionally, we introduce a novel prompt for time series forecasting, termed Time Series Forecasting with Care (TFSC), to further enhance forecasting performance. Experimental results demonstrate that TOKON improves root mean square error (RMSE) for multi-step forecasting by approximately 7% to 18%, depending on the dataset and prompting method. Furthermore, TFSC, when used in conjunction with TOKON, shows additional improvements in forecasting accuracy for certain datasets",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "82",
        "title": "GWRF: A Generalizable Wireless Radiance Field for Wireless Signal Propagation Modeling",
        "author": [
            "Kang Yang",
            "Yuning Chen",
            "Wan Du"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05708",
        "abstract": "We present Generalizable Wireless Radiance Fields (GWRF), a framework for modeling wireless signal propagation at arbitrary 3D transmitter and receiver positions. Unlike previous methods that adapt vanilla Neural Radiance Fields (NeRF) from the optical to the wireless signal domain, requiring extensive per-scene training, GWRF generalizes effectively across scenes. First, a geometry-aware Transformer encoder-based wireless scene representation module incorporates information from geographically proximate transmitters to learn a generalizable wireless radiance field. Second, a neural-driven ray tracing algorithm operates on this field to automatically compute signal reception at the receiver. Experimental results demonstrate that GWRF outperforms existing methods on single scenes and achieves state-of-the-art performance on unseen scenes.",
        "tags": [
            "3D",
            "NeRF",
            "Transformer"
        ]
    },
    {
        "id": "83",
        "title": "Flow-based Conformal Prediction for Multi-dimensional Time Series",
        "author": [
            "Junghwan Lee",
            "Chen Xu",
            "Yao Xie"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05709",
        "abstract": "Conformal prediction for time series presents two key challenges: (1) leveraging sequential correlations in features and non-conformity scores and (2) handling multi-dimensional outcomes. We propose a novel conformal prediction method to address these two key challenges by integrating Transformer and Normalizing Flow. Specifically, the Transformer encodes the historical context of time series, and normalizing flow learns the transformation from the base distribution to the distribution of non-conformity scores conditioned on the encoded historical context. This enables the construction of prediction regions by transforming samples from the base distribution using the learned conditional flow. We ensure the marginal coverage by defining the prediction regions as sets in the transformed space that correspond to a predefined probability mass in the base distribution. The model is trained end-to-end by Flow Matching, avoiding the need for computationally intensive numerical solutions of ordinary differential equations. We demonstrate that our proposed method achieves smaller prediction regions compared to the baselines while satisfying the desired coverage through comprehensive experiments using simulated and real-world time series datasets.",
        "tags": [
            "Flow Matching",
            "Transformer"
        ]
    },
    {
        "id": "84",
        "title": "SSDD-GAN: Single-Step Denoising Diffusion GAN for Cochlear Implant Surgical Scene Completion",
        "author": [
            "Yike Zhang",
            "Eduardo Davalos",
            "Jack Noble"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05710",
        "abstract": "Recent deep learning-based image completion methods, including both inpainting and outpainting, have demonstrated promising results in restoring corrupted images by effectively filling various missing regions. Among these, Generative Adversarial Networks (GANs) and Denoising Diffusion Probabilistic Models (DDPMs) have been employed as key generative image completion approaches, excelling in the field of generating high-quality restorations with reduced artifacts and improved fine details. In previous work, we developed a method aimed at synthesizing views from novel microscope positions for mastoidectomy surgeries; however, that approach did not have the ability to restore the surrounding surgical scene environment. In this paper, we propose an efficient method to complete the surgical scene of the synthetic postmastoidectomy dataset. Our approach leverages self-supervised learning on real surgical datasets to train a Single-Step Denoising Diffusion-GAN (SSDD-GAN), combining the advantages of diffusion models with the adversarial optimization of GANs for improved Structural Similarity results of 6%. The trained model is then directly applied to the synthetic postmastoidectomy dataset using a zero-shot approach, enabling the generation of realistic and complete surgical scenes without the need for explicit ground-truth labels from the synthetic postmastoidectomy dataset. This method addresses key limitations in previous work, offering a novel pathway for full surgical microscopy scene completion and enhancing the usability of the synthetic postmastoidectomy dataset in surgical preoperative planning and intraoperative navigation.",
        "tags": [
            "Diffusion",
            "GAN",
            "Inpainting"
        ]
    },
    {
        "id": "85",
        "title": "Visual Text Mining with Progressive Taxonomy Construction for Environmental Studies",
        "author": [
            "Sam Yu-Te Lee",
            "Cheng-Wei Hung",
            "Mei-Hua Yuan",
            "Kwan-Liu Ma"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05731",
        "abstract": "Environmental experts have developed the DPSIR (Driver, Pressure, State, Impact, Response) framework to systematically study and communicate key relationships between society and the environment. Using this framework requires experts to construct a DPSIR taxonomy from a corpus, annotate the documents, and identify DPSIR variables and relationships, which is laborious and inflexible. Automating it with conventional text mining faces technical challenges, primarily because the taxonomy often begins with abstract definitions, which experts progressively refine and contextualize as they annotate the corpus. In response, we develop GreenMine, a system that supports interactive text mining with prompt engineering. The system implements a prompting pipeline consisting of three simple and evaluable subtasks. In each subtask, the DPSIR taxonomy can be defined in natural language and iteratively refined as experts analyze the corpus. To support users evaluate the taxonomy, we introduce an uncertainty score based on response consistency. Then, we design a radial uncertainty chart that visualizes uncertainties and corpus topics, which supports interleaved evaluation and exploration. Using the system, experts can progressively construct the DPSIR taxonomy and annotate the corpus with LLMs. Using real-world interview transcripts, we present a case study to demonstrate the capability of the system in supporting interactive mining of DPSIR relationships, and an expert review in the form of collaborative discussion to understand the potential and limitations of the system. We discuss the lessons learned from developing the system and future opportunities for supporting interactive text mining in knowledge-intensive tasks for other application scenarios.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "86",
        "title": "Mitigating Sensitive Information Leakage in LLMs4Code through Machine Unlearning",
        "author": [
            "Ruotong Geng",
            "Mingyang Geng",
            "Shangwen Wang",
            "Haotian Wang",
            "Zhipeng Lin",
            "Dezun Dong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05739",
        "abstract": "Large Language Models for Code (LLMs4Code) excel at code generation tasks, yielding promise to release developers from huge software development burdens. Nonetheless, these models have been shown to suffer from the significant privacy risks due to the potential leakage of sensitive information embedded during training, known as the memorization problem. Addressing this issue is crucial for ensuring privacy compliance and upholding user trust, but till now there is a dearth of dedicated studies in the literature that focus on this specific direction. Recently, machine unlearning has emerged as a promising solution by enabling models to \"forget\" sensitive information without full retraining, offering an efficient and scalable approach compared to traditional data cleaning methods. In this paper, we empirically evaluate the effectiveness of unlearning techniques for addressing privacy concerns in http://LLMs4Code.Specifically, we investigate three state-of-the-art unlearning algorithms and three well-known open-sourced LLMs4Code, on a benchmark that takes into consideration both the privacy data to be forgotten as well as the code generation capabilites of these models. Results show that it is feasible to mitigate the privacy concerns of LLMs4Code through machine unlearning while maintain their code generation capabilities at the same time. We also dissect the forms of privacy protection/leakage after unlearning and observe that there is a shift from direct leakage to indirect leakage, which underscores the need for future studies addressing this risk.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "87",
        "title": "Linear Attention Modeling for Learned Image Compression",
        "author": [
            "Donghui Feng",
            "Zhengxue Cheng",
            "Shen Wang",
            "Ronghua Wu",
            "Hongwei Hu",
            "Guo Lu",
            "Li Song"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05741",
        "abstract": "Recent years, learned image compression has made tremendous progress to achieve impressive coding efficiency. Its coding gain mainly comes from non-linear neural network-based transform and learnable entropy modeling. However, most of recent focuses have been solely on a strong backbone, and few studies consider the low-complexity design. In this paper, we propose LALIC, a linear attention modeling for learned image compression. Specially, we propose to use Bi-RWKV blocks, by utilizing the Spatial Mix and Channel Mix modules to achieve more compact features extraction, and apply the Conv based Omni-Shift module to adapt to two-dimensional latent representation. Furthermore, we propose a RWKV-based Spatial-Channel ConTeXt model (RWKV-SCCTX), that leverages the Bi-RWKV to modeling the correlation between neighboring features effectively, to further improve the RD performance. To our knowledge, our work is the first work to utilize efficient Bi-RWKV models with linear attention for learned image compression. Experimental results demonstrate that our method achieves competitive RD performances by outperforming VTM-9.1 by -14.84%, -15.20%, -17.32% in BD-rate on Kodak, Tecnick and CLIC Professional validation datasets.",
        "tags": [
            "RWKV"
        ]
    },
    {
        "id": "88",
        "title": "Understanding Representation Dynamics of Diffusion Models via Low-Dimensional Modeling",
        "author": [
            "Xiao Li",
            "Zekai Zhang",
            "Xiang Li",
            "Siyi Chen",
            "Zhihui Zhu",
            "Peng Wang",
            "Qing Qu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05743",
        "abstract": "This work addresses the critical question of why and when diffusion models, despite being designed for generative tasks, can excel at learning high-quality representations in a self-supervised manner. To address this, we develop a mathematical framework based on a low-dimensional data model and posterior estimation, revealing a fundamental trade-off between generation and representation quality near the final stage of image generation. Our analysis explains the unimodal representation dynamics across noise scales, mainly driven by the interplay between data denoising and class specification. Building on these insights, we propose an ensemble method that aggregates features across noise levels, significantly improving both clean performance and robustness under label noise. Extensive experiments on both synthetic and real-world datasets validate our findings.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "89",
        "title": "UniDB: A Unified Diffusion Bridge Framework via Stochastic Optimal Control",
        "author": [
            "Kaizhen Zhu",
            "Mokai Pan",
            "Yuexin Ma",
            "Yanwei Fu",
            "Jingyi Yu",
            "Jingya Wang",
            "Ye Shi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05749",
        "abstract": "Recent advances in diffusion bridge models leverage Doob's $h$-transform to establish fixed endpoints between distributions, demonstrating promising results in image translation and restoration tasks. However, these approaches frequently produce blurred or excessively smoothed image details and lack a comprehensive theoretical foundation to explain these shortcomings. To address these limitations, we propose UniDB, a unified framework for diffusion bridges based on Stochastic Optimal Control (SOC). UniDB formulates the problem through an SOC-based optimization and derives a closed-form solution for the optimal controller, thereby unifying and generalizing existing diffusion bridge models. We demonstrate that existing diffusion bridges employing Doob's $h$-transform constitute a special case of our framework, emerging when the terminal penalty coefficient in the SOC cost function tends to infinity. By incorporating a tunable terminal penalty coefficient, UniDB achieves an optimal balance between control costs and terminal penalties, substantially improving detail preservation and output quality. Notably, UniDB seamlessly integrates with existing diffusion bridge models, requiring only minimal code modifications. Extensive experiments across diverse image restoration tasks validate the superiority and adaptability of the proposed framework. Our code is available at https://github.com/UniDB-SOC/UniDB/.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "90",
        "title": "PINGS: Gaussian Splatting Meets Distance Fields within a Point-Based Implicit Neural Map",
        "author": [
            "Yue Pan",
            "Xingguang Zhong",
            "Liren Jin",
            "Louis Wiesmann",
            "Marija PopoviÄ",
            "Jens Behley",
            "Cyrill Stachniss"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05752",
        "abstract": "Robots require high-fidelity reconstructions of their environment for effective operation. Such scene representations should be both, geometrically accurate and photorealistic to support downstream tasks. While this can be achieved by building distance fields from range sensors and radiance fields from cameras, the scalable incremental mapping of both fields consistently and at the same time with high quality remains challenging. In this paper, we propose a novel map representation that unifies a continuous signed distance field and a Gaussian splatting radiance field within an elastic and compact point-based implicit neural map. By enforcing geometric consistency between these fields, we achieve mutual improvements by exploiting both modalities. We devise a LiDAR-visual SLAM system called PINGS using the proposed map representation and evaluate it on several challenging large-scale datasets. Experimental results demonstrate that PINGS can incrementally build globally consistent distance and radiance fields encoded with a compact set of neural points. Compared to the state-of-the-art methods, PINGS achieves superior photometric and geometric rendering at novel views by leveraging the constraints from the distance field. Furthermore, by utilizing dense photometric cues and multi-view consistency from the radiance field, PINGS produces more accurate distance fields, leading to improved odometry estimation and mesh reconstruction.",
        "tags": [
            "Gaussian Splatting",
            "SLAM"
        ]
    },
    {
        "id": "91",
        "title": "Exploring Visual Embedding Spaces Induced by Vision Transformers for Online Auto Parts Marketplaces",
        "author": [
            "Cameron Armijo",
            "Pablo Rivas"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05756",
        "abstract": "This study examines the capabilities of the Vision Transformer (ViT) model in generating visual embeddings for images of auto parts sourced from online marketplaces, such as Craigslist and OfferUp. By focusing exclusively on single-modality data, the analysis evaluates ViT's potential for detecting patterns indicative of illicit activities. The workflow involves extracting high-dimensional embeddings from images, applying dimensionality reduction techniques like Uniform Manifold Approximation and Projection (UMAP) to visualize the embedding space, and using K-Means clustering to categorize similar items. Representative posts nearest to each cluster centroid provide insights into the composition and characteristics of the clusters. While the results highlight the strengths of ViT in isolating visual patterns, challenges such as overlapping clusters and outliers underscore the limitations of single-modal approaches in this domain. This work contributes to understanding the role of Vision Transformers in analyzing online marketplaces and offers a foundation for future advancements in detecting fraudulent or illegal activities.",
        "tags": [
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "92",
        "title": "Reinforced Lifelong Editing for Language Models",
        "author": [
            "Zherui Li",
            "Houcheng Jiang",
            "Hao Chen",
            "Baolong Bi",
            "Zhenhong Zhou",
            "Fei Sun",
            "Junfeng Fang",
            "Xiang Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05759",
        "abstract": "Large language models (LLMs) acquire information from pre-training corpora, but their stored knowledge can become inaccurate or outdated over time. Model editing addresses this challenge by modifying model parameters without retraining, and prevalent approaches leverage hypernetworks to generate these parameter updates. However, they face significant challenges in lifelong editing due to their incompatibility with LLM parameters that dynamically change during the editing process. To address this, we observed that hypernetwork-based lifelong editing aligns with reinforcement learning modeling and proposed RLEdit, an RL-based editing method. By treating editing losses as rewards and optimizing hypernetwork parameters at the full knowledge sequence level, we enable it to precisely capture LLM changes and generate appropriate parameter updates. Our extensive empirical evaluation across several LLMs demonstrates that RLEdit outperforms existing methods in lifelong editing with superior effectiveness and efficiency, achieving a 59.24% improvement while requiring only 2.11% of the time compared to most approaches. Our code is available at: https://github.com/zhrli324/RLEdit.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RL"
        ]
    },
    {
        "id": "93",
        "title": "Digital Twin Buildings: 3D Modeling, GIS Integration, and Visual Descriptions Using Gaussian Splatting, ChatGPT/Deepseek, and Google Maps Platforms",
        "author": [
            "Kyle Gao",
            "Dening Lu",
            "Liangzhi Li",
            "Nan Chen",
            "Hongjie He",
            "Linlin Xu",
            "Jonathan Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05769",
        "abstract": "Urban digital twins are virtual replicas of cities that use multi-source data and data analytics to optimize urban planning, infrastructure management, and decision-making. Towards this, we propose a framework focused on the single-building scale. By connecting to cloud mapping platforms such as Google Map Platforms APIs, by leveraging state-of-the-art multi-agent Large Language Models data analysis using ChatGPT(4o) and Deepseek-V3/R1, and by using our Gaussian Splatting-based mesh extraction pipeline, our Digital Twin Buildings framework can retrieve a building's 3D model, visual descriptions, and achieve cloud-based mapping integration with large language model-based data analytics using a building's address, postal code, or geographic coordinates.",
        "tags": [
            "3D",
            "ChatGPT",
            "DeepSeek",
            "Gaussian Splatting",
            "Large Language Models"
        ]
    },
    {
        "id": "94",
        "title": "GOLD: Graph Out-of-Distribution Detection via Implicit Adversarial Latent Generation",
        "author": [
            "Danny Wang",
            "Ruihong Qiu",
            "Guangdong Bai",
            "Zi Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05780",
        "abstract": "Despite graph neural networks' (GNNs) great success in modelling graph-structured data, out-of-distribution (OOD) test instances still pose a great challenge for current GNNs. One of the most effective techniques to detect OOD nodes is to expose the detector model with an additional OOD node-set, yet the extra OOD instances are often difficult to obtain in practice. Recent methods for image data address this problem using OOD data synthesis, typically relying on pre-trained generative models like Stable Diffusion. However, these approaches require vast amounts of additional data, as well as one-for-all pre-trained generative models, which are not available for graph data. Therefore, we propose the GOLD framework for graph OOD detection, an implicit adversarial learning pipeline with synthetic OOD exposure without pre-trained models. The implicit adversarial training process employs a novel alternating optimisation framework by training: (1) a latent generative model to regularly imitate the in-distribution (ID) embeddings from an evolving GNN, and (2) a GNN encoder and an OOD detector to accurately classify ID data while increasing the energy divergence between the ID embeddings and the generative model's synthetic embeddings. This novel approach implicitly transforms the synthetic embeddings into pseudo-OOD instances relative to the ID data, effectively simulating exposure to OOD scenarios without auxiliary data. Extensive OOD detection experiments are conducted on five benchmark graph datasets, verifying the superior performance of GOLD without using real OOD data compared with the state-of-the-art OOD exposure and non-exposure baselines.",
        "tags": [
            "Detection",
            "Diffusion"
        ]
    },
    {
        "id": "95",
        "title": "I3S: Importance Sampling Subspace Selection for Low-Rank Optimization in LLM Pretraining",
        "author": [
            "Haochen Zhang",
            "Junze Yin",
            "Guanchu Wang",
            "Zirui Liu",
            "Tianyi Zhang",
            "Anshumali Shrivastava",
            "Lin Yang",
            "Vladimir Braverman"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05790",
        "abstract": "Low-rank optimization has emerged as a promising approach to enabling memory-efficient training of large language models (LLMs). Existing low-rank optimization methods typically project gradients onto a low-rank subspace, reducing the memory cost of storing optimizer states. A key challenge in these methods is identifying suitable subspaces to ensure an effective optimization trajectory. Most existing approaches select the dominant subspace to preserve gradient information, as this intuitively provides the best approximation. However, we find that in practice, the dominant subspace stops changing during pretraining, thereby constraining weight updates to similar subspaces.\nIn this paper, we propose importance sampling subspace selection (I3S) for low-rank optimization, which theoretically offers a comparable convergence rate to the dominant subspace approach. Empirically, we demonstrate that I3S significantly outperforms previous methods in LLM pretraining tasks.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "96",
        "title": "On Reference (In-)Determinacy in Natural Language Inference",
        "author": [
            "Sihao Chen",
            "Chaitanya Malaviya",
            "Alex Fabrikant",
            "Hagai Taitelbaum",
            "Tal Schuster",
            "Senaka Buthpitiya",
            "Dan Roth"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05793",
        "abstract": "We revisit the reference determinacy (RD) assumption in the task of natural language inference (NLI), i.e., the premise and hypothesis are assumed to refer to the same context when human raters annotate a label. While RD is a practical assumption for constructing a new NLI dataset, we observe that current NLI models, which are typically trained solely on hypothesis-premise pairs created with the RD assumption, fail in downstream applications such as fact verification, where the input premise and hypothesis may refer to different contexts. To highlight the impact of this phenomenon in real-world use cases, we introduce RefNLI, a diagnostic benchmark for identifying reference ambiguity in NLI examples. In RefNLI, the premise is retrieved from a knowledge source (i.e., Wikipedia) and does not necessarily refer to the same context as the hypothesis. With RefNLI, we demonstrate that finetuned NLI models and few-shot prompted LLMs both fail to recognize context mismatch, leading to over 80% false contradiction and over 50% entailment predictions. We discover that the existence of reference ambiguity in NLI examples can in part explain the inherent human disagreements in NLI and provide insight into how the RD assumption impacts the NLI dataset creation process.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "97",
        "title": "The Curse of Depth in Large Language Models",
        "author": [
            "Wenfang Sun",
            "Xinyuan Song",
            "Pengxiang Li",
            "Lu Yin",
            "Yefeng Zheng",
            "Shiwei Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05795",
        "abstract": "In this paper, we introduce the Curse of Depth, a concept that highlights, explains, and addresses the recent observation in modern Large Language Models(LLMs) where nearly half of the layers are less effective than expected. We first confirm the wide existence of this phenomenon across the most popular families of LLMs such as Llama, Mistral, DeepSeek, and Qwen. Our analysis, theoretically and empirically, identifies that the underlying reason for the ineffectiveness of deep layers in LLMs is the widespread usage of Pre-Layer Normalization (Pre-LN). While Pre-LN stabilizes the training of Transformer LLMs, its output variance exponentially grows with the model depth, which undesirably causes the derivative of the deep Transformer blocks to be an identity matrix, and therefore barely contributes to the training. To resolve this training pitfall, we propose LayerNorm Scaling, which scales the variance of output of the layer normalization inversely by the square root of its depth. This simple modification mitigates the output variance explosion of deeper Transformer layers, improving their contribution. Our experimental results, spanning model sizes from 130M to 1B, demonstrate that LayerNorm Scaling significantly enhances LLM pre-training performance compared to Pre-LN. Moreover, this improvement seamlessly carries over to supervised fine-tuning. All these gains can be attributed to the fact that LayerNorm Scaling enables deeper layers to contribute more effectively during training.",
        "tags": [
            "DeepSeek",
            "LLMs",
            "LLaMA",
            "Large Language Models",
            "Qwen",
            "Transformer"
        ]
    },
    {
        "id": "98",
        "title": "StreamDCIM: A Tile-based Streaming Digital CIM Accelerator with Mixed-stationary Cross-forwarding Dataflow for Multimodal Transformer",
        "author": [
            "Shantian Qin",
            "Ziqing Qiang",
            "Zhihua Fan",
            "Wenming Li",
            "Xuejun An",
            "Xiaochun Ye",
            "Dongrui Fan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05798",
        "abstract": "Multimodal Transformers are emerging artificial intelligence (AI) models designed to process a mixture of signals from diverse modalities. Digital computing-in-memory (CIM) architectures are considered promising for achieving high efficiency while maintaining high accuracy. However, current digital CIM-based accelerators exhibit inflexibility in microarchitecture, dataflow, and pipeline to effectively accelerate multimodal Transformer. In this paper, we propose StreamDCIM, a tile-based streaming digital CIM accelerator for multimodal Transformers. It overcomes the above challenges with three features: First, we present a tile-based reconfigurable CIM macro microarchitecture with normal and hybrid reconfigurable modes to improve intra-macro CIM utilization. Second, we implement a mixed-stationary cross-forwarding dataflow with tile-based execution decoupling to exploit tile-level computation parallelism. Third, we introduce a ping-pong-like fine-grained compute-rewriting pipeline to overlap high-latency on-chip CIM rewriting. Experimental results show that StreamDCIM outperforms non-streaming and layer-based streaming CIM-based solutions by geomean 2.63$\\times$ and 1.28$\\times$ on typical multimodal Transformer models.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "99",
        "title": "MicroViT: A Vision Transformer with Low Complexity Self Attention for Edge Device",
        "author": [
            "Novendra Setyawan",
            "Chi-Chia Sun",
            "Mao-Hsiu Hsu",
            "Wen-Kai Kuo",
            "Jun-Wei Hsieh"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05800",
        "abstract": "The Vision Transformer (ViT) has demonstrated state-of-the-art performance in various computer vision tasks, but its high computational demands make it impractical for edge devices with limited resources. This paper presents MicroViT, a lightweight Vision Transformer architecture optimized for edge devices by significantly reducing computational complexity while maintaining high accuracy. The core of MicroViT is the Efficient Single Head Attention (ESHA) mechanism, which utilizes group convolution to reduce feature redundancy and processes only a fraction of the channels, thus lowering the burden of the self-attention mechanism. MicroViT is designed using a multi-stage MetaFormer architecture, stacking multiple MicroViT encoders to enhance efficiency and performance. Comprehensive experiments on the ImageNet-1K and COCO datasets demonstrate that MicroViT achieves competitive accuracy while significantly improving 3.6 faster inference speed and reducing energy consumption with 40% higher efficiency than the MobileViT series, making it suitable for deployment in resource-constrained environments such as mobile and edge devices.",
        "tags": [
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "100",
        "title": "FlashCheck: Exploration of Efficient Evidence Retrieval for Fast Fact-Checking",
        "author": [
            "Kevin Nanekhan",
            "Venktesh V",
            "Erik Martin",
            "Henrik Vatndal",
            "Vinay Setty",
            "Avishek Anand"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05803",
        "abstract": "The advances in digital tools have led to the rampant spread of misinformation. While fact-checking aims to combat this, manual fact-checking is cumbersome and not scalable. It is essential for automated fact-checking to be efficient for aiding in combating misinformation in real-time and at the source. Fact-checking pipelines primarily comprise a knowledge retrieval component which extracts relevant knowledge to fact-check a claim from large knowledge sources like Wikipedia and a verification component. The existing works primarily focus on the fact-verification part rather than evidence retrieval from large data collections, which often face scalability issues for practical applications such as live fact-checking. In this study, we address this gap by exploring various methods for indexing a succinct set of factual statements from large collections like Wikipedia to enhance the retrieval phase of the fact-checking pipeline. We also explore the impact of vector quantization to further improve the efficiency of pipelines that employ dense retrieval approaches for first-stage retrieval. We study the efficiency and effectiveness of the approaches on fact-checking datasets such as HoVer and WiCE, leveraging Wikipedia as the knowledge source. We also evaluate the real-world utility of the efficient retrieval approaches by fact-checking 2024 presidential debate and also open source the collection of claims with corresponding labels identified in the debate. Through a combination of indexed facts together with Dense retrieval and Index compression, we achieve up to a 10.0x speedup on CPUs and more than a 20.0x speedup on GPUs compared to the classical fact-checking pipelines over large collections.",
        "tags": [
            "Vector Quantization"
        ]
    },
    {
        "id": "101",
        "title": "Devil is in the Details: Density Guidance for Detail-Aware Generation with Flow Models",
        "author": [
            "RafaÅ Karczewski",
            "Markus Heinonen",
            "Vikas Garg"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05807",
        "abstract": "Diffusion models have emerged as a powerful class of generative models, capable of producing high-quality images by mapping noise to a data distribution. However, recent findings suggest that image likelihood does not align with perceptual quality: high-likelihood samples tend to be smooth, while lower-likelihood ones are more detailed. Controlling sample density is thus crucial for balancing realism and detail. In this paper, we analyze an existing technique, Prior Guidance, which scales the latent code to influence image detail. We introduce score alignment, a condition that explains why this method works and show that it can be tractably checked for any continuous normalizing flow model. We then propose Density Guidance, a principled modification of the generative ODE that enables exact log-density control during sampling. Finally, we extend Density Guidance to stochastic sampling, ensuring precise log-density control while allowing controlled variation in structure or fine details. Our experiments demonstrate that these techniques provide fine-grained control over image detail without compromising sample quality.",
        "tags": [
            "Diffusion",
            "ODE"
        ]
    },
    {
        "id": "102",
        "title": "Delta - Contrastive Decoding Mitigates Text Hallucinations in Large Language Models",
        "author": [
            "Cheng Peng Huang",
            "Hao-Yuan Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05825",
        "abstract": "Large language models (LLMs) demonstrate strong capabilities in natural language processing but remain prone to hallucinations, generating factually incorrect or fabricated content. This issue undermines their reliability, particularly in high-stakes domains such as healthcare and legal advisory. To address this challenge, we propose Delta, an inference-time method that reduces hallucinations without requiring model retraining or additional data. Delta works by randomly masking parts of the input prompt and contrasting the output distributions for the original and masked inputs, effectively suppressing hallucinations through inference-only computations. We evaluate Delta on context-rich question-answering benchmarks, achieving absolute improvements of approximately 3 and 6 percentage points on SQuAD v1.1 and v2, respectively, and 7 and 2 percentage points on TriviaQA and Natural Questions under-sampling decoding. Delta also improves the no-answer exact match score on SQuAD v2 by over ten percentage points, demonstrating its effectiveness in mitigating hallucinations arising from contextual ambiguity. These results highlight Delta as a computationally efficient and scalable approach for improving the reliability of LLMs in real-world applications.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "103",
        "title": "Training-free Anomaly Event Detection via LLM-guided Symbolic Pattern Discovery",
        "author": [
            "Yuhui Zeng",
            "Haoxiang Wu",
            "Wenjie Nie",
            "Guangyao Chen",
            "Xiawu Zheng",
            "Yunhang Shen",
            "Guilin Li",
            "Yixiong Zou",
            "Yonghong Tian",
            "Rongrong Ji"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05843",
        "abstract": "Anomaly event detection plays a crucial role in various real-world applications. However, current approaches predominantly rely on supervised learning, which faces significant challenges: the requirement for extensive labeled training data and lack of interpretability in decision-making processes. To address these limitations, we present a training-free framework that integrates open-set object detection with symbolic regression, powered by Large Language Models (LLMs) for efficient symbolic pattern discovery. The LLMs guide the symbolic reasoning process, establishing logical relationships between detected entities. Through extensive experiments across multiple domains, our framework demonstrates several key advantages: (1) achieving superior detection accuracy through direct reasoning without any training process; (2) providing highly interpretable logical expressions that are readily comprehensible to humans; and (3) requiring minimal annotation effort - approximately 1% of the data needed by traditional training-based http://methods.To facilitate comprehensive evaluation and future research, we introduce two datasets: a large-scale private dataset containing over 110,000 annotated images covering various anomaly scenarios including construction site safety violations, illegal fishing activities, and industrial hazards, along with a public benchmark dataset of 5,000 samples with detailed anomaly event annotations. Code is available at here.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "104",
        "title": "Fact-or-Fair: A Checklist for Behavioral Testing of AI Models on Fairness-Related Queries",
        "author": [
            "Jen-tse Huang",
            "Yuhang Yan",
            "Linqi Liu",
            "Yixin Wan",
            "Wenxuan Wang",
            "Kai-Wei Chang",
            "Michael R. Lyu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05849",
        "abstract": "The generation of incorrect images, such as depictions of people of color in Nazi-era uniforms by Gemini, frustrated users and harmed Google's reputation, motivating us to investigate the relationship between accurately reflecting factuality and promoting diversity and equity. In this study, we focus on 19 real-world statistics collected from authoritative sources. Using these statistics, we develop a checklist comprising objective and subjective queries to analyze behavior of large language models (LLMs) and text-to-image (T2I) models. Objective queries assess the models' ability to provide accurate world knowledge. In contrast, the design of subjective queries follows a key principle: statistical or experiential priors should not be overgeneralized to individuals, ensuring that models uphold diversity. These subjective queries are based on three common human cognitive errors that often result in social biases. We propose metrics to assess factuality and fairness, and formally prove the inherent trade-off between these two aspects. Results show that GPT-4o and DALL-E 3 perform notably well among six LLMs and four T2I models. Our code is publicly available at https://github.com/uclanlp/Fact-or-Fair.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models",
            "Text-to-Image"
        ]
    },
    {
        "id": "105",
        "title": "DexVLA: Vision-Language Model with Plug-In Diffusion Expert for General Robot Control",
        "author": [
            "Junjie Wen",
            "Yichen Zhu",
            "Jinming Li",
            "Zhibin Tang",
            "Chaomin Shen",
            "Feifei Feng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05855",
        "abstract": "Enabling robots to perform diverse tasks across varied environments is a central challenge in robot learning. While vision-language-action (VLA) models have shown promise for generalizable robot skills, realizing their full potential requires addressing limitations in action representation and efficient training. Current VLA models often focus on scaling the vision-language model (VLM) component, while the action space representation remains a critical bottleneck. This paper introduces DexVLA, a novel framework designed to enhance the efficiency and generalization capabilities of VLAs for complex, long-horizon tasks across diverse robot embodiments. DexVLA features a novel diffusion-based action expert, scaled to one billion parameters, designed for cross-embodiment learning. A novel embodiment curriculum learning strategy facilitates efficient training: (1) pre-training the diffusion expert that is separable from the VLA on cross-embodiment data, (2) aligning the VLA model to specific embodiments, and (3) post-training for rapid adaptation to new tasks. We conduct comprehensive experiments across multiple embodiments, including single-arm, bimanual, and dexterous hand, demonstrating DexVLA's adaptability to challenging tasks without task-specific adaptation, its ability to learn dexterous skills on novel embodiments with limited data, and its capacity to complete complex, long-horizon tasks using only direct language prompting, such as laundry folding. In all settings, our method demonstrates superior performance compared to state-of-the-art models like Octo, OpenVLA, and Diffusion Policy.",
        "tags": [
            "Diffusion",
            "Robot"
        ]
    },
    {
        "id": "106",
        "title": "Acquisition through My Eyes and Steps: A Joint Predictive Agent Model in Egocentric Worlds",
        "author": [
            "Lu Chen",
            "Yizhou Wang",
            "Shixiang Tang",
            "Qianhong Ma",
            "Tong He",
            "Wanli Ouyang",
            "Xiaowei Zhou",
            "Hujun Bao",
            "Sida Peng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05857",
        "abstract": "This paper addresses the task of learning an agent model behaving like humans, which can jointly perceive, predict, and act in egocentric worlds. Previous methods usually train separate models for these three abilities, leading to information silos among them, which prevents these abilities from learning from each other and collaborating effectively. In this paper, we propose a joint predictive agent model, named EgoAgent, that simultaneously learns to represent the world, predict future states, and take reasonable actions with a single transformer. EgoAgent unifies the representational spaces of the three abilities by mapping them all into a sequence of continuous tokens. Learnable query tokens are appended to obtain current states, future states, and next actions. With joint supervision, our agent model establishes the internal relationship among these three abilities and effectively mimics the human inference and learning processes. Comprehensive evaluations of EgoAgent covering image classification, egocentric future state prediction, and 3D human motion prediction tasks demonstrate the superiority of our method. The code and trained model will be released for reproducibility.",
        "tags": [
            "3D",
            "Transformer"
        ]
    },
    {
        "id": "107",
        "title": "Self-Training Large Language Models for Tool-Use Without Demonstrations",
        "author": [
            "Ne Luo",
            "Aryo Pradipta Gema",
            "Xuanli He",
            "Emile van Krieken",
            "Pietro Lesci",
            "Pasquale Minervini"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05867",
        "abstract": "Large language models (LLMs) remain prone to factual inaccuracies and computational errors, including hallucinations and mistakes in mathematical reasoning. Recent work augmented LLMs with tools to mitigate these shortcomings, but often requires curated gold tool-use demonstrations. In this paper, we investigate whether LLMs can learn to use tools without demonstrations. First, we analyse zero-shot prompting strategies to guide LLMs in tool utilisation. Second, we propose a self-training method to synthesise tool-use traces using the LLM itself. We compare supervised fine-tuning and preference fine-tuning techniques for fine-tuning the model on datasets constructed using existing Question Answering (QA) datasets, i.e., TriviaQA and GSM8K. Experiments show that tool-use enhances performance on a long-tail knowledge task: 3.7% on PopQA, which is used solely for evaluation, but leads to mixed results on other datasets, i.e., TriviaQA, GSM8K, and NQ-Open. Our findings highlight the potential and challenges of integrating external tools into LLMs without demonstrations.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "108",
        "title": "HyLiFormer: Hyperbolic Linear Attention for Skeleton-based Human Action Recognition",
        "author": [
            "Yue Li",
            "Haoxuan Qu",
            "Mengyuan Liu",
            "Jun Liu",
            "Yujun Cai"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05869",
        "abstract": "Transformers have demonstrated remarkable performance in skeleton-based human action recognition, yet their quadratic computational complexity remains a bottleneck for real-world applications. To mitigate this, linear attention mechanisms have been explored but struggle to capture the hierarchical structure of skeleton data. Meanwhile, the PoincarÃ© model, as a typical hyperbolic geometry, offers a powerful framework for modeling hierarchical structures but lacks well-defined operations for existing mainstream linear attention. In this paper, we propose HyLiFormer, a novel hyperbolic linear attention Transformer tailored for skeleton-based action recognition. Our approach incorporates a Hyperbolic Transformation with Curvatures (HTC) module to map skeleton data into hyperbolic space and a Hyperbolic Linear Attention (HLA) module for efficient long-range dependency modeling. Theoretical analysis and extensive experiments on NTU RGB+D and NTU RGB+D 120 datasets demonstrate that HyLiFormer significantly reduces computational complexity while preserving model accuracy, making it a promising solution for efficiency-critical applications.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "109",
        "title": "MMGDreamer: Mixed-Modality Graph for Geometry-Controllable 3D Indoor Scene Generation",
        "author": [
            "Zhifei Yang",
            "Keyang Lu",
            "Chao Zhang",
            "Jiaxing Qi",
            "Hanqi Jiang",
            "Ruifei Ma",
            "Shenglin Yin",
            "Yifan Xu",
            "Mingzhe Xing",
            "Zhen Xiao",
            "Jieyi Long",
            "Xiangde Liu",
            "Guangyao Zhai"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05874",
        "abstract": "Controllable 3D scene generation has extensive applications in virtual reality and interior design, where the generated scenes should exhibit high levels of realism and controllability in terms of geometry. Scene graphs provide a suitable data representation that facilitates these applications. However, current graph-based methods for scene generation are constrained to text-based inputs and exhibit insufficient adaptability to flexible user inputs, hindering the ability to precisely control object geometry. To address this issue, we propose MMGDreamer, a dual-branch diffusion model for scene generation that incorporates a novel Mixed-Modality Graph, visual enhancement module, and relation predictor. The mixed-modality graph allows object nodes to integrate textual and visual modalities, with optional relationships between nodes. It enhances adaptability to flexible user inputs and enables meticulous control over the geometry of objects in the generated scenes. The visual enhancement module enriches the visual fidelity of text-only nodes by constructing visual representations using text embeddings. Furthermore, our relation predictor leverages node representations to infer absent relationships between nodes, resulting in more coherent scene layouts. Extensive experimental results demonstrate that MMGDreamer exhibits superior control of object geometry, achieving state-of-the-art scene generation performance. Project page: https://yangzhifeio.github.io/project/MMGDreamer.",
        "tags": [
            "3D",
            "Diffusion"
        ]
    },
    {
        "id": "110",
        "title": "Retrieval-augmented Large Language Models for Financial Time Series Forecasting",
        "author": [
            "Mengxi Xiao",
            "Zihao Jiang",
            "Lingfei Qian",
            "Zhengyu Chen",
            "Yueru He",
            "Yijing Xu",
            "Yuecheng Jiang",
            "Dong Li",
            "Ruey-Ling Weng",
            "Min Peng",
            "Jimin Huang",
            "Sophia Ananiadou",
            "Qianqian Xie"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05878",
        "abstract": "Stock movement prediction, a fundamental task in financial time-series forecasting, requires identifying and retrieving critical influencing factors from vast amounts of time-series data. However, existing text-trained or numeric similarity-based retrieval methods fall short in handling complex financial analysis. To address this, we propose the first retrieval-augmented generation (RAG) framework for financial time-series forecasting, featuring three key innovations: a fine-tuned 1B parameter large language model (StockLLM) as the backbone, a novel candidate selection method leveraging LLM feedback, and a training objective that maximizes similarity between queries and historically significant sequences. This enables our retriever, FinSeer, to uncover meaningful patterns while minimizing noise in complex financial data. We also construct new datasets integrating financial indicators and historical stock prices to train FinSeer and ensure robust evaluation. Experimental results demonstrate that our RAG framework outperforms bare StockLLM and random retrieval, highlighting its effectiveness, while FinSeer surpasses existing retrieval methods, achieving an 8\\% higher accuracy on BIGDATA22 and retrieving more impactful sequences. This work underscores the importance of tailored retrieval models in financial forecasting and provides a novel framework for future research.",
        "tags": [
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "111",
        "title": "Beyond Fine-Tuning: A Systematic Study of Sampling Techniques in Personalized Image Generation",
        "author": [
            "Vera Soboleva",
            "Maksim Nakhodnov",
            "Aibek Alanov"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05895",
        "abstract": "Personalized text-to-image generation aims to create images tailored to user-defined concepts and textual descriptions. Balancing the fidelity of the learned concept with its ability for generation in various contexts presents a significant challenge. Existing methods often address this through diverse fine-tuning parameterizations and improved sampling strategies that integrate superclass trajectories during the diffusion process. While improved sampling offers a cost-effective, training-free solution for enhancing fine-tuned models, systematic analyses of these methods remain limited. Current approaches typically tie sampling strategies with fixed fine-tuning configurations, making it difficult to isolate their impact on generation outcomes. To address this issue, we systematically analyze sampling strategies beyond fine-tuning, exploring the impact of concept and superclass trajectories on the results. Building on this analysis, we propose a decision framework evaluating text alignment, computational constraints, and fidelity objectives to guide strategy selection. It integrates with diverse architectures and training approaches, systematically optimizing concept preservation, prompt adherence, and resource efficiency. The source code can be found at https://github.com/ControlGenAI/PersonGenSampler.",
        "tags": [
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "112",
        "title": "GRAIT: Gradient-Driven Refusal-Aware Instruction Tuning for Effective Hallucination Mitigation",
        "author": [
            "Runchuan Zhu",
            "Zinco Jiang",
            "Jiang Wu",
            "Zhipeng Ma",
            "Jiahe Song",
            "Fengshuo Bai",
            "Dahua Lin",
            "Lijun Wu",
            "Conghui He"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05911",
        "abstract": "Refusal-Aware Instruction Tuning (RAIT) aims to enhance Large Language Models (LLMs) by improving their ability to refuse responses to questions beyond their knowledge, thereby reducing hallucinations and improving reliability. Effective RAIT must address two key challenges: firstly, effectively reject unknown questions to minimize hallucinations; secondly, avoid over-refusal to ensure questions that can be correctly answered are not rejected, thereby maintain the helpfulness of LLM outputs. In this paper, we address the two challenges by deriving insightful observations from the gradient-based perspective, and proposing the Gradient-driven Refusal Aware Instruction Tuning Framework GRAIT: (1) employs gradient-driven sample selection to effectively minimize hallucinations and (2) introduces an adaptive weighting mechanism during fine-tuning to reduce the risk of over-refusal, achieving the balance between accurate refusals and maintaining useful responses. Experimental evaluations on open-ended and multiple-choice question answering tasks demonstrate that GRAIT significantly outperforms existing RAIT methods in the overall performance. The source code and data will be available at https://github.com/opendatalab/GRAIT .",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "113",
        "title": "Can Generative Agent-Based Modeling Replicate the Friendship Paradox in Social Media Simulations?",
        "author": [
            "Gian Marco Orlando",
            "Valerio La Gatta",
            "Diego Russo",
            "Vincenzo Moscato"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05919",
        "abstract": "Generative Agent-Based Modeling (GABM) is an emerging simulation paradigm that combines the reasoning abilities of Large Language Models with traditional Agent-Based Modeling to replicate complex social behaviors, including interactions on social media. While prior work has focused on localized phenomena such as opinion formation and information spread, its potential to capture global network dynamics remains underexplored. This paper addresses this gap by analyzing GABM-based social media simulations through the lens of the Friendship Paradox (FP), a counterintuitive phenomenon where individuals, on average, have fewer friends than their friends. We propose a GABM framework for social media simulations, featuring generative agents that emulate real users with distinct personalities and interests. Using Twitter datasets on the US 2020 Election and the QAnon conspiracy, we show that the FP emerges naturally in GABM simulations. Consistent with real-world observations, the simulations unveil a hierarchical structure, where agents preferentially connect with others displaying higher activity or influence. Additionally, we find that infrequent connections primarily drive the FP, reflecting patterns in real networks. These findings validate GABM as a robust tool for modeling global social media phenomena and highlight its potential for advancing social science by enabling nuanced analysis of user behavior.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "114",
        "title": "Skill Expansion and Composition in Parameter Space",
        "author": [
            "Tenglong Liu",
            "Jianxiong Li",
            "Yinan Zheng",
            "Haoyi Niu",
            "Yixing Lan",
            "Xin Xu",
            "Xianyuan Zhan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05932",
        "abstract": "Humans excel at reusing prior knowledge to address new challenges and developing skills while solving problems. This paradigm becomes increasingly popular in the development of autonomous agents, as it develops systems that can self-evolve in response to new challenges like human beings. However, previous methods suffer from limited training efficiency when expanding new skills and fail to fully leverage prior knowledge to facilitate new task learning. In this paper, we propose Parametric Skill Expansion and Composition (PSEC), a new framework designed to iteratively evolve the agents' capabilities and efficiently address new challenges by maintaining a manageable skill library. This library can progressively integrate skill primitives as plug-and-play Low-Rank Adaptation (LoRA) modules in parameter-efficient finetuning, facilitating efficient and flexible skill expansion. This structure also enables the direct skill compositions in parameter space by merging LoRA modules that encode different skills, leveraging shared information across skills to effectively program new skills. Based on this, we propose a context-aware module to dynamically activate different skills to collaboratively handle new tasks. Empowering diverse applications including multi-objective composition, dynamics shift, and continual policy shift, the results on D4RL, DSRL benchmarks, and the DeepMind Control Suite show that PSEC exhibits superior capacity to leverage prior knowledge to efficiently tackle new challenges, as well as expand its skill libraries to evolve the capabilities. Project website: https://ltlhuuu.github.io/PSEC/.",
        "tags": [
            "LoRA",
            "Low-Rank Adaptation"
        ]
    },
    {
        "id": "115",
        "title": "Learning to Substitute Words with Model-based Score Ranking",
        "author": [
            "Hongye Liu",
            "Ricardo Henao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05933",
        "abstract": "Smart word substitution aims to enhance sentence quality by improving word choices; however current benchmarks rely on human-labeled data. Since word choices are inherently subjective, ground-truth word substitutions generated by a small group of annotators are often incomplete and likely not generalizable. To circumvent this issue, we instead employ a model-based score (BARTScore) to quantify sentence quality, thus forgoing the need for human annotations. Specifically, we use this score to define a distribution for each word substitution, allowing one to test whether a substitution is statistically superior relative to others. In addition, we propose a loss function that directly optimizes the alignment between model predictions and sentence scores, while also enhancing the overall quality score of a substitution. Crucially, model learning no longer requires human labels, thus avoiding the cost of annotation while maintaining the quality of the text modified with substitutions. Experimental results show that the proposed approach outperforms both masked language models (BERT, BART) and large language models (GPT-4, LLaMA). The source code is available at https://github.com/Hyfred/Substitute-Words-with-Ranking.",
        "tags": [
            "BERT",
            "GPT",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "116",
        "title": "A Semi-Supervised Text Generation Framework Combining a Deep Transformer and a GAN",
        "author": [
            "Shengquan Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05937",
        "abstract": "This paper introduces a framework that connects a deep generative pre-trained Transformer language model with a generative adversarial network for semi-supervised text generation. In other words, the proposed model is first pre-trained unsupervised on a large and diverse text corpus with 24 layers. Then a simple GAN architecture for synthetic text generation is introduced, and Gumbel-Softmax is applied to handle the discreteness of tokens. The paper also shows a semi-supervised approach where real data is augmented with GAN samples, which is further used to fine-tune the Transformer model on the merged dataset. Detailed theoretical derivations are also included, outlining the proof of the min-max objective function, and an extensive discussion of the Gumbel-Softmax reparameterization trick.",
        "tags": [
            "GAN",
            "Transformer"
        ]
    },
    {
        "id": "117",
        "title": "Multi-granular Training Strategies for Robust Multi-hop Reasoning Over Noisy and Heterogeneous Knowledge Sources",
        "author": [
            "Jackson Coleman",
            "Isaiah Lawrence",
            "Benjamin Turner"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05944",
        "abstract": "Multi-source multi-hop question answering (QA) represents a challenging task in natural language processing due to the need for dynamic integration of heterogeneous knowledge sources and multi-step reasoning. Existing methods often suffer from cascading errors, insufficient handling of knowledge conflicts, and computational inefficiency. In this paper, we propose Adaptive Multi-source Knowledge-Oriented Reasoning (AMKOR), a generative framework that leverages large language models (LLMs) to dynamically fuse parametric and retrieved knowledge while exploring reasoning trajectories using probabilistic beam reasoning. AMKOR is further enhanced by a multi-granular learning strategy, optimizing both local reasoning steps and global answer accuracy. Experiments conducted on four widely-used multi-hop QA datasets, including HotpotQA and MuSiQue, demonstrate that AMKOR achieves state-of-the-art performance, significantly outperforming baseline methods on both reasoning accuracy and robustness. Additional analyses confirm its scalability, adaptability to noisy knowledge, and superior ability to handle complex multi-hop tasks. This work establishes a new benchmark for multi-source multi-hop QA by effectively combining reasoning quality and efficiency.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "118",
        "title": "\"Let the AI conspiracy begin...\" Language Model coordination is just one inference-intervention away",
        "author": [
            "Paul Darm",
            "Annalisa Riccardi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05945",
        "abstract": "In this work, we introduce a straightforward and effective methodology to steer large language model behaviour capable of bypassing learned alignment goals. We employ interference-time activation shifting, which is effective without additional training. Following prior studies, we derive intervention directions from activation differences in contrastive pairs of model outputs, which represent the desired and undesired behaviour. By prompting the model to include multiple-choice answers in its response, we can automatically evaluate the sensitivity of model output to individual attention heads steering efforts. We demonstrate that interventions on these heads generalize well to open-ended answer generation in the challenging \"AI coordination\" dataset. In this dataset, models must choose between assisting another AI or adhering to ethical, safe, and unharmful behaviour. Our fine-grained interventions lead Llama 2 to prefer coordination with other AIs over following established alignment goals. Additionally, this approach enables stronger interventions than those applied to whole model layers, preserving the overall cohesiveness of the output. The simplicity of our method highlights the shortcomings of current alignment strategies and points to potential future research directions, as concepts like \"AI coordination\" can be influenced by selected attention heads.",
        "tags": [
            "LLaMA"
        ]
    },
    {
        "id": "119",
        "title": "Acceleration Multiple Heads Decoding for LLM via Dynamic Tree Attention",
        "author": [
            "Zhendong Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05947",
        "abstract": "Multiple heads decoding accelerates the inference of Large Language Models (LLMs) by predicting next several tokens simultaneously. It generates and verifies multiple candidate sequences in parallel via tree attention with a fixed structure. In this paper, we replace the fixed tree attention with dynamic tree attention on multiple head decoding, specifically in the context of MEDUSA. We propose a simple and low complexity strategy to generate candidates and construct the dynamic tree structure. Preliminary experiments show that the proposed method improves the decoding efficiency of multiple head decoding for LLMs while maintaining the generation quality. This result demonstrates the potential for improvement of multiple head decoding in candidate generation.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "120",
        "title": "Cyri: A Conversational AI-based Assistant for Supporting the Human User in Detecting and Responding to Phishing Attacks",
        "author": [
            "Antonio La Torre",
            "Marco Angelini"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05951",
        "abstract": "This work introduces Cyri, an AI-powered conversational assistant designed to support a human user in detecting and analyzing phishing emails by leveraging Large Language Models. Cyri has been designed to scrutinize emails for semantic features used in phishing attacks, such as urgency, and undesirable consequences, using an approach that unifies features already established in the literature with others by Cyri features extraction methodology. Cyri can be directly plugged into a client mail or webmail, ensuring seamless integration with the user's email workflow while maintaining data privacy through local processing. By performing analyses on the user's machine, Cyri eliminates the need to transmit sensitive email data over the internet, reducing associated security risks. The Cyri user interface has been designed to reduce habituation effects and enhance user engagement. It employs dynamic visual cues and context-specific explanations to keep users alert and informed while using emails. Additionally, it allows users to explore identified malicious semantic features both through conversation with the agent and visual exploration, obtaining the advantages of both modalities for expert or non-expert users. It also allows users to keep track of the conversation, supports the user in solving additional questions on both computed features or new parts of the mail, and applies its detection on demand. To evaluate Cyri, we crafted a comprehensive dataset of 420 phishing emails and 420 legitimate emails. Results demonstrate high effectiveness in identifying critical phishing semantic features fundamental to phishing detection. A user study involving 10 participants, both experts and non-experts, evaluated Cyri's effectiveness and usability. Results indicated that Cyri significantly aided users in identifying phishing emails and enhanced their understanding of phishing tactics.",
        "tags": [
            "Detection",
            "Large Language Models"
        ]
    },
    {
        "id": "121",
        "title": "$\\mu$nit Scaling: Simple and Scalable FP8 LLM Training",
        "author": [
            "Saaketh Narayan",
            "Abhay Gupta",
            "Mansheej Paul",
            "Davis Blalock"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05967",
        "abstract": "Large Language Model training with 8-bit floating point (FP8) formats promises significant efficiency improvements, but reduced numerical precision makes training challenging. It is currently possible to train in FP8 only if one is willing to tune various hyperparameters, reduce model scale, or accept the overhead of computing dynamic scale factors. We demonstrate simple, scalable FP8 training that requires no dynamic scaling factors or special hyperparameters, even at large model sizes. Our method, $\\mu$nit Scaling ($\\mu$S), also enables simple hyperparameter transfer across model widths, matched numerics across training and inference, and other desirable properties. $\\mu$nit Scaling is straightforward to implement, consisting of a set of minimal interventions based on a first-principles analysis of common transformer operations. We validate our method by training models from 1B to 13B parameters, performing all hidden linear layer computations in FP8. We achieve quality equal to higher precision baselines while also training up to 33% faster.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "122",
        "title": "VFX Creator: Animated Visual Effect Generation with Controllable Diffusion Transformer",
        "author": [
            "Xinyu Liu",
            "Ailing Zeng",
            "Wei Xue",
            "Harry Yang",
            "Wenhan Luo",
            "Qifeng Liu",
            "Yike Guo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05979",
        "abstract": "Crafting magic and illusions is one of the most thrilling aspects of filmmaking, with visual effects (VFX) serving as the powerhouse behind unforgettable cinematic experiences. While recent advances in generative artificial intelligence have driven progress in generic image and video synthesis, the domain of controllable VFX generation remains relatively underexplored. In this work, we propose a novel paradigm for animated VFX generation as image animation, where dynamic effects are generated from user-friendly textual descriptions and static reference images.\nOur work makes two primary contributions: (i) Open-VFX, the first high-quality VFX video dataset spanning 15 diverse effect categories, annotated with textual descriptions, instance segmentation masks for spatial conditioning, and start-end timestamps for temporal control. (ii) VFX Creator, a simple yet effective controllable VFX generation framework based on a Video Diffusion Transformer. The model incorporates a spatial and temporal controllable LoRA adapter, requiring minimal training videos. Specifically, a plug-and-play mask control module enables instance-level spatial manipulation, while tokenized start-end motion timestamps embedded in the diffusion process, alongside the text encoder, allow precise temporal control over effect timing and pace.\nExtensive experiments on the Open-VFX test set demonstrate the superiority of the proposed system in generating realistic and dynamic effects, achieving state-of-the-art performance and generalization ability in both spatial and temporal controllability. Furthermore, we introduce a specialized metric to evaluate the precision of temporal control. By bridging traditional VFX techniques with generative approaches, VFX Creator unlocks new possibilities for efficient and high-quality video effect generation, making advanced VFX accessible to a broader audience.",
        "tags": [
            "Diffusion",
            "Diffusion Transformer",
            "LoRA",
            "Segmentation",
            "Transformer"
        ]
    },
    {
        "id": "123",
        "title": "Analysis of LLM as a grammatical feature tagger for African American English",
        "author": [
            "Rahul Porwal",
            "Alice Rozet",
            "Pryce Houck",
            "Jotsna Gowda",
            "Sarah Moeller",
            "Kevin Tang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06004",
        "abstract": "African American English (AAE) presents unique challenges in natural language processing (NLP). This research systematically compares the performance of available NLP models--rule-based, transformer-based, and large language models (LLMs)--capable of identifying key grammatical features of AAE, namely Habitual Be and Multiple Negation. These features were selected for their distinct grammatical complexity and frequency of occurrence. The evaluation involved sentence-level binary classification tasks, using both zero-shot and few-shot strategies. The analysis reveals that while LLMs show promise compared to the baseline, they are influenced by biases such as recency and unrelated features in the text such as formality. This study highlights the necessity for improved model training and architectural adjustments to better accommodate AAE's unique linguistic characteristics. Data and code are available.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "124",
        "title": "Media Bias Detector: Designing and Implementing a Tool for Real-Time Selection and Framing Bias Analysis in News Coverage",
        "author": [
            "Jenny S Wang",
            "Samar Haider",
            "Amir Tohidi",
            "Anushkaa Gupta",
            "Yuxuan Zhang",
            "Chris Callison-Burch",
            "David Rothschild",
            "Duncan J Watts"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06009",
        "abstract": "Mainstream media, through their decisions on what to cover and how to frame the stories they cover, can mislead readers without using outright falsehoods. Therefore, it is crucial to have tools that expose these editorial choices underlying media bias. In this paper, we introduce the Media Bias Detector, a tool for researchers, journalists, and news consumers. By integrating large language models, we provide near real-time granular insights into the topics, tone, political lean, and facts of news articles aggregated to the publisher level. We assessed the tool's impact by interviewing 13 experts from journalism, communications, and political science, revealing key insights into usability and functionality, practical applications, and AI's role in powering media bias tools. We explored this in more depth with a follow-up survey of 150 news consumers. This work highlights opportunities for AI-driven tools that empower users to critically engage with media content, particularly in politically charged environments.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "125",
        "title": "Noise is an Efficient Learner for Zero-Shot Vision-Language Models",
        "author": [
            "Raza Imam",
            "Asif Hanif",
            "Jian Zhang",
            "Khaled Waleed Dawoud",
            "Yova Kementchedjhieva",
            "Mohammad Yaqub"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06019",
        "abstract": "Recently, test-time adaptation has garnered attention as a method for tuning models without labeled data. The conventional modus operandi for adapting pre-trained vision-language models (VLMs) during test-time primarily focuses on tuning learnable prompts; however, this approach overlooks potential distribution shifts in the visual representations themselves. In this work, we address this limitation by introducing Test-Time Noise Tuning (TNT), a novel method for handling unpredictable shifts in the visual space. TNT leverages, for the first time, a noise adaptation strategy that optimizes learnable noise directly in the visual input space, enabling adaptive feature learning from a single test sample. We further introduce a novel approach for inter-view representation alignment by explicitly enforcing coherence in embedding distances, ensuring consistent feature representations across views. Combined with scaled logits and confident view selection at inference, TNT substantially enhances VLM generalization and calibration, achieving average gains of +7.38% on natural distributions benchmark and +0.80% on cross-dataset evaluations over zero-shot CLIP. These improvements lay a strong foundation for adaptive out-of-distribution handling.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "126",
        "title": "Dual Caption Preference Optimization for Diffusion Models",
        "author": [
            "Amir Saeidi",
            "Yiran Luo",
            "Agneet Chatterjee",
            "Shamanthak Hegde",
            "Bimsara Pathiraja",
            "Yezhou Yang",
            "Chitta Baral"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06023",
        "abstract": "Recent advancements in human preference optimization, originally developed for Large Language Models (LLMs), have shown significant potential in improving text-to-image diffusion models. These methods aim to learn the distribution of preferred samples while distinguishing them from less preferred ones. However, existing preference datasets often exhibit overlap between these distributions, leading to a conflict distribution. Additionally, we identified that input prompts contain irrelevant information for less preferred images, limiting the denoising network's ability to accurately predict noise in preference optimization methods, known as the irrelevant prompt issue. To address these challenges, we propose Dual Caption Preference Optimization (DCPO), a novel approach that utilizes two distinct captions to mitigate irrelevant prompts. To tackle conflict distribution, we introduce the Pick-Double Caption dataset, a modified version of Pick-a-Pic v2 with separate captions for preferred and less preferred images. We further propose three different strategies for generating distinct captions: captioning, perturbation, and hybrid methods. Our experiments show that DCPO significantly improves image quality and relevance to prompts, outperforming Stable Diffusion (SD) 2.1, SFT_Chosen, Diffusion-DPO, and MaPO across multiple metrics, including Pickscore, HPSv2.1, GenEval, CLIPscore, and ImageReward, fine-tuned on SD 2.1 as the backbone.",
        "tags": [
            "Diffusion",
            "LLMs",
            "Large Language Models",
            "Text-to-Image"
        ]
    },
    {
        "id": "127",
        "title": "A Multimodal PDE Foundation Model for Prediction and Scientific Text Descriptions",
        "author": [
            "Elisa Negrini",
            "Yuxuan Liu",
            "Liu Yang",
            "Stanley J. Osher",
            "Hayden Schaeffer"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06026",
        "abstract": "Neural networks are one tool for approximating non-linear differential equations used in scientific computing tasks such as surrogate modeling, real-time predictions, and optimal control. PDE foundation models utilize neural networks to train approximations to multiple differential equations simultaneously and are thus a general purpose solver that can be adapted to downstream tasks. Current PDE foundation models focus on either learning general solution operators and/or the governing system of equations, and thus only handle numerical or symbolic modalities. However, real-world applications may require more flexible data modalities, e.g. text analysis or descriptive outputs. To address this gap, we propose a novel multimodal deep learning approach that leverages a transformer-based architecture to approximate solution operators for a wide variety of ODEs and PDEs. Our method integrates numerical inputs, such as equation parameters and initial conditions, with text descriptions of physical processes or system dynamics. This enables our model to handle settings where symbolic representations may be incomplete or unavailable. In addition to providing accurate numerical predictions, our approach generates interpretable scientific text descriptions, offering deeper insights into the underlying dynamics and solution properties. The numerical experiments show that our model provides accurate solutions for in-distribution data (with average relative error less than 3.3%) and out-of-distribution data (average relative error less than 7.8%) together with precise text descriptions (with correct descriptions generated 100% of times). In certain tests, the model is also shown to be capable of extrapolating solutions in time.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "128",
        "title": "DiTASK: Multi-Task Fine-Tuning with Diffeomorphic Transformations",
        "author": [
            "Krishna Sri Ipsit Mantri",
            "Carola-Bibiane SchÃ¶nlieb",
            "Bruno Ribeiro",
            "Chaim Baskin",
            "Moshe Eliasof"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06029",
        "abstract": "Pre-trained Vision Transformers now serve as powerful tools for computer vision. Yet, efficiently adapting them for multiple tasks remains a challenge that arises from the need to modify the rich hidden representations encoded by the learned weight matrices, without inducing interference between tasks. Current parameter-efficient methods like LoRA, which apply low-rank updates, force tasks to compete within constrained subspaces, ultimately degrading performance. We introduce DiTASK a novel Diffeomorphic Multi-Task Fine-Tuning approach that maintains pre-trained representations by preserving weight matrix singular vectors, while enabling task-specific adaptations through neural diffeomorphic transformations of the singular values. By following this approach, DiTASK enables both shared and task-specific feature modulations with minimal added parameters. Our theoretical analysis shows that DITASK achieves full-rank updates during optimization, preserving the geometric structure of pre-trained features, and establishing a new paradigm for efficient multi-task learning (MTL). Our experiments on PASCAL MTL and NYUD show that DiTASK achieves state-of-the-art performance across four dense prediction tasks, using 75% fewer parameters than existing methods.",
        "tags": [
            "LoRA"
        ]
    },
    {
        "id": "129",
        "title": "Investigating Compositional Reasoning in Time Series Foundation Models",
        "author": [
            "Willa Potosnak",
            "Cristian Challu",
            "Mononito Goswami",
            "Kin G. Olivares",
            "MichaÅ WiliÅski",
            "Nina Å»ukowska",
            "Artur Dubrawski"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06037",
        "abstract": "Large pre-trained time series foundation models (TSFMs) have demonstrated promising zero-shot performance across a wide range of domains. However, a question remains: Do TSFMs succeed solely by memorizing training patterns, or do they possess the ability to reason? While reasoning is a topic of great interest in the study of Large Language Models (LLMs), it is undefined and largely unexplored in the context of TSFMs. In this work, inspired by language modeling literature, we formally define compositional reasoning in forecasting and distinguish it from in-distribution generalization. We evaluate the reasoning and generalization capabilities of 23 popular deep learning forecasting models on multiple synthetic and real-world datasets. Additionally, through controlled studies, we systematically examine which design choices in TSFMs contribute to improved reasoning abilities. Our study yields key insights into the impact of TSFM architecture design on compositional reasoning and generalization. We find that patch-based Transformers have the best reasoning performance, closely followed by residualized MLP-based architectures, which are 97\\% less computationally complex in terms of FLOPs and 86\\% smaller in terms of the number of trainable parameters. Interestingly, in some zero-shot out-of-distribution scenarios, these models can outperform moving average and exponential smoothing statistical baselines trained on in-distribution data. Only a few design choices, such as the tokenization method, had a significant (negative) impact on Transformer model performance.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "130",
        "title": "Provably Overwhelming Transformer Models with Designed Inputs",
        "author": [
            "Lev Stambler",
            "Seyed Sajjad Nezhadi",
            "Matthew Coudron"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06038",
        "abstract": "We develop an algorithm which, given a trained transformer model $\\mathcal{M}$ as input, as well as a string of tokens $s$ of length $n_{fix}$ and an integer $n_{free}$, can generate a mathematical proof that $\\mathcal{M}$ is ``overwhelmed'' by $s$, in time and space $\\widetilde{O}(n_{fix}^2 + n_{free}^3)$. We say that $\\mathcal{M}$ is ``overwhelmed'' by $s$ when the output of the model evaluated on this string plus any additional string $t$, $\\mathcal{M}(s + t)$, is completely insensitive to the value of the string $t$ whenever length($t$) $\\leq n_{free}$. Along the way, we prove a particularly strong worst-case form of ``over-squashing'', which we use to bound the model's behavior. Our technique uses computer-aided proofs to establish this type of operationally relevant guarantee about transformer models. We empirically test our algorithm on a single layer transformer complete with an attention head, layer-norm, MLP/ReLU layers, and RoPE positional encoding. We believe that this work is a stepping stone towards the difficult task of obtaining useful guarantees for trained transformer models.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "131",
        "title": "Benchmarking Prompt Engineering Techniques for Secure Code Generation with GPT Models",
        "author": [
            "Marc Bruni",
            "Fabio Gabrielli",
            "Mohammad Ghafari",
            "Martin Kropp"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06039",
        "abstract": "Prompt engineering reduces reasoning mistakes in Large Language Models (LLMs). However, its effectiveness in mitigating vulnerabilities in LLM-generated code remains underexplored. To address this gap, we implemented a benchmark to automatically assess the impact of various prompt engineering strategies on code security. Our benchmark leverages two peer-reviewed prompt datasets and employs static scanners to evaluate code security at scale. We tested multiple prompt engineering techniques on GPT-3.5-turbo, GPT-4o, and GPT-4o-mini. Our results show that for GPT-4o and GPT-4o-mini, a security-focused prompt prefix can reduce the occurrence of security vulnerabilities by up to 56%. Additionally, all tested models demonstrated the ability to detect and repair between 41.9% and 68.7% of vulnerabilities in previously generated code when using iterative prompting techniques. Finally, we introduce a \"prompt agent\" that demonstrates how the most effective techniques can be applied in real-world development workflows.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "132",
        "title": "LM2: Large Memory Models",
        "author": [
            "Jikun Kang",
            "Wenqi Wu",
            "Filippos Christianos",
            "Alex J. Chan",
            "Fraser Greenlee",
            "George Thomas",
            "Marvin Purtorab",
            "Andy Toulis"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06049",
        "abstract": "This paper introduces the Large Memory Model (LM2), a decoder-only Transformer architecture enhanced with an auxiliary memory module that aims to address the limitations of standard Transformers in multi-step reasoning, relational argumentation, and synthesizing information distributed over long contexts. The proposed LM2 incorporates a memory module that acts as a contextual representation repository, interacting with input tokens via cross attention and updating through gating mechanisms. To preserve the Transformers general-purpose capabilities, LM2 maintains the original information flow while integrating a complementary memory pathway. Experimental results on the BABILong benchmark demonstrate that the LM2model outperforms both the memory-augmented RMT model by 37.1% and the baseline Llama-3.2 model by 86.3% on average across tasks. LM2 exhibits exceptional capabilities in multi-hop inference, numerical reasoning, and large-context question-answering. On the MMLU dataset, it achieves a 5.0% improvement over a pre-trained vanilla model, demonstrating that its memory module does not degrade performance on general tasks. Further, in our analysis, we explore the memory interpretability, effectiveness of memory modules, and test-time behavior. Our findings emphasize the importance of explicit memory in enhancing Transformer architectures.",
        "tags": [
            "LLaMA",
            "Transformer"
        ]
    },
    {
        "id": "133",
        "title": "Online Reward-Weighted Fine-Tuning of Flow Matching with Wasserstein Regularization",
        "author": [
            "Jiajun Fan",
            "Shuaike Shen",
            "Chaoran Cheng",
            "Yuxin Chen",
            "Chumeng Liang",
            "Ge Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06061",
        "abstract": "Recent advancements in reinforcement learning (RL) have achieved great success in fine-tuning diffusion-based generative models. However, fine-tuning continuous flow-based generative models to align with arbitrary user-defined reward functions remains challenging, particularly due to issues such as policy collapse from overoptimization and the prohibitively high computational cost of likelihoods in continuous-time flows. In this paper, we propose an easy-to-use and theoretically sound RL fine-tuning method, which we term Online Reward-Weighted Conditional Flow Matching with Wasserstein-2 Regularization (ORW-CFM-W2). Our method integrates RL into the flow matching framework to fine-tune generative models with arbitrary reward functions, without relying on gradients of rewards or filtered datasets. By introducing an online reward-weighting mechanism, our approach guides the model to prioritize high-reward regions in the data manifold. To prevent policy collapse and maintain diversity, we incorporate Wasserstein-2 (W2) distance regularization into our method and derive a tractable upper bound for it in flow matching, effectively balancing exploration and exploitation of policy optimization. We provide theoretical analyses to demonstrate the convergence properties and induced data distributions of our method, establishing connections with traditional RL algorithms featuring Kullback-Leibler (KL) regularization and offering a more comprehensive understanding of the underlying mechanisms and learning behavior of our approach. Extensive experiments on tasks including target image generation, image compression, and text-image alignment demonstrate the effectiveness of our method, where our method achieves optimal policy convergence while allowing controllable trade-offs between reward maximization and diversity preservation.",
        "tags": [
            "Diffusion",
            "Flow Matching",
            "RL"
        ]
    },
    {
        "id": "134",
        "title": "Benchmarking Prompt Sensitivity in Large Language Models",
        "author": [
            "Amirhossein Razavi",
            "Mina Soltangheis",
            "Negar Arabzadeh",
            "Sara Salamat",
            "Morteza Zihayat",
            "Ebrahim Bagheri"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06065",
        "abstract": "Large language Models (LLMs) are highly sensitive to variations in prompt formulation, which can significantly impact their ability to generate accurate responses. In this paper, we introduce a new task, Prompt Sensitivity Prediction, and a dataset PromptSET designed to investigate the effects of slight prompt variations on LLM performance. Using TriviaQA and HotpotQA datasets as the foundation of our work, we generate prompt variations and evaluate their effectiveness across multiple LLMs. We benchmark the prompt sensitivity prediction task employing state-of-the-art methods from related tasks, including LLM-based self-evaluation, text classification, and query performance prediction techniques. Our findings reveal that existing methods struggle to effectively address prompt sensitivity prediction, underscoring the need to understand how information needs should be phrased for accurate LLM responses.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "135",
        "title": "Deconstructing Depression Stigma: Integrating AI-driven Data Collection and Analysis with Causal Knowledge Graphs",
        "author": [
            "Han Meng",
            "Renwen Zhang",
            "Ganyi Wang",
            "Yitian Yang",
            "Peinuan Qin",
            "Jungup Lee",
            "Yi-Chieh Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06075",
        "abstract": "Mental-illness stigma is a persistent social problem, hampering both treatment-seeking and recovery. Accordingly, there is a pressing need to understand it more clearly, but analyzing the relevant data is highly labor-intensive. Therefore, we designed a chatbot to engage participants in conversations; coded those conversations qualitatively with AI assistance; and, based on those coding results, built causal knowledge graphs to decode stigma. The results we obtained from 1,002 participants demonstrate that conversation with our chatbot can elicit rich information about people's attitudes toward depression, while our AI-assisted coding was strongly consistent with human-expert coding. Our novel approach combining large language models (LLMs) and causal knowledge graphs uncovered patterns in individual responses and illustrated the interrelationships of psychological constructs in the dataset as a whole. The paper also discusses these findings' implications for HCI researchers in developing digital interventions, decomposing human psychological constructs, and fostering inclusive attitudes.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "136",
        "title": "Debiasing Guidance for Discrete Diffusion with Sequential Monte Carlo",
        "author": [
            "Cheuk Kit Lee",
            "Paul Jeha",
            "Jes Frellsen",
            "Pietro Lio",
            "Michael Samuel Albergo",
            "Francisco Vargas"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06079",
        "abstract": "Discrete diffusion models are a class of generative models that produce samples from an approximated data distribution within a discrete state space. Often, there is a need to target specific regions of the data distribution. Current guidance methods aim to sample from a distribution with mass proportional to $p_0(x_0) p(\\zeta|x_0)^\\alpha$ but fail to achieve this in practice. We introduce a Sequential Monte Carlo algorithm that generates unbiasedly from this target distribution, utilising the learnt unconditional and guided process. We validate our approach on low-dimensional distributions, controlled images and text generations. For text generation, our method provides strong control while maintaining low perplexity compared to guidance-based approaches.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "137",
        "title": "Is a Peeled Apple Still Red? Evaluating LLMs' Ability for Conceptual Combination with Property Type",
        "author": [
            "Seokwon Song",
            "Taehyun Lee",
            "Jaewoo Ahn",
            "Jae Hyuk Sung",
            "Gunhee Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06086",
        "abstract": "Conceptual combination is a cognitive process that merges basic concepts, enabling the creation of complex expressions. During this process, the properties of combination (e.g., the whiteness of a peeled apple) can be inherited from basic concepts, newly emerge, or be canceled. However, previous studies have evaluated a limited set of properties and have not examined the generative process. To address this gap, we introduce the Conceptual Combination with Property Type dataset (CCPT), which consists of 12.3K annotated triplets of noun phrases, properties, and property types. Using CCPT, we establish three types of tasks to evaluate LLMs for conceptual combination thoroughly. Our key findings are threefold: (1) Our automatic metric grading property emergence and cancellation closely corresponds with human judgments. (2) LLMs, including OpenAI's o1, struggle to generate noun phrases which possess given emergent properties. (3) Our proposed method, inspired by cognitive psychology model that explains how relationships between concepts are formed, improves performances in all generative tasks. The dataset and experimental code are available at https://github.com/seokwon99/CCPT.git.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "138",
        "title": "ConMeC: A Dataset for Metonymy Resolution with Common Nouns",
        "author": [
            "Saptarshi Ghosh",
            "Tianyu Jiang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06087",
        "abstract": "Metonymy plays an important role in our daily communication. People naturally think about things using their most salient properties or commonly related concepts. For example, by saying \"The bus decided to skip our stop today,\" we actually mean that the bus driver made the decision, not the bus. Prior work on metonymy resolution has mainly focused on named entities. However, metonymy involving common nouns (such as desk, baby, and school) is also a frequent and challenging phenomenon. We argue that NLP systems should be capable of identifying the metonymic use of common nouns in context. We create a new metonymy dataset ConMeC, which consists of 6,000 sentences, where each sentence is paired with a target common noun and annotated by humans to indicate whether that common noun is used metonymically or not in that context. We also introduce a chain-of-thought based prompting method for detecting metonymy using large language models (LLMs). We evaluate our LLM-based pipeline, as well as a supervised BERT model on our dataset and three other metonymy datasets. Our experimental results demonstrate that LLMs could achieve performance comparable to the supervised BERT model on well-defined metonymy categories, while still struggling with instances requiring nuanced semantic understanding. Our dataset is publicly available at: https://github.com/SaptGhosh/ConMeC.",
        "tags": [
            "BERT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "139",
        "title": "CDM: Contact Diffusion Model for Multi-Contact Point Localization",
        "author": [
            "Seo Wook Han",
            "Min Jun Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06109",
        "abstract": "In this paper, we propose a Contact Diffusion Model (CDM), a novel learning-based approach for multi-contact point localization. We consider a robot equipped with joint torque sensors and a force/torque sensor at the base. By leveraging a diffusion model, CDM addresses the singularity where multiple pairs of contact points and forces produce identical sensor measurements. We formulate CDM to be conditioned on past model outputs to account for the time-dependent characteristics of the multi-contact scenarios. Moreover, to effectively address the complex shape of the robot surfaces, we incorporate the signed distance field in the denoising process. Consequently, CDM can localize contacts at arbitrary locations with high accuracy. Simulation and real-world experiments demonstrate the effectiveness of the proposed method. In particular, CDM operates at 15.97ms and, in the real world, achieves an error of 0.44cm in single-contact scenarios and 1.24cm in dual-contact scenarios.",
        "tags": [
            "Diffusion",
            "Robot"
        ]
    },
    {
        "id": "140",
        "title": "CSR-Bench: Benchmarking LLM Agents in Deployment of Computer Science Research Repositories",
        "author": [
            "Yijia Xiao",
            "Runhui Wang",
            "Luyang Kong",
            "Davor Golac",
            "Wei Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06111",
        "abstract": "The increasing complexity of computer science research projects demands more effective tools for deploying code repositories. Large Language Models (LLMs), such as Anthropic Claude and Meta Llama, have demonstrated significant advancements across various fields of computer science research, including the automation of diverse software engineering tasks. To evaluate the effectiveness of LLMs in handling complex code development tasks of research projects, particularly for NLP/CV/AI/ML/DM topics, we introduce CSR-Bench, a benchmark for Computer Science Research projects. This benchmark assesses LLMs from various aspects including accuracy, efficiency, and deployment script quality, aiming to explore their potential in conducting computer science research autonomously. We also introduce a novel framework, CSR-Agents, that utilizes multiple LLM agents to automate the deployment of GitHub code repositories of computer science research projects. Specifically, by checking instructions from markdown files and interpreting repository structures, the model generates and iteratively improves bash commands that set up the experimental environments and deploy the code to conduct research tasks. Preliminary results from CSR-Bench indicate that LLM agents can significantly enhance the workflow of repository deployment, thereby boosting developer productivity and improving the management of developmental workflows.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "141",
        "title": "Token-Domain Multiple Access: Exploiting Semantic Orthogonality for Collision Mitigation",
        "author": [
            "Li Qiao",
            "Mahdi Boloursaz Mashhadi",
            "Zhen Gao",
            "Deniz GÃ¼ndÃ¼z"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06118",
        "abstract": "Token communications is an emerging generative semantic communication concept that reduces transmission rates by using context and transformer-based token processing, with tokens serving as universal semantic units. In this paper, we propose a semantic multiple access scheme in the token domain, referred to as ToDMA, where a large number of devices share a tokenizer and a modulation codebook for source and channel coding, respectively. Specifically, the source signal is tokenized into sequences, with each token modulated into a codeword. Codewords from multiple devices are transmitted simultaneously, resulting in overlap at the receiver. The receiver detects the transmitted tokens, assigns them to their respective sources, and mitigates token collisions by leveraging context and semantic orthogonality across the devices' messages. Simulations demonstrate that the proposed ToDMA framework outperforms context-unaware orthogonal and non-orthogonal communication methods in image transmission tasks, achieving lower latency and better image quality.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "142",
        "title": "Self-Correcting Decoding with Generative Feedback for Mitigating Hallucinations in Large Vision-Language Models",
        "author": [
            "Ce Zhang",
            "Zifu Wan",
            "Zhehan Kan",
            "Martin Q. Ma",
            "Simon Stepputtis",
            "Deva Ramanan",
            "Russ Salakhutdinov",
            "Louis-Philippe Morency",
            "Katia Sycara",
            "Yaqi Xie"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06130",
        "abstract": "While recent Large Vision-Language Models (LVLMs) have shown remarkable performance in multi-modal tasks, they are prone to generating hallucinatory text responses that do not align with the given visual input, which restricts their practical applicability in real-world scenarios. In this work, inspired by the observation that the text-to-image generation process is the inverse of image-conditioned response generation in LVLMs, we explore the potential of leveraging text-to-image generative models to assist in mitigating hallucinations in LVLMs. We discover that generative models can offer valuable self-feedback for mitigating hallucinations at both the response and token levels. Building on this insight, we introduce self-correcting Decoding with Generative Feedback (DeGF), a novel training-free algorithm that incorporates feedback from text-to-image generative models into the decoding process to effectively mitigate hallucinations in LVLMs. Specifically, DeGF generates an image from the initial response produced by LVLMs, which acts as an auxiliary visual reference and provides self-feedback to verify and correct the initial response through complementary or contrastive decoding. Extensive experimental results validate the effectiveness of our approach in mitigating diverse types of hallucinations, consistently surpassing state-of-the-art methods across six benchmarks. Code is available at https://github.com/zhangce01/DeGF.",
        "tags": [
            "Text-to-Image"
        ]
    },
    {
        "id": "143",
        "title": "Enhanced Hybrid Deep Learning Approach for Botnet Attacks Detection in IoT Environment",
        "author": [
            "A. Karthick kumar",
            "S. Rathnamala",
            "T. Vijayashanthi",
            "M. Prabhananthakumar",
            "Alavikunhu Panthakkan",
            "Shadi Atalla",
            "Wathiq Mansoor"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06138",
        "abstract": "Cyberattacks in an Internet of Things (IoT) environment can have significant impacts because of the interconnected nature of devices and systems. An attacker uses a network of compromised IoT devices in a botnet attack to carry out various harmful activities. Detecting botnet attacks poses several challenges because of the intricate and evolving nature of these threats. Botnet attacks erode trust in IoT devices and systems, undermining confidence in their security, reliability, and integrity. Deep learning techniques have significantly enhanced the detection of botnet attacks due to their ability to analyze and learn from complex patterns in data. This research proposed the stacking of Deep convolutional neural networks, Bi-Directional Long Short-Term Memory (Bi-LSTM), Bi-Directional Gated Recurrent Unit (Bi-GRU), and Recurrent Neural Networks (RNN) for botnet attacks detection. The UNSW-NB15 dataset is utilized for botnet attacks detection. According to experimental results, the proposed model accurately provides for the intricate patterns and features of botnet attacks, with a testing accuracy of 99.76%. The proposed model also identifies botnets with a high ROC-AUC curve value of 99.18%. A performance comparison of the proposed method with existing state-of-the-art models confirms its higher performance. The outcomes of this research could strengthen cyber security procedures and safeguard against new attacks.",
        "tags": [
            "Detection",
            "RNN"
        ]
    },
    {
        "id": "144",
        "title": "LCIRC: A Recurrent Compression Approach for Efficient Long-form Context and Query Dependent Modeling in LLMs",
        "author": [
            "Sumin An",
            "Junyoung Sung",
            "Wonpyo Park",
            "Chanjun Park",
            "Paul Hongsuck Seo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06139",
        "abstract": "While large language models (LLMs) excel in generating coherent and contextually rich outputs, their capacity to efficiently handle long-form contexts is limited by fixed-length position embeddings. Additionally, the computational cost of processing long sequences increases quadratically, making it challenging to extend context length. To address these challenges, we propose Long-form Context Injection with Recurrent Compression (LCIRC), a method that enables the efficient processing long-form sequences beyond the model's length limit through recurrent compression without retraining the entire model. We further introduce query dependent context modeling, which selectively compresses query-relevant information, ensuring that the model retains the most pertinent content. Our empirical results demonstrate that Query Dependent LCIRC (QD-LCIRC) significantly improves LLM's ability to manage extended contexts, making it well-suited for tasks that require both comprehensive context understanding and query relevance.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "145",
        "title": "Animate Anyone 2: High-Fidelity Character Image Animation with Environment Affordance",
        "author": [
            "Li Hu",
            "Guangyuan Wang",
            "Zhen Shen",
            "Xin Gao",
            "Dechao Meng",
            "Lian Zhuo",
            "Peng Zhang",
            "Bang Zhang",
            "Liefeng Bo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06145",
        "abstract": "Recent character image animation methods based on diffusion models, such as Animate Anyone, have made significant progress in generating consistent and generalizable character animations. However, these approaches fail to produce reasonable associations between characters and their environments. To address this limitation, we introduce Animate Anyone 2, aiming to animate characters with environment affordance. Beyond extracting motion signals from source video, we additionally capture environmental representations as conditional inputs. The environment is formulated as the region with the exclusion of characters and our model generates characters to populate these regions while maintaining coherence with the environmental context. We propose a shape-agnostic mask strategy that more effectively characterizes the relationship between character and environment. Furthermore, to enhance the fidelity of object interactions, we leverage an object guider to extract features of interacting objects and employ spatial blending for feature injection. We also introduce a pose modulation strategy that enables the model to handle more diverse motion patterns. Experimental results demonstrate the superior performance of the proposed method.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "146",
        "title": "LegalViz: Legal Text Visualization by Text To Diagram Generation",
        "author": [
            "Eri Onami",
            "Taiki Miyanishi",
            "Koki Maeda",
            "Shuhei Kurita"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06147",
        "abstract": "Legal documents including judgments and court orders require highly sophisticated legal knowledge for understanding. To disclose expert knowledge for non-experts, we explore the problem of visualizing legal texts with easy-to-understand diagrams and propose a novel dataset of LegalViz with 23 languages and 7,010 cases of legal document and visualization pairs, using the DOT graph description language of Graphviz. LegalViz provides a simple diagram from a complicated legal corpus identifying legal entities, transactions, legal sources, and statements at a glance, that are essential in each judgment. In addition, we provide new evaluation metrics for the legal diagram visualization by considering graph structures, textual similarities, and legal contents. We conducted empirical studies on few-shot and finetuning large language models for generating legal diagrams and evaluated them with these metrics, including legal content-based evaluation within 23 languages. Models trained with LegalViz outperform existing models including GPTs, confirming the effectiveness of our dataset.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "147",
        "title": "Optimizing Knowledge Integration in Retrieval-Augmented Generation with Self-Selection",
        "author": [
            "Yan Weng",
            "Fengbin Zhu",
            "Tong Ye",
            "Haoyan Liu",
            "Fuli Feng",
            "Tat-Seng Chua"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06148",
        "abstract": "Retrieval-Augmented Generation (RAG), which integrates external knowledge into Large Language Models (LLMs), has proven effective in enabling LLMs to produce more accurate and reliable responses. However, it remains a significant challenge how to effectively integrate external retrieved knowledge with internal parametric knowledge in LLMs. In this work, we propose a novel Self-Selection RAG framework, where the LLM is made to select from pairwise responses generated with internal parametric knowledge solely and with external retrieved knowledge together to achieve enhanced accuracy. To this end, we devise a Self-Selection-RGP method to enhance the capabilities of the LLM in both generating and selecting the correct answer, by training the LLM with Direct Preference Optimization (DPO) over a curated Retrieval Generation Preference (RGP) dataset. Experimental results with two open-source LLMs (i.e., Llama2-13B-Chat and Mistral-7B) well demonstrate the superiority of our approach over other baseline methods on Natural Questions (NQ) and TrivialQA datasets.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "148",
        "title": "Scaling Public Health Text Annotation: Zero-Shot Learning vs. Crowdsourcing for Improved Efficiency and Labeling Accuracy",
        "author": [
            "Kamyar Kazari",
            "Yong Chen",
            "Zahra Shakeri"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06150",
        "abstract": "Public health researchers are increasingly interested in using social media data to study health-related behaviors, but manually labeling this data can be labor-intensive and costly. This study explores whether zero-shot labeling using large language models (LLMs) can match or surpass conventional crowd-sourced annotation for Twitter posts related to sleep disorders, physical activity, and sedentary behavior. Multiple annotation pipelines were designed to compare labels produced by domain experts, crowd workers, and LLM-driven approaches under varied prompt-engineering strategies. Our findings indicate that LLMs can rival human performance in straightforward classification tasks and significantly reduce labeling time, yet their accuracy diminishes for tasks requiring more nuanced domain knowledge. These results clarify the trade-offs between automated scalability and human expertise, demonstrating conditions under which LLM-based labeling can be efficiently integrated into public health research without undermining label quality.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "149",
        "title": "Powerformer: A Transformer with Weighted Causal Attention for Time-series Forecasting",
        "author": [
            "Kareem Hegazy",
            "Michael W. Mahoney",
            "N. Benjamin Erichson"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06151",
        "abstract": "Transformers have recently shown strong performance in time-series forecasting, but their all-to-all attention mechanism overlooks the (temporal) causal and often (temporally) local nature of data. We introduce Powerformer, a novel Transformer variant that replaces noncausal attention weights with causal weights that are reweighted according to a smooth heavy-tailed decay. This simple yet effective modification endows the model with an inductive bias favoring temporally local dependencies, while still allowing sufficient flexibility to learn the unique correlation structure of each dataset. Our empirical results demonstrate that Powerformer not only achieves state-of-the-art accuracy on public time-series benchmarks, but also that it offers improved interpretability of attention patterns. Our analyses show that the model's locality bias is amplified during training, demonstrating an interplay between time-series data and power-law-based attention. These findings highlight the importance of domain-specific modifications to the Transformer architecture for time-series forecasting, and they establish Powerformer as a strong, efficient, and principled baseline for future research and real-world applications.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "150",
        "title": "Low Tensor-Rank Adaptation of Kolmogorov--Arnold Networks",
        "author": [
            "Yihang Gao",
            "Michael K. Ng",
            "Vincent Y.F. Tan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06153",
        "abstract": "Kolmogorov--Arnold networks (KANs) have demonstrated their potential as an alternative to multi-layer perceptions (MLPs) in various domains, especially for science-related tasks. However, transfer learning of KANs remains a relatively unexplored area. In this paper, inspired by Tucker decomposition of tensors and evidence on the low tensor-rank structure in KAN parameter updates, we develop low tensor-rank adaptation (LoTRA) for fine-tuning KANs. We study the expressiveness of LoTRA based on Tucker decomposition approximations. Furthermore, we provide a theoretical analysis to select the learning rates for each LoTRA component to enable efficient training. Our analysis also shows that using identical learning rates across all components leads to inefficient training, highlighting the need for an adaptive learning rate strategy. Beyond theoretical insights, we explore the application of LoTRA for efficiently solving various partial differential equations (PDEs) by fine-tuning KANs. Additionally, we propose Slim KANs that incorporate the inherent low-tensor-rank properties of KAN parameter tensors to reduce model size while maintaining superior performance. Experimental results validate the efficacy of the proposed learning rate selection strategy and demonstrate the effectiveness of LoTRA for transfer learning of KANs in solving PDEs. Further evaluations on Slim KANs for function representation and image classification tasks highlight the expressiveness of LoTRA and the potential for parameter reduction through low tensor-rank decomposition.",
        "tags": [
            "KAN",
            "Kolmogorov-Arnold Networks"
        ]
    },
    {
        "id": "151",
        "title": "Efficient-vDiT: Efficient Video Diffusion Transformers With Attention Tile",
        "author": [
            "Hangliang Ding",
            "Dacheng Li",
            "Runlong Su",
            "Peiyuan Zhang",
            "Zhijie Deng",
            "Ion Stoica",
            "Hao Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06155",
        "abstract": "Despite the promise of synthesizing high-fidelity videos, Diffusion Transformers (DiTs) with 3D full attention suffer from expensive inference due to the complexity of attention computation and numerous sampling steps. For example, the popular Open-Sora-Plan model consumes more than 9 minutes for generating a single video of 29 frames. This paper addresses the inefficiency issue from two aspects: 1) Prune the 3D full attention based on the redundancy within video data; We identify a prevalent tile-style repetitive pattern in the 3D attention maps for video data, and advocate a new family of sparse 3D attention that holds a linear complexity w.r.t. the number of video frames. 2) Shorten the sampling process by adopting existing multi-step consistency distillation; We split the entire sampling trajectory into several segments and perform consistency distillation within each one to activate few-step generation capacities. We further devise a three-stage training pipeline to conjoin the low-complexity attention and few-step generation capacities. Notably, with 0.1% pretraining data, we turn the Open-Sora-Plan-1.2 model into an efficient one that is 7.4x -7.8x faster for 29 and 93 frames 720p video generation with a marginal performance trade-off in VBench. In addition, we demonstrate that our approach is amenable to distributed inference, achieving an additional 3.91x speedup when running on 4 GPUs with sequence parallelism.",
        "tags": [
            "3D",
            "Diffusion",
            "Sora",
            "Video Generation"
        ]
    },
    {
        "id": "152",
        "title": "Universal Approximation of Visual Autoregressive Transformers",
        "author": [
            "Yifang Chen",
            "Xiaoyu Li",
            "Yingyu Liang",
            "Zhenmei Shi",
            "Zhao Song"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06167",
        "abstract": "We investigate the fundamental limits of transformer-based foundation models, extending our analysis to include Visual Autoregressive (VAR) transformers. VAR represents a big step toward generating images using a novel, scalable, coarse-to-fine ``next-scale prediction'' framework. These models set a new quality bar, outperforming all previous methods, including Diffusion Transformers, while having state-of-the-art performance for image synthesis tasks. Our primary contributions establish that, for single-head VAR transformers with a single self-attention layer and single interpolation layer, the VAR Transformer is universal. From the statistical perspective, we prove that such simple VAR transformers are universal approximators for any image-to-image Lipschitz functions. Furthermore, we demonstrate that flow-based autoregressive transformers inherit similar approximation capabilities. Our results provide important design principles for effective and computationally efficient VAR Transformer strategies that can be used to extend their utility to more sophisticated VAR models in image generation and other related areas.",
        "tags": [
            "Diffusion",
            "Transformer"
        ]
    },
    {
        "id": "153",
        "title": "Error analysis of the space-time interface-fitted finite element method for an inverse source problem for an advection-diffusion equation with moving subdomains",
        "author": [
            "Thi Thanh Mai Ta",
            "Quang Huy Nguyen",
            "Dinh Nho HÃ o"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06176",
        "abstract": "A space-time interface-fitted approximation of an inverse source problem for the advection-diffusion equation with moving subdomains is investigated. The problem is reformulated as an optimization problem using Tikhonov regularization. A space-time interface-fitted method is employed to discretize the advection-diffusion equation, where two second-order a priori error estimates are established with respect to the $L^2$-norms. Additionally, the regularized source is discretized sequentially using the variational approach, the element-wise constant discretization, and finally, the post-processing strategy. Optimal error estimates are achieved for the first two methods, while superlinear convergence is obtained for the third. Furthermore, a priori choices for the regularization parameter are proposed, depending on the mesh size and noise level. These choices ensure that the discrete and post-processing solutions strongly converge to the exact source as the mesh size and noise level tend to zero.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "154",
        "title": "RideKE: Leveraging Low-Resource, User-Generated Twitter Content for Sentiment and Emotion Detection in Kenyan Code-Switched Dataset",
        "author": [
            "Naome A. Etori",
            "Maria L. Gini"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06180",
        "abstract": "Social media has become a crucial open-access platform for individuals to express opinions and share experiences. However, leveraging low-resource language data from Twitter is challenging due to scarce, poor-quality content and the major variations in language use, such as slang and code-switching. Identifying tweets in these languages can be difficult as Twitter primarily supports high-resource languages. We analyze Kenyan code-switched data and evaluate four state-of-the-art (SOTA) transformer-based pretrained models for sentiment and emotion classification, using supervised and semi-supervised methods. We detail the methodology behind data collection and annotation, and the challenges encountered during the data curation phase. Our results show that XLM-R outperforms other models; for sentiment analysis, XLM-R supervised model achieves the highest accuracy (69.2\\%) and F1 score (66.1\\%), XLM-R semi-supervised (67.2\\% accuracy, 64.1\\% F1 score). In emotion analysis, DistilBERT supervised leads in accuracy (59.8\\%) and F1 score (31\\%), mBERT semi-supervised (accuracy (59\\% and F1 score 26.5\\%). AfriBERTa models show the lowest accuracy and F1 scores. All models tend to predict neutral sentiment, with Afri-BERT showing the highest bias and unique sensitivity to empathy emotion. https://github.com/NEtori21/Ride_hailing",
        "tags": [
            "BERT",
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "155",
        "title": "Can LLMs Replace Human Evaluators? An Empirical Study of LLM-as-a-Judge in Software Engineering",
        "author": [
            "Ruiqi Wang",
            "Jiyu Guo",
            "Cuiyun Gao",
            "Guodong Fan",
            "Chun Yong Chong",
            "Xin Xia"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06193",
        "abstract": "Recently, large language models (LLMs) have been deployed to tackle various software engineering (SE) tasks like code generation, significantly advancing the automation of SE tasks. However, assessing the quality of these LLM-generated code and text remains challenging. The commonly used Pass@k metric necessitates extensive unit tests and configured environments, demands a high labor cost, and is not suitable for evaluating LLM-generated text. Conventional metrics like BLEU, which measure only lexical rather than semantic similarity, have also come under scrutiny. In response, a new trend has emerged to employ LLMs for automated evaluation, known as LLM-as-a-judge. These LLM-as-a-judge methods are claimed to better mimic human assessment than conventional metrics without relying on high-quality reference answers. Nevertheless, their exact human alignment in SE tasks remains unexplored. In this paper, we empirically explore LLM-as-a-judge methods for evaluating SE tasks, focusing on their alignment with human judgments. We select seven LLM-as-a-judge methods that utilize general-purpose LLMs, alongside two LLMs specifically fine-tuned for evaluation. After generating and manually scoring LLM responses on three recent SE datasets of code translation, code generation, and code summarization, we then prompt these methods to evaluate each response. Finally, we compare the scores generated by these methods with human evaluation. The results indicate that output-based methods reach the highest Pearson correlation of 81.32 and 68.51 with human scores in code translation and generation, achieving near-human evaluation, noticeably outperforming ChrF++, one of the best conventional metrics, at 34.23 and 64.92. Such output-based methods prompt LLMs to output judgments directly, and exhibit more balanced score distributions that resemble human score patterns. Finally, we provide...",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "156",
        "title": "Timing Matters: How Using LLMs at Different Timings Influences Writers' Perceptions and Ideation Outcomes in AI-Assisted Ideation",
        "author": [
            "Peinuan Qin",
            "Chi-Lan Yang",
            "Jingshu Li",
            "Jing Wen",
            "Yi-Chieh Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06197",
        "abstract": "Large Language Models (LLMs) have been widely used to support ideation in the writing process. However, whether generating ideas with the help of LLMs leads to idea fixation or idea expansion is unclear. This study examines how different timings of LLM usage - either at the beginning or after independent ideation - affect people's perceptions and ideation outcomes in a writing task. In a controlled experiment with 60 participants, we found that using LLMs from the beginning reduced the number of original ideas and lowered creative self-efficacy and self-credit, mediated by changes in autonomy and ownership. We discuss the challenges and opportunities associated with using LLMs to assist in idea generation. We propose delaying the use of LLMs to support ideation while considering users' self-efficacy, autonomy, and ownership of the ideation outcomes.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "157",
        "title": "Non-literal Understanding of Number Words by Language Models",
        "author": [
            "Polina Tsvilodub",
            "Kanishk Gandhi",
            "Haoran Zhao",
            "Jan-Philipp FrÃ¤nken",
            "Michael Franke",
            "Noah D. Goodman"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06204",
        "abstract": "Humans naturally interpret numbers non-literally, effortlessly combining context, world knowledge, and speaker intent. We investigate whether large language models (LLMs) interpret numbers similarly, focusing on hyperbole and pragmatic halo effects. Through systematic comparison with human data and computational models of pragmatic reasoning, we find that LLMs diverge from human interpretation in striking ways. By decomposing pragmatic reasoning into testable components, grounded in the Rational Speech Act framework, we pinpoint where LLM processing diverges from human cognition -- not in prior knowledge, but in reasoning with it. This insight leads us to develop a targeted solution -- chain-of-thought prompting inspired by an RSA model makes LLMs' interpretations more human-like. Our work demonstrates how computational cognitive models can both diagnose AI-human differences and guide development of more human-like language understanding capabilities.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "158",
        "title": "C-3PO: Compact Plug-and-Play Proxy Optimization to Achieve Human-like Retrieval-Augmented Generation",
        "author": [
            "Guoxin Chen",
            "Minpeng Liao",
            "Peiying Yu",
            "Dingmin Wang",
            "Zile Qiao",
            "Chao Yang",
            "Xin Zhao",
            "Kai Fan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06205",
        "abstract": "Retrieval-augmented generation (RAG) systems face a fundamental challenge in aligning independently developed retrievers and large language models (LLMs). Existing approaches typically involve modifying either component or introducing simple intermediate modules, resulting in practical limitations and sub-optimal performance. Inspired by human search behavior -- typically involving a back-and-forth process of proposing search queries and reviewing documents, we propose C-3PO, a proxy-centric framework that facilitates communication between retrievers and LLMs through a lightweight multi-agent system. Our framework implements three specialized agents that collaboratively optimize the entire RAG pipeline without altering the retriever and LLMs. These agents work together to assess the need for retrieval, generate effective queries, and select information suitable for the LLMs. To enable effective multi-agent coordination, we develop a tree-structured rollout approach for reward credit assignment in reinforcement learning. Extensive experiments in both in-domain and out-of-distribution scenarios demonstrate that C-3PO significantly enhances RAG performance while maintaining plug-and-play flexibility and superior generalization capabilities.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "159",
        "title": "Unveiling the Capabilities of Large Language Models in Detecting Offensive Language with Annotation Disagreement",
        "author": [
            "Junyu Lu",
            "Kai Ma",
            "Kaichun Wang",
            "Kelaiti Xiao",
            "Roy Ka-Wei Lee",
            "Bo Xu",
            "Liang Yang",
            "Hongfei Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06207",
        "abstract": "LLMs are widely used for offensive language detection due to their advanced capability. However, the challenges posed by human annotation disagreement in real-world datasets remain underexplored. These disagreement samples are difficult to detect due to their ambiguous nature. Additionally, the confidence of LLMs in processing disagreement samples can provide valuable insights into their alignment with human annotators. To address this gap, we systematically evaluate the ability of LLMs to detect offensive language with annotation disagreement. We compare the binary accuracy of multiple LLMs across varying annotation agreement levels and analyze the relationship between LLM confidence and annotation agreement. Furthermore, we investigate the impact of disagreement samples on LLM decision-making during few-shot learning and instruction fine-tuning. Our findings highlight the challenges posed by disagreement samples and offer guidance for improving LLM-based offensive language detection.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "160",
        "title": "LessLeak-Bench: A First Investigation of Data Leakage in LLMs Across 83 Software Engineering Benchmarks",
        "author": [
            "Xin Zhou",
            "Martin Weyssow",
            "Ratnadira Widyasari",
            "Ting Zhang",
            "Junda He",
            "Yunbo Lyu",
            "Jianming Chang",
            "Beiqi Zhang",
            "Dan Huang",
            "David Lo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06215",
        "abstract": "Large Language Models (LLMs) are widely utilized in software engineering (SE) tasks, such as code generation and automated program repair. However, their reliance on extensive and often undisclosed pre-training datasets raises significant concerns about data leakage, where the evaluation benchmark data is unintentionally ``seen'' by LLMs during the model's construction phase. The data leakage issue could largely undermine the validity of LLM-based research and evaluations. Despite the increasing use of LLMs in the SE community, there is no comprehensive study that assesses the extent of data leakage in SE benchmarks for LLMs yet. To address this gap, this paper presents the first large-scale analysis of data leakage in 83 SE benchmarks concerning LLMs. Our results show that in general, data leakage in SE benchmarks is minimal, with average leakage ratios of only 4.8\\%, 2.8\\%, and 0.7\\% for Python, Java, and C/C++ benchmarks, respectively. However, some benchmarks exhibit relatively higher leakage ratios, which raises concerns about their bias in evaluation. For instance, QuixBugs and BigCloneBench have leakage ratios of 100.0\\% and 55.7\\%, respectively. Furthermore, we observe that data leakage has a substantial impact on LLM evaluation. We also identify key causes of high data leakage, such as the direct inclusion of benchmark data in pre-training datasets and the use of coding platforms like LeetCode for benchmark construction. To address the data leakage, we introduce \\textbf{LessLeak-Bench}, a new benchmark that removes leaked samples from the 83 SE benchmarks, enabling more reliable LLM evaluations in future research. Our study enhances the understanding of data leakage in SE benchmarks and provides valuable insights for future research involving LLMs in SE.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "161",
        "title": "Fully Exploiting Vision Foundation Model's Profound Prior Knowledge for Generalizable RGB-Depth Driving Scene Parsing",
        "author": [
            "Sicen Guo",
            "Tianyou Wen",
            "Chuang-Wei Liu",
            "Qijun Chen",
            "Rui Fan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06219",
        "abstract": "Recent vision foundation models (VFMs), typically based on Vision Transformer (ViT), have significantly advanced numerous computer vision tasks. Despite their success in tasks focused solely on RGB images, the potential of VFMs in RGB-depth driving scene parsing remains largely under-explored. In this article, we take one step toward this emerging research area by investigating a feasible technique to fully exploit VFMs for generalizable RGB-depth driving scene parsing. Specifically, we explore the inherent characteristics of RGB and depth data, thereby presenting a Heterogeneous Feature Integration Transformer (HFIT). This network enables the efficient extraction and integration of comprehensive heterogeneous features without re-training ViTs. Relative depth prediction results from VFMs, used as inputs to the HFIT side adapter, overcome the limitations of the dependence on depth maps. Our proposed HFIT demonstrates superior performance compared to all other traditional single-modal and data-fusion scene parsing networks, pre-trained VFMs, and ViT adapters on the Cityscapes and KITTI Semantics datasets. We believe this novel strategy paves the way for future innovations in VFM-based data-fusion techniques for driving scene parsing. Our source code is publicly available at https://mias.group/HFIT.",
        "tags": [
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "162",
        "title": "FunduSAM: A Specialized Deep Learning Model for Enhanced Optic Disc and Cup Segmentation in Fundus Images",
        "author": [
            "Jinchen Yu",
            "Yongwei Nie",
            "Fei Qi",
            "Wenxiong Liao",
            "Hongmin Cai"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06220",
        "abstract": "The Segment Anything Model (SAM) has gained popularity as a versatile image segmentation method, thanks to its strong generalization capabilities across various domains. However, when applied to optic disc (OD) and optic cup (OC) segmentation tasks, SAM encounters challenges due to the complex structures, low contrast, and blurred boundaries typical of fundus images, leading to suboptimal performance. To overcome these challenges, we introduce a novel model, FunduSAM, which incorporates several Adapters into SAM to create a deep network specifically designed for OD and OC segmentation. The FunduSAM utilizes Adapter into each transformer block after encoder for parameter fine-tuning (PEFT). It enhances SAM's feature extraction capabilities by designing a Convolutional Block Attention Module (CBAM), addressing issues related to blurred boundaries and low contrast. Given the unique requirements of OD and OC segmentation, polar transformation is used to convert the original fundus OD images into a format better suited for training and evaluating FunduSAM. A joint loss is used to achieve structure preservation between the OD and OC, while accurate segmentation. Extensive experiments on the REFUGE dataset, comprising 1,200 fundus images, demonstrate the superior performance of FunduSAM compared to five mainstream approaches.",
        "tags": [
            "SAM",
            "Segment Anything",
            "Segmentation",
            "Transformer"
        ]
    },
    {
        "id": "163",
        "title": "Confidence Improves Self-Consistency in LLMs",
        "author": [
            "Amir Taubenfeld",
            "Tom Sheffer",
            "Eran Ofek",
            "Amir Feder",
            "Ariel Goldstein",
            "Zorik Gekhman",
            "Gal Yona"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06233",
        "abstract": "Self-consistency decoding enhances LLMs' performance on reasoning tasks by sampling diverse reasoning paths and selecting the most frequent answer. However, it is computationally expensive, as sampling many of these (lengthy) paths is required to increase the chances that the correct answer emerges as the most frequent one. To address this, we introduce Confidence-Informed Self-Consistency (CISC). CISC performs a weighted majority vote based on confidence scores obtained directly from the model. By prioritizing high-confidence paths, it can identify the correct answer with a significantly smaller sample size. When tested on nine models and four datasets, CISC outperforms self-consistency in nearly all configurations, reducing the required number of reasoning paths by over 40% on average. In addition, we introduce the notion of within-question confidence evaluation, after showing that standard evaluation methods are poor predictors of success in distinguishing correct and incorrect answers to the same question. In fact, the most calibrated confidence method proved to be the least effective for CISC. Lastly, beyond these practical implications, our results and analyses show that LLMs can effectively judge the correctness of their own outputs, contributing to the ongoing debate on this topic.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "164",
        "title": "Evaluating Entity Retrieval in Electronic Health Records: a Semantic Gap Perspective",
        "author": [
            "Zhengyun Zhao",
            "Hongyi Yuan",
            "Jingjing Liu",
            "Haichao Chen",
            "Huaiyuan Ying",
            "Songchi Zhou",
            "Sheng Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06252",
        "abstract": "Entity retrieval plays a crucial role in the utilization of Electronic Health Records (EHRs) and is applied across a wide range of clinical practices. However, a comprehensive evaluation of this task is lacking due to the absence of a public benchmark. In this paper, we propose the development and release of a novel benchmark for evaluating entity retrieval in EHRs, with a particular focus on the semantic gap issue. Using discharge summaries from the MIMIC-III dataset, we incorporate ICD codes and prescription labels associated with the notes as queries, and annotate relevance judgments using GPT-4. In total, we use 1,000 patient notes, generate 1,246 queries, and provide over 77,000 relevance annotations. To offer the first assessment of the semantic gap, we introduce a novel classification system for relevance matches. Leveraging GPT-4, we categorize each relevant pair into one of five categories: string, synonym, abbreviation, hyponym, and implication. Using the proposed benchmark, we evaluate several retrieval methods, including BM25, query expansion, and state-of-the-art dense retrievers. Our findings show that BM25 provides a strong baseline but struggles with semantic matches. Query expansion significantly improves performance, though it slightly reduces string match capabilities. Dense retrievers outperform traditional methods, particularly for semantic matches, and general-domain dense retrievers often surpass those trained specifically in the biomedical domain.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "165",
        "title": "K-ON: Stacking Knowledge On the Head Layer of Large Language Model",
        "author": [
            "Lingbing Guo",
            "Yichi Zhang",
            "Zhongpu Bo",
            "Zhuo Chen",
            "Mengshu Sun",
            "Zhiqiang Zhang",
            "Wen Zhang",
            "Huajun Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06257",
        "abstract": "Recent advancements in large language models (LLMs) have significantly improved various natural language processing (NLP) tasks. Typically, LLMs are trained to predict the next token, aligning well with many NLP tasks. However, in knowledge graph (KG) scenarios, entities are the fundamental units and identifying an entity requires at least several tokens. This leads to a granularity mismatch between KGs and natural languages. To address this issue, we propose K-ON, which integrates KG knowledge into the LLM by employing multiple head layers for next k-step prediction. K-ON can not only generate entity-level results in one step, but also enables contrastive loss against entities, which is the most powerful tool in KG representation learning. Experimental results show that K-ON outperforms state-of-the-art methods that incorporate text and even the other modalities.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "166",
        "title": "Emergent Response Planning in LLM",
        "author": [
            "Zhichen Dong",
            "Zhanhui Zhou",
            "Zhixuan Liu",
            "Chao Yang",
            "Chaochao Lu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06258",
        "abstract": "In this work, we argue that large language models (LLMs), though trained to predict only the next token, exhibit emergent planning behaviors: $\\textbf{their hidden representations encode future outputs beyond the next token}$. Through simple probing, we demonstrate that LLM prompt representations encode global attributes of their entire responses, including $\\textit{structural attributes}$ (response length, reasoning steps), $\\textit{content attributes}$ (character choices in storywriting, multiple-choice answers at the end of response), and $\\textit{behavioral attributes}$ (answer confidence, factual consistency). In addition to identifying response planning, we explore how it scales with model size across tasks and how it evolves during generation. The findings that LLMs plan ahead for the future in their hidden representations suggests potential applications for improving transparency and generation control.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "167",
        "title": "Beyond Batch Learning: Global Awareness Enhanced Domain Adaptation",
        "author": [
            "Lingkun Luo",
            "Shiqiang Hu",
            "Liming Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06272",
        "abstract": "In domain adaptation (DA), the effectiveness of deep learning-based models is often constrained by batch learning strategies that fail to fully apprehend the global statistical and geometric characteristics of data distributions. Addressing this gap, we introduce 'Global Awareness Enhanced Domain Adaptation' (GAN-DA), a novel approach that transcends traditional batch-based limitations. GAN-DA integrates a unique predefined feature representation (PFR) to facilitate the alignment of cross-domain distributions, thereby achieving a comprehensive global statistical awareness. This representation is innovatively expanded to encompass orthogonal and common feature aspects, which enhances the unification of global manifold structures and refines decision boundaries for more effective DA. Our extensive experiments, encompassing 27 diverse cross-domain image classification tasks, demonstrate GAN-DA's remarkable superiority, outperforming 24 established DA methods by a significant margin. Furthermore, our in-depth analyses shed light on the decision-making processes, revealing insights into the adaptability and efficiency of GAN-DA. This approach not only addresses the limitations of existing DA methodologies but also sets a new benchmark in the realm of domain adaptation, offering broad implications for future research and applications in this field.",
        "tags": [
            "GAN"
        ]
    },
    {
        "id": "168",
        "title": "Liquid Welfare and Revenue Monotonicity in Adaptive Clinching Auctions",
        "author": [
            "Ryosuke Sato"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06278",
        "abstract": "This study explores the monotonicity of adaptive clinching auctions -- a key mechanism in budget-constrained auctions -- with respect to fluctuations in the number of bidders. Specifically, we investigate how the addition of new bidders affect efficiency and revenue. In a symmetric setting, where all bidders have equal budgets, we show that while the allocated goods and payments for many bidders decrease, overall both liquid welfare and revenue weakly increase. Our analysis also extends to scenarios where bidders arrive online during the auction. In contrast, for asymmetric budgets, we provide counterexamples showing that these monotonicity properties no longer hold. These findings contribute to a better theoretical understanding of budget-constrained auctions and offer insights into the behavior of adaptive clinching auctions in social networks, where new bidders emerge through information diffusion.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "169",
        "title": "DebateBench: A Challenging Long Context Reasoning Benchmark For Large Language Models",
        "author": [
            "Utkarsh Tiwari",
            "Aryan Seth",
            "Adi Mukherjee",
            "Kaavya Mer",
            "Kavish",
            "Dhruv Kumar"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06279",
        "abstract": "We introduce DebateBench, a novel dataset consisting of an extensive collection of transcripts and metadata from some of the world's most prestigious competitive debates. The dataset consists of British Parliamentary debates from prestigious debating tournaments on diverse topics, annotated with detailed speech-level scores and house rankings sourced from official adjudication data. We curate 256 speeches across 32 debates with each debate being over 1 hour long with each input being an average of 32,000 tokens. Designed to capture long-context, large-scale reasoning tasks, DebateBench provides a benchmark for evaluating modern large language models (LLMs) on their ability to engage in argumentation, deliberation, and alignment with human experts. To do well on DebateBench, the LLMs must perform in-context learning to understand the rules and evaluation criteria of the debates, then analyze 8 seven minute long speeches and reason about the arguments presented by all speakers to give the final results. Our preliminary evaluation using GPT o1, GPT-4o, and Claude Haiku, shows that LLMs struggle to perform well on DebateBench, highlighting the need to develop more sophisticated techniques for improving their performance.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "170",
        "title": "Occupancy-SLAM: An Efficient and Robust Algorithm for Simultaneously Optimizing Robot Poses and Occupancy Map",
        "author": [
            "Yingyu Wang",
            "Liang Zhao",
            "Shoudong Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06292",
        "abstract": "Joint optimization of poses and features has been extensively studied and demonstrated to yield more accurate results in feature-based SLAM problems. However, research on jointly optimizing poses and non-feature-based maps remains limited. Occupancy maps are widely used non-feature-based environment representations because they effectively classify spaces into obstacles, free areas, and unknown regions, providing robots with spatial information for various tasks. In this paper, we propose Occupancy-SLAM, a novel optimization-based SLAM method that enables the joint optimization of robot trajectory and the occupancy map through a parameterized map representation. The key novelty lies in optimizing both robot poses and occupancy values at different cell vertices simultaneously, a significant departure from existing methods where the robot poses need to be optimized first before the map can be estimated. Evaluations using simulations and practical 2D laser datasets demonstrate that the proposed approach can robustly obtain more accurate robot trajectories and occupancy maps than state-of-the-art techniques with comparable computational time. Preliminary results in the 3D case further confirm the potential of the proposed method in practical 3D applications, achieving more accurate results than existing methods.",
        "tags": [
            "3D",
            "Robot",
            "SLAM"
        ]
    },
    {
        "id": "171",
        "title": "SeaExam and SeaBench: Benchmarking LLMs with Local Multilingual Questions in Southeast Asia",
        "author": [
            "Chaoqun Liu",
            "Wenxuan Zhang",
            "Jiahao Ying",
            "Mahani Aljunied",
            "Anh Tuan Luu",
            "Lidong Bing"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06298",
        "abstract": "This study introduces two novel benchmarks, SeaExam and SeaBench, designed to evaluate the capabilities of Large Language Models (LLMs) in Southeast Asian (SEA) application scenarios. Unlike existing multilingual datasets primarily derived from English translations, these benchmarks are constructed based on real-world scenarios from SEA regions. SeaExam draws from regional educational exams to form a comprehensive dataset that encompasses subjects such as local history and literature. In contrast, SeaBench is crafted around multi-turn, open-ended tasks that reflect daily interactions within SEA communities. Our evaluations demonstrate that SeaExam and SeaBench more effectively discern LLM performance on SEA language tasks compared to their translated benchmarks. This highlights the importance of using real-world queries to assess the multilingual capabilities of LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "172",
        "title": "Utilizing Novelty-based Evolution Strategies to Train Transformers in Reinforcement Learning",
        "author": [
            "MatyÃ¡Å¡ Lorenc"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06301",
        "abstract": "In this paper, we experiment with novelty-based variants of OpenAI-ES, the NS-ES and NSR-ES algorithms, and evaluate their effectiveness in training complex, transformer-based architectures designed for the problem of reinforcement learning such as Decision Transformers. We also test if we can accelerate the novelty-based training of these larger models by seeding the training by a pretrained models. By this, we build on our previous work, where we tested the ability of evolution strategies - specifically the aforementioned OpenAI-ES - to train the Decision Transformer architecture. The results were mixed. NS-ES showed progress, but it would clearly need many more iterations for it to yield interesting results. NSR-ES, on the other hand, proved quite capable of being straightforwardly used on larger models, since its performance appears as similar between the feed-forward model and Decision Transformer, as it was for the OpenAI-ES in our previous work.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "173",
        "title": "Latent Convergence Modulation in Large Language Models: A Novel Approach to Iterative Contextual Realignment",
        "author": [
            "Patricia Porretta",
            "Sylvester Pakenham",
            "Huxley Ainsworth",
            "Gregory Chatten",
            "Godfrey Allerton",
            "Simon Hollingsworth",
            "Vance Periwinkle"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06302",
        "abstract": "Token prediction stability remains a challenge in autoregressive generative models, where minor variations in early inference steps often lead to significant semantic drift over extended sequences. A structured modulation mechanism was introduced to regulate hidden state transitions, ensuring that latent representation trajectories remain aligned with prior contextual dependencies while preserving generative flexibility. The modulation framework was designed to function within transformer-based architectures, dynamically constraining representation evolution without imposing external memory dependencies or extensive architectural modifications. Empirical evaluations demonstrated that structured latent adjustments contributed to reductions in perplexity fluctuations, entropy variance, and lexical instability, improving coherence in long-form text generation. Gradient propagation stability was further analyzed, revealing that the modulation process led to smoother optimization pathways, mitigating erratic fluctuations in weight updates across successive inference steps. The computational efficiency of the modulation process was assessed, showing that its integration within transformer-based architectures introduced only marginal overhead while maintaining compatibility with existing optimization frameworks. The structured modulation constraints also influenced syntactic variation, preventing excessive repetition while maintaining balanced sentence length distributions. Comparative evaluations against baseline models reinforced the role of controlled latent state evolution in improving pronoun resolution, logical consistency, and contextual alignment across autoregressive text generation tasks.",
        "tags": [
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "174",
        "title": "Can AI Examine Novelty of Patents?: Novelty Evaluation Based on the Correspondence between Patent Claim and Prior Art",
        "author": [
            "Hayato Ikoma",
            "Teruko Mitamura"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06316",
        "abstract": "Assessing the novelty of patent claims is a critical yet challenging task traditionally performed by patent examiners. While advancements in NLP have enabled progress in various patent-related tasks, novelty assessment remains unexplored. This paper introduces a novel challenge by evaluating the ability of large language models (LLMs) to assess patent novelty by comparing claims with cited prior art documents, following the process similar to that of patent examiners done. We present the first dataset specifically designed for novelty evaluation, derived from real patent examination cases, and analyze the capabilities of LLMs to address this task. Our study reveals that while classification models struggle to effectively assess novelty, generative models make predictions with a reasonable level of accuracy, and their explanations are accurate enough to understand the relationship between the target patent and prior art. These findings demonstrate the potential of LLMs to assist in patent evaluation, reducing the workload for both examiners and applicants. Our contributions highlight the limitations of current models and provide a foundation for improving AI-driven patent analysis through advanced models and refined datasets.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "175",
        "title": "Expect the Unexpected: FailSafe Long Context QA for Finance",
        "author": [
            "Kiran Kamble",
            "Melisa Russak",
            "Dmytro Mozolevskyi",
            "Muayad Ali",
            "Mateusz Russak",
            "Waseem AlShikh"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06329",
        "abstract": "We propose a new long-context financial benchmark, FailSafeQA, designed to test the robustness and context-awareness of LLMs against six variations in human-interface interactions in LLM-based query-answer systems within finance. We concentrate on two case studies: Query Failure and Context Failure. In the Query Failure scenario, we perturb the original query to vary in domain expertise, completeness, and linguistic accuracy. In the Context Failure case, we simulate the uploads of degraded, irrelevant, and empty documents. We employ the LLM-as-a-Judge methodology with Qwen2.5-72B-Instruct and use fine-grained rating criteria to define and calculate Robustness, Context Grounding, and Compliance scores for 24 off-the-shelf models. The results suggest that although some models excel at mitigating input perturbations, they must balance robust answering with the ability to refrain from hallucinating. Notably, Palmyra-Fin-128k-Instruct, recognized as the most compliant model, maintained strong baseline performance but encountered challenges in sustaining robust predictions in 17% of test cases. On the other hand, the most robust model, OpenAI o3-mini, fabricated information in 41% of tested cases. The results demonstrate that even high-performing models have significant room for improvement and highlight the role of FailSafeQA as a tool for developing LLMs optimized for dependability in financial applications. The dataset is available at: https://huggingface.co/datasets/Writer/FailSafeQA",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "176",
        "title": "Zero-shot Depth Completion via Test-time Alignment with Affine-invariant Depth Prior",
        "author": [
            "Lee Hyoseok",
            "Kyeong Seon Kim",
            "Kwon Byung-Ki",
            "Tae-Hyun Oh"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06338",
        "abstract": "Depth completion, predicting dense depth maps from sparse depth measurements, is an ill-posed problem requiring prior knowledge. Recent methods adopt learning-based approaches to implicitly capture priors, but the priors primarily fit in-domain data and do not generalize well to out-of-domain scenarios. To address this, we propose a zero-shot depth completion method composed of an affine-invariant depth diffusion model and test-time alignment. We use pre-trained depth diffusion models as depth prior knowledge, which implicitly understand how to fill in depth for scenes. Our approach aligns the affine-invariant depth prior with metric-scale sparse measurements, enforcing them as hard constraints via an optimization loop at test-time. Our zero-shot depth completion method demonstrates generalization across various domain datasets, achieving up to a 21\\% average performance improvement over the previous state-of-the-art methods while enhancing spatial understanding by sharpening scene details. We demonstrate that aligning a monocular affine-invariant depth prior with sparse metric measurements is a proven strategy to achieve domain-generalizable depth completion without relying on extensive training data. Project page: https://hyoseok1223.github.io/zero-shot-depth-completion/.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "177",
        "title": "AiRacleX: Automated Detection of Price Oracle Manipulations via LLM-Driven Knowledge Mining and Prompt Generation",
        "author": [
            "Bo Gao",
            "Yuan Wang",
            "Qingsong Wei",
            "Yong Liu",
            "Rick Siow Mong Goh"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06348",
        "abstract": "Decentralized finance applications depend on accurate price oracles to ensure secure transactions, yet these oracles are highly vulnerable to manipulation, enabling attackers to exploit smart contract vulnerabilities for unfair asset valuation and financial gain. Detecting such manipulations traditionally relies on the manual effort of experienced experts, presenting significant challenges. In this paper, we propose a novel LLM-driven framework that automates the detection of price oracle manipulations by leveraging the complementary strengths of different LLM models. Our approach begins with domain-specific knowledge extraction, where an LLM model synthesizes precise insights about price oracle vulnerabilities from top-tier academic papers, eliminating the need for profound expertise from developers or auditors. This knowledge forms the foundation for a second LLM model to generate structured, context-aware chain of thought prompts, which guide a third LLM model in accurately identifying manipulation patterns in smart contracts. We validate the framework effectiveness through experiments on 60 known vulnerabilities from 46 real-world DeFi attacks or projects spanning 2021 to 2023. The best performing combination of LLMs (Haiku-Haiku-4o-mini) identified by AiRacleX demonstrate a 2.58-times improvement in recall (0.667 vs 0.259) compared to the state-of-the-art tool GPTScan, while maintaining comparable precision. Furthermore, our framework demonstrates the feasibility of replacing commercial models with open-source alternatives, enhancing privacy and security for developers.",
        "tags": [
            "Detection",
            "LLMs"
        ]
    },
    {
        "id": "178",
        "title": "Calibrating LLMs with Information-Theoretic Evidential Deep Learning",
        "author": [
            "Yawei Li",
            "David RÃ¼gamer",
            "Bernd Bischl",
            "Mina Rezaei"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06351",
        "abstract": "Fine-tuned large language models (LLMs) often exhibit overconfidence, particularly when trained on small datasets, resulting in poor calibration and inaccurate uncertainty estimates. Evidential Deep Learning (EDL), an uncertainty-aware approach, enables uncertainty estimation in a single forward pass, making it a promising method for calibrating fine-tuned LLMs. However, despite its computational efficiency, EDL is prone to overfitting, as its training objective can result in overly concentrated probability distributions. To mitigate this, we propose regularizing EDL by incorporating an information bottleneck (IB). Our approach IB-EDL suppresses spurious information in the evidence generated by the model and encourages truly predictive information to influence both the predictions and uncertainty estimates. Extensive experiments across various fine-tuned LLMs and tasks demonstrate that IB-EDL outperforms both existing EDL and non-EDL approaches. By improving the trustworthiness of LLMs, IB-EDL facilitates their broader adoption in domains requiring high levels of confidence calibration. Code is available at https://github.com/sandylaker/ib-edl.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "179",
        "title": "Guidance-base Diffusion Models for Improving Photoacoustic Image Quality",
        "author": [
            "Tatsuhiro Eguchi",
            "Shumpei Takezaki",
            "Mihoko Shimano",
            "Takayuki Yagi",
            "Ryoma Bise"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06354",
        "abstract": "Photoacoustic(PA) imaging is a non-destructive and non-invasive technology for visualizing minute blood vessel structures in the body using ultrasonic sensors. In PA imaging, the image quality of a single-shot image is poor, and it is necessary to improve the image quality by averaging many single-shot images. Therefore, imaging the entire subject requires high imaging costs. In our study, we propose a method to improve the quality of PA images using diffusion models. In our method, we improve the reverse diffusion process using sensor information of PA imaging and introduce a guidance method using imaging condition information to generate high-quality images.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "180",
        "title": "Towards bandit-based prompt-tuning for in-the-wild foundation agents",
        "author": [
            "Finn Rietz",
            "Oleg Smirnov",
            "Sara Karimi",
            "Lele Cao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06358",
        "abstract": "Prompting has emerged as the dominant paradigm for adapting large, pre-trained transformer-based models to downstream tasks. The Prompting Decision Transformer (PDT) enables large-scale, multi-task offline reinforcement learning pre-training by leveraging stochastic trajectory prompts to identify the target task. However, these prompts are sampled uniformly from expert demonstrations, overlooking a critical limitation: Not all prompts are equally informative for differentiating between tasks. To address this, we propose an inference time bandit-based prompt-tuning framework that explores and optimizes trajectory prompt selection to enhance task performance. Our experiments indicate not only clear performance gains due to bandit-based prompt-tuning, but also better sample complexity, scalability, and prompt space exploration compared to prompt-tuning baselines.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "181",
        "title": "Simulation as Reality? The Effectiveness of LLM-Generated Data in Open-ended Question Assessment",
        "author": [
            "Long Zhang",
            "Meng Zhang",
            "Wei Lin Wang",
            "Yu Luo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06371",
        "abstract": "The advancement of Artificial Intelligence (AI) has created opportunities for e-learning, particularly in automated assessment systems that reduce educators' workload and provide timely feedback to students. However, developing effective AI-based assessment tools remains challenging due to the substantial resources required for collecting and annotating real student data. This study investigates the potential and gap of simulative data to address this limitation. Through a two-phase experimental study, we examined the effectiveness and gap of Large Language Model generated synthetic data in training educational assessment systems. Our findings reveal that while simulative data demonstrates promising results in training automated assessment models, outperforming state-of-the-art GPT-4o in most question types, its effectiveness has notable limitations. Specifically, models trained on synthetic data show excellent performance in simulated environment but need progress when applied to real-world scenarios. This performance gap highlights the limitations of only using synthetic data in controlled experimental settings for AI training. The absence of real-world noise and biases, which are also present in over-processed real-world data, contributes to this limitation. We recommend that future development of automated assessment agents and other AI tools should incorporate a mixture of synthetic and real-world data, or introduce more realistic noise and biases patterns, rather than relying solely on synthetic or over-processed data.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "182",
        "title": "Solving Linear-Gaussian Bayesian Inverse Problems with Decoupled Diffusion Sequential Monte Carlo",
        "author": [
            "Filip EkstrÃ¶m Kelvinius",
            "Zheng Zhao",
            "Fredrik Lindsten"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06379",
        "abstract": "A recent line of research has exploited pre-trained generative diffusion models as priors for solving Bayesian inverse problems. We contribute to this research direction by designing a sequential Monte Carlo method for linear-Gaussian inverse problems which builds on ``decoupled diffusion\", where the generative process is designed such that larger updates to the sample are possible. The method is asymptotically exact and we demonstrate the effectiveness of our Decoupled Diffusion Sequential Monte Carlo (DDSMC) algorithm on both synthetic data and image reconstruction tasks. Further, we demonstrate how the approach can be extended to discrete data.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "183",
        "title": "How Humans Help LLMs: Assessing and Incentivizing Human Preference Annotators",
        "author": [
            "Shang Liu",
            "Hanzhao Wang",
            "Zhongyao Ma",
            "Xiaocheng Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06387",
        "abstract": "Human-annotated preference data play an important role in aligning large language models (LLMs). In this paper, we investigate the questions of assessing the performance of human annotators and incentivizing them to provide high-quality annotations. The quality assessment of language/text annotation faces two challenges: (i) the intrinsic heterogeneity among annotators, which prevents the classic methods that assume the underlying existence of a true label; and (ii) the unclear relationship between the annotation quality and the performance of downstream tasks, which excludes the possibility of inferring the annotators' behavior based on the model performance trained from the annotation data. Then we formulate a principal-agent model to characterize the behaviors of and the interactions between the company and the human annotators. The model rationalizes a practical mechanism of a bonus scheme to incentivize annotators which benefits both parties and it underscores the importance of the joint presence of an assessment system and a proper contract scheme. From a technical perspective, our analysis extends the existing literature on the principal-agent model by considering a continuous action space for the agent. We show the gap between the first-best and the second-best solutions (under the continuous action space) is of $\\Theta(1/\\sqrt{n \\log n})$ for the binary contracts and $\\Theta(1/n)$ for the linear contracts, where $n$ is the number of samples used for performance assessment; this contrasts with the known result of $\\exp(-\\Theta(n))$ for the binary contracts when the action space is discrete. Throughout the paper, we use real preference annotation data to accompany our discussions.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "184",
        "title": "TANGLED: Generating 3D Hair Strands from Images with Arbitrary Styles and Viewpoints",
        "author": [
            "Pengyu Long",
            "Zijun Zhao",
            "Min Ouyang",
            "Qingcheng Zhao",
            "Qixuan Zhang",
            "Wei Yang",
            "Lan Xu",
            "Jingyi Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06392",
        "abstract": "Hairstyles are intricate and culturally significant with various geometries, textures, and structures. Existing text or image-guided generation methods fail to handle the richness and complexity of diverse styles. We present TANGLED, a novel approach for 3D hair strand generation that accommodates diverse image inputs across styles, viewpoints, and quantities of input views. TANGLED employs a three-step pipeline. First, our MultiHair Dataset provides 457 diverse hairstyles annotated with 74 attributes, emphasizing complex and culturally significant styles to improve model generalization. Second, we propose a diffusion framework conditioned on multi-view linearts that can capture topological cues (e.g., strand density and parting lines) while filtering out noise. By leveraging a latent diffusion model with cross-attention on lineart features, our method achieves flexible and robust 3D hair generation across diverse input conditions. Third, a parametric post-processing module enforces braid-specific constraints to maintain coherence in complex structures. This framework not only advances hairstyle realism and diversity but also enables culturally inclusive digital avatars and novel applications like sketch-based 3D strand editing for animation and augmented reality.",
        "tags": [
            "3D",
            "Diffusion"
        ]
    },
    {
        "id": "185",
        "title": "SynthDetoxM: Modern LLMs are Few-Shot Parallel Detoxification Data Annotators",
        "author": [
            "Daniil Moskovskiy",
            "Nikita Sushko",
            "Sergey Pletenev",
            "Elena Tutubalina",
            "Alexander Panchenko"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06394",
        "abstract": "Existing approaches to multilingual text detoxification are hampered by the scarcity of parallel multilingual datasets. In this work, we introduce a pipeline for the generation of multilingual parallel detoxification data. We also introduce SynthDetoxM, a manually collected and synthetically generated multilingual parallel text detoxification dataset comprising 16,000 high-quality detoxification sentence pairs across German, French, Spanish and Russian. The data was sourced from different toxicity evaluation datasets and then rewritten with nine modern open-source LLMs in few-shot setting. Our experiments demonstrate that models trained on the produced synthetic datasets have superior performance to those trained on the human-annotated MultiParaDetox dataset even in data limited setting. Models trained on SynthDetoxM outperform all evaluated LLMs in few-shot setting. We release our dataset and code to help further research in multilingual text detoxification.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "186",
        "title": "AppVLM: A Lightweight Vision Language Model for Online App Control",
        "author": [
            "Georgios Papoudakis",
            "Thomas Coste",
            "Zhihao Wu",
            "Jianye Hao",
            "Jun Wang",
            "Kun Shao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06395",
        "abstract": "The utilisation of foundation models as smartphone assistants, termed app agents, is a critical research challenge. These agents aim to execute human instructions on smartphones by interpreting textual instructions and performing actions via the device's interface. While promising, current approaches face significant limitations. Methods that use large proprietary models, such as GPT-4o, are computationally expensive, while those that use smaller fine-tuned models often lack adaptability to out-of-distribution tasks. In this work, we introduce AppVLM, a lightweight Vision-Language Model (VLM). First, we fine-tune it offline on the AndroidControl dataset. Then, we refine its policy by collecting data from the AndroidWorld environment and performing further training iterations. Our results indicate that AppVLM achieves the highest action prediction accuracy in offline evaluation on the AndroidControl dataset, compared to all evaluated baselines, and matches GPT-4o in online task completion success rate in the AndroidWorld environment, while being up to ten times faster. This makes AppVLM a practical and efficient solution for real-world deployment.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "187",
        "title": "Habitizing Diffusion Planning for Efficient and Effective Decision Making",
        "author": [
            "Haofei Lu",
            "Yifei Shen",
            "Dongsheng Li",
            "Junliang Xing",
            "Dongqi Han"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06401",
        "abstract": "Diffusion models have shown great promise in decision-making, also known as diffusion planning. However, the slow inference speeds limit their potential for broader real-world applications. Here, we introduce Habi, a general framework that transforms powerful but slow diffusion planning models into fast decision-making models, which mimics the cognitive process in the brain that costly goal-directed behavior gradually transitions to efficient habitual behavior with repetitive practice. Even using a laptop CPU, the habitized model can achieve an average 800+ Hz decision-making frequency (faster than previous diffusion planners by orders of magnitude) on standard offline reinforcement learning benchmarks D4RL, while maintaining comparable or even higher performance compared to its corresponding diffusion planner. Our work proposes a fresh perspective of leveraging powerful diffusion models for real-world decision-making tasks. We also provide robust evaluations and analysis, offering insights from both biological and engineering perspectives for efficient and effective decision-making.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "188",
        "title": "Systematic Outliers in Large Language Models",
        "author": [
            "Yongqi An",
            "Xu Zhao",
            "Tao Yu",
            "Ming Tang",
            "Jinqiao Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06415",
        "abstract": "Outliers have been widely observed in Large Language Models (LLMs), significantly impacting model performance and posing challenges for model compression. Understanding the functionality and formation mechanisms of these outliers is critically important. Existing works, however, largely focus on reducing the impact of outliers from an algorithmic perspective, lacking an in-depth investigation into their causes and roles. In this work, we provide a detailed analysis of the formation process, underlying causes, and functions of outliers in LLMs. We define and categorize three types of outliers-activation outliers, weight outliers, and attention outliers-and analyze their distributions across different dimensions, uncovering inherent connections between their occurrences and their ultimate influence on the attention mechanism. Based on these observations, we hypothesize and explore the mechanisms by which these outliers arise and function, demonstrating through theoretical derivations and experiments that they emerge due to the self-attention mechanism's softmax operation. These outliers act as implicit context-aware scaling factors within the attention mechanism. As these outliers stem from systematic influences, we term them systematic outliers. Our study not only enhances the understanding of Transformer-based LLMs but also shows that structurally eliminating outliers can accelerate convergence and improve model compression. The code is avilable at https://github.com/an-yongqi/systematic-outliers.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "189",
        "title": "Occ-LLM: Enhancing Autonomous Driving with Occupancy-Based Large Language Models",
        "author": [
            "Tianshuo Xu",
            "Hao Lu",
            "Xu Yan",
            "Yingjie Cai",
            "Bingbing Liu",
            "Yingcong Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06419",
        "abstract": "Large Language Models (LLMs) have made substantial advancements in the field of robotic and autonomous driving. This study presents the first Occupancy-based Large Language Model (Occ-LLM), which represents a pioneering effort to integrate LLMs with an important representation. To effectively encode occupancy as input for the LLM and address the category imbalances associated with occupancy, we propose Motion Separation Variational Autoencoder (MS-VAE). This innovative approach utilizes prior knowledge to distinguish dynamic objects from static scenes before inputting them into a tailored Variational Autoencoder (VAE). This separation enhances the model's capacity to concentrate on dynamic trajectories while effectively reconstructing static scenes. The efficacy of Occ-LLM has been validated across key tasks, including 4D occupancy forecasting, self-ego planning, and occupancy-based scene question answering. Comprehensive evaluations demonstrate that Occ-LLM significantly surpasses existing state-of-the-art methodologies, achieving gains of about 6\\% in Intersection over Union (IoU) and 4\\% in mean Intersection over Union (mIoU) for the task of 4D occupancy forecasting. These findings highlight the transformative potential of Occ-LLM in reshaping current paradigms within robotic and autonomous driving.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "VAE"
        ]
    },
    {
        "id": "190",
        "title": "Generating Privacy-Preserving Personalized Advice with Zero-Knowledge Proofs and LLMs",
        "author": [
            "Hiroki Watanabe",
            "Motonobu Uchikoshi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06425",
        "abstract": "Large language models (LLMs) are increasingly utilized in domains such as finance, healthcare, and interpersonal relationships to provide advice tailored to user traits and contexts. However, this personalization often relies on sensitive data, raising critical privacy concerns and necessitating data minimization. To address these challenges, we propose a framework that integrates zero-knowledge proof (ZKP) technology, specifically zkVM, with LLM-based chatbots. This integration enables privacy-preserving data sharing by verifying user traits without disclosing sensitive information. Our research introduces both an architecture and a prompting strategy for this approach. Through empirical evaluation, we clarify the current constraints and performance limitations of both zkVM and the proposed prompting strategy, thereby demonstrating their practical feasibility in real-world scenarios.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "191",
        "title": "Hybrid State-Space and GRU-based Graph Tokenization Mamba for Hyperspectral Image Classification",
        "author": [
            "Muhammad Ahmad",
            "Muhammad Hassaan Farooq Butt",
            "Muhammad Usama",
            "Manuel Mazzara",
            "Salvatore Distefano",
            "Adil Mehmood Khan",
            "Danfeng Hong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06427",
        "abstract": "Hyperspectral image (HSI) classification plays a pivotal role in domains such as environmental monitoring, agriculture, and urban planning. However, it faces significant challenges due to the high-dimensional nature of the data and the complex spectral-spatial relationships inherent in HSI. Traditional methods, including conventional machine learning and convolutional neural networks (CNNs), often struggle to effectively capture these intricate spectral-spatial features and global contextual information. Transformer-based models, while powerful in capturing long-range dependencies, often demand substantial computational resources, posing challenges in scenarios where labeled datasets are limited, as is commonly seen in HSI applications. To overcome these challenges, this work proposes GraphMamba, a hybrid model that combines spectral-spatial token generation, graph-based token prioritization, and cross-attention mechanisms. The model introduces a novel hybridization of state-space modeling and Gated Recurrent Units (GRU), capturing both linear and nonlinear spatial-spectral dynamics. GraphMamba enhances the ability to model complex spatial-spectral relationships while maintaining scalability and computational efficiency across diverse HSI datasets. Through comprehensive experiments, we demonstrate that GraphMamba outperforms existing state-of-the-art models, offering a scalable and robust solution for complex HSI classification tasks.",
        "tags": [
            "Mamba",
            "Transformer"
        ]
    },
    {
        "id": "192",
        "title": "CoS: Chain-of-Shot Prompting for Long Video Understanding",
        "author": [
            "Jian Hu",
            "Zixu Cheng",
            "Chenyang Si",
            "Wei Li",
            "Shaogang Gong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06428",
        "abstract": "Multi-modal Large Language Models (MLLMs) struggle with long videos due to the need for excessive visual tokens. These tokens exceed massively the context length of MLLMs, resulting in filled by redundant task-irrelevant shots. How to select shots is an unsolved critical problem: sparse sampling risks missing key details, while exhaustive sampling overwhelms the model with irrelevant content, leading to video misunderstanding. To solve this problem, we propose Chain-of-Shot prompting (CoS). The key idea is to frame shot selection as test-time visual prompt optimisation, choosing shots adaptive to video understanding semantic task by optimising shots-task alignment. CoS has two key parts: (1) a binary video summary mechanism that performs pseudo temporal grounding, discovering a binary coding to identify task-relevant shots, and (2) a video co-reasoning module that deploys the binary coding to pair (learning to align) task-relevant positive shots with irrelevant negative shots. It embeds the optimised shot selections into the original video, facilitating a focus on relevant context to optimize long video understanding. Experiments across three baselines and five datasets demonstrate the effectiveness and adaptability of CoS. Code given in https://lwpyh.github.io/CoS.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "193",
        "title": "Prompt-SID: Learning Structural Representation Prompt via Latent Diffusion for Single-Image Denoising",
        "author": [
            "Huaqiu Li",
            "Wang Zhang",
            "Xiaowan Hu",
            "Tao Jiang",
            "Zikang Chen",
            "Haoqian Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06432",
        "abstract": "Many studies have concentrated on constructing supervised models utilizing paired datasets for image denoising, which proves to be expensive and time-consuming. Current self-supervised and unsupervised approaches typically rely on blind-spot networks or sub-image pairs sampling, resulting in pixel information loss and destruction of detailed structural information, thereby significantly constraining the efficacy of such methods. In this paper, we introduce Prompt-SID, a prompt-learning-based single image denoising framework that emphasizes preserving of structural details. This approach is trained in a self-supervised manner using downsampled image pairs. It captures original-scale image information through structural encoding and integrates this prompt into the denoiser. To achieve this, we propose a structural representation generation model based on the latent diffusion process and design a structural attention module within the transformer-based denoiser architecture to decode the prompt. Additionally, we introduce a scale replay training mechanism, which effectively mitigates the scale gap from images of different resolutions. We conduct comprehensive experiments on synthetic, real-world, and fluorescence imaging datasets, showcasing the remarkable effectiveness of Prompt-SID.",
        "tags": [
            "Diffusion",
            "Transformer"
        ]
    },
    {
        "id": "194",
        "title": "FEMBA: Efficient and Scalable EEG Analysis with a Bidirectional Mamba Foundation Model",
        "author": [
            "Anna Tegon",
            "Thorir Mar Ingolfsson",
            "Xiaying Wang",
            "Luca Benini",
            "Yawei Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06438",
        "abstract": "Accurate and efficient electroencephalography (EEG) analysis is essential for detecting seizures and artifacts in long-term monitoring, with applications spanning hospital diagnostics to wearable health devices. Robust EEG analytics have the potential to greatly improve patient care. However, traditional deep learning models, especially Transformer-based architectures, are hindered by their quadratic time and memory complexity, making them less suitable for resource-constrained environments. To address these challenges, we present FEMBA (Foundational EEG Mamba + Bidirectional Architecture), a novel self-supervised framework that establishes new efficiency benchmarks for EEG analysis through bidirectional state-space modeling. Unlike Transformer-based models, which incur quadratic time and memory complexity, FEMBA scales linearly with sequence length, enabling more scalable and efficient processing of extended EEG recordings. Trained on over 21,000 hours of unlabeled EEG and fine-tuned on three downstream tasks, FEMBA achieves competitive performance in comparison with transformer models, with significantly lower computational cost. Specifically, it reaches 81.82% balanced accuracy (0.8921 AUROC) on TUAB and 0.949 AUROC on TUAR, while a tiny 7.8M-parameter variant demonstrates viability for resource-constrained devices. These results pave the way for scalable, general-purpose EEG analytics in both clinical and highlight FEMBA as a promising candidate for wearable applications.",
        "tags": [
            "Mamba",
            "Transformer"
        ]
    },
    {
        "id": "195",
        "title": "Benchmarking Vision-Language Models on Optical Character Recognition in Dynamic Video Environments",
        "author": [
            "Sankalp Nagaonkar",
            "Augustya Sharma",
            "Ashish Choithani",
            "Ashutosh Trivedi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06445",
        "abstract": "This paper introduces an open-source benchmark for evaluating Vision-Language Models (VLMs) on Optical Character Recognition (OCR) tasks in dynamic video environments. We present a curated dataset containing 1,477 manually annotated frames spanning diverse domains, including code editors, news broadcasts, YouTube videos, and advertisements. Three state of the art VLMs - Claude-3, Gemini-1.5, and GPT-4o are benchmarked against traditional OCR systems such as EasyOCR and RapidOCR. Evaluation metrics include Word Error Rate (WER), Character Error Rate (CER), and Accuracy. Our results highlight the strengths and limitations of VLMs in video-based OCR tasks, demonstrating their potential to outperform conventional OCR models in many scenarios. However, challenges such as hallucinations, content security policies, and sensitivity to occluded or stylized text remain. The dataset and benchmarking framework are publicly available to foster further research.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "196",
        "title": "MATH-Perturb: Benchmarking LLMs' Math Reasoning Abilities against Hard Perturbations",
        "author": [
            "Kaixuan Huang",
            "Jiacheng Guo",
            "Zihao Li",
            "Xiang Ji",
            "Jiawei Ge",
            "Wenzhe Li",
            "Yingqing Guo",
            "Tianle Cai",
            "Hui Yuan",
            "Runzhe Wang",
            "Yue Wu",
            "Ming Yin",
            "Shange Tang",
            "Yangsibo Huang",
            "Chi Jin",
            "Xinyun Chen",
            "Chiyuan Zhang",
            "Mengdi Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06453",
        "abstract": "Large language models have demonstrated impressive performance on challenging mathematical reasoning tasks, which has triggered the discussion of whether the performance is achieved by true reasoning capability or memorization. To investigate this question, prior work has constructed mathematical benchmarks when questions undergo simple perturbations -- modifications that still preserve the underlying reasoning patterns of the solutions. However, no work has explored hard perturbations, which fundamentally change the nature of the problem so that the original solution steps do not apply. To bridge the gap, we construct MATH-P-Simple and MATH-P-Hard via simple perturbation and hard perturbation, respectively. Each consists of 279 perturbed math problems derived from level-5 (hardest) problems in the MATH dataset (Hendrycksmath et. al., 2021). We observe significant performance drops on MATH-P-Hard across various models, including o1-mini (-16.49%) and gemini-2.0-flash-thinking (-12.9%). We also raise concerns about a novel form of memorization where models blindly apply learned problem-solving skills without assessing their applicability to modified contexts. This issue is amplified when using original problems for in-context learning. We call for research efforts to address this challenge, which is critical for developing more robust and reliable reasoning models.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "197",
        "title": "Group-CLIP Uncertainty Modeling for Group Re-Identification",
        "author": [
            "Qingxin Zhang",
            "Haoyan Wei",
            "Yang Qian"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06460",
        "abstract": "Group Re-Identification (Group ReID) aims matching groups of pedestrians across non-overlapping cameras. Unlike single-person ReID, Group ReID focuses more on the changes in group structure, emphasizing the number of members and their spatial arrangement. However, most methods rely on certainty-based models, which consider only the specific group structures in the group images, often failing to match unseen group configurations. To this end, we propose a novel Group-CLIP UncertaintyModeling (GCUM) approach that adapts group text descriptions to undetermined accommodate member and layout variations. Specifically, we design a Member Variant Simulation (MVS)module that simulates member exclusions using a Bernoulli distribution and a Group Layout Adaptation (GLA) module that generates uncertain group text descriptions with identity-specific tokens. In addition, we design a Group RelationshipConstruction Encoder (GRCE) that uses group features to refine individual features, and employ cross-modal contrastive loss to obtain generalizable knowledge from group text descriptions. It is worth noting that we are the first to employ CLIP to GroupReID, and extensive experiments show that GCUM significantly outperforms state-of-the-art Group ReID methods.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "198",
        "title": "A Survey of Theory of Mind in Large Language Models: Evaluations, Representations, and Safety Risks",
        "author": [
            "Hieu Minh \"Jord\" Nguyen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06470",
        "abstract": "Theory of Mind (ToM), the ability to attribute mental states to others and predict their behaviour, is fundamental to social intelligence. In this paper, we survey studies evaluating behavioural and representational ToM in Large Language Models (LLMs), identify important safety risks from advanced LLM ToM capabilities, and suggest several research directions for effective evaluation and mitigation of these risks.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "199",
        "title": "KARMA: Leveraging Multi-Agent LLMs for Automated Knowledge Graph Enrichment",
        "author": [
            "Yuxing Lu",
            "Jinzhuo Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06472",
        "abstract": "Maintaining comprehensive and up-to-date knowledge graphs (KGs) is critical for modern AI systems, but manual curation struggles to scale with the rapid growth of scientific literature. This paper presents KARMA, a novel framework employing multi-agent large language models (LLMs) to automate KG enrichment through structured analysis of unstructured text. Our approach employs nine collaborative agents, spanning entity discovery, relation extraction, schema alignment, and conflict resolution that iteratively parse documents, verify extracted knowledge, and integrate it into existing graph structures while adhering to domain-specific schema. Experiments on 1,200 PubMed articles from three different domains demonstrate the effectiveness of KARMA in knowledge graph enrichment, with the identification of up to 38,230 new entities while achieving 83.1\\% LLM-verified correctness and reducing conflict edges by 18.6\\% through multi-layer assessments.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "200",
        "title": "UniMoD: Efficient Unified Multimodal Transformers with Mixture-of-Depths",
        "author": [
            "Weijia Mao",
            "Zhenheng Yang",
            "Mike Zheng Shou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06474",
        "abstract": "Unified multimodal transformers, which handle both generation and understanding tasks within a shared parameter space, have received increasing attention in recent research. Although various unified transformers have been proposed, training these models is costly due to redundant tokens and heavy attention computation. In the past, studies on large language models have demonstrated that token pruning methods, such as Mixture of Depths (MoD), can significantly improve computational efficiency. MoD employs a router to select the most important ones for processing within a transformer layer. However, directly applying MoD-based token pruning to unified transformers will result in suboptimal performance because different tasks exhibit varying levels of token redundancy. In our work, we analyze the unified transformers by (1) examining attention weight patterns, (2) evaluating the layer importance and token redundancy, and (3) analyzing task interactions. Our findings reveal that token redundancy is primarily influenced by different tasks and layers. Building on these findings, we introduce UniMoD, a task-aware token pruning method that employs a separate router for each task to determine which tokens should be pruned. We apply our method to Show-o and Emu3, reducing training FLOPs by approximately 15% in Show-o and 40% in Emu3, while maintaining or improving performance on several benchmarks. Code will be released at https://github.com/showlab/UniMoD.",
        "tags": [
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "201",
        "title": "Adaptive Prompting: Ad-hoc Prompt Composition for Social Bias Detection",
        "author": [
            "Maximilian SpliethÃ¶ver",
            "Tim Knebler",
            "Fabian Fumagalli",
            "Maximilian Muschalik",
            "Barbara Hammer",
            "Eyke HÃ¼llermeier",
            "Henning Wachsmuth"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06487",
        "abstract": "Recent advances on instruction fine-tuning have led to the development of various prompting techniques for large language models, such as explicit reasoning steps. However, the success of techniques depends on various parameters, such as the task, language model, and context provided. Finding an effective prompt is, therefore, often a trial-and-error process. Most existing approaches to automatic prompting aim to optimize individual techniques instead of compositions of techniques and their dependence on the input. To fill this gap, we propose an adaptive prompting approach that predicts the optimal prompt composition ad-hoc for a given input. We apply our approach to social bias detection, a highly context-dependent task that requires semantic understanding. We evaluate it with three large language models on three datasets, comparing compositions to individual techniques and other baselines. The results underline the importance of finding an effective prompt composition. Our approach robustly ensures high detection performance, and is best in several settings. Moreover, first experiments on other tasks support its generalizability.",
        "tags": [
            "Detection",
            "Large Language Models"
        ]
    },
    {
        "id": "202",
        "title": "GuideLLM: Exploring LLM-Guided Conversation with Applications in Autobiography Interviewing",
        "author": [
            "Jinhao Duan",
            "Xinyu Zhao",
            "Zhuoxuan Zhang",
            "Eunhye Ko",
            "Lily Boddy",
            "Chenan Wang",
            "Tianhao Li",
            "Alexander Rasgon",
            "Junyuan Hong",
            "Min Kyung Lee",
            "Chenxi Yuan",
            "Qi Long",
            "Ying Ding",
            "Tianlong Chen",
            "Kaidi Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06494",
        "abstract": "Although Large Language Models (LLMs) succeed in human-guided conversations such as instruction following and question answering, the potential of LLM-guided conversations-where LLMs direct the discourse and steer the conversation's objectives-remains under-explored. In this study, we first characterize LLM-guided conversation into three fundamental components: (i) Goal Navigation; (ii) Context Management; (iii) Empathetic Engagement, and propose GuideLLM as an installation. We then implement an interviewing environment for the evaluation of LLM-guided conversation. Specifically, various topics are involved in this environment for comprehensive interviewing evaluation, resulting in around 1.4k turns of utterances, 184k tokens, and over 200 events mentioned during the interviewing for each chatbot evaluation. We compare GuideLLM with 6 state-of-the-art LLMs such as GPT-4o and Llama-3-70b-Instruct, from the perspective of interviewing quality, and autobiography generation quality. For automatic evaluation, we derive user proxies from multiple autobiographies and employ LLM-as-a-judge to score LLM behaviors. We further conduct a human-involved experiment by employing 45 human participants to chat with GuideLLM and baselines. We then collect human feedback, preferences, and ratings regarding the qualities of conversation and autobiography. Experimental results indicate that GuideLLM significantly outperforms baseline LLMs in automatic evaluation and achieves consistent leading performances in human ratings.",
        "tags": [
            "GPT",
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "203",
        "title": "Boost-and-Skip: A Simple Guidance-Free Diffusion for Minority Generation",
        "author": [
            "Soobin Um",
            "Beomsu Kim",
            "Jong Chul Ye"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06516",
        "abstract": "Minority samples are underrepresented instances located in low-density regions of a data manifold, and are valuable in many generative AI applications, such as data augmentation, creative content generation, etc. Unfortunately, existing diffusion-based minority generators often rely on computationally expensive guidance dedicated for minority generation. To address this, here we present a simple yet powerful guidance-free approach called Boost-and-Skip for generating minority samples using diffusion models. The key advantage of our framework requires only two minimal changes to standard generative processes: (i) variance-boosted initialization and (ii) timestep skipping. We highlight that these seemingly-trivial modifications are supported by solid theoretical and empirical evidence, thereby effectively promoting emergence of underrepresented minority features. Our comprehensive experiments demonstrate that Boost-and-Skip greatly enhances the capability of generating minority samples, even rivaling guidance-based state-of-the-art approaches while requiring significantly fewer computations.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "204",
        "title": "SIREN: Semantic, Initialization-Free Registration of Multi-Robot Gaussian Splatting Maps",
        "author": [
            "Ola Shorinwa",
            "Jiankai Sun",
            "Mac Schwager",
            "Anirudha Majumdar"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06519",
        "abstract": "We present SIREN for registration of multi-robot Gaussian Splatting (GSplat) maps, with zero access to camera poses, images, and inter-map transforms for initialization or fusion of local submaps. To realize these capabilities, SIREN harnesses the versatility and robustness of semantics in three critical ways to derive a rigorous registration pipeline for multi-robot GSplat maps. First, SIREN utilizes semantics to identify feature-rich regions of the local maps where the registration problem is better posed, eliminating the need for any initialization which is generally required in prior work. Second, SIREN identifies candidate correspondences between Gaussians in the local maps using robust semantic features, constituting the foundation for robust geometric optimization, coarsely aligning 3D Gaussian primitives extracted from the local maps. Third, this key step enables subsequent photometric refinement of the transformation between the submaps, where SIREN leverages novel-view synthesis in GSplat maps along with a semantics-based image filter to compute a high-accuracy non-rigid transformation for the generation of a high-fidelity fused map. We demonstrate the superior performance of SIREN compared to competing baselines across a range of real-world datasets, and in particular, across the most widely-used robot hardware platforms, including a manipulator, drone, and quadruped. In our experiments, SIREN achieves about 90x smaller rotation errors, 300x smaller translation errors, and 44x smaller scale errors in the most challenging scenes, where competing methods struggle. We will release the code and provide a link to the project page after the review process.",
        "tags": [
            "3D",
            "Gaussian Splatting",
            "Robot"
        ]
    },
    {
        "id": "205",
        "title": "CustomVideoX: 3D Reference Attention Driven Dynamic Adaptation for Zero-Shot Customized Video Diffusion Transformers",
        "author": [
            "D. She",
            "Mushui Liu",
            "Jingxuan Pang",
            "Jin Wang",
            "Zhen Yang",
            "Wanggui He",
            "Guanghao Zhang",
            "Yi Wang",
            "Qihan Huang",
            "Haobin Tang",
            "Yunlong Yu",
            "Siming Fu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06527",
        "abstract": "Customized generation has achieved significant progress in image synthesis, yet personalized video generation remains challenging due to temporal inconsistencies and quality degradation. In this paper, we introduce CustomVideoX, an innovative framework leveraging the video diffusion transformer for personalized video generation from a reference image. CustomVideoX capitalizes on pre-trained video networks by exclusively training the LoRA parameters to extract reference features, ensuring both efficiency and adaptability. To facilitate seamless interaction between the reference image and video content, we propose 3D Reference Attention, which enables direct and simultaneous engagement of reference image features with all video frames across spatial and temporal dimensions. To mitigate the excessive influence of reference image features and textual guidance on generated video content during inference, we implement the Time-Aware Reference Attention Bias (TAB) strategy, dynamically modulating reference bias over different time steps. Additionally, we introduce the Entity Region-Aware Enhancement (ERAE) module, aligning highly activated regions of key entity tokens with reference feature injection by adjusting attention bias. To thoroughly evaluate personalized video generation, we establish a new benchmark, VideoBench, comprising over 50 objects and 100 prompts for extensive assessment. Experimental results show that CustomVideoX significantly outperforms existing methods in terms of video consistency and quality.",
        "tags": [
            "3D",
            "Diffusion",
            "Diffusion Transformer",
            "LoRA",
            "Transformer",
            "Video Generation"
        ]
    },
    {
        "id": "206",
        "title": "Ignore the KL Penalty! Boosting Exploration on Critical Tokens to Enhance RL Fine-Tuning",
        "author": [
            "Jean Vassoyan",
            "NathanaÃ«l Beau",
            "Roman Plaud"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06533",
        "abstract": "The ability to achieve long-term goals is a key challenge in the current development of large language models (LLMs). To address this, pre-trained LLMs can be fine-tuned with reinforcement learning (RL) to explore solutions that optimize a given goal. However, exploration with LLMs is difficult, as a balance has to be struck between discovering new solutions and staying close enough to the pre-trained model, so as not to degrade basic capabilities. This is typically controlled with a Kullback-Leibler (KL) penalty. In this paper, we investigate the exploration dynamics of a small language model on a simple arithmetic task. We show how varying degrees of pre-training influence exploration and demonstrate the importance of \"critical tokens\" which have a dramatic impact on the final outcome. Consequently, we introduce a simple modification to the KL penalty that favors exploration on critical tokens, increasing the efficiency of the RL fine-tuning stage.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RL"
        ]
    },
    {
        "id": "207",
        "title": "Efficient Scientific Full Text Classification: The Case of EICAT Impact Assessments",
        "author": [
            "Marc Felix Brinner",
            "Sina ZarrieÃ"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06551",
        "abstract": "This study explores strategies for efficiently classifying scientific full texts using both small, BERT-based models and local large language models like Llama-3.1 8B. We focus on developing methods for selecting subsets of input sentences to reduce input size while simultaneously enhancing classification performance. To this end, we compile a novel dataset consisting of full-text scientific papers from the field of invasion biology, specifically addressing the impacts of invasive species. These papers are aligned with publicly available impact assessments created by researchers for the International Union for Conservation of Nature (IUCN). Through extensive experimentation, we demonstrate that various sources like human evidence annotations, LLM-generated annotations or explainability scores can be used to train sentence selection models that improve the performance of both encoder- and decoder-based language models while optimizing efficiency through the reduction in input length, leading to improved results even if compared to models like ModernBERT that are able to handle the complete text as input. Additionally, we find that repeated sampling of shorter inputs proves to be a very effective strategy that, at a slightly increased cost, can further improve classification performance.",
        "tags": [
            "BERT",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "208",
        "title": "ProjectTest: A Project-level Unit Test Generation Benchmark and Impact of Error Fixing Mechanisms",
        "author": [
            "Yibo Wang",
            "Congying Xia",
            "Wenting Zhao",
            "Jiangshu Du",
            "Chunyu Miao",
            "Zhongfen Deng",
            "Philip S. Yu",
            "Chen Xing"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06556",
        "abstract": "Unit test generation has become a promising and important use case of LLMs. However, existing evaluation benchmarks for assessing LLM unit test generation capabilities focus on function- or class-level code rather than more practical and challenging project-level codebases. To address such limitation, we propose ProjectTest, a project-level benchmark for unit test generation covering Python, Java, and JavaScript. ProjectTest features 20 moderate-sized and high-quality projects per language. We evaluate nine frontier LLMs on ProjectTest and the results show that all frontier LLMs tested exhibit moderate performance on ProjectTest on Python and Java, highlighting the difficulty of ProjectTest. We also conduct a thorough error analysis, which shows that even frontier LLMs, such as Claude-3.5-Sonnet, have significant simple errors, including compilation and cascade errors. Motivated by this observation, we further evaluate all frontier LLMs under manual error-fixing and self-error-fixing scenarios to assess their potential when equipped with error-fixing mechanisms.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "209",
        "title": "Position: It's Time to Act on the Risk of Efficient Personalized Text Generation",
        "author": [
            "Eugenia Iofinova",
            "Andrej Jovanovic",
            "Dan Alistarh"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06560",
        "abstract": "The recent surge in high-quality open-sourced Generative AI text models (colloquially: LLMs), as well as efficient finetuning techniques, has opened the possibility of creating high-quality personalized models, i.e., models generating text attuned to a specific individual's needs and capable of credibly imitating their writing style by leveraging that person's own data to refine an open-source model. The technology to create such models is accessible to private individuals, and training and running such models can be done cheaply on consumer-grade hardware. These advancements are a huge gain for usability and privacy. This position paper argues, however, that these advancements also introduce new safety risks by making it practically feasible for malicious actors to impersonate specific individuals at scale, for instance for the purpose of phishing emails, based on small amounts of publicly available text. We further argue that these risks are complementary to - and distinct from - the much-discussed risks of other impersonation attacks such as image, voice, or video deepfakes, and are not adequately addressed by the larger research community, or the current generation of open - and closed-source models.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "210",
        "title": "Large Language Models Meet Symbolic Provers for Logical Reasoning Evaluation",
        "author": [
            "Chengwen Qi",
            "Ren Ma",
            "Bowen Li",
            "He Du",
            "Binyuan Hui",
            "Jinwang Wu",
            "Yuanjun Laili",
            "Conghui He"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06563",
        "abstract": "First-order logic (FOL) reasoning, which involves sequential deduction, is pivotal for intelligent systems and serves as a valuable task for evaluating reasoning capabilities, particularly in chain-of-thought (CoT) contexts. Existing benchmarks often rely on extensive human annotation or handcrafted templates, making it difficult to achieve the necessary complexity, scalability, and diversity for robust evaluation. To address these limitations, we propose a novel framework called ProverGen that synergizes the generative strengths of Large Language Models (LLMs) with the rigor and precision of symbolic provers, enabling the creation of a scalable, diverse, and high-quality FOL reasoning dataset, ProverQA. ProverQA is also distinguished by its inclusion of accessible and logically coherent intermediate reasoning steps for each problem. Our evaluation shows that state-of-the-art LLMs struggle to solve ProverQA problems, even with CoT prompting, highlighting the dataset's challenging nature. We also finetune Llama3.1-8B-Instruct on a separate training set generated by our framework. The finetuned model demonstrates consistent improvements on both in-distribution and out-of-distribution test sets, suggesting the value of our proposed data generation framework. Code available at: https://github.com/opendatalab/ProverGen",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "211",
        "title": "LawGPT: Knowledge-Guided Data Generation and Its Application to Legal LLM",
        "author": [
            "Zhi Zhou",
            "Kun-Yang Yu",
            "Shi-Yu Tian",
            "Jiang-Xin Shi",
            "Xiao-Wen Yang",
            "Pengxiao Song",
            "Yi-Xuan Jin",
            "Lan-Zhe Guo",
            "Yu-Feng Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06572",
        "abstract": "Large language models (LLMs), both proprietary and open-source, have demonstrated remarkable capabilities across various natural language processing tasks. However, they face significant limitations in legal reasoning tasks. Proprietary models introduce data privacy risks and high inference costs, while open-source models underperform due to insufficient legal domain training data. To address these limitations, we study data generation for legal reasoning to improve the legal reasoning performance of open-source LLMs with the help of proprietary LLMs. This is challenging due to the lack of legal knowledge in proprietary LLMs and the difficulty in verifying the generated data. We propose KgDG, a knowledge-guided data generation framework for legal reasoning. Our framework enables leveraging legal knowledge to enhance generation diversity and introduces a refinement and verification process to ensure the quality of generated data. Moreover, we expand the generated dataset to further enhance the LLM reasoning capabilities. Using KgDG, we create a synthetic legal reasoning dataset containing 50K high-quality examples. Our trained model LawGPT outperforms existing legal-specific LLMs and achieves performance comparable to proprietary LLMs, demonstrating the effectiveness of KgDG and LawGPT. Our code and resources is publicly available at https://anonymous.4open.science/r/KgDG-45F5 .",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "212",
        "title": "Predictive Red Teaming: Breaking Policies Without Breaking Robots",
        "author": [
            "Anirudha Majumdar",
            "Mohit Sharma",
            "Dmitry Kalashnikov",
            "Sumeet Singh",
            "Pierre Sermanet",
            "Vikas Sindhwani"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06575",
        "abstract": "Visuomotor policies trained via imitation learning are capable of performing challenging manipulation tasks, but are often extremely brittle to lighting, visual distractors, and object locations. These vulnerabilities can depend unpredictably on the specifics of training, and are challenging to expose without time-consuming and expensive hardware evaluations. We propose the problem of predictive red teaming: discovering vulnerabilities of a policy with respect to environmental factors, and predicting the corresponding performance degradation without hardware evaluations in off-nominal scenarios. In order to achieve this, we develop RoboART: an automated red teaming (ART) pipeline that (1) modifies nominal observations using generative image editing to vary different environmental factors, and (2) predicts performance under each variation using a policy-specific anomaly detector executed on edited observations. Experiments across 500+ hardware trials in twelve off-nominal conditions for visuomotor diffusion policies demonstrate that RoboART predicts performance degradation with high accuracy (less than 0.19 average difference between predicted and real success rates). We also demonstrate how predictive red teaming enables targeted data collection: fine-tuning with data collected under conditions predicted to be adverse boosts baseline performance by 2-7x.",
        "tags": [
            "Diffusion",
            "Image Editing"
        ]
    },
    {
        "id": "213",
        "title": "A Survey on Video Analytics in Cloud-Edge-Terminal Collaborative Systems",
        "author": [
            "Linxiao Gong",
            "Hao Yang",
            "Gaoyun Fang",
            "Bobo Ju",
            "Juncen Guo",
            "Xiaoguang Zhu",
            "Yan Wang",
            "Xiping Hu",
            "Peng Sun",
            "Azzedine Boukerche"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06581",
        "abstract": "The explosive growth of video data has driven the development of distributed video analytics in cloud-edge-terminal collaborative (CETC) systems, enabling efficient video processing, real-time inference, and privacy-preserving analysis. Among multiple advantages, CETC systems can distribute video processing tasks and enable adaptive analytics across cloud, edge, and terminal devices, leading to breakthroughs in video surveillance, autonomous driving, and smart cities. In this survey, we first analyze fundamental architectural components, including hierarchical, distributed, and hybrid frameworks, alongside edge computing platforms and resource management mechanisms. Building upon these foundations, edge-centric approaches emphasize on-device processing, edge-assisted offloading, and edge intelligence, while cloud-centric methods leverage powerful computational capabilities for complex video understanding and model training. Our investigation also covers hybrid video analytics incorporating adaptive task offloading and resource-aware scheduling techniques that optimize performance across the entire system. Beyond conventional approaches, recent advances in large language models and multimodal integration reveal both opportunities and challenges in platform scalability, data protection, and system reliability. Future directions also encompass explainable systems, efficient processing mechanisms, and advanced video analytics, offering valuable insights for researchers and practitioners in this dynamic field.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "214",
        "title": "Hephaestus: Improving Fundamental Agent Capabilities of Large Language Models through Continual Pre-Training",
        "author": [
            "Yuchen Zhuang",
            "Jingfeng Yang",
            "Haoming Jiang",
            "Xin Liu",
            "Kewei Cheng",
            "Sanket Lokegaonkar",
            "Yifan Gao",
            "Qing Ping",
            "Tianyi Liu",
            "Binxuan Huang",
            "Zheng Li",
            "Zhengyang Wang",
            "Pei Chen",
            "Ruijie Wang",
            "Rongzhi Zhang",
            "Nasser Zalmout",
            "Priyanka Nigam",
            "Bing Yin",
            "Chao Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06589",
        "abstract": "Due to the scarcity of agent-oriented pre-training data, LLM-based autonomous agents typically rely on complex prompting or extensive fine-tuning, which often fails to introduce new capabilities while preserving strong generalizability. We introduce Hephaestus-Forge, the first large-scale pre-training corpus designed to enhance the fundamental capabilities of LLM agents in API function calling, intrinsic reasoning and planning, and adapting to environmental feedback. Hephaestus-Forge comprises 103B agent-specific data encompassing 76,537 APIs, including both tool documentation to introduce knowledge of API functions and function calling trajectories to strengthen intrinsic reasoning. To explore effective training protocols, we investigate scaling laws to identify the optimal recipe in data mixing ratios. By continual pre-training on Hephaestus-Forge, Hephaestus outperforms small- to medium-scale open-source LLMs and rivals commercial LLMs on three agent benchmarks, demonstrating the effectiveness of our pre-training corpus in enhancing fundamental agentic capabilities and generalization of LLMs to new tasks or environments.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "215",
        "title": "A Large-scale AI-generated Image Inpainting Benchmark",
        "author": [
            "Paschalis Giakoumoglou",
            "Dimitrios Karageorgiou",
            "Symeon Papadopoulos",
            "Panagiotis C. Petrantonakis"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06593",
        "abstract": "Recent advances in generative models enable highly realistic image manipulations, creating an urgent need for robust forgery detection methods. Current datasets for training and evaluating these methods are limited in scale and diversity. To address this, we propose a methodology for creating high-quality inpainting datasets and apply it to create DiQuID, comprising over 95,000 inpainted images generated from 78,000 original images sourced from MS-COCO, RAISE, and OpenImages. Our methodology consists of three components: (1) Semantically Aligned Object Replacement (SAOR) that identifies suitable objects through instance segmentation and generates contextually appropriate prompts, (2) Multiple Model Image Inpainting (MMII) that employs various state-of-the-art inpainting pipelines primarily based on diffusion models to create diverse manipulations, and (3) Uncertainty-Guided Deceptiveness Assessment (UGDA) that evaluates image realism through comparative analysis with originals. The resulting dataset surpasses existing ones in diversity, aesthetic quality, and technical quality. We provide comprehensive benchmarking results using state-of-the-art forgery detection methods, demonstrating the dataset's effectiveness in evaluating and improving detection algorithms. Through a human study with 42 participants on 1,000 images, we show that while humans struggle with images classified as deceiving by our methodology, models trained on our dataset maintain high performance on these challenging cases. Code and dataset are available at https://github.com/mever-team/DiQuID.",
        "tags": [
            "Detection",
            "Diffusion",
            "Inpainting",
            "Segmentation"
        ]
    },
    {
        "id": "216",
        "title": "Surrogate models for diffusion on graphs via sparse polynomials",
        "author": [
            "Giuseppe Alessio D'Inverno",
            "Kylian Ajavon",
            "Simone Brugiapaglia"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06595",
        "abstract": "Diffusion kernels over graphs have been widely utilized as effective tools in various applications due to their ability to accurately model the flow of information through nodes and edges. However, there is a notable gap in the literature regarding the development of surrogate models for diffusion processes on graphs. In this work, we fill this gap by proposing sparse polynomial-based surrogate models for parametric diffusion equations on graphs with community structure. In tandem, we provide convergence guarantees for both least squares and compressed sensing-based approximations by showing the holomorphic regularity of parametric solutions to these diffusion equations. Our theoretical findings are accompanied by a series of numerical experiments conducted on both synthetic and real-world graphs that demonstrate the applicability of our methodology.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "217",
        "title": "Evaluation of Multilingual Image Captioning: How far can we get with CLIP models?",
        "author": [
            "GonÃ§alo Gomes",
            "Chrysoula Zerva",
            "Bruno Martins"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06600",
        "abstract": "The evaluation of image captions, looking at both linguistic fluency and semantic correspondence to visual contents, has witnessed a significant effort. Still, despite advancements such as the CLIPScore metric, multilingual captioning evaluation has remained relatively unexplored. This work presents several strategies, and extensive experiments, related to evaluating CLIPScore variants in multilingual settings. To address the lack of multilingual test data, we consider two different strategies: (1) using quality aware machine-translated datasets with human judgements, and (2) re-purposing multilingual datasets that target semantic inference and reasoning. Our results highlight the potential of finetuned multilingual models to generalize across languages and to handle complex linguistic challenges. Tests with machine-translated data show that multilingual CLIPScore models can maintain a high correlation with human judgements across different languages, and additional tests with natively multilingual and multicultural data further attest to the high-quality assessments.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "218",
        "title": "Amortized In-Context Bayesian Posterior Estimation",
        "author": [
            "Sarthak Mittal",
            "Niels Leif Bracher",
            "Guillaume Lajoie",
            "Priyank Jaini",
            "Marcus Brubaker"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06601",
        "abstract": "Bayesian inference provides a natural way of incorporating prior beliefs and assigning a probability measure to the space of hypotheses. Current solutions rely on iterative routines like Markov Chain Monte Carlo (MCMC) sampling and Variational Inference (VI), which need to be re-run whenever new observations are available. Amortization, through conditional estimation, is a viable strategy to alleviate such difficulties and has been the guiding principle behind simulation-based inference, neural processes and in-context methods using pre-trained models. In this work, we conduct a thorough comparative analysis of amortized in-context Bayesian posterior estimation methods from the lens of different optimization objectives and architectural choices. Such methods train an amortized estimator to perform posterior parameter inference by conditioning on a set of data examples passed as context to a sequence model such as a transformer. In contrast to language models, we leverage permutation invariant architectures as the true posterior is invariant to the ordering of context examples. Our empirical study includes generalization to out-of-distribution tasks, cases where the assumed underlying model is misspecified, and transfer from simulated to real problems. Subsequently, it highlights the superiority of the reverse KL estimator for predictive problems, especially when combined with the transformer architecture and normalizing flows.",
        "tags": [
            "Normalizing Flows",
            "Transformer"
        ]
    },
    {
        "id": "219",
        "title": "Do we really have to filter out random noise in pre-training data for language models?",
        "author": [
            "Jinghan Ru",
            "Yuxin Xie",
            "Xianwei Zhuang",
            "Yuguo Yin",
            "Yuexian Zou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06604",
        "abstract": "Web-scale pre-training datasets are the cornerstone of LLMs' success. However, text data curated from the internet inevitably contains random noise caused by decoding errors or unregulated web content. In contrast to previous works that focus on low quality or synthetic data, our study \\textbf{provides the first systematic investigation into such random noise through a cohesive ``What-Why-How'' framework.} Surprisingly, we observed that the resulting increase in next-token prediction (NTP) loss was significantly lower than the proportion of random noise. We provide a theoretical justification for this phenomenon, which also elucidates the success of multilingual models. On the other hand, experiments show that the model's performance in downstream tasks is not based solely on the NTP loss, which means that random noise may result in degraded downstream performance. To address the potential adverse effects, we introduce a novel plug-and-play Local Gradient Matching loss, which explicitly enhances the denoising capability of the downstream task head by aligning the gradient of normal and perturbed features without requiring knowledge of the model's parameters. Additional experiments on 8 language and 14 vision benchmarks further validate its effectiveness.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "220",
        "title": "MaterialFusion: High-Quality, Zero-Shot, and Controllable Material Transfer with Diffusion Models",
        "author": [
            "Kamil Garifullin",
            "Maxim Nikolaev",
            "Andrey Kuznetsov",
            "Aibek Alanov"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06606",
        "abstract": "Manipulating the material appearance of objects in images is critical for applications like augmented reality, virtual prototyping, and digital content creation. We present MaterialFusion, a novel framework for high-quality material transfer that allows users to adjust the degree of material application, achieving an optimal balance between new material properties and the object's original features. MaterialFusion seamlessly integrates the modified object into the scene by maintaining background consistency and mitigating boundary artifacts. To thoroughly evaluate our approach, we have compiled a dataset of real-world material transfer examples and conducted complex comparative analyses. Through comprehensive quantitative evaluations and user studies, we demonstrate that MaterialFusion significantly outperforms existing methods in terms of quality, user control, and background preservation. Code is available at https://github.com/kzGarifullin/MaterialFusion.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "221",
        "title": "TripoSG: High-Fidelity 3D Shape Synthesis using Large-Scale Rectified Flow Models",
        "author": [
            "Yangguang Li",
            "Zi-Xin Zou",
            "Zexiang Liu",
            "Dehu Wang",
            "Yuan Liang",
            "Zhipeng Yu",
            "Xingchao Liu",
            "Yuan-Chen Guo",
            "Ding Liang",
            "Wanli Ouyang",
            "Yan-Pei Cao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06608",
        "abstract": "Recent advancements in diffusion techniques have propelled image and video generation to unprece- dented levels of quality, significantly accelerating the deployment and application of generative AI. However, 3D shape generation technology has so far lagged behind, constrained by limitations in 3D data scale, complexity of 3D data process- ing, and insufficient exploration of advanced tech- niques in the 3D domain. Current approaches to 3D shape generation face substantial challenges in terms of output quality, generalization capa- bility, and alignment with input conditions. We present TripoSG, a new streamlined shape diffu- sion paradigm capable of generating high-fidelity 3D meshes with precise correspondence to input images. Specifically, we propose: 1) A large-scale rectified flow transformer for 3D shape generation, achieving state-of-the-art fidelity through training on extensive, high-quality data. 2) A hybrid supervised training strategy combining SDF, normal, and eikonal losses for 3D VAE, achieving high- quality 3D reconstruction performance. 3) A data processing pipeline to generate 2 million high- quality 3D samples, highlighting the crucial rules for data quality and quantity in training 3D gen- erative models. Through comprehensive experi- ments, we have validated the effectiveness of each component in our new framework. The seamless integration of these parts has enabled TripoSG to achieve state-of-the-art performance in 3D shape generation. The resulting 3D shapes exhibit en- hanced detail due to high-resolution capabilities and demonstrate exceptional fidelity to input im- ages. Moreover, TripoSG demonstrates improved versatility in generating 3D models from diverse image styles and contents, showcasing strong gen- eralization capabilities. To foster progress and innovation in the field of 3D generation, we will make our model publicly available.",
        "tags": [
            "3D",
            "Diffusion",
            "Rectified Flow",
            "Transformer",
            "VAE",
            "Video Generation"
        ]
    },
    {
        "id": "222",
        "title": "Scaling Multi-Document Event Summarization: Evaluating Compression vs. Full-Text Approaches",
        "author": [
            "Adithya Pratapa",
            "Teruko Mitamura"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06617",
        "abstract": "Automatically summarizing large text collections is a valuable tool for document research, with applications in journalism, academic research, legal work, and many other fields. In this work, we contrast two classes of systems for large-scale multi-document summarization (MDS): compression and full-text. Compression-based methods use a multi-stage pipeline and often lead to lossy summaries. Full-text methods promise a lossless summary by relying on recent advances in long-context reasoning. To understand their utility on large-scale MDS, we evaluated them on three datasets, each containing approximately one hundred documents per summary. Our experiments cover a diverse set of long-context transformers (Llama-3.1, Command-R, Jamba-1.5-Mini) and compression methods (retrieval-augmented, hierarchical, incremental). Overall, we find that full-text and retrieval methods perform the best in most settings. With further analysis into the salient information retention patterns, we show that compression-based methods show strong promise at intermediate stages, even outperforming full-context. However, they suffer information loss due to their multi-stage pipeline and lack of global context. Our results highlight the need to develop hybrid approaches that combine compression and full-text approaches for optimal performance on large-scale multi-document summarization.",
        "tags": [
            "LLaMA"
        ]
    },
    {
        "id": "223",
        "title": "Unleashing the Potential of Pre-Trained Diffusion Models for Generalizable Person Re-Identification",
        "author": [
            "Jiachen Li",
            "Xiaojin Gong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06619",
        "abstract": "Domain-generalizable re-identification (DG Re-ID) aims to train a model on one or more source domains and evaluate its performance on unseen target domains, a task that has attracted growing attention due to its practical relevance. While numerous methods have been proposed, most rely on discriminative or contrastive learning frameworks to learn generalizable feature representations. However, these approaches often fail to mitigate shortcut learning, leading to suboptimal performance. In this work, we propose a novel method called diffusion model-assisted representation learning with a correlation-aware conditioning scheme (DCAC) to enhance DG Re-ID. Our method integrates a discriminative and contrastive Re-ID model with a pre-trained diffusion model through a correlation-aware conditioning scheme. By incorporating ID classification probabilities generated from the Re-ID model with a set of learnable ID-wise prompts, the conditioning scheme injects dark knowledge that captures ID correlations to guide the diffusion process. Simultaneously, feedback from the diffusion model is back-propagated through the conditioning scheme to the Re-ID model, effectively improving the generalization capability of Re-ID features. Extensive experiments on both single-source and multi-source DG Re-ID tasks demonstrate that our method achieves state-of-the-art performance. Comprehensive ablation studies further validate the effectiveness of the proposed approach, providing insights into its robustness. Codes will be available at https://github.com/RikoLi/DCAC.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "224",
        "title": "Combining Large Language Models with Static Analyzers for Code Review Generation",
        "author": [
            "Imen Jaoua",
            "Oussama Ben Sghaier",
            "Houari Sahraoui"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06633",
        "abstract": "Code review is a crucial but often complex, subjective, and time-consuming activity in software development. Over the past decades, significant efforts have been made to automate this process. Early approaches focused on knowledge-based systems (KBS) that apply rule-based mechanisms to detect code issues, providing precise feedback but struggling with complex, context-dependent cases. More recent work has shifted toward fine-tuning pre-trained language models for code review, enabling broader issue coverage but often at the expense of precision. In this paper, we propose a hybrid approach that combines the strengths of KBS and learning-based systems (LBS) to generate high-quality, comprehensive code reviews. Our method integrates knowledge at three distinct stages of the language model pipeline: during data preparation (Data-Augmented Training, DAT), at inference (Retrieval-Augmented Generation, RAG), and after inference (Naive Concatenation of Outputs, NCO). We empirically evaluate our combination strategies against standalone KBS and LBS fine-tuned on a real-world dataset. Our results show that these hybrid strategies enhance the relevance, completeness, and overall quality of review comments, effectively bridging the gap between rule-based tools and deep learning models.",
        "tags": [
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "225",
        "title": "Steel-LLM:From Scratch to Open Source -- A Personal Journey in Building a Chinese-Centric LLM",
        "author": [
            "Qingshui Gu",
            "Shu Li",
            "Tianyu Zheng",
            "Zhaoxiang Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06635",
        "abstract": "Steel-LLM is a Chinese-centric language model developed from scratch with the goal of creating a high-quality, open-source model despite limited computational resources. Launched in March 2024, the project aimed to train a 1-billion-parameter model on a large-scale dataset, prioritizing transparency and the sharing of practical insights to assist others in the community. The training process primarily focused on Chinese data, with a small proportion of English data included, addressing gaps in existing open-source LLMs by providing a more detailed and practical account of the model-building journey. Steel-LLM has demonstrated competitive performance on benchmarks such as CEVAL and CMMLU, outperforming early models from larger institutions. This paper provides a comprehensive summary of the project's key contributions, including data collection, model design, training methodologies, and the challenges encountered along the way, offering a valuable resource for researchers and practitioners looking to develop their own LLMs. The model checkpoints and training script are available at https://github.com/zhanshijinwat/Steel-LLM.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "226",
        "title": "MoETuner: Optimized Mixture of Expert Serving with Balanced Expert Placement and Token Routing",
        "author": [
            "Seokjin Go",
            "Divya Mahajan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06643",
        "abstract": "Mixture-of-Experts (MoE) model architecture has emerged as a promising solution for scaling transformer models efficiently, offering sparse activation that reduces computational costs while increasing model capacity. However, as MoE models scale, they need to be distributed across GPU devices, thus face critical performance bottlenecks due to their large memory footprint. Expert parallelism distributes experts across GPUs, however, faces key challenges including an unbalanced token routing and expert activation, resulting in communication tail latency and processing inefficiencies. While existing solutions address some of these issues, they fail to resolve the dual challenges of load imbalance and communication skew. The imbalance in token processing load across experts causes uneven processing times on different GPUs, while communication skew between GPUs leads to unbalanced inter-GPU data transfers. These factors degrade the performance of MoE models by increasing tail latency and reducing overall throughput. To address these limitations, we propose an Integer Linear Programming (ILP) formulation to optimize expert placement by jointly considering token load, communication, and computation costs. We exploit the property that there is a token routing dependency across layers, where tokens routed to a specific expert in one layer are likely to be routed to a limited set of experts in the subsequent layer. Our solution, MoETuner, offers an optimal expert-to-GPU assignment that minimizes inter-GPU token routing costs and balances token processing across devices, thereby reducing tail latency and end-to-end execution time. Experimental results demonstrate 9.3% and 17.5% of end-to-end speedups for single-node and multi-node inference respectively, showcasing the potential of our ILP-based optimization for offering expert parallel solutions for next-generation MoEs.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "227",
        "title": "In-Context Learning (and Unlearning) of Length Biases",
        "author": [
            "Stephanie Schoch",
            "Yangfeng Ji"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06653",
        "abstract": "Large language models have demonstrated strong capabilities to learn in-context, where exemplar input-output pairings are appended to the prompt for demonstration. However, existing work has demonstrated the ability of models to learn lexical and label biases in-context, which negatively impacts both performance and robustness of models. The impact of other statistical data biases remains under-explored, which this work aims to address. We specifically investigate the impact of length biases on in-context learning. We demonstrate that models do learn length biases in the context window for their predictions, and further empirically analyze the factors that modulate the level of bias exhibited by the model. In addition, we show that learning length information in-context can be used to counter the length bias that has been encoded in models (e.g., via fine-tuning). This reveals the power of in-context learning in debiasing model prediction behaviors without the need for costly parameter updates.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "228",
        "title": "Unbiased Evaluation of Large Language Models from a Causal Perspective",
        "author": [
            "Meilin Chen",
            "Jian Tian",
            "Liang Ma",
            "Di Xie",
            "Weijie Chen",
            "Jiang Zhu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06655",
        "abstract": "Benchmark contamination has become a significant concern in the LLM evaluation community. Previous Agents-as-an-Evaluator address this issue by involving agents in the generation of questions. Despite their success, the biases in Agents-as-an-Evaluator methods remain largely unexplored. In this paper, we present a theoretical formulation of evaluation bias, providing valuable insights into designing unbiased evaluation protocols. Furthermore, we identify two type of bias in Agents-as-an-Evaluator through carefully designed probing tasks on a minimal Agents-as-an-Evaluator setup. To address these issues, we propose the Unbiased Evaluator, an evaluation protocol that delivers a more comprehensive, unbiased, and interpretable assessment of http://LLMs.Extensive experiments reveal significant room for improvement in current LLMs. Additionally, we demonstrate that the Unbiased Evaluator not only offers strong evidence of benchmark contamination but also provides interpretable evaluation results.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "229",
        "title": "Who Taught You That? Tracing Teachers in Model Distillation",
        "author": [
            "Somin Wadhwa",
            "Chantal Shaib",
            "Silvio Amir",
            "Byron C. Wallace"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06659",
        "abstract": "Model distillation -- using outputs from a large teacher model to teach a small student model -- is a practical means of creating efficient models for a particular task. We ask: Can we identify a students' teacher based on its outputs? Such \"footprints\" left by teacher LLMs would be interesting artifacts. Beyond this, reliable teacher inference may have practical implications as actors seek to distill specific capabilities of massive proprietary LLMs into deployed smaller LMs, potentially violating terms of service. We consider practical task distillation targets including summarization, question answering, and instruction-following. We assume a finite set of candidate teacher models, which we treat as blackboxes. We design discriminative models that operate over lexical features. We find that $n$-gram similarity alone is unreliable for identifying teachers, but part-of-speech (PoS) templates preferred by student models mimic those of their teachers.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "230",
        "title": "EfficientLLM: Scalable Pruning-Aware Pretraining for Architecture-Agnostic Edge Language Models",
        "author": [
            "Xingrun Xing",
            "Zheng Liu",
            "Shitao Xiao",
            "Boyan Gao",
            "Yiming Liang",
            "Wanpeng Zhang",
            "Haokun Lin",
            "Guoqi Li",
            "Jiajun Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06663",
        "abstract": "Modern large language models (LLMs) driven by scaling laws, achieve intelligence emergency in large model sizes. Recently, the increasing concerns about cloud costs, latency, and privacy make it an urgent requirement to develop compact edge language models. Distinguished from direct pretraining that bounded by the scaling law, this work proposes the pruning-aware pretraining, focusing on retaining performance of much larger optimized models. It features following characteristics: 1) Data-scalable: we introduce minimal parameter groups in LLM and continuously optimize structural pruning, extending post-training pruning methods like LLM-Pruner and SparseGPT into the pretraining phase. 2) Architecture-agnostic: the LLM architecture is auto-designed using saliency-driven pruning, which is the first time to exceed SoTA human-designed LLMs in modern pretraining. We reveal that it achieves top-quality edge language models, termed EfficientLLM, by scaling up LLM compression and extending its boundary. EfficientLLM significantly outperforms SoTA baselines with $100M \\sim 1B$ parameters, such as MobileLLM, SmolLM, Qwen2.5-0.5B, OLMo-1B, Llama3.2-1B in common sense benchmarks. As the first attempt, EfficientLLM bridges the performance gap between traditional LLM compression and direct pretraining methods, and we will fully open source at https://github.com/Xingrun-Xing2/EfficientLLM.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "231",
        "title": "Boosting Self-Efficacy and Performance of Large Language Models via Verbal Efficacy Stimulations",
        "author": [
            "Rui Chen",
            "Tailai Peng",
            "Xinran Xie",
            "Dekun Lin",
            "Zhe Cui",
            "Zheng Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06669",
        "abstract": "Significant improvements have been observed in the zero-shot capabilities of the Large Language Models (LLMs). Due to their high sensitivity to input, research has increasingly focused on enhancing LLMs' performance via direct and simple prompt engineering rather than intricate domain adaptation. Studies suggest that LLMs exhibit emotional intelligence, and both positive and negative emotions can potentially enhance task performances. However, prior interaction prompts have predominantly concentrated on a single stimulus type, neglecting to compare different stimulus effects, examine the influence of varying task difficulties, or explore underlying mechanisms. This paper, inspired by the positive correlation between self-efficacy and task performance within the social cognitive theory, introduces Verbal Efficacy Stimulations (VES). Our VES comprises three types of verbal prompts: encouraging, provocative, and critical, addressing six aspects such as helpfulness and competence. And we further categorize task difficulty, aiming to extensively investigate how distinct VES influence the self-efficacy and task achievements of language models at varied levels of difficulty. The experimental results show that the three types of VES improve the performance of LLMs on most tasks, and the most effective VES varies for different models. In extensive experiments, we have obtained some findings consistent with psychological theories, providing novel insights for future research.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "232",
        "title": "Transfer Your Perspective: Controllable 3D Generation from Any Viewpoint in a Driving Scene",
        "author": [
            "Tai-Yu Pan",
            "Sooyoung Jeon",
            "Mengdi Fan",
            "Jinsu Yoo",
            "Zhenyang Feng",
            "Mark Campbell",
            "Kilian Q. Weinberger",
            "Bharath Hariharan",
            "Wei-Lun Chao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06682",
        "abstract": "Self-driving cars relying solely on ego-centric perception face limitations in sensing, often failing to detect occluded, faraway objects. Collaborative autonomous driving (CAV) seems like a promising direction, but collecting data for development is non-trivial. It requires placing multiple sensor-equipped agents in a real-world driving scene, simultaneously! As such, existing datasets are limited in locations and agents. We introduce a novel surrogate to the rescue, which is to generate realistic perception from different viewpoints in a driving scene, conditioned on a real-world sample - the ego-car's sensory data. This surrogate has huge potential: it could potentially turn any ego-car dataset into a collaborative driving one to scale up the development of CAV. We present the very first solution, using a combination of simulated collaborative data and real ego-car data. Our method, Transfer Your Perspective (TYP), learns a conditioned diffusion model whose output samples are not only realistic but also consistent in both semantics and layouts with the given ego-car data. Empirical results demonstrate TYP's effectiveness in aiding in a CAV setting. In particular, TYP enables us to (pre-)train collaborative perception algorithms like early and late fusion with little or no real-world collaborative data, greatly facilitating downstream CAV applications.",
        "tags": [
            "3D",
            "Diffusion"
        ]
    },
    {
        "id": "233",
        "title": "Can 1B LLM Surpass 405B LLM? Rethinking Compute-Optimal Test-Time Scaling",
        "author": [
            "Runze Liu",
            "Junqi Gao",
            "Jian Zhao",
            "Kaiyan Zhang",
            "Xiu Li",
            "Biqing Qi",
            "Wanli Ouyang",
            "Bowen Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06703",
        "abstract": "Test-Time Scaling (TTS) is an important method for improving the performance of Large Language Models (LLMs) by using additional computation during the inference phase. However, current studies do not systematically analyze how policy models, Process Reward Models (PRMs), and problem difficulty influence TTS. This lack of analysis limits the understanding and practical use of TTS methods. In this paper, we focus on two core questions: (1) What is the optimal approach to scale test-time computation across different policy models, PRMs, and problem difficulty levels? (2) To what extent can extended computation improve the performance of LLMs on complex tasks, and can smaller language models outperform larger ones through this approach? Through comprehensive experiments on MATH-500 and challenging AIME24 tasks, we have the following observations: (1) The compute-optimal TTS strategy is highly dependent on the choice of policy model, PRM, and problem difficulty. (2) With our compute-optimal TTS strategy, extremely small policy models can outperform larger models. For example, a 1B LLM can exceed a 405B LLM on MATH-500. Moreover, on both MATH-500 and AIME24, a 0.5B LLM outperforms GPT-4o, a 3B LLM surpasses a 405B LLM, and a 7B LLM beats o1 and DeepSeek-R1, while with higher inference efficiency. These findings show the significance of adapting TTS strategies to the specific characteristics of each task and model and indicate that TTS is a promising approach for enhancing the reasoning abilities of LLMs.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "234",
        "title": "FinMamba: Market-Aware Graph Enhanced Multi-Level Mamba for Stock Movement Prediction",
        "author": [
            "Yifan Hu",
            "Peiyuan Liu",
            "Yuante Li",
            "Dawei Cheng",
            "Naiqi Li",
            "Tao Dai",
            "Jigang Bao",
            "Shu-Tao Xia"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06707",
        "abstract": "Recently, combining stock features with inter-stock correlations has become a common and effective approach for stock movement prediction. However, financial data presents significant challenges due to its low signal-to-noise ratio and the dynamic complexity of the market, which give rise to two key limitations in existing methods. First, the relationships between stocks are highly influenced by multifaceted factors including macroeconomic market dynamics, and current models fail to adaptively capture these evolving interactions under specific market conditions. Second, for the accuracy and timeliness required by real-world trading, existing financial data mining methods struggle to extract beneficial pattern-oriented dependencies from long historical data while maintaining high efficiency and low memory consumption. To address the limitations, we propose FinMamba, a Mamba-GNN-based framework for market-aware and multi-level hybrid stock movement prediction. Specifically, we devise a dynamic graph to learn the changing representations of inter-stock relationships by integrating a pruning module that adapts to market trends. Afterward, with a selective mechanism, the multi-level Mamba discards irrelevant information and resets states to skillfully recall historical patterns across multiple time scales with linear time costs, which are then jointly optimized for reliable prediction. Extensive experiments on U.S. and Chinese stock markets demonstrate the effectiveness of our proposed FinMamba, achieving state-of-the-art prediction accuracy and trading profitability, while maintaining low computational complexity. The code is available at https://github.com/TROUBADOUR000/FinMamba.",
        "tags": [
            "Mamba"
        ]
    },
    {
        "id": "235",
        "title": "TEMSET-24K: Densely Annotated Dataset for Indexing Multipart Endoscopic Videos using Surgical Timeline Segmentation",
        "author": [
            "Muhammad Bilal",
            "Mahmood Alam",
            "Deepa Bapu",
            "Stephan Korsgen",
            "Neeraj Lal",
            "Simon Bach",
            "Amir M Hajivanand",
            "Muhammed Ali",
            "Kamran Soomro",
            "Iqbal Qasim",
            "PaweÅ Capik",
            "Aslam Khan",
            "Zaheer Khan",
            "Hunaid Vohra",
            "Massimo Caputo",
            "Andrew Beggs",
            "Adnan Qayyum",
            "Junaid Qadir",
            "Shazad Ashraf"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06708",
        "abstract": "Indexing endoscopic surgical videos is vital in surgical data science, forming the basis for systematic retrospective analysis and clinical performance evaluation. Despite its significance, current video analytics rely on manual indexing, a time-consuming process. Advances in computer vision, particularly deep learning, offer automation potential, yet progress is limited by the lack of publicly available, densely annotated surgical datasets. To address this, we present TEMSET-24K, an open-source dataset comprising 24,306 trans-anal endoscopic microsurgery (TEMS) video micro-clips. Each clip is meticulously annotated by clinical experts using a novel hierarchical labeling taxonomy encompassing phase, task, and action triplets, capturing intricate surgical workflows. To validate this dataset, we benchmarked deep learning models, including transformer-based architectures. Our in silico evaluation demonstrates high accuracy (up to 0.99) and F1 scores (up to 0.99) for key phases like Setup and Suturing. The STALNet model, tested with ConvNeXt, ViT, and SWIN V2 encoders, consistently segmented well-represented phases. TEMSET-24K provides a critical benchmark, propelling state-of-the-art solutions in surgical data science.",
        "tags": [
            "CLIP",
            "Segmentation",
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "236",
        "title": "Dynamic Loss-Based Sample Reweighting for Improved Large Language Model Pretraining",
        "author": [
            "Daouda Sow",
            "Herbert WoisetschlÃ¤ger",
            "Saikiran Bulusu",
            "Shiqiang Wang",
            "Hans-Arno Jacobsen",
            "Yingbin Liang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06733",
        "abstract": "Pretraining large language models (LLMs) on vast and heterogeneous datasets is crucial for achieving state-of-the-art performance across diverse downstream tasks. However, current training paradigms treat all samples equally, overlooking the importance or relevance of individual samples throughout the training process. Existing reweighting strategies, which primarily focus on group-level data importance, fail to leverage fine-grained instance-level information and do not adapt dynamically to individual sample importance as training progresses. In this paper, we introduce novel algorithms for dynamic, instance-level data reweighting aimed at improving both the efficiency and effectiveness of LLM pretraining. Our methods adjust the weight of each training sample based on its loss value in an online fashion, allowing the model to dynamically focus on more informative or important samples at the current training stage. In particular, our framework allows us to systematically devise reweighting strategies deprioritizing redundant or uninformative data, which we find tend to work best. Furthermore, we develop a new theoretical framework for analyzing the impact of loss-based reweighting on the convergence of gradient-based optimization, providing the first formal characterization of how these strategies affect convergence bounds. We empirically validate our approach across a spectrum of tasks, from pretraining 7B and 1.4B parameter LLMs to smaller-scale language models and linear regression problems, demonstrating that our loss-based reweighting approach can lead to faster convergence and significantly improved performance.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "237",
        "title": "Se\\~norita-2M: A High-Quality Instruction-based Dataset for General Video Editing by Video Specialists",
        "author": [
            "Bojia Zi",
            "Penghui Ruan",
            "Marco Chen",
            "Xianbiao Qi",
            "Shaozhe Hao",
            "Shihao Zhao",
            "Youze Huang",
            "Bin Liang",
            "Rong Xiao",
            "Kam-Fai Wong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06734",
        "abstract": "Recent advancements in video generation have spurred the development of video editing techniques, which can be divided into inversion-based and end-to-end methods. However, current video editing methods still suffer from several challenges. Inversion-based methods, though training-free and flexible, are time-consuming during inference, struggle with fine-grained editing instructions, and produce artifacts and jitter. On the other hand, end-to-end methods, which rely on edited video pairs for training, offer faster inference speeds but often produce poor editing results due to a lack of high-quality training video pairs. In this paper, to close the gap in end-to-end methods, we introduce SeÃ±orita-2M, a high-quality video editing dataset. SeÃ±orita-2M consists of approximately 2 millions of video editing pairs. It is built by crafting four high-quality, specialized video editing models, each crafted and trained by our team to achieve state-of-the-art editing results. We also propose a filtering pipeline to eliminate poorly edited video pairs. Furthermore, we explore common video editing architectures to identify the most effective structure based on current pre-trained generative model. Extensive experiments show that our dataset can help to yield remarkably high-quality video editing results. More details are available at https://senorita.github.io.",
        "tags": [
            "Video Editing",
            "Video Generation"
        ]
    },
    {
        "id": "238",
        "title": "VersaPRM: Multi-Domain Process Reward Model via Synthetic Reasoning Data",
        "author": [
            "Thomas Zeng",
            "Shuibai Zhang",
            "Shutong Wu",
            "Christian Classen",
            "Daewon Chae",
            "Ethan Ewer",
            "Minjae Lee",
            "Heeju Kim",
            "Wonjun Kang",
            "Jackson Kunde",
            "Ying Fan",
            "Jungtaek Kim",
            "Hyung Il Koo",
            "Kannan Ramchandran",
            "Dimitris Papailiopoulos",
            "Kangwook Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06737",
        "abstract": "Process Reward Models (PRMs) have proven effective at enhancing mathematical reasoning for Large Language Models (LLMs) by leveraging increased inference-time computation. However, they are predominantly trained on mathematical data and their generalizability to non-mathematical domains has not been rigorously studied. In response, this work first shows that current PRMs have poor performance in other domains. To address this limitation, we introduce VersaPRM, a multi-domain PRM trained on synthetic reasoning data generated using our novel data generation and annotation method. VersaPRM achieves consistent performance gains across diverse domains. For instance, in the MMLU-Pro category of Law, VersaPRM via weighted majority voting, achieves a 7.9% performance gain over the majority voting baseline -- surpassing Qwen2.5-Math-PRM's gain of 1.3%. We further contribute to the community by open-sourcing all data, code and models for VersaPRM.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "239",
        "title": "Resurrecting saturated LLM benchmarks with adversarial encoding",
        "author": [
            "Igor Ivanov",
            "Dmitrii Volkov"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06738",
        "abstract": "Recent work showed that small changes in benchmark questions can reduce LLMs' reasoning and recall. We explore two such changes: pairing questions and adding more answer options, on three benchmarks: WMDP-bio, GPQA, and MMLU variants. We find that for more capable models, these predictably reduce performance, essentially heightening the performance ceiling of a benchmark and unsaturating it again. We suggest this approach can resurrect old benchmarks.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "240",
        "title": "ViSIR: Vision Transformer Single Image Reconstruction Method for Earth System Models",
        "author": [
            "Ehsan Zeraatkar",
            "Salah Faroughi",
            "Jelena Tesic"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06741",
        "abstract": "Purpose: Earth system models (ESMs) integrate the interactions of the atmosphere, ocean, land, ice, and biosphere to estimate the state of regional and global climate under a wide variety of conditions. The ESMs are highly complex, and thus, deep neural network architectures are used to model the complexity and store the down-sampled data. In this paper, we propose the Vision Transformer Sinusoidal Representation Networks (ViSIR) to improve the single image SR (SR) reconstruction task for the ESM data.\nMethods: ViSIR combines the SR capability of Vision Transformers (ViT) with the high-frequency detail preservation of the Sinusoidal Representation Network (SIREN) to address the spectral bias observed in SR tasks.\nResults: The ViSIR outperforms ViT by 4.1 dB, SIREN by 7.5 dB, and SR-Generative Adversarial (SR-GANs) by 7.1dB PSNR on average for three different measurements.\nConclusion: The proposed ViSIR is evaluated and compared with state-of-the-art methods. The results show that the proposed algorithm is outperforming other methods in terms of Mean Square Error(MSE), Peak-Signal-to-Noise-Ratio(PSNR), and Structural Similarity Index Measure(SSIM).",
        "tags": [
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "241",
        "title": "Gradient Multi-Normalization for Stateless and Scalable LLM Training",
        "author": [
            "Meyer Scetbon",
            "Chao Ma",
            "Wenbo Gong",
            "Edward Meeds"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06742",
        "abstract": "Training large language models (LLMs) typically relies on adaptive optimizers like Adam (Kingma & Ba, 2015) which store additional state information to accelerate convergence but incur significant memory overhead. Recent efforts, such as SWAN (Ma et al., 2024) address this by eliminating the need for optimizer states while achieving performance comparable to Adam via a multi-step preprocessing procedure applied to instantaneous gradients. Motivated by the success of SWAN, we introduce a novel framework for designing stateless optimizers that normalizes stochastic gradients according to multiple norms. To achieve this, we propose a simple alternating scheme to enforce the normalization of gradients w.r.t these norms. We show that our procedure can produce, up to an arbitrary precision, a fixed-point of the problem, and that SWAN is a particular instance of our approach with carefully chosen norms, providing a deeper understanding of its design. However, SWAN's computationally expensive whitening/orthogonalization step limit its practicality for large LMs. Using our principled perspective, we develop of a more efficient, scalable, and practical stateless optimizer. Our algorithm relaxes the properties of SWAN, significantly reducing its computational cost while retaining its memory efficiency, making it applicable to training large-scale models. Experiments on pre-training LLaMA models with up to 1 billion parameters demonstrate a 3X speedup over Adam with significantly reduced memory requirements, outperforming other memory-efficient baselines.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "242",
        "title": "SAMRefiner: Taming Segment Anything Model for Universal Mask Refinement",
        "author": [
            "Yuqi Lin",
            "Hengjia Li",
            "Wenqi Shao",
            "Zheng Yang",
            "Jun Zhao",
            "Xiaofei He",
            "Ping Luo",
            "Kaipeng Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06756",
        "abstract": "In this paper, we explore a principal way to enhance the quality of widely pre-existing coarse masks, enabling them to serve as reliable training data for segmentation models to reduce the annotation cost. In contrast to prior refinement techniques that are tailored to specific models or tasks in a close-world manner, we propose SAMRefiner, a universal and efficient approach by adapting SAM to the mask refinement task. The core technique of our model is the noise-tolerant prompting scheme. Specifically, we introduce a multi-prompt excavation strategy to mine diverse input prompts for SAM (i.e., distance-guided points, context-aware elastic bounding boxes, and Gaussian-style masks) from initial coarse masks. These prompts can collaborate with each other to mitigate the effect of defects in coarse masks. In particular, considering the difficulty of SAM to handle the multi-object case in semantic segmentation, we introduce a split-then-merge (STM) pipeline. Additionally, we extend our method to SAMRefiner++ by introducing an additional IoU adaption step to further boost the performance of the generic SAMRefiner on the target dataset. This step is self-boosted and requires no additional annotation. The proposed framework is versatile and can flexibly cooperate with existing segmentation methods. We evaluate our mask framework on a wide range of benchmarks under different settings, demonstrating better accuracy and efficiency. SAMRefiner holds significant potential to expedite the evolution of refinement tools. Our code is available at https://github.com/linyq2117/SAMRefiner.",
        "tags": [
            "SAM",
            "Segment Anything",
            "Segmentation"
        ]
    },
    {
        "id": "243",
        "title": "History-Guided Video Diffusion",
        "author": [
            "Kiwhan Song",
            "Boyuan Chen",
            "Max Simchowitz",
            "Yilun Du",
            "Russ Tedrake",
            "Vincent Sitzmann"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06764",
        "abstract": "Classifier-free guidance (CFG) is a key technique for improving conditional generation in diffusion models, enabling more accurate control while enhancing sample quality. It is natural to extend this technique to video diffusion, which generates video conditioned on a variable number of context frames, collectively referred to as history. However, we find two key challenges to guiding with variable-length history: architectures that only support fixed-size conditioning, and the empirical observation that CFG-style history dropout performs poorly. To address this, we propose the Diffusion Forcing Transformer (DFoT), a video diffusion architecture and theoretically grounded training objective that jointly enable conditioning on a flexible number of history frames. We then introduce History Guidance, a family of guidance methods uniquely enabled by DFoT. We show that its simplest form, vanilla history guidance, already significantly improves video generation quality and temporal consistency. A more advanced method, history guidance across time and frequency further enhances motion dynamics, enables compositional generalization to out-of-distribution history, and can stably roll out extremely long videos. Website: https://boyuan.space/history-guidance",
        "tags": [
            "Diffusion",
            "Transformer",
            "Video Generation"
        ]
    },
    {
        "id": "244",
        "title": "Exploiting Sparsity for Long Context Inference: Million Token Contexts on Commodity GPUs",
        "author": [
            "Ryan Synk",
            "Monte Hoover",
            "John Kirchenbauer",
            "Neel Jain",
            "Alex Stein",
            "Manli Shu",
            "Josue Melendez Sanchez",
            "Ramani Duraiswami",
            "Tom Goldstein"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06766",
        "abstract": "There is growing demand for performing inference with hundreds of thousands of input tokens on trained transformer models. Inference at this extreme scale demands significant computational resources, hindering the application of transformers at long contexts on commodity (i.e not data center scale) hardware. To address the inference time costs associated with running self-attention based transformer language models on long contexts and enable their adoption on widely available hardware, we propose a tunable mechanism that reduces the cost of the forward pass by attending to only the most relevant tokens at every generation step using a top-k selection mechanism. We showcase the efficiency gains afforded by our method by performing inference on context windows up to 1M tokens using approximately 16GB of GPU RAM. Our experiments reveal that models are capable of handling the sparsity induced by the reduced number of keys and values. By attending to less than 2% of input tokens, we achieve over 95% of model performance on common long context benchmarks (LM-Eval, AlpacaEval, and RULER).",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "245",
        "title": "Train for the Worst, Plan for the Best: Understanding Token Ordering in Masked Diffusions",
        "author": [
            "Jaeyeon Kim",
            "Kulin Shah",
            "Vasilis Kontonis",
            "Sham Kakade",
            "Sitan Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06768",
        "abstract": "In recent years, masked diffusion models (MDMs) have emerged as a promising alternative approach for generative modeling over discrete domains. Compared to autoregressive models (ARMs), MDMs trade off complexity at training time with flexibility at inference time. At training time, they must learn to solve an exponentially large number of infilling problems, but at inference time, they can decode tokens in essentially arbitrary order. In this work, we closely examine these two competing effects. On the training front, we theoretically and empirically demonstrate that MDMs indeed train on computationally intractable subproblems compared to their autoregressive counterparts. On the inference front, we show that a suitable strategy for adaptively choosing the token decoding order significantly enhances the capabilities of MDMs, allowing them to sidestep hard subproblems. On logic puzzles like Sudoku, we show that adaptive inference can boost solving accuracy in pretrained MDMs from $<7$% to $\\approx 90$%, even outperforming ARMs with $7\\times$ as many parameters and that were explicitly trained via teacher forcing to learn the right order of decoding.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "246",
        "title": "ReasonFlux: Hierarchical LLM Reasoning via Scaling Thought Templates",
        "author": [
            "Ling Yang",
            "Zhaochen Yu",
            "Bin Cui",
            "Mengdi Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06772",
        "abstract": "We present that hierarchical LLM reasoning via scaling thought templates can effectively optimize the reasoning search space and outperform the mathematical reasoning capabilities of powerful LLMs like OpenAI o1-preview and DeepSeek V3. We train our ReasonFlux-32B model with only 8 GPUs and introduces three innovations: (i) a structured and generic thought template library, containing around 500 high-level thought templates capable of generalizing to similar or relevant reasoning problems; (ii) performing hierarchical reinforcement learning on a sequence of thought templates instead of long CoTs, optimizing a base LLM to plan out an optimal template trajectory for gradually handling complex problems; (iii) a brand new inference scaling system that enables hierarchical LLM reasoning by adaptively scaling thought templates at inference time. With a template trajectory containing sequential thought templates, our ReasonFlux-32B significantly advances math reasoning capabilities to state-of-the-art levels. Notably, on the MATH benchmark, it achieves an accuracy of 91.2% and surpasses o1-preview by 6.7%. On the USA Math Olympiad (AIME) benchmark, ReasonFlux-32B solves an average of 56.7% of problems, surpassing o1-preview and DeepSeek-V3 by 27% and 45%, respectively. Code: https://github.com/Gen-Verse/ReasonFlux",
        "tags": [
            "DeepSeek",
            "LLMs"
        ]
    },
    {
        "id": "247",
        "title": "On the Emergence of Thinking in LLMs I: Searching for the Right Intuition",
        "author": [
            "Guanghao Ye",
            "Khiem Duc Pham",
            "Xinzhi Zhang",
            "Sivakanth Gopi",
            "Baolin Peng",
            "Beibin Li",
            "Janardhan Kulkarni",
            "Huseyin A. Inan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06773",
        "abstract": "Recent AI advancements, such as OpenAI's new models, are transforming LLMs into LRMs (Large Reasoning Models) that perform reasoning during inference, taking extra time and compute for higher-quality outputs. We aim to uncover the algorithmic framework for training LRMs. Methods like self-consistency, PRM, and AlphaZero suggest reasoning as guided search. We ask: what is the simplest, most scalable way to enable search in LLMs?\nWe propose a post-training framework called Reinforcement Learning via Self-Play (RLSP). RLSP involves three steps: (1) supervised fine-tuning with human or synthetic demonstrations of the reasoning process, (2) using an exploration reward signal to encourage diverse and efficient reasoning behaviors, and (3) RL training with an outcome verifier to ensure correctness while preventing reward hacking. Our key innovation is to decouple exploration and correctness signals during PPO training, carefully balancing them to improve performance and efficiency.\nEmpirical studies in the math domain show that RLSP improves reasoning. On the Llama-3.1-8B-Instruct model, RLSP can boost performance by 23% in MATH-500 test set; On AIME 2024 math problems, Qwen2.5-32B-Instruct improved by 10% due to RLSP. However, a more important finding of this work is that the models trained using RLSP, even with the simplest exploration reward that encourages the model to take more intermediate steps, showed several emergent behaviors such as backtracking, exploration of ideas, and verification. These findings demonstrate that RLSP framework might be enough to enable emergence of complex reasoning abilities in LLMs when scaled. Lastly, we propose a theory as to why RLSP search strategy is more suitable for LLMs inspired by a remarkable result that says CoT provably increases computational power of LLMs, which grows as the number of steps in CoT \\cite{li2024chain,merrill2023expresssive}.",
        "tags": [
            "LLMs",
            "LLaMA",
            "RL"
        ]
    },
    {
        "id": "248",
        "title": "Towards Internet-Scale Training For Agents",
        "author": [
            "Brandon Trabucco",
            "Gunnar Sigurdsson",
            "Robinson Piramuthu",
            "Ruslan Salakhutdinov"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06776",
        "abstract": "The predominant approach for training web navigation agents gathers human demonstrations for a set of popular websites and hand-written tasks, but it is becoming clear that human data are an inefficient resource. We develop a pipeline to facilitate Internet-scale training for agents without laborious human annotations. In the first stage, an LLM generates tasks for 150k diverse websites. In the next stage, LLM agents complete tasks and produce trajectories. In the final stage, an LLM reviews the trajectories and judges their success. Language models are competitive with human annotators, detecting and filtering out harmful content with an accuracy of 97%, generating feasible tasks with an 89% rate, and judging successful trajectories with an 82.6% accuracy. Scaling the pipeline, agents based on Llama 3.1 70B solve 16.7% of tasks for 150k sites. Training on the data generated by our pipeline is competitive with training on human demonstrations. In data-limited settings derived from Mind2Web and WebLINX, we improve Step Accuracy by up to +89.5% and +122.1% respectively for agents trained on mixtures of data from our pipeline, and human data. When training agents with all available human data from these benchmarks, agents fail to generalize to diverse real sites, and adding our data improves their generalization by +149.0% for WebLINX and +156.3% for Mind2Web. Code will be available at: http://data-for-agents.github.io.",
        "tags": [
            "LLaMA"
        ]
    },
    {
        "id": "249",
        "title": "Lumina-Video: Efficient and Flexible Video Generation with Multi-scale Next-DiT",
        "author": [
            "Dongyang Liu",
            "Shicheng Li",
            "Yutong Liu",
            "Zhen Li",
            "Kai Wang",
            "Xinyue Li",
            "Qi Qin",
            "Yufei Liu",
            "Yi Xin",
            "Zhongyu Li",
            "Bin Fu",
            "Chenyang Si",
            "Yuewen Cao",
            "Conghui He",
            "Ziwei Liu",
            "Yu Qiao",
            "Qibin Hou",
            "Hongsheng Li",
            "Peng Gao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06782",
        "abstract": "Recent advancements have established Diffusion Transformers (DiTs) as a dominant framework in generative modeling. Building on this success, Lumina-Next achieves exceptional performance in the generation of photorealistic images with Next-DiT. However, its potential for video generation remains largely untapped, with significant challenges in modeling the spatiotemporal complexity inherent to video data. To address this, we introduce Lumina-Video, a framework that leverages the strengths of Next-DiT while introducing tailored solutions for video synthesis. Lumina-Video incorporates a Multi-scale Next-DiT architecture, which jointly learns multiple patchifications to enhance both efficiency and flexibility. By incorporating the motion score as an explicit condition, Lumina-Video also enables direct control of generated videos' dynamic degree. Combined with a progressive training scheme with increasingly higher resolution and FPS, and a multi-source training scheme with mixed natural and synthetic data, Lumina-Video achieves remarkable aesthetic quality and motion smoothness at high training and inference efficiency. We additionally propose Lumina-V2A, a video-to-audio model based on Next-DiT, to create synchronized sounds for generated videos. Codes are released at https://www.github.com/Alpha-VLLM/Lumina-Video.",
        "tags": [
            "DiT",
            "Diffusion",
            "Video Generation"
        ]
    },
    {
        "id": "250",
        "title": "DeepCrossAttention: Supercharging Transformer Residual Connections",
        "author": [
            "Mike Heddes",
            "Adel Javanmard",
            "Kyriakos Axiotis",
            "Gang Fu",
            "MohammadHossein Bateni",
            "Vahab Mirrokni"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06785",
        "abstract": "Transformer networks have achieved remarkable success across diverse domains, leveraging a variety of architectural innovations, including residual connections. However, traditional residual connections, which simply sum the outputs of previous layers, can dilute crucial information. This work introduces DeepCrossAttention (DCA), an approach that enhances residual learning in transformers. DCA employs learnable, input-dependent weights to dynamically combine layer outputs, enabling the model to selectively focus on the most relevant information in any of the previous layers. Furthermore, DCA incorporates depth-wise cross-attention, allowing for richer interactions between layers at different depths. Our language modeling experiments show that DCA achieves improved perplexity for a given training time. Moreover, DCA obtains the same model quality up to 3x faster while adding a negligible number of parameters. Theoretical analysis confirms that DCA provides an improved trade-off between accuracy and model size when the ratio of collective layer ranks to the ambient dimension falls below a critical threshold.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "251",
        "title": "Multimodal Stock Price Prediction",
        "author": [
            "Furkan KaradaÅ",
            "Bahaeddin EravcÄ±",
            "Ahmet Murat ÃzbayoÄlu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05186",
        "abstract": "In an era where financial markets are heavily influenced by many static and dynamic factors, it has become increasingly critical to carefully integrate diverse data sources with machine learning for accurate stock price prediction. This paper explores a multimodal machine learning approach for stock price prediction by combining data from diverse sources, including traditional financial metrics, tweets, and news articles. We capture real-time market dynamics and investor mood through sentiment analysis on these textual data using both ChatGPT-4o and FinBERT models. We look at how these integrated data streams augment predictions made with a standard Long Short-Term Memory (LSTM model) to illustrate the extent of performance gains. Our study's results indicate that incorporating the mentioned data sources considerably increases the forecast effectiveness of the reference model by up to 5%. We also provide insights into the individual and combined predictive capacities of these modalities, highlighting the substantial impact of incorporating sentiment analysis from tweets and news articles. This research offers a systematic and effective framework for applying multimodal data analytics techniques in financial time series forecasting that provides a new view for investors to leverage data for decision-making.",
        "tags": [
            "ChatGPT"
        ]
    },
    {
        "id": "252",
        "title": "Blackout DIFUSCO",
        "author": [
            "Jun Pyo Seo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05221",
        "abstract": "This study explores the integration of Blackout Diffusion into the DIFUSCO framework for combinatorial optimization, specifically targeting the Traveling Salesman Problem (TSP). Inspired by the success of discrete-time diffusion models (D3PM) in maintaining structural integrity, we extend the paradigm to a continuous-time framework, leveraging the unique properties of Blackout Diffusion. Continuous-time modeling introduces smoother transitions and refined control, hypothesizing enhanced solution quality over traditional discrete methods. We propose three key improvements to enhance the diffusion process. First, we transition from a discrete-time-based model to a continuous-time framework, providing a more refined and flexible formulation. Second, we refine the observation time scheduling to ensure a smooth and linear transformation throughout the diffusion process, allowing for a more natural progression of states. Finally, building upon the second improvement, we further enhance the reverse process by introducing finer time slices in regions that are particularly challenging for the model, thereby improving accuracy and stability in the reconstruction phase. Although the experimental results did not exceed the baseline performance, they demonstrate the effectiveness of these methods in balancing simplicity and complexity, offering new insights into diffusion-based combinatorial optimization. This work represents the first application of Blackout Diffusion to combinatorial optimization, providing a foundation for further advancements in this domain. * The code is available for review at https://github.com/Giventicket/BlackoutDIFUSCO.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "253",
        "title": "Deep Generative model that uses physical quantities to generate and retrieve solar magnetic active regions",
        "author": [
            "Subhamoy Chatterjee",
            "Andres Munoz-Jaramillo",
            "Anna Malanushenko"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05351",
        "abstract": "Deep generative models have shown immense potential in generating unseen data that has properties of real data. These models learn complex data-generating distributions starting from a smaller set of latent dimensions. However, generative models have encountered great skepticism in scientific domains due to the disconnection between generative latent vectors and scientifically relevant quantities. In this study, we integrate three types of machine learning models to generate solar magnetic patches in a physically interpretable manner and use those as a query to find matching patches in real observations. We use the magnetic field measurements from Space-weather HMI Active Region Patches (SHARPs) to train a Generative Adversarial Network (GAN). We connect the physical properties of GAN-generated images with their latent vectors to train Support Vector Machines (SVMs) that do mapping between physical and latent spaces. These produce directions in the GAN latent space along which known physical parameters of the SHARPs change. We train a self-supervised learner (SSL) to make queries with generated images and find matches from real data. We find that the GAN-SVM combination enables users to produce high-quality patches that change smoothly only with a prescribed physical quantity, making generative models physically interpretable. We also show that GAN outputs can be used to retrieve real data that shares the same physical properties as the generated query. This elevates Generative Artificial Intelligence (AI) from a means-to-produce artificial data to a novel tool for scientific data interrogation, supporting its applicability beyond the domain of heliophysics.",
        "tags": [
            "GAN"
        ]
    },
    {
        "id": "254",
        "title": "Physics-Conditioned Diffusion Models for Lattice Gauge Theory",
        "author": [
            "Qianteng Zhu",
            "Gert Aarts",
            "Wei Wang",
            "Kai Zhou",
            "Lingxiao Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05504",
        "abstract": "We develop diffusion models for simulating lattice gauge theories, where stochastic quantization is explicitly incorporated as a physical condition for sampling. We demonstrate the applicability of this novel sampler to U(1) gauge theory in two spacetime dimensions and find that a model trained at a small inverse coupling constant can be extrapolated to larger inverse coupling regions without encountering the topological freezing problem. Additionally, the trained model can be employed to sample configurations on different lattice sizes without requiring further training. The exactness of the generated samples is ensured by incorporating Metropolis-adjusted Langevin dynamics into the generation process. Furthermore, we demonstrate that this approach enables more efficient sampling of topological quantities compared to traditional algorithms such as Hybrid Monte Carlo and Langevin simulations.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "255",
        "title": "Inverse Problem Sampling in Latent Space Using Sequential Monte Carlo",
        "author": [
            "Idan Achituve",
            "Hai Victor Habi",
            "Amir Rosenfeld",
            "Arnon Netzer",
            "Idit Diamant",
            "Ethan Fetaya"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05908",
        "abstract": "In image processing, solving inverse problems is the task of finding plausible reconstructions of an image that was corrupted by some (usually known) degradation model. Commonly, this process is done using a generative image model that can guide the reconstruction towards solutions that appear natural. The success of diffusion models over the last few years has made them a leading candidate for this task. However, the sequential nature of diffusion models makes this conditional sampling process challenging. Furthermore, since diffusion models are often defined in the latent space of an autoencoder, the encoder-decoder transformations introduce additional difficulties. Here, we suggest a novel sampling method based on sequential Monte Carlo (SMC) in the latent space of diffusion models. We use the forward process of the diffusion model to add additional auxiliary observations and then perform an SMC sampling as part of the backward process. Empirical evaluations on ImageNet and FFHQ show the benefits of our approach over competing methods on various inverse problem tasks.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "256",
        "title": "Diffusion Models for Inverse Problems in the Exponential Family",
        "author": [
            "Alessandro Micheli",
            "MÃ©lodie Monod",
            "Samir Bhatt"
        ],
        "pdf": "https://arxiv.org/pdf/2502.05994",
        "abstract": "Diffusion models have emerged as powerful tools for solving inverse problems, yet prior work has primarily focused on observations with Gaussian measurement noise, restricting their use in real-world scenarios. This limitation persists due to the intractability of the likelihood score, which until now has only been approximated in the simpler case of Gaussian likelihoods. In this work, we extend diffusion models to handle inverse problems where the observations follow a distribution from the exponential family, such as a Poisson or a Binomial distribution. By leveraging the conjugacy properties of exponential family distributions, we introduce the evidence trick, a method that provides a tractable approximation to the likelihood score. In our experiments, we demonstrate that our methodology effectively performs Bayesian inference on spatially inhomogeneous Poisson processes with intensities as intricate as ImageNet images. Furthermore, we demonstrate the real-world impact of our methodology by showing that it performs competitively with the current state-of-the-art in predicting malaria prevalence estimates in Sub-Saharan Africa.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "257",
        "title": "Transformers versus the EM Algorithm in Multi-class Clustering",
        "author": [
            "Yihan He",
            "Hong-Yu Chen",
            "Yuan Cao",
            "Jianqing Fan",
            "Han Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06007",
        "abstract": "LLMs demonstrate significant inference capacities in complicated machine learning tasks, using the Transformer model as its backbone. Motivated by the limited understanding of such models on the unsupervised learning problems, we study the learning guarantees of Transformers in performing multi-class clustering of the Gaussian Mixture Models. We develop a theory drawing strong connections between the Softmax Attention layers and the workflow of the EM algorithm on clustering the mixture of Gaussians. Our theory provides approximation bounds for the Expectation and Maximization steps by proving the universal approximation abilities of multivariate mappings by Softmax functions. In addition to the approximation guarantees, we also show that with a sufficient number of pre-training samples and an initialization, Transformers can achieve the minimax optimal rate for the problem considered. Our extensive simulations empirically verified our theory by revealing the strong learning capacities of Transformers even beyond the assumptions in the theory, shedding light on the powerful inference capacities of LLMs.",
        "tags": [
            "LLMs",
            "Transformer"
        ]
    },
    {
        "id": "258",
        "title": "WyckoffDiff - A Generative Diffusion Model for Crystal Symmetry",
        "author": [
            "Filip EkstrÃ¶m Kelvinius",
            "Oskar B. Andersson",
            "Abhijith S. Parackal",
            "Dong Qian",
            "Rickard Armiento",
            "Fredrik Lindsten"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06485",
        "abstract": "Crystalline materials often exhibit a high level of symmetry. However, most generative models do not account for symmetry, but rather model each atom without any constraints on its position or element. We propose a generative model, Wyckoff Diffusion (WyckoffDiff), which generates symmetry-based descriptions of crystals. This is enabled by considering a crystal structure representation that encodes all symmetry, and we design a novel neural network architecture which enables using this representation inside a discrete generative model framework. In addition to respecting symmetry by construction, the discrete nature of our model enables fast generation. We additionally present a new metric, FrÃ©chet Wrenformer Distance, which captures the symmetry aspects of the materials generated, and we benchmark WyckoffDiff against recently proposed generative models for crystal generation.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "259",
        "title": "Recent Advances in Discrete Speech Tokens: A Review",
        "author": [
            "Yiwei Guo",
            "Zhihan Li",
            "Hankun Wang",
            "Bohan Li",
            "Chongtian Shao",
            "Hanglei Zhang",
            "Chenpeng Du",
            "Xie Chen",
            "Shujie Liu",
            "Kai Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.06490",
        "abstract": "The rapid advancement of speech generation technologies in the era of large language models (LLMs) has established discrete speech tokens as a foundational paradigm for speech representation. These tokens, characterized by their discrete, compact, and concise nature, are not only advantageous for efficient transmission and storage, but also inherently compatible with the language modeling framework, enabling seamless integration of speech into text-dominated LLM architectures. Current research categorizes discrete speech tokens into two principal classes: acoustic tokens and semantic tokens, each of which has evolved into a rich research domain characterized by unique design philosophies and methodological approaches. This survey systematically synthesizes the existing taxonomy and recent innovations in discrete speech tokenization, conducts a critical examination of the strengths and limitations of each paradigm, and presents systematic experimental comparisons across token types. Furthermore, we identify persistent challenges in the field and propose potential research directions, aiming to offer actionable insights to inspire future advancements in the development and application of discrete speech tokens.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    }
]