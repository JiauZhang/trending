[
    {
        "id": "1",
        "title": "Scientific Map of Artificial Intelligence in Communication (2004-2024)",
        "author": [
            "Carmen GÃ¡lvez"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08648",
        "abstract": "Introduction: Artificial Intelligence (AI) is having a significant impact in the field of communication, causing transcendental changes in the processing and consumption of information. The objective of this work was to analyze the most influential AI topic areas in the field of communication based on scientific literature. Methodology: 996 references indexed in Web of Science between 2004-2024 were selected, a bibliometric analysis of co-words was carried out and visualization techniques were applied to build scientific maps. Results: The most relevant thematic areas were datafication, the linking of AI with social media and digital journalism. The emerging area of generative AI was identified, linked to new AI models, such as ChatGPT, designed to generate content in the form of written text, audio, images or videos. Another emerging topic area was China's impact on the use of AI in communication. Discussions: Despite the impact of AI in communication, the field is still in the process of structuring, with few consolidated topics. Conclusions: This study made it possible to identify the thematic areas of the field studied, as well as the detection of emerging trends.",
        "tags": [
            "ChatGPT",
            "Detection"
        ]
    },
    {
        "id": "2",
        "title": "Who is Responsible? The Data, Models, Users or Regulations? Responsible Generative AI for a Sustainable Future",
        "author": [
            "Shaina Raza",
            "Rizwan Qureshi",
            "Anam Zahid",
            "Joseph Fioresi",
            "Ferhat Sadak",
            "Muhammad Saeed",
            "Ranjan Sapkota",
            "Aditya Jain",
            "Anas Zafar",
            "Muneeb Ul Hassan",
            "Aizan Zafar",
            "Hasan Maqbool",
            "Jia Wu",
            "Maged Shoman"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08650",
        "abstract": "Responsible Artificial Intelligence (RAI) has emerged as a crucial framework for addressing ethical concerns in the development and deployment of Artificial Intelligence (AI) systems. A significant body of literature exists, primarily focusing on either RAI guidelines and principles or the technical aspects of RAI, largely within the realm of traditional AI. However, a notable gap persists in bridging theoretical frameworks with practical implementations in real-world settings, as well as transitioning from RAI to Responsible Generative AI (Gen AI). To bridge this gap, we present this article, which examines the challenges and opportunities in implementing ethical, transparent, and accountable AI systems in the post-ChatGPT era, an era significantly shaped by Gen AI. Our analysis includes governance and technical frameworks, the exploration of explainable AI as the backbone to achieve RAI, key performance indicators in RAI, alignment of Gen AI benchmarks with governance frameworks, reviews of AI-ready test beds, and RAI applications across multiple sectors. Additionally, we discuss challenges in RAI implementation and provide a philosophical perspective on the future of RAI. This comprehensive article aims to offer an overview of RAI, providing valuable insights for researchers, policymakers, users, and industry practitioners to develop and deploy AI systems that benefit individuals and society while minimizing potential risks and societal impacts. A curated list of resources and datasets covered in this survey is available on GitHub {https://github.com/anas-zafar/Responsible-AI}.",
        "tags": [
            "ChatGPT"
        ]
    },
    {
        "id": "3",
        "title": "LegalScore: Development of a Benchmark for Evaluating AI Models in Legal Career Exams in Brazil",
        "author": [
            "Roberto Caparroz",
            "Marcelo Roitman",
            "Beatriz G. Chow",
            "Caroline Giusti",
            "Larissa Torhacs",
            "Pedro A. Sola",
            "JoÃ£o H. M. Diogo",
            "Luiza Balby",
            "Carolina D. L. Vasconcelos",
            "Leonardo R. Caparroz",
            "Albano P. Franco"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08652",
        "abstract": "This research introduces LegalScore, a specialized index for assessing how generative artificial intelligence models perform in a selected range of career exams that require a legal background in Brazil. The index evaluates fourteen different types of artificial intelligence models' performance, from proprietary to open-source models, in answering objective questions applied to these exams. The research uncovers the response of the models when applying English-trained large language models to Brazilian legal contexts, leading us to reflect on the importance and the need for Brazil-specific training data in generative artificial intelligence models. Performance analysis shows that while proprietary and most known models achieved better results overall, local and smaller models indicated promising performances due to their Brazilian context alignment in training. By establishing an evaluation framework with metrics including accuracy, confidence intervals, and normalized scoring, LegalScore enables systematic assessment of artificial intelligence performance in legal examinations in Brazil. While the study demonstrates artificial intelligence's potential value for exam preparation and question development, it concludes that significant improvements are needed before AI can match human performance in advanced legal assessments. The benchmark creates a foundation for continued research, highlighting the importance of local adaptation in artificial intelligence development.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "4",
        "title": "Personalizing Education through an Adaptive LMS with Integrated LLMs",
        "author": [
            "Kyle Spriggs",
            "Meng Cheng Lau",
            "Kalpdrum Passi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08655",
        "abstract": "The widespread adoption of large language models (LLMs) marks a transformative era in technology, especially within the educational sector. This paper explores the integration of LLMs within learning management systems (LMSs) to develop an adaptive learning management system (ALMS) personalized for individual learners across various educational stages. Traditional LMSs, while facilitating the distribution of educational materials, fall short in addressing the nuanced needs of diverse student populations, particularly in settings with limited instructor availability. Our proposed system leverages the flexibility of AI to provide a customizable learning environment that adjusts to each user's evolving needs. By integrating a suite of general-purpose and domain-specific LLMs, this system aims to minimize common issues such as factual inaccuracies and outdated information, characteristic of general LLMs like OpenAI's ChatGPT. This paper details the development of an ALMS that not only addresses privacy concerns and the limitations of existing educational tools but also enhances the learning experience by maintaining engagement through personalized educational content.",
        "tags": [
            "ChatGPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "5",
        "title": "Refining Positive and Toxic Samples for Dual Safety Self-Alignment of LLMs with Minimal Human Interventions",
        "author": [
            "Jingxin Xu",
            "Guoshun Nan",
            "Sheng Guan",
            "Sicong Leng",
            "Yilian Liu",
            "Zixiao Wang",
            "Yuyang Ma",
            "Zhili Zhou",
            "Yanzhao Hou",
            "Xiaofeng Tao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08657",
        "abstract": "Recent AI agents, such as ChatGPT and LLaMA, primarily rely on instruction tuning and reinforcement learning to calibrate the output of large language models (LLMs) with human intentions, ensuring the outputs are harmless and helpful. Existing methods heavily depend on the manual annotation of high-quality positive samples, while contending with issues such as noisy labels and minimal distinctions between preferred and dispreferred response data. However, readily available toxic samples with clear safety distinctions are often filtered out, removing valuable negative references that could aid LLMs in safety alignment. In response, we propose PT-ALIGN, a novel safety self-alignment approach that minimizes human supervision by automatically refining positive and toxic samples and performing fine-grained dual instruction tuning. Positive samples are harmless responses, while toxic samples deliberately contain extremely harmful content, serving as a new supervisory signals. Specifically, we utilize LLM itself to iteratively generate and refine training instances by only exploring fewer than 50 human annotations. We then employ two losses, i.e., maximum likelihood estimation (MLE) and fine-grained unlikelihood training (UT), to jointly learn to enhance the LLM's safety. The MLE loss encourages an LLM to maximize the generation of harmless content based on positive samples. Conversely, the fine-grained UT loss guides the LLM to minimize the output of harmful words based on negative samples at the token-level, thereby guiding the model to decouple safety from effectiveness, directing it toward safer fine-tuning objectives, and increasing the likelihood of generating helpful and reliable content. Experiments on 9 popular open-source LLMs demonstrate the effectiveness of our PT-ALIGN for safety alignment, while maintaining comparable levels of helpfulness and usefulness.",
        "tags": [
            "ChatGPT",
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "6",
        "title": "Semantic Role Labeling: A Systematical Survey",
        "author": [
            "Huiyao Chen",
            "Meishan Zhang",
            "Jing Li",
            "Min Zhang",
            "Lilja Ãvrelid",
            "Jan HajiÄ",
            "Hao Fei"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08660",
        "abstract": "Semantic role labeling (SRL) is a central natural language processing (NLP) task aiming to understand the semantic roles within texts, facilitating a wide range of downstream applications. While SRL has garnered extensive and enduring research, there is currently a lack of a comprehensive survey that thoroughly organizes and synthesizes the field. This paper aims to review the entire research trajectory of the SRL community over the past two decades. We begin by providing a complete definition of SRL. To offer a comprehensive taxonomy, we categorize SRL methodologies into four key perspectives: model architectures, syntax feature modeling, application scenarios, and multi-modal extensions. Further, we discuss SRL benchmarks, evaluation metrics, and paradigm modeling approaches, while also exploring practical applications across various domains. Finally, we analyze future research directions in SRL, addressing the evolving role of SRL in the age of large language models (LLMs) and its potential impact on the broader NLP landscape. We maintain a public repository and consistently update related resources at: https://github.com/DreamH1gh/Awesome-SRL",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "7",
        "title": "Few-shot_LLM_Synthetic_Data_with_Distribution_Matching",
        "author": [
            "Jiyuan Ren",
            "Zhaocheng Du",
            "Zhihao Wen",
            "Qinglin Jia",
            "Sunhao Dai",
            "Chuhan Wu",
            "Zhenhua Dong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08661",
        "abstract": "As large language models (LLMs) advance, their ability to perform in-context learning and few-shot language generation has improved significantly. This has spurred using LLMs to produce high-quality synthetic data to enhance the performance of smaller models like online retrievers or weak LLMs. However, LLM-generated synthetic data often differs from the real data in key language attributes (e.g., styles, tones, content proportions, etc.). As a result, mixing these synthetic data directly with real data may distort the original data distribution, potentially hindering performance improvements. To solve this, we introduce SynAlign: a synthetic data generation and filtering framework based on key attribute distribution matching. Before generation, SynAlign employs an uncertainty tracker surrogated by the Gaussian Process model to iteratively select data clusters distinct from selected ones as demonstrations for new data synthesis, facilitating the efficient exploration diversity of the real data. Then, a latent attribute reasoning method is employed: the LLM summarizes linguistic attributes of demonstrations and then synthesizes new data based on them. This approach facilitates synthesizing diverse data with linguistic attributes that appear in real http://data.After generation, the Maximum Mean Discrepancy is used as the objective function to learn the sampling weight of each synthetic data, ensuring distribution matching with the real data. Our experiments on multiple text prediction tasks show significant performance improvements. We also conducted an online A/B test on an online retriever to demonstrate SynAlign's effectiveness.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "8",
        "title": "Hallucination Detection: A Probabilistic Framework Using Embeddings Distance Analysis",
        "author": [
            "Emanuele Ricco",
            "Lorenzo Cima",
            "Roberto Di Pietro"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08663",
        "abstract": "Hallucinations are one of the major issues affecting LLMs, hindering their wide adoption in production systems. While current research solutions for detecting hallucinations are mainly based on heuristics, in this paper we introduce a mathematically sound methodology to reason about hallucination, and leverage it to build a tool to detect hallucinations. To the best of our knowledge, we are the first to show that hallucinated content has structural differences with respect to correct content. To prove this result, we resort to the Minkowski distances in the embedding space. Our findings demonstrate statistically significant differences in the embedding distance distributions, that are also scale free -- they qualitatively hold regardless of the distance norm used and the number of keywords, questions, or responses. We leverage these structural differences to develop a tool to detect hallucinated responses, achieving an accuracy of 66\\% for a specific configuration of system parameters -- comparable with the best results in the field. In conclusion, the suggested methodology is promising and novel, possibly paving the way for further research in the domain, also along the directions highlighted in our future work.",
        "tags": [
            "Detection",
            "LLMs"
        ]
    },
    {
        "id": "9",
        "title": "Hallucination, Monofacts, and Miscalibration: An Empirical Investigation",
        "author": [
            "Muqing Miao",
            "Michael Kearns"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08666",
        "abstract": "Recent theoretical work by [Kalai and Vempala 2024] proves that a particular notion of hallucination rate in LLMs must be lower bounded by the training data monofact rate (related to the classical Good-Turing missing mass estimator) minus model miscalibration. Through systematic experiments with n-gram models and in-context learning with LLMs, we empirically investigate and validate this theory by examining how different underlying data distributions affect the monofact rate and a model's tendency to hallucinate. We then vary model miscalibration through controlled upweighting of training samples while holding monofact rates constant, allowing us to isolate miscalibration's reduction effect on hallucination. These findings suggest that both the distribution of fact frequencies in training data and the calibration-hallucination trade-off are inherent to probabilistic language generation. Our results also suggest that current practices of aggressive deduplication in training data may need to be reconsidered, as selective duplication could serve as a principled mechanism for reducing hallucination.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "10",
        "title": "Style Extraction on Text Embeddings Using VAE and Parallel Dataset",
        "author": [
            "InJin Kong",
            "Shinyee Kang",
            "Yuna Park",
            "Sooyong Kim",
            "Sanghyun Park"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08668",
        "abstract": "This study investigates the stylistic differences among various Bible translations using a Variational Autoencoder (VAE) model. By embedding textual data into high-dimensional vectors, the study aims to detect and analyze stylistic variations between translations, with a specific focus on distinguishing the American Standard Version (ASV) from other translations. The results demonstrate that each translation exhibits a unique stylistic distribution, which can be effectively identified using the VAE model. These findings suggest that the VAE model is proficient in capturing and differentiating textual styles, although it is primarily optimized for distinguishing a single style. The study highlights the model's potential for broader applications in AI-based text generation and stylistic analysis, while also acknowledging the need for further model refinement to address the complexity of multi-dimensional stylistic relationships. Future research could extend this methodology to other text domains, offering deeper insights into the stylistic features embedded within various types of textual data.",
        "tags": [
            "VAE"
        ]
    },
    {
        "id": "11",
        "title": "Mathematical Reasoning in Large Language Models: Assessing Logical and Arithmetic Errors across Wide Numerical Ranges",
        "author": [
            "Safal Shrestha",
            "Minwu Kim",
            "Keith Ross"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08680",
        "abstract": "Mathematical reasoning in Large Language Models (LLMs) is often evaluated using benchmarks with limited numerical ranges, failing to reflect real-world problem-solving across diverse scales. Furthermore, most existing evaluation methods only compare model outputs to ground-truth answers, obscuring insights into reasoning processes. To address these limitations, we introduce GSM-Ranges, a dataset generator derived from GSM8K that systematically perturbs numerical values in math problems to assess model robustness across varying numerical scales. Additionally, we propose a novel grading methodology that distinguishes between logical and non-logical errors, offering a more precise evaluation of reasoning processes beyond computational accuracy. Our experiments with various models reveal a significant increase in logical error rates-up to 14 percentage points-as numerical complexity rises, demonstrating a general weakness in reasoning with out-of-distribution numerical values. Moreover, while models demonstrate high accuracy on standalone arithmetic tasks, their performance deteriorates substantially when computations are embedded within word problems. These findings provide a comprehensive evaluation of LLMs' mathematical reasoning capabilities and inform future research directions for improving numerical generalization in language models.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "12",
        "title": "Self-Evaluation for Job-Shop Scheduling",
        "author": [
            "Imanol Echeverria",
            "Maialen Murua",
            "Roberto Santana"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08684",
        "abstract": "Combinatorial optimization problems, such as scheduling and route planning, are crucial in various industries but are computationally intractable due to their NP-hard nature. Neural Combinatorial Optimization methods leverage machine learning to address these challenges but often depend on sequential decision-making, which is prone to error accumulation as small mistakes propagate throughout the process. Inspired by self-evaluation techniques in Large Language Models, we propose a novel framework that generates and evaluates subsets of assignments, moving beyond traditional stepwise approaches. Applied to the Job-Shop Scheduling Problem, our method integrates a heterogeneous graph neural network with a Transformer to build a policy model and a self-evaluation function. Experimental validation on challenging, well-known benchmarks demonstrates the effectiveness of our approach, surpassing state-of-the-art methods.",
        "tags": [
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "13",
        "title": "Data Augmentation to Improve Large Language Models in Food Hazard and Product Detection",
        "author": [
            "Areeg Fahad Rasheed",
            "M. Zarkoosh",
            "Shimam Amer Chasib",
            "Safa F. Abbas"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08687",
        "abstract": "The primary objective of this study is to demonstrate the impact of data augmentation using ChatGPT-4o-mini on food hazard and product analysis. The augmented data is generated using ChatGPT-4o-mini and subsequently used to train two large language models: RoBERTa-base and Flan-T5-base. The models are evaluated on test sets. The results indicate that using augmented data helped improve model performance across key metrics, including recall, F1 score, precision, and accuracy, compared to using only the provided dataset. The full code, including model training and the augmented dataset, can be found in this repository: https://github.com/AREEG94FAHAD/food-hazard-prdouct-cls",
        "tags": [
            "ChatGPT",
            "Detection",
            "Large Language Models"
        ]
    },
    {
        "id": "14",
        "title": "Skrr: Skip and Re-use Text Encoder Layers for Memory Efficient Text-to-Image Generation",
        "author": [
            "Hoigi Seo",
            "Wongi Jeong",
            "Jae-sun Seo",
            "Se Young Chun"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08690",
        "abstract": "Large-scale text encoders in text-to-image (T2I) diffusion models have demonstrated exceptional performance in generating high-quality images from textual prompts. Unlike denoising modules that rely on multiple iterative steps, text encoders require only a single forward pass to produce text embeddings. However, despite their minimal contribution to total inference time and floating-point operations (FLOPs), text encoders demand significantly higher memory usage, up to eight times more than denoising modules. To address this inefficiency, we propose Skip and Re-use layers (Skrr), a simple yet effective pruning strategy specifically designed for text encoders in T2I diffusion models. Skrr exploits the inherent redundancy in transformer blocks by selectively skipping or reusing certain layers in a manner tailored for T2I tasks, thereby reducing memory consumption without compromising performance. Extensive experiments demonstrate that Skrr maintains image quality comparable to the original model even under high sparsity levels, outperforming existing blockwise pruning methods. Furthermore, Skrr achieves state-of-the-art memory efficiency while preserving performance across multiple evaluation metrics, including the FID, CLIP, DreamSim, and GenEval scores.",
        "tags": [
            "CLIP",
            "Diffusion",
            "Text-to-Image",
            "Transformer"
        ]
    },
    {
        "id": "15",
        "title": "AgentSociety: Large-Scale Simulation of LLM-Driven Generative Agents Advances Understanding of Human Behaviors and Society",
        "author": [
            "Jinghua Piao",
            "Yuwei Yan",
            "Jun Zhang",
            "Nian Li",
            "Junbo Yan",
            "Xiaochong Lan",
            "Zhihong Lu",
            "Zhiheng Zheng",
            "Jing Yi Wang",
            "Di Zhou",
            "Chen Gao",
            "Fengli Xu",
            "Fang Zhang",
            "Ke Rong",
            "Jun Su",
            "Yong Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08691",
        "abstract": "Understanding human behavior and society is a central focus in social sciences, with the rise of generative social science marking a significant paradigmatic shift. By leveraging bottom-up simulations, it replaces costly and logistically challenging traditional experiments with scalable, replicable, and systematic computational approaches for studying complex social dynamics. Recent advances in large language models (LLMs) have further transformed this research paradigm, enabling the creation of human-like generative social agents and realistic simulacra of society. In this paper, we propose AgentSociety, a large-scale social simulator that integrates LLM-driven agents, a realistic societal environment, and a powerful large-scale simulation engine. Based on the proposed simulator, we generate social lives for over 10k agents, simulating their 5 million interactions both among agents and between agents and their environment. Furthermore, we explore the potential of AgentSociety as a testbed for computational social experiments, focusing on four key social issues: polarization, the spread of inflammatory messages, the effects of universal basic income policies, and the impact of external shocks such as hurricanes. These four issues serve as valuable cases for assessing AgentSociety's support for typical research methods -- such as surveys, interviews, and interventions -- as well as for investigating the patterns, causes, and underlying mechanisms of social issues. The alignment between AgentSociety's outcomes and real-world experimental results not only demonstrates its ability to capture human behaviors and their underlying mechanisms, but also underscores its potential as an important platform for social scientists and policymakers.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "16",
        "title": "Scalable Discrete Diffusion Samplers: Combinatorial Optimization and Statistical Physics",
        "author": [
            "Sebastian Sanokowski",
            "Wilhelm Berghammer",
            "Martin Ennemoser",
            "Haoyu Peter Wang",
            "Sepp Hochreiter",
            "Sebastian Lehner"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08696",
        "abstract": "Learning to sample from complex unnormalized distributions over discrete domains emerged as a promising research direction with applications in statistical physics, variational inference, and combinatorial optimization. Recent work has demonstrated the potential of diffusion models in this domain. However, existing methods face limitations in memory scaling and thus the number of attainable diffusion steps since they require backpropagation through the entire generative process. To overcome these limitations we introduce two novel training methods for discrete diffusion samplers, one grounded in the policy gradient theorem and the other one leveraging Self-Normalized Neural Importance Sampling (SN-NIS). These methods yield memory-efficient training and achieve state-of-the-art results in unsupervised combinatorial optimization. Numerous scientific applications additionally require the ability of unbiased sampling. We introduce adaptations of SN-NIS and Neural Markov Chain Monte Carlo that enable for the first time the application of discrete diffusion models to this problem. We validate our methods on Ising model benchmarks and find that they outperform popular autoregressive approaches. Our work opens new avenues for applying diffusion models to a wide range of scientific applications in discrete domains that were hitherto restricted to exact likelihood models.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "17",
        "title": "Beyond the Lens: Quantifying the Impact of Scientific Documentaries through Amazon Reviews",
        "author": [
            "Jill Naiman",
            "Aria Pessianzadeh",
            "Hanyu Zhao",
            "AJ Christensen",
            "Alistair Nunn",
            "Shriya Srikanth",
            "Anushka Gami",
            "Emma Maxwell",
            "Louisa Zhang",
            "Sri Nithya Yeragorla",
            "Rezvaneh Rezapour"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08705",
        "abstract": "Engaging the public with science is critical for a well-informed population. A popular method of scientific communication is documentaries. Once released, it can be difficult to assess the impact of such works on a large scale, due to the overhead required for in-depth audience feedback studies. In what follows, we overview our complementary approach to qualitative studies through quantitative impact and sentiment analysis of Amazon reviews for several scientific documentaries. In addition to developing a novel impact category taxonomy for this analysis, we release a dataset containing 1296 human-annotated sentences from 1043 Amazon reviews for six movies created in whole or part by a team of visualization designers who focus on cinematic presentations of scientific data. Using this data, we train and evaluate several machine learning and large language models, discussing their effectiveness and possible generalizability for documentaries beyond those focused on for this work. Themes are also extracted from our annotated dataset which, along with our large language model analysis, demonstrate a measure of the ability of scientific documentaries to engage with the public.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "18",
        "title": "Recurrent Memory for Online Interdomain Gaussian Processes",
        "author": [
            "Wenlong Chen",
            "Naoki Kiyohara",
            "Harrison Bo Hua Zhu",
            "Yingzhen Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08736",
        "abstract": "We propose a novel online Gaussian process (GP) model that is capable of capturing long-term memory in sequential data in an online regression setting. Our model, Online HiPPO Sparse Variational Gaussian Process Regression (OHSGPR), leverages the HiPPO (High-order Polynomial Projection Operators) framework, which is popularized in the RNN domain due to its long-range memory modeling capabilities. We interpret the HiPPO time-varying orthogonal projections as inducing variables with time-dependent orthogonal polynomial basis functions, which allows the SGPR inducing points to memorize the process history. We show that the HiPPO framework fits naturally into the interdomain GP framework and demonstrate that the kernel matrices can also be updated online in a recurrence form based on the ODE evolution of HiPPO. We evaluate our method on time series regression tasks, showing that it outperforms the existing online GP method in terms of predictive performance and computational efficiency",
        "tags": [
            "ODE",
            "RNN"
        ]
    },
    {
        "id": "19",
        "title": "From PowerPoint UI Sketches to Web-Based Applications: Pattern-Driven Code Generation for GIS Dashboard Development Using Knowledge-Augmented LLMs, Context-Aware Visual Prompting, and the React Framework",
        "author": [
            "Haowen Xu",
            "Xiao-Ying Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08756",
        "abstract": "Developing web-based GIS applications, commonly known as CyberGIS dashboards, for querying and visualizing GIS data in environmental research often demands repetitive and resource-intensive efforts. While Generative AI offers automation potential for code generation, it struggles with complex scientific applications due to challenges in integrating domain knowledge, software engineering principles, and UI design best practices. This paper introduces a knowledge-augmented code generation framework that retrieves software engineering best practices, domain expertise, and advanced technology stacks from a specialized knowledge base to enhance Generative Pre-trained Transformers (GPT) for front-end development. The framework automates the creation of GIS-based web applications (e.g., dashboards, interfaces) from user-defined UI wireframes sketched in tools like PowerPoint or Adobe Illustrator. A novel Context-Aware Visual Prompting method, implemented in Python, extracts layouts and interface features from these wireframes to guide code generation. Our approach leverages Large Language Models (LLMs) to generate front-end code by integrating structured reasoning, software engineering principles, and domain knowledge, drawing inspiration from Chain-of-Thought (CoT) prompting and Retrieval-Augmented Generation (RAG). A case study demonstrates the framework's capability to generate a modular, maintainable web platform hosting multiple dashboards for visualizing environmental and energy data (e.g., time-series, shapefiles, rasters) from user-sketched wireframes. By employing a knowledge-driven approach, the framework produces scalable, industry-standard front-end code using design patterns such as Model-View-ViewModel (MVVM) and frameworks like React. This significantly reduces manual effort in design and coding, pioneering an automated and efficient method for developing smart city software.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "20",
        "title": "Contextual bandits with entropy-based human feedback",
        "author": [
            "Raihan Seraj",
            "Lili Meng",
            "Tristan Sylvain"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08759",
        "abstract": "In recent years, preference-based human feedback mechanisms have become essential for enhancing model performance across diverse applications, including conversational AI systems such as ChatGPT. However, existing approaches often neglect critical aspects, such as model uncertainty and the variability in feedback quality. To address these challenges, we introduce an entropy-based human feedback framework for contextual bandits, which dynamically balances exploration and exploitation by soliciting expert feedback only when model entropy exceeds a predefined threshold. Our method is model-agnostic and can be seamlessly integrated with any contextual bandit agent employing stochastic policies. Through comprehensive experiments, we show that our approach achieves significant performance improvements while requiring minimal human feedback, even under conditions of suboptimal feedback quality. This work not only presents a novel strategy for feedback solicitation but also highlights the robustness and efficacy of incorporating human guidance into machine learning systems. Our code is publicly available: https://github.com/BorealisAI/CBHF",
        "tags": [
            "ChatGPT"
        ]
    },
    {
        "id": "21",
        "title": "Cluster and Predict Latents Patches for Improved Masked Image Modeling",
        "author": [
            "TimothÃ©e Darcet",
            "Federico Baldassarre",
            "Maxime Oquab",
            "Julien Mairal",
            "Piotr Bojanowski"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08769",
        "abstract": "Masked Image Modeling (MIM) offers a promising approach to self-supervised representation learning, however existing MIM models still lag behind the state-of-the-art. In this paper, we systematically analyze target representations, loss functions, and architectures, to introduce CAPI - a novel pure-MIM framework that relies on the prediction of latent clusterings. Our approach leverages a clustering-based loss, which is stable to train, and exhibits promising scaling properties. Our ViT-L backbone, CAPI, achieves 83.8% accuracy on ImageNet and 32.1% mIoU on ADE20K with simple linear probes, substantially outperforming previous MIM methods and approaching the performance of the current state-of-the-art, DINOv2. We release all our code and models.",
        "tags": [
            "ViT"
        ]
    },
    {
        "id": "22",
        "title": "Universal Model Routing for Efficient LLM Inference",
        "author": [
            "Wittawat Jitkrittum",
            "Harikrishna Narasimhan",
            "Ankit Singh Rawat",
            "Jeevesh Juneja",
            "Zifeng Wang",
            "Chen-Yu Lee",
            "Pradeep Shenoy",
            "Rina Panigrahy",
            "Aditya Krishna Menon",
            "Sanjiv Kumar"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08773",
        "abstract": "Large language models' significant advances in capabilities are accompanied by significant increases in inference costs. Model routing is a simple technique for reducing inference cost, wherein one maintains a pool of candidate LLMs, and learns to route each prompt to the smallest feasible LLM. Existing works focus on learning a router for a fixed pool of LLMs. In this paper, we consider the problem of dynamic routing, where new, previously unobserved LLMs are available at test time. We propose a new approach to this problem that relies on representing each LLM as a feature vector, derived based on predictions on a set of representative prompts. Based on this, we detail two effective strategies, relying on cluster-based routing and a learned cluster map respectively. We prove that these strategies are estimates of a theoretically optimal routing rule, and provide an excess risk bound to quantify their errors. Experiments on a range of public benchmarks show the effectiveness of the proposed strategies in routing amongst more than 30 unseen LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "23",
        "title": "Zero-Shot Belief: A Hard Problem for LLMs",
        "author": [
            "John Murzaku",
            "Owen Rambow"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08777",
        "abstract": "We present two LLM-based approaches to zero-shot source-and-target belief prediction on FactBank: a unified system that identifies events, sources, and belief labels in a single pass, and a hybrid approach that uses a fine-tuned DeBERTa tagger for event detection. We show that multiple open-sourced, closed-source, and reasoning-based LLMs struggle with the task. Using the hybrid approach, we achieve new state-of-the-art results on FactBank and offer a detailed error analysis. Our approach is then tested on the Italian belief corpus ModaFact.",
        "tags": [
            "Detection",
            "LLMs"
        ]
    },
    {
        "id": "24",
        "title": "If Multi-Agent Debate is the Answer, What is the Question?",
        "author": [
            "Hangfan Zhang",
            "Zhiyao Cui",
            "Xinrun Wang",
            "Qiaosheng Zhang",
            "Zhen Wang",
            "Dinghao Wu",
            "Shuyue Hu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08788",
        "abstract": "Multi-agent debate (MAD) has emerged as a promising approach to enhance the factual accuracy and reasoning quality of large language models (LLMs) by engaging multiple agents in iterative discussions during inference. Despite its potential, we argue that current MAD research suffers from critical shortcomings in evaluation practices, including limited dataset overlap and inconsistent baselines, raising significant concerns about generalizability. Correspondingly, this paper presents a systematic evaluation of five representative MAD methods across nine benchmarks using four foundational models. Surprisingly, our findings reveal that MAD methods fail to reliably outperform simple single-agent baselines such as Chain-of-Thought and Self-Consistency, even when consuming additional inference-time computation. From our analysis, we found that model heterogeneity can significantly improve MAD frameworks. We propose Heter-MAD enabling a single LLM agent to access the output from heterogeneous foundation models, which boosts the performance of current MAD frameworks. Finally, we outline potential directions for advancing MAD, aiming to spark a broader conversation and inspire future work in this area.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "25",
        "title": "ClipRover: Zero-shot Vision-Language Exploration and Target Discovery by Mobile Robots",
        "author": [
            "Yuxuan Zhang",
            "Adnan Abdullah",
            "Sanjeev J. Koppal",
            "Md Jahidul Islam"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08791",
        "abstract": "Vision-language navigation (VLN) has emerged as a promising paradigm, enabling mobile robots to perform zero-shot inference and execute tasks without specific pre-programming. However, current systems often separate map exploration and path planning, with exploration relying on inefficient algorithms due to limited (partially observed) environmental information. In this paper, we present a novel navigation pipeline named ''ClipRover'' for simultaneous exploration and target discovery in unknown environments, leveraging the capabilities of a vision-language model named CLIP. Our approach requires only monocular vision and operates without any prior map or knowledge about the target. For comprehensive evaluations, we design the functional prototype of a UGV (unmanned ground vehicle) system named ''Rover Master'', a customized platform for general-purpose VLN tasks. We integrate and deploy the ClipRover pipeline on Rover Master to evaluate its throughput, obstacle avoidance capability, and trajectory performance across various real-world scenarios. Experimental results demonstrate that ClipRover consistently outperforms traditional map traversal algorithms and achieves performance comparable to path-planning methods that depend on prior map and target knowledge. Notably, ClipRover offers real-time active navigation without requiring pre-captured candidate images or pre-built node graphs, addressing key limitations of existing VLN pipelines.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "26",
        "title": "Spectral Journey: How Transformers Predict the Shortest Path",
        "author": [
            "Andrew Cohen",
            "Andrey Gromov",
            "Kaiyu Yang",
            "Yuandong Tian"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08794",
        "abstract": "Decoder-only transformers lead to a step-change in capability of large language models. However, opinions are mixed as to whether they are really planning or reasoning. A path to making progress in this direction is to study the model's behavior in a setting with carefully controlled data. Then interpret the learned representations and reverse-engineer the computation performed internally. We study decoder-only transformer language models trained from scratch to predict shortest paths on simple, connected and undirected graphs. In this setting, the representations and the dynamics learned by the model are interpretable. We present three major results: (1) Two-layer decoder-only language models can learn to predict shortest paths on simple, connected graphs containing up to 10 nodes. (2) Models learn a graph embedding that is correlated with the spectral decomposition of the line graph. (3) Following the insights, we discover a novel approximate path-finding algorithm Spectral Line Navigator (SLN) that finds shortest path by greedily selecting nodes in the space of spectral embedding of the line graph.",
        "tags": [
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "27",
        "title": "Low-Resolution Neural Networks",
        "author": [
            "Eduardo Lobo Lustosa Cabral",
            "Larissa Driemeier"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08795",
        "abstract": "The expanding scale of large neural network models introduces significant challenges, driving efforts to reduce memory usage and enhance computational efficiency. Such measures are crucial to ensure the practical implementation and effective application of these sophisticated models across a wide array of use cases. This study examines the impact of parameter bit precision on model performance compared to standard 32-bit models, with a focus on multiclass object classification in images. The models analyzed include those with fully connected layers, convolutional layers, and transformer blocks, with model weight resolution ranging from 1 bit to 4.08 bits. The findings indicate that models with lower parameter bit precision achieve results comparable to 32-bit models, showing promise for use in memory-constrained devices. While low-resolution models with a small number of parameters require more training epochs to achieve accuracy comparable to 32-bit models, those with a large number of parameters achieve similar performance within the same number of epochs. Additionally, data augmentation can destabilize training in low-resolution models, but including zero as a potential value in the weight parameters helps maintain stability and prevents performance degradation. Overall, 2.32-bit weights offer the optimal balance of memory reduction, performance, and efficiency. However, further research should explore other dataset types and more complex and larger models. These findings suggest a potential new era for optimized neural network models with reduced memory requirements and improved computational efficiency, though advancements in dedicated hardware are necessary to fully realize this potential.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "28",
        "title": "A Systematic Review on the Evaluation of Large Language Models in Theory of Mind Tasks",
        "author": [
            "Karahan SarÄ±taÅ",
            "KÄ±vanÃ§ TezÃ¶ren",
            "Yavuz Durmazkeser"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08796",
        "abstract": "In recent years, evaluating the Theory of Mind (ToM) capabilities of large language models (LLMs) has received significant attention within the research community. As the field rapidly evolves, navigating the diverse approaches and methodologies has become increasingly complex. This systematic review synthesizes current efforts to assess LLMs' ability to perform ToM tasks, an essential aspect of human cognition involving the attribution of mental states to oneself and others. Despite notable advancements, the proficiency of LLMs in ToM remains a contentious issue. By categorizing benchmarks and tasks through a taxonomy rooted in cognitive science, this review critically examines evaluation techniques, prompting strategies, and the inherent limitations of LLMs in replicating human-like mental state reasoning. A recurring theme in the literature reveals that while LLMs demonstrate emerging competence in ToM tasks, significant gaps persist in their emulation of human cognitive abilities.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "29",
        "title": "Deep EEG Super-Resolution: Upsampling EEG Spatial Resolution with Generative Adversarial Networks",
        "author": [
            "Isaac Corley",
            "Yufei Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08803",
        "abstract": "Electroencephalography (EEG) activity contains a wealth of information about what is happening within the human brain. Recording more of this data has the potential to unlock endless future applications. However, the cost of EEG hardware is increasingly expensive based upon the number of EEG channels being recorded simultaneously. We combat this problem in this paper by proposing a novel deep EEG super-resolution (SR) approach based on Generative Adversarial Networks (GANs). This approach can produce high spatial resolution EEG data from low resolution samples, by generating channel-wise upsampled data to effectively interpolate numerous missing channels, thus reducing the need for expensive EEG equipment. We tested the performance using an EEG dataset from a mental imagery task. Our proposed GAN model provided 10^4 fold and 10^2 fold reduction in mean-squared error (MSE) and mean-absolute error (MAE), respectively, over the baseline bicubic interpolation method. We further validate our method by training a classifier on the original classification task, which displayed minimal loss in accuracy while using the super-resolved data. The proposed SR EEG by GAN is a promising approach to improve the spatial resolution of low density EEG headsets.",
        "tags": [
            "GAN",
            "Super Resolution"
        ]
    },
    {
        "id": "30",
        "title": "CLOVER: A Test Case Generation Benchmark with Coverage, Long-Context, and Verification",
        "author": [
            "Jiacheng Xu",
            "Bo Pang",
            "Jin Qu",
            "Hiroaki Hayashi",
            "Caiming Xiong",
            "Yingbo Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08806",
        "abstract": "Software testing is a critical aspect of software development, yet generating test cases remains a routine task for engineers. This paper presents a benchmark, CLOVER, to evaluate models' capabilities in generating and completing test cases under specific conditions. Spanning from simple assertion completions to writing test cases that cover specific code blocks across multiple files, these tasks are based on 12 python repositories, analyzing 845 problems with context lengths ranging from 4k to 128k tokens. Utilizing code testing frameworks, we propose a method to construct retrieval contexts using coverage information. While models exhibit comparable performance with short contexts, notable differences emerge with 16k contexts. Notably, models like GPT-4o and Claude 3.5 can effectively leverage relevant snippets; however, all models score below 35\\% on the complex Task III, even with the oracle context provided, underscoring the benchmark's significance and the potential for model improvement. The benchmark is containerized for code execution across tasks, and we will release the code, data, and construction methodologies.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "31",
        "title": "InTAR: Inter-Task Auto-Reconfigurable Accelerator Design for High Data Volume Variation in DNNs",
        "author": [
            "Zifan He",
            "Anderson Truong",
            "Yingqi Cao",
            "Jason Cong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08807",
        "abstract": "The rise of deep neural networks (DNNs) has driven a boom in AI services, which results in an increased demand for computing power and memory. In modern DNNs, the data sizes produced and consumed are highly varied across operations (high data volume variation, HDV). Because existing design paradigms use fixed execution patterns that lead to either low computational efficiency due to pipeline stalls or frequent off-chip memory accesses to manage large intermediate data, HDV applications are challenging to accelerate on FPGAs. To address these challenges, we introduce the Inter-Task Auto-Reconfigurable Accelerator (InTAR), a novel accelerator design for HDV applications on FPGAs. InTAR combines the high computational efficiency of sequential execution with the reduced off-chip memory overhead of dataflow execution. It switches execution patterns automatically with a static schedule determined before circuit design based on resource constraints and model parameters. Unlike previous reconfigurable accelerators, InTAR encodes reconfiguration schedules during circuit design, allowing model-specific optimizations that allocate only the necessary logic and interconnects. Thus, InTAR achieves a high clock frequency with fewer resources and low reconfiguration time. Furthermore, InTAR supports high-level tools such as HLS for fast design generation. We implement a set of multi-task kernels in various HDV DNNs using InTAR. Compared with dataflow and sequential accelerators, InTAR exhibits $1.8\\times$ and $7.1 \\times$ speedups correspondingly. We also implement InTAR for GPT-2 medium as a more complex example, which achieves a speedup of $\\mathbf{3.65 \\sim 39.14\\times}$ and a $\\mathbf{1.72 \\sim 10.44\\times}$ boost in DSP efficiency compared to the corresponding SoTA accelerators on FPGAs.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "32",
        "title": "A First-order Generative Bilevel Optimization Framework for Diffusion Models",
        "author": [
            "Quan Xiao",
            "Hui Yuan",
            "A F M Saif",
            "Gaowen Liu",
            "Ramana Kompella",
            "Mengdi Wang",
            "Tianyi Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08808",
        "abstract": "Diffusion models, which iteratively denoise data samples to synthesize high-quality outputs, have achieved empirical success across domains. However, optimizing these models for downstream tasks often involves nested bilevel structures, such as tuning hyperparameters for fine-tuning tasks or noise schedules in training dynamics, where traditional bilevel methods fail due to the infinite-dimensional probability space and prohibitive sampling costs. We formalize this challenge as a generative bilevel optimization problem and address two key scenarios: (1) fine-tuning pre-trained models via an inference-only lower-level solver paired with a sample-efficient gradient estimator for the upper level, and (2) training diffusion models from scratch with noise schedule optimization by reparameterizing the lower-level problem and designing a computationally tractable gradient estimator. Our first-order bilevel framework overcomes the incompatibility of conventional bilevel methods with diffusion processes, offering theoretical grounding and computational practicality. Experiments demonstrate that our method outperforms existing fine-tuning and hyperparameter search baselines.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "33",
        "title": "Lexical Manifold Reconfiguration in Large Language Models: A Novel Architectural Approach for Contextual Modulation",
        "author": [
            "Koinis Vassilis",
            "Godfrey Milbourne",
            "Harriet Featherstone",
            "Xanthe Peverell",
            "Yorick Bletchley",
            "Zachary Montford"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08818",
        "abstract": "Contextual adaptation in token embeddings plays a central role in determining how well language models maintain coherence and retain semantic relationships over extended text sequences. Static embeddings often impose constraints on lexical flexibility, leading to suboptimal performance when faced with complex sentence structures or domain-specific terminology shifts. To address this limitation, a structured approach was developed for dynamically reconfiguring token embeddings through continuous geometric transformations, ensuring that representations evolved in response to evolving discourse structures. A manifold-based transformation mechanism was integrated to regulate lexical positioning, allowing embeddings to undergo controlled shifts while preserving linguistic relationships across varying textual contexts. Empirical evaluations demonstrated that embedding reconfiguration contributed to reductions in perplexity, improved lexical coherence, and enhanced sentence-level continuity, particularly in structured and domain-adaptive text generation tasks. Comparative analyses of embedding drift indicated that dynamically restructured representations maintained stronger contextual consistency, reducing misalignment in token dependencies while preserving fluency in language modeling outputs. Computational overhead assessments confirmed that while training complexity increased due to the iterative refinement of embeddings, inference remained efficient, ensuring practical feasibility for real-time generation. Evaluations across multiple datasets further demonstrated that dynamically modulated embeddings exhibited broader lexical diversity, reducing repetitive token patterns and enabling a more adaptable representation learning process.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "34",
        "title": "Can a Single Model Master Both Multi-turn Conversations and Tool Use? CALM: A Unified Conversational Agentic Language Model",
        "author": [
            "Emre Can Acikgoz",
            "Jeremiah Greer",
            "Akul Datta",
            "Ze Yang",
            "William Zeng",
            "Oussama Elachqar",
            "Emmanouil Koukoumidis",
            "Dilek Hakkani-TÃ¼r",
            "Gokhan Tur"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08820",
        "abstract": "Large Language Models (LLMs) with API-calling capabilities enabled building effective Language Agents (LA), while also revolutionizing the conventional task-oriented dialogue (TOD) paradigm. However, current approaches face a critical dilemma: TOD systems are often trained on a limited set of target APIs, requiring new data to maintain their quality when interfacing with new services, while LAs are not trained to maintain user intent over multi-turn conversations. Because both robust multi-turn management and advanced function calling are crucial for effective conversational agents, we evaluate these skills on three popular benchmarks: MultiWOZ 2.4 (TOD), BFCL V3 (LA), and API-Bank (LA), and our analyses reveal that specialized approaches excel in one domain but underperform in the other. To bridge this chasm, we introduce CALM (Conversational Agentic Language Model), a unified approach that integrates both conversational and agentic capabilities. We created CALM-IT, a carefully constructed multi-task dataset that interleave multi-turn ReAct reasoning with complex API usage. Using CALM-IT, we train three models CALM 8B, CALM 70B, and CALM 405B, which outperform top domain-specific models, including GPT-4o, across all three benchmarks.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "35",
        "title": "DejAIvu: Identifying and Explaining AI Art on the Web in Real-Time with Saliency Maps",
        "author": [
            "Jocelyn Dzuong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08821",
        "abstract": "The recent surge in advanced generative models, such as diffusion models and generative adversarial networks (GANs), has led to an alarming rise in AI-generated images across various domains on the web. While such technologies offer benefits such as democratizing artistic creation, they also pose challenges in misinformation, digital forgery, and authenticity verification. Additionally, the uncredited use of AI-generated images in media and marketing has sparked significant backlash from online communities. In response to this, we introduce DejAIvu, a Chrome Web extension that combines real-time AI-generated image detection with saliency-based explainability while users browse the web. Using an ONNX-optimized deep learning model, DejAIvu automatically analyzes images on websites such as Google Images, identifies AI-generated content using model inference, and overlays a saliency heatmap to highlight AI-related artifacts. Our approach integrates efficient in-browser inference, gradient-based saliency analysis, and a seamless user experience, ensuring that AI detection is both transparent and interpretable. We also evaluate DejAIvu across multiple pretrained architectures and benchmark datasets, demonstrating high accuracy and low latency, making it a practical and deployable tool for enhancing AI image accountability. The code for this system can be found at https://github.com/Noodulz/dejAIvu.",
        "tags": [
            "Detection",
            "Diffusion"
        ]
    },
    {
        "id": "36",
        "title": "Ask in Any Modality: A Comprehensive Survey on Multimodal Retrieval-Augmented Generation",
        "author": [
            "Mohammad Mahdi Abootorabi",
            "Amirhosein Zobeiri",
            "Mahdi Dehghani",
            "Mohammadali Mohammadkhani",
            "Bardia Mohammadi",
            "Omid Ghahroodi",
            "Mahdieh Soleymani Baghshah",
            "Ehsaneddin Asgari"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08826",
        "abstract": "Large Language Models (LLMs) struggle with hallucinations and outdated knowledge due to their reliance on static training data. Retrieval-Augmented Generation (RAG) mitigates these issues by integrating external dynamic information enhancing factual and updated grounding. Recent advances in multimodal learning have led to the development of Multimodal RAG, incorporating multiple modalities such as text, images, audio, and video to enhance the generated outputs. However, cross-modal alignment and reasoning introduce unique challenges to Multimodal RAG, distinguishing it from traditional unimodal RAG. This survey offers a structured and comprehensive analysis of Multimodal RAG systems, covering datasets, metrics, benchmarks, evaluation, methodologies, and innovations in retrieval, fusion, augmentation, and generation. We precisely review training strategies, robustness enhancements, and loss functions, while also exploring the diverse Multimodal RAG scenarios. Furthermore, we discuss open challenges and future research directions to support advancements in this evolving field. This survey lays the foundation for developing more capable and reliable AI systems that effectively leverage multimodal dynamic external knowledge bases. Resources are available at https://github.com/llm-lab-org/Multimodal-RAG-Survey.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "37",
        "title": "A Reversible Solver for Diffusion SDEs",
        "author": [
            "Zander W. Blasingame",
            "Chen Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08834",
        "abstract": "Diffusion models have quickly become the state-of-the-art for generation tasks across many different data modalities. An important ability of diffusion models is the ability to encode samples from the data distribution back into the sampling prior distribution. This is useful for performing alterations to real data samples along with guided generation via the continuous adjoint equations. We propose an algebraically reversible solver for diffusion SDEs that can exactly invert real data samples into the prior distribution.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "38",
        "title": "Delayed takedown of illegal content on social media makes moderation ineffective",
        "author": [
            "Bao Tran Truong",
            "Sangyeon Kim",
            "Gianluca Nogara",
            "Enrico Verdolotti",
            "Erfan Samieyan Sahneh",
            "Florian Saurwein",
            "Natascha Just",
            "Luca Luceri",
            "Silvia Giordano",
            "Filippo Menczer"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08841",
        "abstract": "Social media platforms face legal and regulatory demands to swiftly remove illegal content, sometimes under strict takedown deadlines. However, the effects of moderation speed and the impact of takedown deadlines remain underexplored. This study models the relationship between the timeliness of illegal content removal and its prevalence, reach, and exposure on social media. By simulating illegal content diffusion using empirical data from the DSA Transparency Database, we demonstrate that rapid takedown (within hours) significantly reduces illegal content prevalence and exposure, while longer delays decrease the effectiveness of moderation efforts. While these findings support tight takedown deadlines for content removal, such deadlines cannot address the delay in identifying the illegal content and can adversely affect the quality of content moderation.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "39",
        "title": "BrainWavLM: Fine-tuning Speech Representations with Brain Responses to Language",
        "author": [
            "Nishitha Vattikonda",
            "Aditya R. Vaidya",
            "Richard J. Antonello",
            "Alexander G. Huth"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08866",
        "abstract": "Speech encoding models use auditory representations to predict how the human brain responds to spoken language stimuli. Most performant encoding models linearly map the hidden states of artificial neural networks to brain data, but this linear restriction may limit their effectiveness. In this work, we use low-rank adaptation (LoRA) to fine-tune a WavLM-based encoding model end-to-end on a brain encoding objective, producing a model we name BrainWavLM. We show that fine-tuning across all of cortex improves average encoding performance with greater stability than without LoRA. This improvement comes at the expense of low-level regions like auditory cortex (AC), but selectively fine-tuning on these areas improves performance in AC, while largely retaining gains made in the rest of cortex. Fine-tuned models generalized across subjects, indicating that they learned robust brain-like representations of the speech stimuli. Finally, by training linear probes, we showed that the brain data strengthened semantic representations in the speech model without any explicit annotations. Our results demonstrate that brain fine-tuning produces best-in-class speech encoding models, and that non-linear methods have the potential to bridge the gap between artificial and biological representations of semantics.",
        "tags": [
            "LoRA",
            "Low-Rank Adaptation"
        ]
    },
    {
        "id": "40",
        "title": "Harnessing Vision Models for Time Series Analysis: A Survey",
        "author": [
            "Jingchao Ni",
            "Ziming Zhao",
            "ChengAo Shen",
            "Hanghang Tong",
            "Dongjin Song",
            "Wei Cheng",
            "Dongsheng Luo",
            "Haifeng Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08869",
        "abstract": "Time series analysis has witnessed the inspiring development from traditional autoregressive models, deep learning models, to recent Transformers and Large Language Models (LLMs). Efforts in leveraging vision models for time series analysis have also been made along the way but are less visible to the community due to the predominant research on sequence modeling in this domain. However, the discrepancy between continuous time series and the discrete token space of LLMs, and the challenges in explicitly modeling the correlations of variates in multivariate time series have shifted some research attentions to the equally successful Large Vision Models (LVMs) and Vision Language Models (VLMs). To fill the blank in the existing literature, this survey discusses the advantages of vision models over LLMs in time series analysis. It provides a comprehensive and in-depth overview of the existing methods, with dual views of detailed taxonomy that answer the key research questions including how to encode time series as images and how to model the imaged time series for various tasks. Additionally, we address the challenges in the pre- and post-processing steps involved in this framework and outline future directions to further advance time series analysis with vision models.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "41",
        "title": "2D Integrated Bayesian Tomography of Plasma Electron Density Profile for HL-3 Based on Gaussian Process",
        "author": [
            "Cong Wang",
            "Renjie Yang",
            "Dong Li",
            "Zongyu Yang",
            "Zhijun Wang",
            "Yixiong Wei",
            "Jing Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08882",
        "abstract": "This paper introduces an integrated Bayesian model that combines line integral measurements and point values using Gaussian Process (GP). The proposed method leverages Gaussian Process Regression (GPR) to incorporate point values into 2D profiles and employs coordinate mapping to integrate magnetic flux information for 2D inversion. The average relative error of the reconstructed profile, using the integrated Bayesian tomography model with normalized magnetic flux, is as low as 3.60*10^(-4). Additionally, sensitivity tests were conducted on the number of grids, the standard deviation of synthetic diagnostic data, and noise levels, laying a solid foundation for the application of the model to experimental data. This work not only achieves accurate 2D inversion using the integrated Bayesian model but also provides a robust framework for decoupling pressure information from equilibrium reconstruction, thus making it possible to optimize equilibrium reconstruction using inversion results.",
        "tags": [
            "FLUX"
        ]
    },
    {
        "id": "42",
        "title": "ShapeLib: designing a library of procedural 3D shape abstractions with Large Language Models",
        "author": [
            "R. Kenny Jones",
            "Paul Guerrero",
            "Niloy J. Mitra",
            "Daniel Ritchie"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08884",
        "abstract": "Procedural representations are desirable, versatile, and popular shape encodings. Authoring them, either manually or using data-driven procedures, remains challenging, as a well-designed procedural representation should be compact, intuitive, and easy to manipulate. A long-standing problem in shape analysis studies how to discover a reusable library of procedural functions, with semantically aligned exposed parameters, that can explain an entire shape family. We present ShapeLib as the first method that leverages the priors of frontier LLMs to design a library of 3D shape abstraction functions. Our system accepts two forms of design intent: text descriptions of functions to include in the library and a seed set of exemplar shapes. We discover procedural abstractions that match this design intent by proposing, and then validating, function applications and implementations. The discovered shape functions in the library are not only expressive but also generalize beyond the seed set to a full family of shapes. We train a recognition network that learns to infer shape programs based on our library from different visual modalities (primitives, voxels, point clouds). Our shape functions have parameters that are semantically interpretable and can be modified to produce plausible shape variations. We show that this allows inferred programs to be successfully manipulated by an LLM given a text prompt. We evaluate ShapeLib on different datasets and show clear advantages over existing methods and alternative formulations.",
        "tags": [
            "3D",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "43",
        "title": "Communication is All You Need: Persuasion Dataset Construction via Multi-LLM Communication",
        "author": [
            "Weicheng Ma",
            "Hefan Zhang",
            "Ivory Yang",
            "Shiyu Ji",
            "Joice Chen",
            "Farnoosh Hashemi",
            "Shubham Mohole",
            "Ethan Gearey",
            "Michael Macy",
            "Saeed Hassanpour",
            "Soroush Vosoughi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08896",
        "abstract": "Large Language Models (LLMs) have shown proficiency in generating persuasive dialogue, yet concerns about the fluency and sophistication of their outputs persist. This paper presents a multi-LLM communication framework designed to enhance the generation of persuasive data automatically. This framework facilitates the efficient production of high-quality, diverse linguistic content with minimal human oversight. Through extensive evaluations, we demonstrate that the generated data excels in naturalness, linguistic diversity, and the strategic use of persuasion, even in complex scenarios involving social taboos. The framework also proves adept at generalizing across novel contexts. Our results highlight the framework's potential to significantly advance research in both computational and social science domains concerning persuasive communication.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "44",
        "title": "Can Uniform Meaning Representation Help GPT-4 Translate from Indigenous Languages?",
        "author": [
            "Shira Wein"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08900",
        "abstract": "While ChatGPT and GPT-based models are able to effectively perform many tasks without additional fine-tuning, they struggle with related to extremely low-resource languages and indigenous languages. Uniform Meaning Representation (UMR), a semantic representation designed to capture the meaning of texts in many languages, is well-poised to be leveraged in the development of low-resource language technologies. In this work, we explore the downstream technical utility of UMR for low-resource languages by incorporating it into GPT-4 prompts. Specifically, we examine the ability of GPT-4 to perform translation from three indigenous languages (Navajo, ArÃ¡paho, and Kukama), with and without demonstrations, as well as with and without UMR annotations. Ultimately we find that in the majority of our test cases, integrating UMR into the prompt results in a statistically significant increase in performance, which is a promising indication of future applications of the UMR formalism.",
        "tags": [
            "ChatGPT",
            "GPT"
        ]
    },
    {
        "id": "45",
        "title": "3D-Grounded Vision-Language Framework for Robotic Task Planning: Automated Prompt Synthesis and Supervised Reasoning",
        "author": [
            "Guoqin Tang",
            "Qingxuan Jia",
            "Zeyuan Huang",
            "Gang Chen",
            "Ning Ji",
            "Zhipeng Yao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08903",
        "abstract": "Vision-language models (VLMs) have achieved remarkable success in scene understanding and perception tasks, enabling robots to plan and execute actions adaptively in dynamic environments. However, most multimodal large language models lack robust 3D scene localization capabilities, limiting their effectiveness in fine-grained robotic operations. Additionally, challenges such as low recognition accuracy, inefficiency, poor transferability, and reliability hinder their use in precision tasks. To address these limitations, we propose a novel framework that integrates a 2D prompt synthesis module by mapping 2D images to point clouds, and incorporates a small language model (SLM) for supervising VLM outputs. The 2D prompt synthesis module enables VLMs, trained on 2D images and text, to autonomously extract precise 3D spatial information without manual intervention, significantly enhancing 3D scene understanding. Meanwhile, the SLM supervises VLM outputs, mitigating hallucinations and ensuring reliable, executable robotic control code generation. Our framework eliminates the need for retraining in new environments, thereby improving cost efficiency and operational robustness. Experimental results that the proposed framework achieved a 96.0\\% Task Success Rate (TSR), outperforming other methods. Ablation studies demonstrated the critical role of both the 2D prompt synthesis module and the output supervision module (which, when removed, caused a 67\\% TSR drop). These findings validate the framework's effectiveness in improving 3D recognition, task planning, and robotic task execution.",
        "tags": [
            "3D",
            "Large Language Models"
        ]
    },
    {
        "id": "46",
        "title": "MIH-TCCT: Mitigating Inconsistent Hallucinations in LLMs via Event-Driven Text-Code Cyclic Training",
        "author": [
            "Xinxin You",
            "Xien Liu",
            "Qixin Sun",
            "Huan Zhang",
            "Kaiyin Zhou",
            "Shaohui Liu",
            "GuoPing Hu",
            "ShiJin Wang",
            "Si Liu",
            "Ji Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08904",
        "abstract": "Recent methodologies utilizing synthetic datasets have aimed to address inconsistent hallucinations in large language models (LLMs); however,these approaches are primarily tailored to specific tasks, limiting their generalizability. Inspired by the strong performance of code-trained models in logic-intensive domains, we propose a novel framework that leverages event-based text to generate corresponding code and employs cyclic training to transfer the logical consistency of code to natural language effectively. Our method significantly reduces inconsistent hallucinations across three leading LLMs and two categories of natural language tasks while maintaining overall performance. This framework effectively alleviates hallucinations without necessitating adaptation to downstream tasks, demonstrating generality and providing new perspectives to tackle the challenge of inconsistent hallucinations.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "47",
        "title": "DiffoRA: Enabling Parameter-Efficient LLM Fine-Tuning via Differential Low-Rank Matrix Adaptation",
        "author": [
            "Tangyu Jiang",
            "Haodi Wang",
            "Chun Yuan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08905",
        "abstract": "The Parameter-Efficient Fine-Tuning (PEFT) methods have been extensively researched for large language models in the downstream tasks. Among all the existing approaches, the Low-Rank Adaptation (LoRA) has gained popularity for its streamlined design by incorporating low-rank matrices into existing pre-trained models. Though effective, LoRA allocates every module an identical low-rank matrix, which ignores the varying properties and contributions across different components. Moreover, the existing adaptive LoRA solutions rely highly on intuitive importance scoring indicators to adjust the interior rank of the decomposition matrices. In this paper, we propose a new PEFT scheme called DiffoRA, which is theoretically grounded and enables module-wise adoption of LoRA. At the core of our DiffoRA lies a Differential Adaptation Matrix (DAM) to determine which module is the most suitable and essential for fine-tuning. We explain how the designed matrix impacts the convergence rate and generalization capability of a pre-trained model. Furthermore, we construct the DAM via continuous relaxation and discretization with weight-sharing optimizations. We fully implement our DiffoRA and design comprehensive experiments to evaluate its performance. The experimental results demonstrate that our approach achieves the best model accuracy over all the state-of-the-art baselines across various benchmarks.",
        "tags": [
            "Large Language Models",
            "LoRA",
            "Low-Rank Adaptation"
        ]
    },
    {
        "id": "48",
        "title": "Towards Automated Fact-Checking of Real-World Claims: Exploring Task Formulation and Assessment with LLMs",
        "author": [
            "Premtim Sahitaj",
            "Iffat Maab",
            "Junichi Yamagishi",
            "Jawan Kolanowski",
            "Sebastian MÃ¶ller",
            "Vera Schmitt"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08909",
        "abstract": "Fact-checking is necessary to address the increasing volume of misinformation. Traditional fact-checking relies on manual analysis to verify claims, but it is slow and resource-intensive. This study establishes baseline comparisons for Automated Fact-Checking (AFC) using Large Language Models (LLMs) across multiple labeling schemes (binary, three-class, five-class) and extends traditional claim verification by incorporating analysis, verdict classification, and explanation in a structured setup to provide comprehensive justifications for real-world claims. We evaluate Llama-3 models of varying sizes (3B, 8B, 70B) on 17,856 claims collected from PolitiFact (2007-2024) using evidence retrieved via restricted web searches. We utilize TIGERScore as a reference-free evaluation metric to score the justifications. Our results show that larger LLMs consistently outperform smaller LLMs in classification accuracy and justification quality without fine-tuning. We find that smaller LLMs in a one-shot scenario provide comparable task performance to fine-tuned Small Language Models (SLMs) with large context sizes, while larger LLMs consistently surpass them. Evidence integration improves performance across all models, with larger LLMs benefiting most. Distinguishing between nuanced labels remains challenging, emphasizing the need for further exploration of labeling schemes and alignment with evidences. Our findings demonstrate the potential of retrieval-augmented AFC with LLMs.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "49",
        "title": "InfiniteHiP: Extending Language Model Context Up to 3 Million Tokens on a Single GPU",
        "author": [
            "Heejun Lee",
            "Geon Park",
            "Jaduk Suh",
            "Sung Ju Hwang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08910",
        "abstract": "In modern large language models (LLMs), handling very long context lengths presents significant challenges as it causes slower inference speeds and increased memory costs. Additionally, most existing pre-trained LLMs fail to generalize beyond their original training sequence lengths. To enable efficient and practical long-context utilization, we introduce InfiniteHiP, a novel, and practical LLM inference framework that accelerates processing by dynamically eliminating irrelevant context tokens through a modular hierarchical token pruning algorithm. Our method also allows generalization to longer sequences by selectively applying various RoPE adjustment methods according to the internal attention patterns within LLMs. Furthermore, we offload the key-value cache to host memory during inference, significantly reducing GPU memory pressure. As a result, InfiniteHiP enables the processing of up to 3 million tokens on a single L40s 48GB GPU -- 3x larger -- without any permanent loss of context information. Our framework achieves an 18.95x speedup in attention decoding for a 1 million token context without requiring additional training. We implement our method in the SGLang framework and demonstrate its effectiveness and practicality through extensive evaluations.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "50",
        "title": "Diffusion Models Through a Global Lens: Are They Culturally Inclusive?",
        "author": [
            "Zahra Bayramli",
            "Ayhan Suleymanzade",
            "Na Min An",
            "Huzama Ahmad",
            "Eunsu Kim",
            "Junyeong Park",
            "James Thorne",
            "Alice Oh"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08914",
        "abstract": "Text-to-image diffusion models have recently enabled the creation of visually compelling, detailed images from textual prompts. However, their ability to accurately represent various cultural nuances remains an open question. In our work, we introduce CultDiff benchmark, evaluating state-of-the-art diffusion models whether they can generate culturally specific images spanning ten countries. We show that these models often fail to generate cultural artifacts in architecture, clothing, and food, especially for underrepresented country regions, by conducting a fine-grained analysis of different similarity aspects, revealing significant disparities in cultural relevance, description fidelity, and realism compared to real-world reference images. With the collected human evaluations, we develop a neural-based image-image similarity metric, namely, CultDiff-S, to predict human judgment on real and generated images with cultural artifacts. Our work highlights the need for more inclusive generative AI systems and equitable dataset representation over a wide range of cultures.",
        "tags": [
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "51",
        "title": "Detecting Malicious Concepts Without Image Generation in AIGC",
        "author": [
            "Kun Xu",
            "Yushu Zhang",
            "Shuren Qi",
            "Tao Wang",
            "Wenying Wen",
            "Yuming Fang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08921",
        "abstract": "The task of text-to-image generation has achieved tremendous success in practice, with emerging concept generation models capable of producing highly personalized and customized content. Fervor for concept generation is increasing rapidly among users, and platforms for concept sharing have sprung up. The concept owners may upload malicious concepts and disguise them with non-malicious text descriptions and example images to deceive users into downloading and generating malicious content. The platform needs a quick method to determine whether a concept is malicious to prevent the spread of malicious concepts. However, simply relying on concept image generation to judge whether a concept is malicious requires time and computational resources. Especially, as the number of concepts uploaded and downloaded on the platform continues to increase, this approach becomes impractical and poses a risk of generating malicious content. In this paper, we propose Concept QuickLook, the first systematic work to incorporate malicious concept detection into research, which performs detection based solely on concept files without generating any images. We define malicious concepts and design two work modes for detection: concept matching and fuzzy detection. Extensive experiments demonstrate that the proposed Concept QuickLook can detect malicious concepts and demonstrate practicality in concept sharing platforms. We also design robustness experiments to further validate the effectiveness of the solution. We hope this work can initiate malicious concept detection tasks and provide some inspiration.",
        "tags": [
            "Detection",
            "Text-to-Image"
        ]
    },
    {
        "id": "52",
        "title": "Self-Consistency of the Internal Reward Models Improves Self-Rewarding Language Models",
        "author": [
            "Xin Zhou",
            "Yiwen Guo",
            "Ruotian Ma",
            "Tao Gui",
            "Qi Zhang",
            "Xuanjing Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08922",
        "abstract": "Aligning Large Language Models (LLMs) with human preferences is crucial for their deployment in real-world applications. Recent advancements in Self-Rewarding Language Models suggest that an LLM can use its internal reward models (such as LLM-as-a-Judge) \\cite{yuanself} to generate preference data, improving alignment performance without costly human annotation. However, we find that different internal reward models within the same LLM often generate inconsistent preferences. This inconsistency raises concerns about the reliability of self-generated preference data, hinders overall alignment performance, and highlights the need for further research to ensure reliable and coherent alignment with human preferences. To address this limitation, we propose Self-Consistent Internal Rewards (SCIR), a novel framework designed to enhance consistency among internal reward models during training. In each training step, we collect preference predictions from multiple pre-defined internal reward models and enforce consistency and confidence through an inconsistency penalty mechanism, thereby improving the reliability of these internal reward models. We selectively use data with consistent predictions for preference optimization, ensuring the quality of the preference data. By employing self-consistent internal rewards, our method significantly improves the alignment performance and reward modeling capability of LLMs, outperforming baseline methods by a notable margin.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "53",
        "title": "CopySpec: Accelerating LLMs with Speculative Copy-and-Paste Without Compromising Quality",
        "author": [
            "Razvan-Gabriel Dumitru",
            "Minglai Yang",
            "Vikas Yadav",
            "Mihai Surdeanu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08923",
        "abstract": "We introduce CopySpec, an innovative technique designed to tackle the inefficiencies LLMs face when generating responses that closely resemble previous outputs. CopySpec identifies repeated sequences in the model's chat history and speculates that the same tokens will follow, enabling seamless copying without compromising output quality or requiring additional GPU memory. To evaluate the effectiveness of our approach, we conducted experiments using five LLMs and five datasets: MT-Bench, CNN/DM, GSM-8K, HumanEval, and our newly created dataset, MT-Redundant. MT-Redundant, introduced in this paper, transforms the second turn of MT-Bench into a request for variations of the first turn's answer, simulating real-world scenarios where users request modifications to prior responses. Our results demonstrate significant speed-ups: up to 2.35x on CNN/DM, 3.08x on the second turn of select MT-Redundant categories, and 2.66x on the third turn of GSM-8K's self-correction tasks. Moreover, we show that CopySpec integrates seamlessly with speculative decoding, yielding an average 49% additional speed-up over speculative decoding for the second turn of MT-Redundant across all eight categories. While LLMs, even with speculative decoding, suffer from slower inference as context sizes grow, CopySpec leverages the expanded context to accelerate inference, making it faster as the context size increases. Our code and dataset are publicly available at https://github.com/RazvanDu/CopySpec.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "54",
        "title": "Escaping Collapse: The Strength of Weak Data for Large Language Model Training",
        "author": [
            "Kareem Amin",
            "Sara Babakniya",
            "Alex Bie",
            "Weiwei Kong",
            "Umar Syed",
            "Sergei Vassilvitskii"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08924",
        "abstract": "Synthetically-generated data plays an increasingly larger role in training large language models. However, while synthetic data has been found to be useful, studies have also shown that without proper curation it can cause LLM performance to plateau, or even \"collapse\", after many training iterations. In this paper, we formalize this question and develop a theoretical framework to investigate how much curation is needed in order to ensure that LLM performance continually improves. We find that the requirements are nearly minimal. We describe a training procedure that converges to an optimal LLM even if almost all of the non-synthetic training data is of poor quality. Our analysis is inspired by boosting, a classic machine learning technique that leverages a very weak learning algorithm to produce an arbitrarily good classifier. Our training procedure subsumes many recently proposed methods for training LLMs on synthetic data, and thus our analysis sheds light on why they are successful, and also suggests opportunities for future improvement. We present experiments that validate our theory, and show that dynamically focusing labeling resources on the most challenging examples -- in much the same way that boosting focuses the efforts of the weak learner -- leads to improved performance.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "55",
        "title": "TokenSynth: A Token-based Neural Synthesizer for Instrument Cloning and Text-to-Instrument",
        "author": [
            "Kyungsu Kim",
            "Junghyun Koo",
            "Sungho Lee",
            "Haesun Joung",
            "Kyogu Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08939",
        "abstract": "Recent advancements in neural audio codecs have enabled the use of tokenized audio representations in various audio generation tasks, such as text-to-speech, text-to-audio, and text-to-music generation. Leveraging this approach, we propose TokenSynth, a novel neural synthesizer that utilizes a decoder-only transformer to generate desired audio tokens from MIDI tokens and CLAP (Contrastive Language-Audio Pretraining) embedding, which has timbre-related information. Our model is capable of performing instrument cloning, text-to-instrument synthesis, and text-guided timbre manipulation without any fine-tuning. This flexibility enables diverse sound design and intuitive timbre control. We evaluated the quality of the synthesized audio, the timbral similarity between synthesized and target audio/text, and synthesis accuracy (i.e., how accurately it follows the input MIDI) using objective measures. TokenSynth demonstrates the potential of leveraging advanced neural audio codecs and transformers to create powerful and versatile neural synthesizers. The source code, model weights, and audio demos are available at: https://github.com/KyungsuKim42/tokensynth",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "56",
        "title": "Beyond the Singular: The Essential Role of Multiple Generations in Effective Benchmark Evaluation and Analysis",
        "author": [
            "Wenbo Zhang",
            "Hengrui Cai",
            "Wenyu Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08943",
        "abstract": "Large language models (LLMs) have demonstrated significant utilities in real-world applications, exhibiting impressive capabilities in natural language processing and understanding. Benchmark evaluations are crucial for assessing the capabilities of LLMs as they can provide a comprehensive assessment of their strengths and weaknesses. However, current evaluation methods often overlook the inherent randomness of LLMs by employing deterministic generation strategies or relying on a single random sample, resulting in unaccounted sampling variance and unreliable benchmark score estimates. In this paper, we propose a hierarchical statistical model that provides a more comprehensive representation of the benchmarking process by incorporating both benchmark characteristics and LLM randomness. We show that leveraging multiple generations improves the accuracy of estimating the benchmark score and reduces variance. We also introduce $\\mathbb P\\left(\\text{correct}\\right)$, a prompt-level difficulty score based on correct ratios, providing fine-grained insights into individual prompts. Additionally, we create a data map that visualizes difficulty and semantic prompts, enabling error detection and quality control in benchmark construction.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "57",
        "title": "The Stochastic Parrot on LLM's Shoulder: A Summative Assessment of Physical Concept Understanding",
        "author": [
            "Mo Yu",
            "Lemao Liu",
            "Junjie Wu",
            "Tsz Ting Chung",
            "Shunchi Zhang",
            "Jiangnan Li",
            "Dit-Yan Yeung",
            "Jie Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08946",
        "abstract": "In a systematic way, we investigate a widely asked question: Do LLMs really understand what they say?, which relates to the more familiar term Stochastic Parrot. To this end, we propose a summative assessment over a carefully designed physical concept understanding task, PhysiCo. Our task alleviates the memorization issue via the usage of grid-format inputs that abstractly describe physical phenomena. The grids represents varying levels of understanding, from the core phenomenon, application examples to analogies to other abstract patterns in the grid world. A comprehensive study on our task demonstrates: (1) state-of-the-art LLMs, including GPT-4o, o1 and Gemini 2.0 flash thinking, lag behind humans by ~40%; (2) the stochastic parrot phenomenon is present in LLMs, as they fail on our grid task but can describe and recognize the same concepts well in natural language; (3) our task challenges the LLMs due to intrinsic difficulties rather than the unfamiliar grid format, as in-context learning and fine-tuning on same formatted data added little to their performance.",
        "tags": [
            "GPT",
            "LLMs"
        ]
    },
    {
        "id": "58",
        "title": "Biologically Plausible Brain Graph Transformer",
        "author": [
            "Ciyuan Peng",
            "Yuelong Huang",
            "Qichao Dong",
            "Shuo Yu",
            "Feng Xia",
            "Chengqi Zhang",
            "Yaochu Jin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08958",
        "abstract": "State-of-the-art brain graph analysis methods fail to fully encode the small-world architecture of brain graphs (accompanied by the presence of hubs and functional modules), and therefore lack biological plausibility to some extent. This limitation hinders their ability to accurately represent the brain's structural and functional properties, thereby restricting the effectiveness of machine learning models in tasks such as brain disorder detection. In this work, we propose a novel Biologically Plausible Brain Graph Transformer (BioBGT) that encodes the small-world architecture inherent in brain graphs. Specifically, we present a network entanglement-based node importance encoding technique that captures the structural importance of nodes in global information propagation during brain graph communication, highlighting the biological properties of the brain structure. Furthermore, we introduce a functional module-aware self-attention to preserve the functional segregation and integration characteristics of brain graphs in the learned representations. Experimental results on three benchmark datasets demonstrate that BioBGT outperforms state-of-the-art models, enhancing biologically plausible brain graph representations for various brain graph analytical tasks",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "59",
        "title": "Residual Transformer Fusion Network for Salt and Pepper Image Denoising",
        "author": [
            "Bintang Pradana Erlangga Putra",
            "Heri Prasetyo",
            "Esti Suryani"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09000",
        "abstract": "Convolutional Neural Network (CNN) has been widely used in unstructured datasets, one of which is image denoising. Image denoising is a noisy image reconstruction process that aims to reduce additional noise that occurs from the noisy image with various strategies. Image denoising has a problem, namely that some image denoising methods require some prior knowledge of information about noise. To overcome this problem, a combined architecture of Convolutional Vision Transformer (CvT) and Residual Networks (ResNet) is used which is called the Residual Transformer Fusion Network (RTF-Net). In general, the process in this architecture can be divided into two parts, Noise Suppression Network (NSN) and Structure Enhancement Network (SEN). Residual Block is used in the Noise Suppression Network and is used to learn the noise map in the image, while the CvT is used in the Structure Enhancement Network and is used to learn the details that need to be added to the image processed by the Noise Suppression Network. The model was trained using the DIV2K Training Set dataset, and validation using the DIV2K Validation Set. After doing the training, the model was tested using Lena, Bridge, Pepper, and BSD300 images with noise levels ranging from 30%, 50%, and 70% and the PSNR results were compared with the DBA, NASNLM, PARIGI, NLSF, NLSF-MLP and NLSF-CNN methods. The test results show that the proposed method is superior in all cases except for Pepper's image with a noise level of 30%, where NLSF-CNN is superior with a PSNR value of 32.99 dB, while the proposed method gets a PSNR value of 31.70 dB.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "60",
        "title": "RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models",
        "author": [
            "Quan Wei",
            "Chung-Yiu Yau",
            "Hoi-To Wai",
            "Yang",
            "Zhao",
            "Dongyeop Kang",
            "Youngsuk Park",
            "Mingyi Hong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09003",
        "abstract": "Supervised fine-tuning is a standard method for adapting pre-trained large language models (LLMs) to downstream tasks. Quantization has been recently studied as a post-training technique for efficient LLM deployment. To obtain quantized fine-tuned LLMs, conventional pipelines would first fine-tune the pre-trained models, followed by post-training quantization. This often yields suboptimal performance as it fails to leverage the synergy between fine-tuning and quantization. To effectively realize low-bit quantization of weights, activations, and KV caches in LLMs, we propose an algorithm named Rotated Straight-Through-Estimator (RoSTE), which combines quantization-aware supervised fine-tuning (QA-SFT) with an adaptive rotation strategy that identifies an effective rotation configuration to reduce activation outliers. We provide theoretical insights on RoSTE by analyzing its prediction error when applied to an overparameterized least square quantized training problem. Our findings reveal that the prediction error is directly proportional to the quantization error of the converged weights, which can be effectively managed through an optimized rotation configuration. Experiments on Pythia and Llama models of different sizes demonstrate the effectiveness of RoSTE. Compared to existing post-SFT quantization baselines, our method consistently achieves superior performances across various tasks and different LLM architectures.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "61",
        "title": "Hope vs. Hate: Understanding User Interactions with LGBTQ+ News Content in Mainstream US News Media through the Lens of Hope Speech",
        "author": [
            "Jonathan Pofcher",
            "Christopher M. Homan",
            "Randall Sell",
            "Ashiqur R. KhudaBukhsh"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09004",
        "abstract": "This paper makes three contributions. First, via a substantial corpus of 1,419,047 comments posted on 3,161 YouTube news videos of major US cable news outlets, we analyze how users engage with LGBTQ+ news content. Our analyses focus both on positive and negative content. In particular, we construct a fine-grained hope speech classifier that detects positive (hope speech), negative, neutral, and irrelevant content. Second, in consultation with a public health expert specializing on LGBTQ+ health, we conduct an annotation study with a balanced and diverse political representation and release a dataset of 3,750 instances with fine-grained labels and detailed annotator demographic information. Finally, beyond providing a vital resource for the LGBTQ+ community, our annotation study and subsequent in-the-wild assessments reveal (1) strong association between rater political beliefs and how they rate content relevant to a marginalized community; (2) models trained on individual political beliefs exhibit considerable in-the-wild disagreement; and (3) zero-shot large language models (LLMs) align more with liberal raters.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "62",
        "title": "RED: Energy Optimization Framework for eDRAM-based PIM with Reconfigurable Voltage Swing and Retention-aware Scheduling",
        "author": [
            "Jae-Young Kim",
            "Donghyuk Kim",
            "Seungjae Yoo",
            "Sungyeob Yoo",
            "Teokkyu Suh",
            "Joo-Young Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09007",
        "abstract": "In the era of artificial intelligence (AI), Transformer demonstrates its performance across various applications. The excessive amount of parameters incurs high latency and energy overhead when processed in the von Neumann architecture. Processing-in-memory (PIM) has shown the potential in accelerating data-intensive applications by reducing data movement. While previous works mainly optimize the computational part of PIM to enhance energy efficiency, the importance of memory design, which consumes the most power in PIM, has been rather neglected. In this work, we present RED, an energy optimization framework for eDRAM-based PIM. We first analyze the PIM operations in eDRAM, obtaining two key observations: 1) memory access energy consumption is predominant in PIM, and 2) read bitline (RBL) voltage swing, sense amplifier power, and retention time are in trade-off relations. Leveraging them, we propose a novel reconfigurable eDRAM and retention-aware scheduling that minimizes the runtime energy consumption of the eDRAM macro. The framework pinpoints the optimal operating point by pre-estimating energy consumption across all possible tiling schemes and memory operations. Then, the reconfigurable eDRAM controls the RBL voltage swing at runtime according to the scheduling, optimizing the memory access power. Moreover, RED employs refresh skipping and sense amplifier power gating to mitigate the energy consumption overhead coming from the trade-off relation. Finally, the RED framework achieves up to 3.05x higher energy efficiency than the prior SRAM-based PIM, reducing the energy consumption of eDRAM macro up to 74.88% with reconfigurable eDRAM and optimization schemes, requiring only 3.5% area and 0.77% energy overhead for scheduling.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "63",
        "title": "Diversity Enhances an LLM's Performance in RAG and Long-context Task",
        "author": [
            "Zhchao Wang",
            "Bin Bi",
            "Yanqi Luo",
            "Sitaram Asur",
            "Claire Na Cheng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09017",
        "abstract": "The rapid advancements in large language models (LLMs) have highlighted the challenge of context window limitations, primarily due to the quadratic time complexity of the self-attention mechanism (\\(O(N^2)\\), where \\(N\\) denotes the context window length). This constraint impacts tasks such as retrieval-augmented generation (RAG) in question answering (Q\\&A) and long context summarization. A common approach involves selecting content with the highest similarity to the query; however, this often leads to redundancy and the exclusion of diverse yet relevant information. Building on principles from Maximal Marginal Relevance (MMR) and Farthest Point Sampling (FPS), we integrate diversity into the content selection process. Our findings reveal that incorporating diversity substantially increases the recall of selecting relevant sentences or chunks before LLM-based Q\\&A and summarization. These results highlight the importance of maintaining diversity in future LLM applications to further improve summarization and Q\\&A outcomes.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "64",
        "title": "EventSTR: A Benchmark Dataset and Baselines for Event Stream based Scene Text Recognition",
        "author": [
            "Xiao Wang",
            "Jingtao Jiang",
            "Dong Li",
            "Futian Wang",
            "Lin Zhu",
            "Yaowei Wang",
            "Yongyong Tian",
            "Jin Tang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09020",
        "abstract": "Mainstream Scene Text Recognition (STR) algorithms are developed based on RGB cameras which are sensitive to challenging factors such as low illumination, motion blur, and cluttered backgrounds. In this paper, we propose to recognize the scene text using bio-inspired event cameras by collecting and annotating a large-scale benchmark dataset, termed EventSTR. It contains 9,928 high-definition (1280 * 720) event samples and involves both Chinese and English characters. We also benchmark multiple STR algorithms as the baselines for future works to compare. In addition, we propose a new event-based scene text recognition framework, termed SimC-ESTR. It first extracts the event features using a visual encoder and projects them into tokens using a Q-former module. More importantly, we propose to augment the vision tokens based on a memory mechanism before feeding into the large language models. A similarity-based error correction mechanism is embedded within the large language model to correct potential minor errors fundamentally based on contextual information. Extensive experiments on the newly proposed EventSTR dataset and two simulation STR datasets fully demonstrate the effectiveness of our proposed model. We believe that the dataset and algorithmic model can innovatively propose an event-based STR task and are expected to accelerate the application of event cameras in various industries. The source code and pre-trained models will be released on https://github.com/Event-AHU/EventSTR",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "65",
        "title": "From Occupations to Tasks: A New Perspective on Automatability Prediction Using BERT",
        "author": [
            "Dawei Xu",
            "Haoran Yang",
            "Marian-Andrei Rizoiu",
            "Guandong Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09021",
        "abstract": "As automation technologies continue to advance at an unprecedented rate, concerns about job displacement and the future of work have become increasingly prevalent. While existing research has primarily focused on the potential impact of automation at the occupation level, there has been a lack of investigation into the automatability of individual tasks. This paper addresses this gap by proposing a BERT-based classifier to predict the automatability of tasks in the forthcoming decade at a granular level leveraging the context and semantics information of tasks. We leverage three public datasets: O*NET Task Statements, ESCO Skills, and Australian Labour Market Insights Tasks, and perform expert annotation. Our BERT-based classifier, fine-tuned on our task statement data, demonstrates superior performance over traditional machine learning models, neural network architectures, and other transformer models. Our findings also indicate that approximately 25.1% of occupations within the O*NET database are at substantial risk of automation, with a diverse spectrum of automation vulnerability across sectors. This research provides a robust tool for assessing the future impact of automation on the labor market, offering valuable insights for policymakers, workers, and industry leaders in the face of rapid technological advancement.",
        "tags": [
            "BERT",
            "Transformer"
        ]
    },
    {
        "id": "66",
        "title": "Mechanistic Unveiling of Transformer Circuits: Self-Influence as a Key to Model Reasoning",
        "author": [
            "Lin Zhang",
            "Lijie Hu",
            "Di Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09022",
        "abstract": "Transformer-based language models have achieved notable success, yet their internal reasoning mechanisms remain largely opaque due to complex non-linear interactions and high-dimensional operations. While previous research suggests that these models implicitly encode reasoning structures, it is still unclear which specific multi-step thought processes they employ to solve complex tasks. To address this gap, we propose a novel mechanistic interpretability framework, SICAF, designed to trace and analyze the reasoning strategies that language models use in multi-step inference tasks. By employing circuit analysis and self-influence functions, we quantify the evolving importance of each token throughout the reasoning process, thereby mapping the pathways the model uses for inference. Applying SICAF to the GPT-2 model on the Indirect Object Identification (IOI) prediction task, we demonstrate how underlying circuits can reveal a reasoning process that aligns with human interpretability, offering new insights into the model's internal logic.",
        "tags": [
            "GPT",
            "Transformer"
        ]
    },
    {
        "id": "67",
        "title": "MTDP: Modulated Transformer Diffusion Policy Model",
        "author": [
            "Qianhao Wang",
            "Yinqian Sun",
            "Enmeng Lu",
            "Qian Zhang",
            "Yi Zeng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09029",
        "abstract": "Recent research on robot manipulation based on Behavior Cloning (BC) has made significant progress. By combining diffusion models with BC, diffusion policiy has been proposed, enabling robots to quickly learn manipulation tasks with high success rates. However, integrating diffusion policy with high-capacity Transformer presents challenges, traditional Transformer architectures struggle to effectively integrate guiding conditions, resulting in poor performance in manipulation tasks when using Transformer-based models. In this paper, we investigate key architectural designs of Transformers and improve the traditional Transformer architecture by proposing the Modulated Transformer Diffusion Policy (MTDP) model for diffusion policy. The core of this model is the Modulated Attention module we proposed, which more effectively integrates the guiding conditions with the main input, improving the generative model's output quality and, consequently, increasing the robot's task success rate. In six experimental tasks, MTDP outperformed existing Transformer model architectures, particularly in the Toolhang experiment, where the success rate increased by 12\\%. To verify the generality of Modulated Attention, we applied it to the UNet architecture to construct Modulated UNet Diffusion Policy model (MUDP), which also achieved higher success rates than existing UNet architectures across all six experiments. The Diffusion Policy uses Denoising Diffusion Probabilistic Models (DDPM) as the diffusion model. Building on this, we also explored Denoising Diffusion Implicit Models (DDIM) as the diffusion model, constructing the MTDP-I and MUDP-I model, which nearly doubled the generation speed while maintaining performance.",
        "tags": [
            "DDIM",
            "DDPM",
            "Diffusion",
            "Robot",
            "Transformer"
        ]
    },
    {
        "id": "68",
        "title": "Large Images are Gaussians: High-Quality Large Image Representation with Levels of 2D Gaussian Splatting",
        "author": [
            "Lingting Zhu",
            "Guying Lin",
            "Jinnan Chen",
            "Xinjie Zhang",
            "Zhenchao Jin",
            "Zhao Wang",
            "Lequan Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09039",
        "abstract": "While Implicit Neural Representations (INRs) have demonstrated significant success in image representation, they are often hindered by large training memory and slow decoding speed. Recently, Gaussian Splatting (GS) has emerged as a promising solution in 3D reconstruction due to its high-quality novel view synthesis and rapid rendering capabilities, positioning it as a valuable tool for a broad spectrum of applications. In particular, a GS-based representation, 2DGS, has shown potential for image fitting. In our work, we present \\textbf{L}arge \\textbf{I}mages are \\textbf{G}aussians (\\textbf{LIG}), which delves deeper into the application of 2DGS for image representations, addressing the challenge of fitting large images with 2DGS in the situation of numerous Gaussian points, through two distinct modifications: 1) we adopt a variant of representation and optimization strategy, facilitating the fitting of a large number of Gaussian points; 2) we propose a Level-of-Gaussian approach for reconstructing both coarse low-frequency initialization and fine high-frequency details. Consequently, we successfully represent large images as Gaussian points and achieve high-quality large image representation, demonstrating its efficacy across various types of large images. Code is available at {\\href{https://github.com/HKU-MedAI/LIG}{https://github.com/HKU-MedAI/LIG}}.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "69",
        "title": "Typhoon T1: An Open Thai Reasoning Model",
        "author": [
            "Pittawat Taveekitworachai",
            "Potsawee Manakul",
            "Kasima Tharnpipitchai",
            "Kunat Pipatanakul"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09042",
        "abstract": "This paper introduces Typhoon T1, an open effort to develop an open Thai reasoning model. A reasoning model is a relatively new type of generative model built on top of large language models (LLMs). A reasoning model generates a long chain of thought before arriving at a final answer, an approach found to improve performance on complex tasks. However, details on developing such a model are limited, especially for reasoning models that can generate traces in a low-resource language. Typhoon T1 presents an open effort that dives into the details of developing a reasoning model in a more cost-effective way by leveraging supervised fine-tuning using open datasets, instead of reinforcement learning. This paper shares the details about synthetic data generation and training, as well as our dataset and model weights. Additionally, we provide insights gained from developing a reasoning model that generalizes across domains and is capable of generating reasoning traces in a low-resource language, using Thai as an example. We hope this open effort provides a foundation for further research in this field.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "70",
        "title": "Game Theory Meets Large Language Models: A Systematic Survey",
        "author": [
            "Haoran Sun",
            "Yusen Wu",
            "Yukun Cheng",
            "Xu Chu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09053",
        "abstract": "Game theory establishes a fundamental framework for analyzing strategic interactions among rational decision-makers. The rapid advancement of large language models (LLMs) has sparked extensive research exploring the intersection of these two fields. Specifically, game-theoretic methods are being applied to evaluate and enhance LLM capabilities, while LLMs themselves are reshaping classic game models. This paper presents a comprehensive survey of the intersection of these fields, exploring a bidirectional relationship from three perspectives: (1) Establishing standardized game-based benchmarks for evaluating LLM behavior; (2) Leveraging game-theoretic methods to improve LLM performance through algorithmic innovations; (3) Characterizing the societal impacts of LLMs through game modeling. Among these three aspects, we also highlight how the equilibrium analysis for traditional game models is impacted by LLMs' advanced language understanding, which in turn extends the study of game theory. Finally, we identify key challenges and future research directions, assessing their feasibility based on the current state of the field. By bridging theoretical rigor with emerging AI capabilities, this survey aims to foster interdisciplinary collaboration and drive progress in this evolving research area.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "71",
        "title": "Cost-Saving LLM Cascades with Early Abstention",
        "author": [
            "Michael J. Zellinger",
            "Rex Liu",
            "Matt Thomson"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09054",
        "abstract": "LLM cascades are based on the idea that processing all queries with the largest and most expensive LLMs is inefficient. Instead, cascades deploy small LLMs to answer the majority of queries, limiting the use of large and expensive LLMs to only the most difficult queries. This approach can significantly reduce costs without impacting performance. However, risk-sensitive domains such as finance or medicine place an additional premium on avoiding model errors. Recognizing that even the most expensive models may make mistakes, applications in these domains benefit from allowing LLM systems to completely abstain from answering a query when the chance of making a mistake is significant. However, giving a cascade the ability to abstain poses an immediate design question for LLM cascades: should abstention only be allowed at the final model or also at earlier models? Since the error patterns of small and large models are correlated, the latter strategy may further reduce inference costs by letting inexpensive models anticipate abstention decisions by expensive models, thereby obviating the need to run the expensive models. We investigate the benefits of \"early abstention\" in LLM cascades and find that it reduces the overall test loss by 2.2% on average across six benchmarks (GSM8K, MedMCQA, MMLU, TriviaQA, TruthfulQA, and XSum). These gains result from a more effective use of abstention, which trades a 4.1% average increase in the overall abstention rate for a 13.0% reduction in cost and a 5.0% reduction in error rate. Our findings demonstrate that it is possible to leverage correlations between the error patterns of different language models to drive performance improvements for LLM systems with abstention.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "72",
        "title": "An Open Recipe: Adapting Language-Specific LLMs to a Reasoning Model in One Day via Model Merging",
        "author": [
            "Kunat Pipatanakul",
            "Pittawat Taveekitworachai",
            "Potsawee Manakul",
            "Kasima Tharnpipitchai"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09056",
        "abstract": "This paper investigates data selection and model merging methodologies aimed at incorporating advanced reasoning capabilities such as those of DeepSeek R1 into language-specific large language models (LLMs), with a particular focus on the Thai LLM. Our goal is to enhance the reasoning capabilities of language-specific LLMs while maintaining their target language abilities. DeepSeek R1 excels in reasoning but primarily benefits high-resource languages such as English and Chinese. However, low-resource languages remain underserved due to the dominance of English-centric training data and model optimizations, which limit performance in these languages. This limitation results in unreliable code-switching and diminished effectiveness on tasks in low-resource languages. Meanwhile, local and regional LLM initiatives have attempted to bridge this gap by developing language-specific LLMs that focus on improving local linguistic fidelity. We demonstrate that, with only publicly available datasets and a computational budget of $120, it is possible to enhance the reasoning capabilities of language-specific LLMs to match the level of DeepSeek R1, without compromising their performance on target language tasks.",
        "tags": [
            "DeepSeek",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "73",
        "title": "CRANE: Reasoning with constrained LLM generation",
        "author": [
            "Debangshu Banerjee",
            "Tarun Suresh",
            "Shubham Ugare",
            "Sasa Misailovic",
            "Gagandeep Singh"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09061",
        "abstract": "Code generation, symbolic math reasoning, and other tasks require LLMs to produce outputs that are both syntactically and semantically correct. Constrained LLM generation is a promising direction to enforce adherence to formal grammar, but prior works have empirically observed that strict enforcement of formal constraints often diminishes the reasoning capabilities of LLMs. In this work, we first provide a theoretical explanation for why constraining LLM outputs to very restrictive grammars that only allow syntactically valid final answers reduces the reasoning capabilities of the model. Second, we demonstrate that by augmenting the output grammar with carefully designed additional rules, it is always possible to preserve the reasoning capabilities of the LLM while ensuring syntactic and semantic correctness in its outputs. Building on these theoretical insights, we propose a reasoning-augmented constrained decoding algorithm, CRANE, which effectively balances the correctness of constrained generation with the flexibility of unconstrained generation. Experiments on multiple open-source LLMs and benchmarks show that CRANE significantly outperforms both state-of-the-art constrained decoding strategies and standard unconstrained decoding, showing up to 10% points accuracy improvement over baselines on challenging symbolic reasoning benchmarks GSM-symbolic and FOLIO.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "74",
        "title": "StyleBlend: Enhancing Style-Specific Content Creation in Text-to-Image Diffusion Models",
        "author": [
            "Zichong Chen",
            "Shijin Wang",
            "Yang Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09064",
        "abstract": "Synthesizing visually impressive images that seamlessly align both text prompts and specific artistic styles remains a significant challenge in Text-to-Image (T2I) diffusion models. This paper introduces StyleBlend, a method designed to learn and apply style representations from a limited set of reference images, enabling content synthesis of both text-aligned and stylistically coherent. Our approach uniquely decomposes style into two components, composition and texture, each learned through different strategies. We then leverage two synthesis branches, each focusing on a corresponding style component, to facilitate effective style blending through shared features without affecting content generation. StyleBlend addresses the common issues of text misalignment and weak style representation that previous methods have struggled with. Extensive qualitative and quantitative comparisons demonstrate the superiority of our approach.",
        "tags": [
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "75",
        "title": "Lowering the Error Floor of Error Correction Code Transformer",
        "author": [
            "Taewoo Park",
            "Seong-Joon Park",
            "Hee-Youl Kwak",
            "Sang-Hyo Kim",
            "Yongjune Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09065",
        "abstract": "With the success of transformer architectures across diverse applications, the error correction code transformer (ECCT) has gained significant attention for its superior decoding performance. In spite of its advantages, the error floor phenomenon in ECCT decoding remains unexplored. We present the first investigation of the error floor issue in ECCT and propose a hybrid decoding approach that integrates hard decision decoders as pre- and post-decoders with ECCT to effectively lower the error floor. In particular, we introduce a novel loss function for ECCT that considers the dynamics of hybrid decoding algorithm. Training ECCT with the proposed loss function enhances its ability to correct specific error patterns by taking into account its interaction with the auxiliary decoders. Simulation results demonstrate that the proposed hybrid decoder with the novel loss function significantly outperforms the original ECCT in both the waterfall and the error floor regions.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "76",
        "title": "Enhancing RAG with Active Learning on Conversation Records: Reject Incapables and Answer Capables",
        "author": [
            "Xuzhao Geng",
            "Haozhao Wang",
            "Jun Wang",
            "Wei Liu",
            "Ruixuan Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09073",
        "abstract": "Retrieval-augmented generation (RAG) is a key technique for leveraging external knowledge and reducing hallucinations in large language models (LLMs). However, RAG still struggles to fully prevent hallucinated responses. To address this, it is essential to identify samples prone to hallucination or guide LLMs toward correct responses, which experts then annotate to develop high-quality datasets for refining LLMs. However, the growing scarcity of such datasets makes their creation challenging. This paper proposes using the vast amount of conversations from widespread LLM usage to build these datasets, training LLMs to avoid hallucination-prone questions while accurately responding to manageable ones. Given the impracticality of expert-annotating all conversation records, the paper introduces AL4RAG, which uses active learning to select the most suitable conversation samples for annotation, optimizing performance within an annotation budget. Additionally, recognizing that traditional active learning methods are not fully compatible with RAG due to unsuitable distance metrics, we develop a novel sample distance measurement for RAG active learning. Extensive experiments show that our method consistently outperforms baselines across multiple metrics.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "77",
        "title": "CoSER: Coordinating LLM-Based Persona Simulation of Established Roles",
        "author": [
            "Xintao Wang",
            "Heng Wang",
            "Yifei Zhang",
            "Xinfeng Yuan",
            "Rui Xu",
            "Jen-tse Huang",
            "Siyu Yuan",
            "Haoran Guo",
            "Jiangjie Chen",
            "Wei Wang",
            "Yanghua Xiao",
            "Shuchang Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09082",
        "abstract": "Role-playing language agents (RPLAs) have emerged as promising applications of large language models (LLMs). However, simulating established characters presents a challenging task for RPLAs, due to the lack of authentic character datasets and nuanced evaluation methods using such data. In this paper, we present CoSER, a collection of a high-quality dataset, open models, and an evaluation protocol towards effective RPLAs of established characters. The CoSER dataset covers 17,966 characters from 771 renowned books. It provides authentic dialogues with real-world intricacies, as well as diverse data types such as conversation setups, character experiences and internal thoughts. Drawing from acting methodology, we introduce given-circumstance acting for training and evaluating role-playing LLMs, where LLMs sequentially portray multiple characters in book scenes. Using our dataset, we develop CoSER 8B and CoSER 70B, i.e., advanced open role-playing LLMs built on LLaMA-3.1 models. Extensive experiments demonstrate the value of the CoSER dataset for RPLA training, evaluation and retrieval. Moreover, CoSER 70B exhibits state-of-the-art performance surpassing or matching GPT-4o on our evaluation and three existing benchmarks, i.e., achieving 75.80% and 93.47% accuracy on the InCharacter and LifeChoice benchmarks respectively.",
        "tags": [
            "GPT",
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "78",
        "title": "Show Me the Work: Fact-Checkers' Requirements for Explainable Automated Fact-Checking",
        "author": [
            "Greta Warren",
            "Irina Shklovski",
            "Isabelle Augenstein"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09083",
        "abstract": "The pervasiveness of large language models and generative AI in online media has amplified the need for effective automated fact-checking to assist fact-checkers in tackling the increasing volume and sophistication of misinformation. The complex nature of fact-checking demands that automated fact-checking systems provide explanations that enable fact-checkers to scrutinise their outputs. However, it is unclear how these explanations should align with the decision-making and reasoning processes of fact-checkers to be effectively integrated into their workflows. Through semi-structured interviews with fact-checking professionals, we bridge this gap by: (i) providing an account of how fact-checkers assess evidence, make decisions, and explain their processes; (ii) examining how fact-checkers use automated tools in practice; and (iii) identifying fact-checker explanation requirements for automated fact-checking tools. The findings show unmet explanation needs and identify important criteria for replicable fact-checking explanations that trace the model's reasoning path, reference specific evidence, and highlight uncertainty and information gaps.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "79",
        "title": "Semantic Ads Retrieval at Walmart eCommerce with Language Models Progressively Trained on Multiple Knowledge Domains",
        "author": [
            "Zhaodong Wang",
            "Weizhi Du",
            "Md Omar Faruk Rokon",
            "Pooshpendu Adhikary",
            "Yanbing Xue",
            "Jiaxuan Xu",
            "Jianghong Zhou",
            "Kuang-chih Lee",
            "Musen Wen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09089",
        "abstract": "Sponsored search in e-commerce poses several unique and complex challenges. These challenges stem from factors such as the asymmetric language structure between search queries and product names, the inherent ambiguity in user search intent, and the vast volume of sparse and imbalanced search corpus data. The role of the retrieval component within a sponsored search system is pivotal, serving as the initial step that directly affects the subsequent ranking and bidding systems. In this paper, we present an end-to-end solution tailored to optimize the ads retrieval system on http://Walmart.com. Our approach is to pretrain the BERT-like classification model with product category information, enhancing the model's understanding of Walmart product semantics. Second, we design a two-tower Siamese Network structure for embedding structures to augment training efficiency. Third, we introduce a Human-in-the-loop Progressive Fusion Training method to ensure robust model performance. Our results demonstrate the effectiveness of this pipeline. It enhances the search relevance metric by up to 16% compared to a baseline DSSM-based model. Moreover, our large-scale online A/B testing demonstrates that our approach surpasses the ad revenue of the existing production model.",
        "tags": [
            "BERT"
        ]
    },
    {
        "id": "80",
        "title": "A Hybrid Transformer Model for Fake News Detection: Leveraging Bayesian Optimization and Bidirectional Recurrent Unit",
        "author": [
            "Tianyi Huang",
            "Zeqiu Xu",
            "Peiyang Yu",
            "Jingyuan Yi",
            "Xiaochuan Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09097",
        "abstract": "In this paper, we propose an optimized Transformer model that integrates Bayesian algorithms with a Bidirectional Gated Recurrent Unit (BiGRU), and apply it to fake news classification for the first time. First, we employ the TF-IDF method to extract features from news texts and transform them into numeric representations to facilitate subsequent machine learning tasks. Two sets of experiments are then conducted for fake news detection and classification: one using a Transformer model optimized only with BiGRU, and the other incorporating Bayesian algorithms into the BiGRU-based Transformer. Experimental results show that the BiGRU-optimized Transformer achieves 100% accuracy on the training set and 99.67% on the test set, while the addition of the Bayesian algorithm maintains 100% accuracy on the training set and slightly improves test-set accuracy to 99.73%. This indicates that the Bayesian algorithm boosts model accuracy by 0.06%, further enhancing the detection capability for fake news. Moreover, the proposed algorithm converges rapidly at around the 10th training epoch with accuracy nearing 100%, demonstrating both its effectiveness and its fast classification ability. Overall, the optimized Transformer model, enhanced by the Bayesian algorithm and BiGRU, exhibits excellent continuous learning and detection performance, offering a robust technical means to combat the spread of fake news in the current era of information overload.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "81",
        "title": "Logical Reasoning in Large Language Models: A Survey",
        "author": [
            "Hanmeng Liu",
            "Zhizhang Fu",
            "Mengru Ding",
            "Ruoxi Ning",
            "Chaoli Zhang",
            "Xiaozhang Liu",
            "Yue Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09100",
        "abstract": "With the emergence of advanced reasoning models like OpenAI o3 and DeepSeek-R1, large language models (LLMs) have demonstrated remarkable reasoning capabilities. However, their ability to perform rigorous logical reasoning remains an open question. This survey synthesizes recent advancements in logical reasoning within LLMs, a critical area of AI research. It outlines the scope of logical reasoning in LLMs, its theoretical foundations, and the benchmarks used to evaluate reasoning proficiency. We analyze existing capabilities across different reasoning paradigms - deductive, inductive, abductive, and analogical - and assess strategies to enhance reasoning performance, including data-centric tuning, reinforcement learning, decoding strategies, and neuro-symbolic approaches. The review concludes with future directions, emphasizing the need for further exploration to strengthen logical reasoning in AI systems.",
        "tags": [
            "DeepSeek",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "82",
        "title": "Bridging the Gap Between LLMs and Human Intentions: Progresses and Challenges in Instruction Understanding, Intention Reasoning, and Reliable Generation",
        "author": [
            "Zongyu Chang",
            "Feihong Lu",
            "Ziqin Zhu",
            "Qian Li",
            "Cheng Ji",
            "Zhuo Chen",
            "Yang Liu",
            "Ruifeng Xu",
            "Yangqiu Song",
            "Shangguang Wang",
            "Jianxin Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09101",
        "abstract": "Large language models (LLMs) have demonstrated exceptional capabilities in understanding and generation. However, when interacting with human instructions in real-world scenarios, LLMs still face significant challenges, particularly in accurately capturing and comprehending human instructions and intentions. This paper focuses on three challenges in LLM-based text generation tasks: instruction understanding, intention reasoning, and reliable generation. Regarding human complex instruction, LLMs have deficiencies in understanding long contexts and instructions in multi-round conversations. For intention reasoning, LLMs may have inconsistent command reasoning, difficulty reasoning about commands containing incorrect information, difficulty understanding user ambiguous language commands, and a weak understanding of user intention in commands. Besides, In terms of reliable generation, LLMs may have unstable generated content and unethical generation. To this end, we classify and analyze the performance of LLMs in challenging scenarios and conduct a comprehensive evaluation of existing solutions. Furthermore, we introduce benchmarks and categorize them based on the aforementioned three core challenges. Finally, we explore potential directions for future research to enhance the reliability and adaptability of LLMs in real-world applications.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "83",
        "title": "One-shot Federated Learning Methods: A Practical Guide",
        "author": [
            "Xiang Liu",
            "Zhenheng Tang",
            "Xia Li",
            "Yijun Song",
            "Sijie Ji",
            "Zemin Liu",
            "Bo Han",
            "Linshan Jiang",
            "Jialin Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09104",
        "abstract": "One-shot Federated Learning (OFL) is a distributed machine learning paradigm that constrains client-server communication to a single round, addressing privacy and communication overhead issues associated with multiple rounds of data exchange in traditional Federated Learning (FL). OFL demonstrates the practical potential for integration with future approaches that require collaborative training models, such as large language models (LLMs). However, current OFL methods face two major challenges: data heterogeneity and model heterogeneity, which result in subpar performance compared to conventional FL methods. Worse still, despite numerous studies addressing these limitations, a comprehensive summary is still lacking. To address these gaps, this paper presents a systematic analysis of the challenges faced by OFL and thoroughly reviews the current methods. We also offer an innovative categorization method and analyze the trade-offs of various techniques. Additionally, we discuss the most promising future directions and the technologies that should be integrated into the OFL field. This work aims to provide guidance and insights for future research.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "84",
        "title": "DenseSplat: Densifying Gaussian Splatting SLAM with Neural Radiance Prior",
        "author": [
            "Mingrui Li",
            "Shuhong Liu",
            "Tianchen Deng",
            "Hongyu Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09111",
        "abstract": "Gaussian SLAM systems excel in real-time rendering and fine-grained reconstruction compared to NeRF-based systems. However, their reliance on extensive keyframes is impractical for deployment in real-world robotic systems, which typically operate under sparse-view conditions that can result in substantial holes in the map. To address these challenges, we introduce DenseSplat, the first SLAM system that effectively combines the advantages of NeRF and 3DGS. DenseSplat utilizes sparse keyframes and NeRF priors for initializing primitives that densely populate maps and seamlessly fill gaps. It also implements geometry-aware primitive sampling and pruning strategies to manage granularity and enhance rendering efficiency. Moreover, DenseSplat integrates loop closure and bundle adjustment, significantly enhancing frame-to-frame tracking accuracy. Extensive experiments on multiple large-scale datasets demonstrate that DenseSplat achieves superior performance in tracking and mapping compared to current state-of-the-art methods.",
        "tags": [
            "Gaussian Splatting",
            "NeRF",
            "SLAM"
        ]
    },
    {
        "id": "85",
        "title": "The influence of visual and linguistic cues on ignorance inference in Vision-Language Models (VLMs)",
        "author": [
            "Ye-eun Cho",
            "Yunho Maeng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09120",
        "abstract": "This study explored how Vision-Language Models (VLMs) process ignorance implicatures with visual and linguistic cues. Particularly, we focused on the effects of contexts (precise and approximate contexts) and modifier types (bare numerals, superlative, and comparative modifiers), which were considered pragmatic and semantic factors respectively. Methodologically, we conducted a truth-value judgment task in visually grounded settings using GPT-4o and Gemini 1.5 Pro. The results indicate that while both models exhibited sensitivity to linguistic cues (modifier), they failed to process ignorance implicatures with visual cues (context) as humans do. Specifically, the influence of context was weaker and inconsistent across models, indicating challenges in pragmatic reasoning for VLMs. On the other hand, superlative modifiers were more strongly associated with ignorance implicatures as compared to comparative modifiers, supporting the semantic view. These findings highlight the need for further advancements in VLMs to process language-vision information in a context-dependent way to achieve human-like pragmatic inference.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "86",
        "title": "Feature-based Graph Attention Networks Improve Online Continual Learning",
        "author": [
            "Adjovi Sim",
            "Zhengkui Wang",
            "Aik Beng Ng",
            "Shalini De Mello",
            "Simon See",
            "Wonmin Byeon"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09143",
        "abstract": "Online continual learning for image classification is crucial for models to adapt to new data while retaining knowledge of previously learned tasks. This capability is essential to address real-world challenges involving dynamic environments and evolving data distributions. Traditional approaches predominantly employ Convolutional Neural Networks, which are limited to processing images as grids and primarily capture local patterns rather than relational information. Although the emergence of transformer architectures has improved the ability to capture relationships, these models often require significantly larger resources. In this paper, we present a novel online continual learning framework based on Graph Attention Networks (GATs), which effectively capture contextual relationships and dynamically update the task-specific representation via learned attention weights. Our approach utilizes a pre-trained feature extractor to convert images into graphs using hierarchical feature maps, representing information at varying levels of granularity. These graphs are then processed by a GAT and incorporate an enhanced global pooling strategy to improve classification performance for continual learning. In addition, we propose the rehearsal memory duplication technique that improves the representation of the previous tasks while maintaining the memory budget. Comprehensive evaluations on benchmark datasets, including SVHN, CIFAR10, CIFAR100, and MiniImageNet, demonstrate the superiority of our method compared to the state-of-the-art methods.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "87",
        "title": "Regularization can make diffusion models more efficient",
        "author": [
            "Mahsa Taheri",
            "Johannes Lederer"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09151",
        "abstract": "Diffusion models are one of the key architectures of generative AI. Their main drawback, however, is the computational costs. This study indicates that the concept of sparsity, well known especially in statistics, can provide a pathway to more efficient diffusion pipelines. Our mathematical guarantees prove that sparsity can reduce the input dimension's influence on the computational complexity to that of a much smaller intrinsic dimension of the data. Our empirical findings confirm that inducing sparsity can indeed lead to better samples at a lower cost.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "88",
        "title": "E-MD3C: Taming Masked Diffusion Transformers for Efficient Zero-Shot Object Customization",
        "author": [
            "Trung X. Pham",
            "Zhang Kang",
            "Ji Woo Hong",
            "Xuran Zheng",
            "Chang D. Yoo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09164",
        "abstract": "We propose E-MD3C ($\\underline{E}$fficient $\\underline{M}$asked $\\underline{D}$iffusion Transformer with Disentangled $\\underline{C}$onditions and $\\underline{C}$ompact $\\underline{C}$ollector), a highly efficient framework for zero-shot object image customization. Unlike prior works reliant on resource-intensive Unet architectures, our approach employs lightweight masked diffusion transformers operating on latent patches, offering significantly improved computational efficiency. The framework integrates three core components: (1) an efficient masked diffusion transformer for processing autoencoder latents, (2) a disentangled condition design that ensures compactness while preserving background alignment and fine details, and (3) a learnable Conditions Collector that consolidates multiple inputs into a compact representation for efficient denoising and learning. E-MD3C outperforms the existing approach on the VITON-HD dataset across metrics such as PSNR, FID, SSIM, and LPIPS, demonstrating clear advantages in parameters, memory efficiency, and inference speed. With only $\\frac{1}{4}$ of the parameters, our Transformer-based 468M model delivers $2.5\\times$ faster inference and uses $\\frac{2}{3}$ of the GPU memory compared to an 1720M Unet-based latent diffusion model.",
        "tags": [
            "Diffusion",
            "Diffusion Transformer",
            "Transformer"
        ]
    },
    {
        "id": "89",
        "title": "LOB-Bench: Benchmarking Generative AI for Finance - an Application to Limit Order Book Data",
        "author": [
            "Peer Nagy",
            "Sascha Frey",
            "Kang Li",
            "Bidipta Sarkar",
            "Svitlana Vyetrenko",
            "Stefan Zohren",
            "Ani Calinescu",
            "Jakob Foerster"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09172",
        "abstract": "While financial data presents one of the most challenging and interesting sequence modelling tasks due to high noise, heavy tails, and strategic interactions, progress in this area has been hindered by the lack of consensus on quantitative evaluation paradigms. To address this, we present LOB-Bench, a benchmark, implemented in python, designed to evaluate the quality and realism of generative message-by-order data for limit order books (LOB) in the LOBSTER format. Our framework measures distributional differences in conditional and unconditional statistics between generated and real LOB data, supporting flexible multivariate statistical evaluation. The benchmark also includes features commonly used LOB statistics such as spread, order book volumes, order imbalance, and message inter-arrival times, along with scores from a trained discriminator network. Lastly, LOB-Bench contains \"market impact metrics\", i.e. the cross-correlations and price response functions for specific events in the data. We benchmark generative autoregressive state-space models, a (C)GAN, as well as a parametric LOB model and find that the autoregressive GenAI approach beats traditional model classes.",
        "tags": [
            "GAN",
            "State Space Models"
        ]
    },
    {
        "id": "90",
        "title": "RefineCoder: Iterative Improving of Large Language Models via Adaptive Critique Refinement for Code Generation",
        "author": [
            "Changzhi Zhou",
            "Xinyu Zhang",
            "Dandan Song",
            "Xiancai Chen",
            "Wanli Gu",
            "Huipeng Ma",
            "Yuhang Tian",
            "Mengdi Zhang",
            "Linmei Hu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09183",
        "abstract": "Code generation has attracted increasing attention with the rise of Large Language Models (LLMs). Many studies have developed powerful code LLMs by synthesizing code-related instruction data and applying supervised fine-tuning. However, these methods are limited by teacher model distillation and ignore the potential of iterative refinement by self-generated code. In this paper, we propose Adaptive Critique Refinement (ACR), which enables the model to refine itself by self-generated code and external critique, rather than directly imitating the code responses of the teacher model. Concretely, ACR includes a composite scoring system with LLM-as-a-Judge to evaluate the quality of code responses and a selective critique strategy with LLM-as-a-Critic to critique self-generated low-quality code responses. We develop the RefineCoder series by iteratively applying ACR, achieving continuous performance improvement on multiple code generation benchmarks. Compared to the baselines of the same size, our proposed RefineCoder series can achieve comparable or even superior performance using less data.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "91",
        "title": "Matina: A Large-Scale 73B Token Persian Text Corpus",
        "author": [
            "Sara Bourbour Hosseinbeigi",
            "Fatemeh Taherinezhad",
            "Heshaam Faili",
            "Hamed Baghbani",
            "Fatemeh Nadi",
            "Mostafa Amiri"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09188",
        "abstract": "Text corpora are essential for training models used in tasks like summarization, translation, and large language models (LLMs). While various efforts have been made to collect monolingual and multilingual datasets in many languages, Persian has often been underrepresented due to limited resources for data collection and preprocessing. Existing Persian datasets are typically small and lack content diversity, consisting mainly of weblogs and news articles. This shortage of high-quality, varied data has slowed the development of NLP models and open-source LLMs for Persian. Since model performance depends heavily on the quality of training data, we address this gap by introducing the Matina corpus, a new Persian dataset of 72.9B tokens, carefully preprocessed and deduplicated to ensure high data quality. We further assess its effectiveness by training and evaluating transformer-based models on key NLP tasks. Both the dataset and preprocessing codes are publicly available, enabling researchers to build on and improve this resource for future Persian NLP advancements.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "92",
        "title": "Thinking beyond the anthropomorphic paradigm benefits LLM research",
        "author": [
            "Lujain Ibrahim",
            "Myra Cheng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09192",
        "abstract": "Anthropomorphism, or the attribution of human traits to technology, is an automatic and unconscious response that occurs even in those with advanced technical expertise. In this position paper, we analyze hundreds of thousands of computer science research articles from the past decade and present empirical evidence of the prevalence and growth of anthropomorphic terminology in research on large language models (LLMs). This terminology reflects deeper anthropomorphic conceptualizations which shape how we think about and conduct LLM research. We argue these conceptualizations may be limiting, and that challenging them opens up new pathways for understanding and improving LLMs beyond human analogies. To illustrate this, we identify and analyze five core anthropomorphic assumptions shaping prominent methodologies across the LLM development lifecycle, from the assumption that models must use natural language for reasoning tasks to the assumption that model capabilities should be evaluated through human-centric benchmarks. For each assumption, we demonstrate how non-anthropomorphic alternatives can open new directions for research and development.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "93",
        "title": "Logical Lease Litigation: Prolog and LLMs for Rental Law Compliance in New York",
        "author": [
            "Sanskar Sehgal",
            "Yanhong A. Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09204",
        "abstract": "Legal cases require careful logical reasoning following the laws, whereas interactions with non- technical users must be in natural language. As an application combining logical reasoning using Prolog and natural language processing using large language models (LLMs), this paper presents a novel approach and system, LogicLease, to automate the analysis of landlord-tenant legal cases in the state of New York. LogicLease determines compliance with relevant legal requirements by analyzing case descriptions and citing all relevant laws. It leverages LLMs for information extraction and Prolog for legal reasoning. By separating information extraction from legal reasoning, LogicLease achieves greater transparency and control over the legal logic applied to each case. We evaluate the accuracy, efficiency, and robustness of LogicLease through a series of tests, achieving 100% accuracy and an average processing time of 2.57 seconds. LogicLease presents advantages over state-of-the-art LLM- based legal analysis systems by providing clear, step-by-step reasoning, citing specific laws, and distinguishing itself by its ability to avoid hallucinations - a common issue in LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "94",
        "title": "On LLM-generated Logic Programs and their Inference Execution Methods",
        "author": [
            "Paul Tarau"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09209",
        "abstract": "Large Language Models (LLMs) trained on petabytes of data are highly compressed repositories of a significant proportion of the knowledge accumulated and distilled so far. In this paper we study techniques to elicit this knowledge in the form of several classes of logic programs, including propositional Horn clauses, Dual Horn clauses, relational triplets and Definite Clause Grammars. Exposing this knowledge as logic programs enables sound reasoning methods that can verify alignment of LLM outputs to their intended uses and extend their inference capabilities.  We study new execution methods for the generated programs, including soft-unification of abducible facts against LLM-generated content stored in a vector database as well as GPU-based acceleration of minimal model computation that supports  inference with large LLM-generated programs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "95",
        "title": "Visual Graph Question Answering with ASP and LLMs for Language Parsing",
        "author": [
            "Jakob Johannes Bauer",
            "Thomas Eiter",
            "Nelson Higuera Ruiz",
            "Johannes Oetsch"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09211",
        "abstract": "Visual Question Answering (VQA) is a challenging problem that requires to process multimodal input. Answer-Set Programming (ASP) has shown great potential in this regard to add interpretability and explainability to modular VQA architectures. In this work, we address the problem of how to integrate ASP with modules for vision and natural language processing to solve a new and demanding VQA variant that is concerned with images of graphs (not graphs in symbolic form). Images containing graph-based structures are an ubiquitous and popular form of visualisation. Here, we deal with the particular problem of graphs inspired by transit networks, and we introduce a novel dataset that amends an existing one by adding images of graphs that resemble metro lines. Our modular neuro-symbolic approach combines optical graph recognition for graph parsing, a pretrained optical character recognition neural network for parsing labels, Large Language Models (LLMs) for language processing, and ASP for reasoning. This method serves as a first baseline and achieves an overall average accuracy of 73% on the dataset. Our evaluation provides further evidence of the potential of modular neuro-symbolic systems, in particular with pretrained models that do not involve any further training and logic programming for reasoning, to solve complex VQA tasks.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "96",
        "title": "LP-LM: No Hallucinations in Question Answering with Logic Programming",
        "author": [
            "Katherine Wu",
            "Yanhong A. Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09212",
        "abstract": "Large language models (LLMs) are able to generate human-like responses to user queries. However, LLMs exhibit inherent limitations, especially because they hallucinate. This paper introduces LP-LM, a system that grounds answers to questions in known facts contained in a knowledge base (KB), facilitated through semantic parsing in Prolog, and always produces answers that are reliable.\nLP-LM generates a most probable constituency parse tree along with a corresponding Prolog term for an input question via Prolog definite clause grammar (DCG) parsing. The term is then executed against a KB of natural language sentences also represented as Prolog terms for question answering. By leveraging DCG and tabling, LP-LM runs in linear time in the size of input sentences for sufficiently many grammar rules. Performing experiments comparing LP-LM with current well-known LLMs in accuracy, we show that LLMs hallucinate on even simple questions, unlike LP-LM.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "97",
        "title": "Reliable Conversational Agents under ASP Control that Understand Natural Language",
        "author": [
            "Yankai Zeng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09237",
        "abstract": "Efforts have been made to make machines converse like humans in the past few decades. The recent techniques of Large Language Models (LLMs) make it possible to have human-like conversations with machines, but LLM's flaws of lacking understanding and reliability are well documented. We believe that the best way to eliminate this problem is to use LLMs only as parsers to translate text to knowledge and vice versa and carry out the conversation by reasoning over this knowledge using the answer set programming. I have been developing a framework based on LLMs and ASP to realize reliable chatbots that \"understand\" human conversation. This framework has been used to develop task-specific chatbots as well as socialbots. My future research is focused on making these chatbots scalable and trainable.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "98",
        "title": "OpenBench: A New Benchmark and Baseline for Semantic Navigation in Smart Logistics",
        "author": [
            "Junhui Wang",
            "Dongjie Huo",
            "Zehui Xu",
            "Yongliang Shi",
            "Yimin Yan",
            "Yuanxin Wang",
            "Chao Gao",
            "Yan Qiao",
            "Guyue Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09238",
        "abstract": "The increasing demand for efficient last-mile delivery in smart logistics underscores the role of autonomous robots in enhancing operational efficiency and reducing costs. Traditional navigation methods, which depend on high-precision maps, are resource-intensive, while learning-based approaches often struggle with generalization in real-world scenarios. To address these challenges, this work proposes the Openstreetmap-enhanced oPen-air sEmantic Navigation (OPEN) system that combines foundation models with classic algorithms for scalable outdoor navigation. The system uses off-the-shelf OpenStreetMap (OSM) for flexible map representation, thereby eliminating the need for extensive pre-mapping efforts. It also employs Large Language Models (LLMs) to comprehend delivery instructions and Vision-Language Models (VLMs) for global localization, map updates, and house number recognition. To compensate the limitations of existing benchmarks that are inadequate for assessing last-mile delivery, this work introduces a new benchmark specifically designed for outdoor navigation in residential areas, reflecting the real-world challenges faced by autonomous delivery systems. Extensive experiments in simulated and real-world environments demonstrate the proposed system's efficacy in enhancing navigation efficiency and reliability. To facilitate further research, our code and benchmark are publicly available.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "99",
        "title": "You Do Not Fully Utilize Transformer's Representation Capacity",
        "author": [
            "Gleb Gerasimov",
            "Yaroslav Aksenov",
            "Nikita Balagansky",
            "Viacheslav Sinii",
            "Daniil Gavrilov"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09245",
        "abstract": "In contrast to RNNs, which compress previous tokens into a single hidden state, Transformers can attend to all previous tokens directly. However, standard Transformers only use representations from the immediately preceding layer. In this paper, we show that this design choice causes representation collapse and leads to suboptimal performance. To address this issue, we introduce Layer-Integrated Memory (LIMe), a simple yet powerful approach that preserves the model's overall memory footprint while expanding its representational capacity by allowing access to hidden states from earlier layers. Through extensive experiments across various architectures and different lookup mechanisms, we demonstrate consistent performance improvements on a wide range of tasks. Moreover, our analysis of the learned representation dynamics and our exploration of depthwise circuits reveal how LIMe integrates information across layers, pointing to promising directions for future research.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "100",
        "title": "GEVRM: Goal-Expressive Video Generation Model For Robust Visual Manipulation",
        "author": [
            "Hongyin Zhang",
            "Pengxiang Ding",
            "Shangke Lyu",
            "Ying Peng",
            "Donglin Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09268",
        "abstract": "With the rapid development of embodied artificial intelligence, significant progress has been made in vision-language-action (VLA) models for general robot decision-making. However, the majority of existing VLAs fail to account for the inevitable external perturbations encountered during deployment. These perturbations introduce unforeseen state information to the VLA, resulting in inaccurate actions and consequently, a significant decline in generalization performance. The classic internal model control (IMC) principle demonstrates that a closed-loop system with an internal model that includes external input signals can accurately track the reference input and effectively offset the disturbance. We propose a novel closed-loop VLA method GEVRM that integrates the IMC principle to enhance the robustness of robot visual manipulation. The text-guided video generation model in GEVRM can generate highly expressive future visual planning goals. Simultaneously, we evaluate perturbations by simulating responses, which are called internal embeddings and optimized through prototype contrastive learning. This allows the model to implicitly infer and distinguish perturbations from the external environment. The proposed GEVRM achieves state-of-the-art performance on both standard and perturbed CALVIN benchmarks and shows significant improvements in realistic robot tasks.",
        "tags": [
            "Robot",
            "Video Generation"
        ]
    },
    {
        "id": "101",
        "title": "ConsistentDreamer: View-Consistent Meshes Through Balanced Multi-View Gaussian Optimization",
        "author": [
            "Onat Åahin",
            "Mohammad Altillawi",
            "George Eskandar",
            "Carlos Carbone",
            "Ziyuan Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09278",
        "abstract": "Recent advances in diffusion models have significantly improved 3D generation, enabling the use of assets generated from an image for embodied AI simulations. However, the one-to-many nature of the image-to-3D problem limits their use due to inconsistent content and quality across views. Previous models optimize a 3D model by sampling views from a view-conditioned diffusion prior, but diffusion models cannot guarantee view consistency. Instead, we present ConsistentDreamer, where we first generate a set of fixed multi-view prior images and sample random views between them with another diffusion model through a score distillation sampling (SDS) loss. Thereby, we limit the discrepancies between the views guided by the SDS loss and ensure a consistent rough shape. In each iteration, we also use our generated multi-view prior images for fine-detail reconstruction. To balance between the rough shape and the fine-detail optimizations, we introduce dynamic task-dependent weights based on homoscedastic uncertainty, updated automatically in each iteration. Additionally, we employ opacity, depth distortion, and normal alignment losses to refine the surface for mesh extraction. Our method ensures better view consistency and visual quality compared to the state-of-the-art.",
        "tags": [
            "3D",
            "Diffusion",
            "Image-to-3D"
        ]
    },
    {
        "id": "102",
        "title": "SparQLe: Speech Queries to Text Translation Through LLMs",
        "author": [
            "Amirbek Djanibekov",
            "Hanan Aldarmaki"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09284",
        "abstract": "With the growing influence of Large Language Models (LLMs), there is increasing interest in integrating speech representations with them to enable more seamless multi-modal processing and speech understanding. This study introduces a novel approach that leverages self-supervised speech representations in combination with instruction-tuned LLMs for speech-to-text translation. The proposed approach leverages a modality adapter to align extracted speech features with instruction-tuned LLMs using English-language data. Our experiments demonstrate that this method effectively preserves the semantic content of the input speech and serves as an effective bridge between self-supervised speech models and instruction-tuned LLMs, offering a promising solution for various speech understanding applications.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "103",
        "title": "EmoAssist: Emotional Assistant for Visual Impairment Community",
        "author": [
            "Xingyu Qi",
            "He Li",
            "Linjie Li",
            "Zhenyu Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09285",
        "abstract": "The rapid advancement of large multi-modality models (LMMs) has significantly propelled the integration of artificial intelligence into practical applications. Visual Question Answering (VQA) systems, which can process multi-modal data including vision, text, and audio, hold great potential for assisting the Visual Impairment (VI) community in navigating complex and dynamic real-world environments. However, existing VI assistive LMMs overlook the emotional needs of VI individuals, and current benchmarks lack emotional evaluation of these LMMs. To address these gaps, this paper introduces the EmoAssist Benchmark, a comprehensive benchmark designed to evaluate the assistive performance of LMMs for the VI community. To the best of our knowledge, this is the first benchmark that incorporates emotional intelligence as a key consideration. Furthermore, we propose the EmoAssist Model, an Emotion-Assistive LMM specifically designed for the VI community. The EmoAssist Model utilizes Direct Preference Optimization (DPO) to align outputs with human emotional preferences. Experiment results demonstrate that the EmoAssist Model significantly enhances the recognition of implicit emotions and intentions of VI users, delivers empathetic responses, and provides actionable guidance. Specifically, it shows respective improvements of 147.8% and 89.7% in the Empathy and Suggestion metrics on the EmoAssist Benchmark, compared to the pre-tuning LMM, and even outperforms state-of-the-art LLMs such as GPT-4o.",
        "tags": [
            "GPT",
            "LLMs"
        ]
    },
    {
        "id": "104",
        "title": "When do neural networks learn world models?",
        "author": [
            "Tianren Zhang",
            "Guanyu Chen",
            "Feng Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09297",
        "abstract": "Humans develop world models that capture the underlying generation process of data. Whether neural networks can learn similar world models remains an open problem. In this work, we provide the first theoretical results for this problem, showing that in a multi-task setting, models with a low-degree bias provably recover latent data-generating variables under mild assumptions -- even if proxy tasks involve complex, non-linear functions of the latents. However, such recovery is also sensitive to model architecture. Our analysis leverages Boolean models of task solutions via the Fourier-Walsh transform and introduces new techniques for analyzing invertible Boolean transforms, which may be of independent interest. We illustrate the algorithmic implications of our results and connect them to related research areas, including self-supervised learning, out-of-distribution generalization, and the linear representation hypothesis in large language models.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "105",
        "title": "KET-RAG: A Cost-Efficient Multi-Granular Indexing Framework for Graph-RAG",
        "author": [
            "Yiqian Huang",
            "Shiqi Zhang",
            "Xiaokui Xiao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09304",
        "abstract": "Graph-RAG constructs a knowledge graph from text chunks to improve retrieval in Large Language Model (LLM)-based question answering. It is particularly useful in domains such as biomedicine, law, and political science, where retrieval often requires multi-hop reasoning over proprietary documents. Some existing Graph-RAG systems construct KNN graphs based on text chunk relevance, but this coarse-grained approach fails to capture entity relationships within texts, leading to sub-par retrieval and generation quality. To address this, recent solutions leverage LLMs to extract entities and relationships from text chunks, constructing triplet-based knowledge graphs. However, this approach incurs significant indexing costs, especially for large document collections.\nTo ensure a good result accuracy while reducing the indexing cost, we propose KET-RAG, a multi-granular indexing framework. KET-RAG first identifies a small set of key text chunks and leverages an LLM to construct a knowledge graph skeleton. It then builds a text-keyword bipartite graph from all text chunks, serving as a lightweight alternative to a full knowledge graph. During retrieval, KET-RAG searches both structures: it follows the local search strategy of existing Graph-RAG systems on the skeleton while mimicking this search on the bipartite graph to improve retrieval quality. We evaluate eight solutions on two real-world datasets, demonstrating that KET-RAG outperforms all competitors in indexing cost, retrieval effectiveness, and generation quality. Notably, it achieves comparable or superior retrieval quality to Microsoft's Graph-RAG while reducing indexing costs by over an order of magnitude. Additionally, it improves the generation quality by up to 32.4% while lowering indexing costs by around 20%.",
        "tags": [
            "LLMs",
            "RAG"
        ]
    },
    {
        "id": "106",
        "title": "When the LM misunderstood the human chuckled: Analyzing garden path effects in humans and language models",
        "author": [
            "Samuel Joseph Amouyal",
            "Aya Meltzer-Asscher",
            "Jonathan Berant"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09307",
        "abstract": "Modern Large Language Models (LLMs) have shown human-like abilities in many language tasks, sparking interest in comparing LLMs' and humans' language processing. In this paper, we conduct a detailed comparison of the two on a sentence comprehension task using garden-path constructions, which are notoriously challenging for humans. Based on psycholinguistic research, we formulate hypotheses on why garden-path sentences are hard, and test these hypotheses on human participants and a large suite of LLMs using comprehension questions. Our findings reveal that both LLMs and humans struggle with specific syntactic complexities, with some models showing high correlation with human comprehension. To complement our findings, we test LLM comprehension of garden-path constructions with paraphrasing and text-to-image generation tasks, and find that the results mirror the sentence comprehension question results, further validating our findings on LLM understanding of these constructions.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Text-to-Image"
        ]
    },
    {
        "id": "107",
        "title": "A Judge-free LLM Open-ended Generation Benchmark Based on the Distributional Hypothesis",
        "author": [
            "Kentaro Imajo",
            "Masanori Hirano",
            "Shuji Suzuki",
            "Hiroaki Mikami"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09316",
        "abstract": "Evaluating the open-ended text generation of large language models (LLMs) is challenging because of the lack of a clear ground truth and the high cost of human or LLM-based assessments. We propose a novel benchmark that evaluates LLMs using n-gram statistics and rules, without relying on human judgement or LLM-as-a-judge approaches. Using 50 question and reference answer sets, we introduce three new metrics based on n-grams and rules: Fluency, Truthfulness, and Helpfulness. Our benchmark strongly correlates with GPT-4o-based evaluations while requiring significantly fewer computational resources, demonstrating its effectiveness as a scalable alternative for assessing LLMs' open-ended generation capabilities.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "108",
        "title": "A Benchmark for Crime Surveillance Video Analysis with Large Models",
        "author": [
            "Haoran Chen",
            "Dong Yi",
            "Moyan Cao",
            "Chensen Huang",
            "Guibo Zhu",
            "Jinqiao Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09325",
        "abstract": "Anomaly analysis in surveillance videos is a crucial topic in computer vision. In recent years, multimodal large language models (MLLMs) have outperformed task-specific models in various domains. Although MLLMs are particularly versatile, their abilities to understand anomalous concepts and details are insufficiently studied because of the outdated benchmarks of this field not providing MLLM-style QAs and efficient algorithms to assess the model's open-ended text responses. To fill this gap, we propose a benchmark for crime surveillance video analysis with large models denoted as UCVL, including 1,829 videos and reorganized annotations from the UCF-Crime and UCF-Crime Annotation datasets. We design six types of questions and generate diverse QA pairs. Then we develop detailed instructions and use OpenAI's GPT-4o for accurate assessment. We benchmark eight prevailing MLLMs ranging from 0.5B to 40B parameters, and the results demonstrate the reliability of this bench. Moreover, we finetune LLaVA-OneVision on UCVL's training set. The improvement validates our data's high quality for video anomaly analysis.",
        "tags": [
            "GPT",
            "LLaVA",
            "Large Language Models"
        ]
    },
    {
        "id": "109",
        "title": "Copilot Arena: A Platform for Code LLM Evaluation in the Wild",
        "author": [
            "Wayne Chi",
            "Valerie Chen",
            "Anastasios Nikolas Angelopoulos",
            "Wei-Lin Chiang",
            "Aditya Mittal",
            "Naman Jain",
            "Tianjun Zhang",
            "Ion Stoica",
            "Chris Donahue",
            "Ameet Talwalkar"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09328",
        "abstract": "Evaluating in-the-wild coding capabilities of large language models (LLMs) is a challenging endeavor with no clear solution. We introduce Copilot Arena, a platform to collect user preferences for code generation through native integration into a developer's working environment. Copilot Arena comprises a novel interface for comparing pairs of model outputs, a sampling strategy optimized to reduce latency, and a prompting scheme to enable code completion functionality. Copilot Arena has served over 4.5 million suggestions from 10 models and collected over 11k pairwise judgements. Our results highlight the importance of model evaluations in integrated settings. We find that model rankings from Copilot Arena differ from those of existing evaluations, which we attribute to the more realistic distribution of data and tasks contained in Copilot Arena. We also identify novel insights into human preferences on code such as an observed consistency in user preference across programming languages yet significant variation in preference due to task category. We open-source Copilot Arena and release data to enable human-centric evaluations and improve understanding of coding assistants.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "110",
        "title": "Beyond English: The Impact of Prompt Translation Strategies across Languages and Tasks in Multilingual LLMs",
        "author": [
            "Itai Mondshine",
            "Tzuf Paz-Argaman",
            "Reut Tsarfaty"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09331",
        "abstract": "Despite advances in the multilingual capabilities of Large Language Models (LLMs) across diverse tasks, English remains the dominant language for LLM research and development. So, when working with a different language, this has led to the widespread practice of pre-translation, i.e., translating the task prompt into English before inference. Selective pre-translation, a more surgical approach, focuses on translating specific prompt components. However, its current use is sporagic and lacks a systematic research foundation. Consequently, the optimal pre-translation strategy for various multilingual settings and tasks remains unclear. In this work, we aim to uncover the optimal setup for pre-translation by systematically assessing its use. Specifically, we view the prompt as a modular entity, composed of four functional parts: instruction, context, examples, and output, either of which could be translated or not. We evaluate pre-translation strategies across 35 languages covering both low and high-resource languages, on various tasks including Question Answering (QA), Natural Language Inference (NLI), Named Entity Recognition (NER), and Abstractive Summarization. Our experiments show the impact of factors as similarity to English, translation quality and the size of pre-trained data, on the model performance with pre-translation. We suggest practical guidelines for choosing optimal strategies in various multilingual settings.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "111",
        "title": "ThunderServe: High-performance and Cost-efficient LLM Serving in Cloud Environments",
        "author": [
            "Youhe Jiang",
            "Fangcheng Fu",
            "Xiaozhe Yao",
            "Taiyi Wang",
            "Bin Cui",
            "Ana Klimovic",
            "Eiko Yoneki"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09334",
        "abstract": "Recent developments in large language models (LLMs) have demonstrated their remarkable proficiency in a range of tasks. Compared to in-house homogeneous GPU clusters, deploying LLMs in cloud environments with diverse types of GPUs is crucial for addressing the GPU shortage problem and being more cost-effective. However, the diversity of network environments and various GPU types on the cloud bring difficulties to achieving high-performance serving. In this work, we propose ThunderServe, a high-performance and cost-efficient LLM serving system for heterogeneous cloud environments. We introduce a novel scheduling algorithm, which optimizes the deployment plan of LLM serving to accommodate the heterogeneous resource and network bandwidth conditions in cloud environments. Furthermore, we propose a lightweight re-scheduling mechanism, designed to adapt to fluctuating online conditions (e.g., node failures, workload shifts) without the need for costly restarts of ongoing services. Empirical results in both heterogeneous cloud and homogeneous in-house environments reveal that ThunderServe delivers up to a 2.1$\\times$ and on average a $1.7\\times$ increase in throughput and achieves up to a 2.5$\\times$ and on average a $1.5\\times$ reduction in latency deadlines compared with state-of-the-art systems given the same price budget, suggesting opting for cloud services provides a more cost-efficient solution.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "112",
        "title": "Machine learning for modelling unstructured grid data in computational physics: a review",
        "author": [
            "Sibo Cheng",
            "Marc Bocquet",
            "Weiping Ding",
            "Tobias Sebastian Finn",
            "Rui Fu",
            "Jinlong Fu",
            "Yike Guo",
            "Eleda Johnson",
            "Siyi Li",
            "Che Liu",
            "Eric Newton Moro",
            "Jie Pan",
            "Matthew Piggott",
            "Cesar Quilodran",
            "Prakhar Sharma",
            "Kun Wang",
            "Dunhui Xiao",
            "Xiao Xue",
            "Yong Zeng",
            "Mingrui Zhang",
            "Hao Zhou",
            "Kewei Zhu",
            "Rossella Arcucci"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09346",
        "abstract": "Unstructured grid data are essential for modelling complex geometries and dynamics in computational physics. Yet, their inherent irregularity presents significant challenges for conventional machine learning (ML) techniques. This paper provides a comprehensive review of advanced ML methodologies designed to handle unstructured grid data in high-dimensional dynamical systems. Key approaches discussed include graph neural networks, transformer models with spatial attention mechanisms, interpolation-integrated ML methods, and meshless techniques such as physics-informed neural networks. These methodologies have proven effective across diverse fields, including fluid dynamics and environmental simulations. This review is intended as a guidebook for computational scientists seeking to apply ML approaches to unstructured grid data in their domains, as well as for ML researchers looking to address challenges in computational physics. It places special focus on how ML methods can overcome the inherent limitations of traditional numerical techniques and, conversely, how insights from computational physics can inform ML development. To support benchmarking, this review also provides a summary of open-access datasets of unstructured grid data in computational physics. Finally, emerging directions such as generative models with unstructured data, reinforcement learning for mesh generation, and hybrid physics-data-driven paradigms are discussed to inspire future advancements in this evolving field.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "113",
        "title": "Language Agents as Digital Representatives in Collective Decision-Making",
        "author": [
            "Daniel Jarrett",
            "Miruna PÃ®slar",
            "Michiel A. Bakker",
            "Michael Henry Tessler",
            "Raphael KÃ¶ster",
            "Jan Balaguer",
            "Romuald Elie",
            "Christopher Summerfield",
            "Andrea Tacchetti"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09369",
        "abstract": "Consider the process of collective decision-making, in which a group of individuals interactively select a preferred outcome from among a universe of alternatives. In this context, \"representation\" is the activity of making an individual's preferences present in the process via participation by a proxy agent -- i.e. their \"representative\". To this end, learned models of human behavior have the potential to fill this role, with practical implications for multi-agent scenario studies and mechanism design. In this work, we investigate the possibility of training \\textit{language agents} to behave in the capacity of representatives of human agents, appropriately expressing the preferences of those individuals whom they stand for. First, we formalize the setting of \\textit{collective decision-making} -- as the episodic process of interaction between a group of agents and a decision mechanism. On this basis, we then formalize the problem of \\textit{digital representation} -- as the simulation of an agent's behavior to yield equivalent outcomes from the mechanism. Finally, we conduct an empirical case study in the setting of \\textit{consensus-finding} among diverse humans, and demonstrate the feasibility of fine-tuning large language models to act as digital representatives.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "114",
        "title": "An initial-corrected splitting approach for convection-diffusion-reaction problems",
        "author": [
            "Thi Tam Dang",
            "Lukas Einkemmer",
            "Alexander Ostermann"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09371",
        "abstract": "Splitting methods constitute a well-established class of numerical schemes for solving convection-diffusion-reaction problems. They have been shown to be effective in solving problems with periodic boundary conditions. However, in the case of Dirichlet boundary conditions, order reduction has been observed even with homogeneous boundary conditions. In this paper, we propose a novel splitting approach, the so-called `initial-corrected splitting method', which succeeds in overcoming order reduction. A convergence analysis is performed to demonstrate second-order convergence of this modified Strang splitting method. Furthermore, we conduct numerical experiments to illustrate the performance of the newly developed splitting approach.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "115",
        "title": "LoRA Training Provably Converges to a Low-Rank Global Minimum or It Fails Loudly (But it Probably Won't Fail)",
        "author": [
            "Junsu Kim",
            "Jaeyeon Kim",
            "Ernest K. Ryu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09376",
        "abstract": "Low-rank adaptation (LoRA) has become a standard approach for fine-tuning large foundation models. However, our theoretical understanding of LoRA remains limited as prior analyses of LoRA's training dynamics either rely on linearization arguments or consider highly simplified setups. In this work, we analyze the LoRA loss landscape without such restrictive assumptions. We define two regimes: a ``special regime'', which includes idealized setups where linearization arguments hold, and a ``generic regime'' representing more realistic setups where linearization arguments do not hold. In the generic regime, we show that LoRA training converges to a global minimizer with low rank and small magnitude, or a qualitatively distinct solution with high rank and large magnitude. Finally, we argue that the zero-initialization and weight decay in LoRA training induce an implicit bias toward the low-rank, small-magnitude region of the parameter space -- where global minima lie -- thus shedding light on why LoRA training usually succeeds in finding global minima.",
        "tags": [
            "LoRA",
            "Low-Rank Adaptation"
        ]
    },
    {
        "id": "116",
        "title": "A Deep Inverse-Mapping Model for a Flapping Robotic Wing",
        "author": [
            "Hadar Sharvit",
            "Raz Karl",
            "Tsevi Beatus"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09378",
        "abstract": "In systems control, the dynamics of a system are governed by modulating its inputs to achieve a desired outcome. For example, to control the thrust of a quad-copter propeller the controller modulates its rotation rate, relying on a straightforward mapping between the input rotation rate and the resulting thrust. This mapping can be inverted to determine the rotation rate needed to generate a desired thrust. However, in complex systems, such as flapping-wing robots where intricate fluid motions are involved, mapping inputs (wing kinematics) to outcomes (aerodynamic forces) is nontrivial and inverting this mapping for real-time control is computationally impractical. Here, we report a machine-learning solution for the inverse mapping of a flapping-wing system based on data from an experimental system we have developed. Our model learns the input wing motion required to generate a desired aerodynamic force outcome. We used a sequence-to-sequence model tailored for time-series data and augmented it with a novel adaptive-spectrum layer that implements representation learning in the frequency domain. To train our model, we developed a flapping wing system that simultaneously measures the wing's aerodynamic force and its 3D motion using high-speed cameras. We demonstrate the performance of our system on an additional open-source dataset of a flapping wing in a different flow regime. Results show superior performance compared with more complex state-of-the-art transformer-based models, with 11% improvement on the test datasets median loss. Moreover, our model shows superior inference time, making it practical for onboard robotic control. Our open-source data and framework may improve modeling and real-time control of systems governed by complex dynamics, from biomimetic robots to biomedical devices.",
        "tags": [
            "3D",
            "Transformer"
        ]
    },
    {
        "id": "117",
        "title": "Truth Knows No Language: Evaluating Truthfulness Beyond English",
        "author": [
            "Blanca Calvo Figueras",
            "Eneko Sagarzazu",
            "Julen Etxaniz",
            "Jeremy Barnes",
            "Pablo Gamallo",
            "Iria De Dios Flores",
            "Rodrigo Agerri"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09387",
        "abstract": "We introduce a professionally translated extension of the TruthfulQA benchmark designed to evaluate truthfulness in Basque, Catalan, Galician, and Spanish. Truthfulness evaluations of large language models (LLMs) have primarily been conducted in English. However, the ability of LLMs to maintain truthfulness across languages remains under-explored. Our study evaluates 12 state-of-the-art open LLMs, comparing base and instruction-tuned models using human evaluation, multiple-choice metrics, and LLM-as-a-Judge scoring. Our findings reveal that, while LLMs perform best in English and worst in Basque (the lowest-resourced language), overall truthfulness discrepancies across languages are smaller than anticipated. Furthermore, we show that LLM-as-a-Judge correlates more closely with human judgments than multiple-choice metrics, and that informativeness plays a critical role in truthfulness assessment. Our results also indicate that machine translation provides a viable approach for extending truthfulness benchmarks to additional languages, offering a scalable alternative to professional translation. Finally, we observe that universal knowledge questions are better handled across languages than context- and time-dependent ones, highlighting the need for truthfulness evaluations that account for cultural and temporal variability. Dataset and code are publicly available under open licenses.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "118",
        "title": "S$^2$-Diffusion: Generalizing from Instance-level to Category-level Skills in Robot Manipulation",
        "author": [
            "Quantao Yang",
            "Michael C. Welle",
            "Danica Kragic",
            "Olov Andersson"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09389",
        "abstract": "Recent advances in skill learning has propelled robot manipulation to new heights by enabling it to learn complex manipulation tasks from a practical number of demonstrations. However, these skills are often limited to the particular action, object, and environment \\textit{instances} that are shown in the training data, and have trouble transferring to other instances of the same category. In this work we present an open-vocabulary Spatial-Semantic Diffusion policy (S$^2$-Diffusion) which enables generalization from instance-level training data to category-level, enabling skills to be transferable between instances of the same category. We show that functional aspects of skills can be captured via a promptable semantic module combined with a spatial representation. We further propose leveraging depth estimation networks to allow the use of only a single RGB camera. Our approach is evaluated and compared on a diverse number of robot manipulation tasks, both in simulation and in the real world. Our results show that S$^2$-Diffusion is invariant to changes in category-irrelevant factors as well as enables satisfying performance on other instances within the same category, even if it was not trained on that specific instance. Full videos of all real-world experiments are available in the supplementary material.",
        "tags": [
            "Depth Estimation",
            "Diffusion",
            "Robot"
        ]
    },
    {
        "id": "119",
        "title": "SQuARE: Sequential Question Answering Reasoning Engine for Enhanced Chain-of-Thought in Large Language Models",
        "author": [
            "Daniel Fleischer",
            "Moshe Berchansky",
            "Gad Markovits",
            "Moshe Wasserblat"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09390",
        "abstract": "In the rapidly evolving field of Natural Language Processing, Large Language Models (LLMs) are tasked with increasingly complex reasoning challenges. Traditional methods like chain-of-thought prompting have shown promise but often fall short in fully leveraging a model's reasoning capabilities. This paper introduces SQuARE (Sequential Question Answering Reasoning Engine), a novel prompting technique designed to improve reasoning through a self-interrogation paradigm. Building upon CoT frameworks, SQuARE prompts models to generate and resolve multiple auxiliary questions before tackling the main query, promoting a more thorough exploration of various aspects of a topic. Our expansive evaluations, conducted with Llama 3 and GPT-4o models across multiple question-answering datasets, demonstrate that SQuARE significantly surpasses traditional CoT prompts and existing rephrase-and-respond methods. By systematically decomposing queries, SQuARE advances LLM capabilities in reasoning tasks. The code is publicly available at https://github.com/IntelLabs/RAG-FiT/tree/square.",
        "tags": [
            "GPT",
            "LLMs",
            "LLaMA",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "120",
        "title": "Parameter Robust Isogeometric Methods for a Four-Field Formulation of Biot's Consolidation Model",
        "author": [
            "Hanyu Chu",
            "Luca Franco Pavarino"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09410",
        "abstract": "In this paper, a novel isogeometric method for Biot's consolidation model is constructed and analyzed, using a four-field formulation where the unknown variables are the solid displacement, solid pressure, fluid flux, and fluid pressure. Mixed isogeometric spaces based on B-splines basis functions are employed in the space discretization, allowing a smooth representation of the problem geometry and solution fields. The main result of the paper is the proof of optimal error estimates that are robust with respect to material parameters for all solution fields, particularly in the case of nearly incompressible materials. The analysis does not require a uniformly positive storage coefficient. The results of numerical experiments in two and three dimensions confirm the theoretical error estimates and high-order convergence rates attained by the proposed isogeometric Biot discretization and assess its performance with respect to the mesh size, spline polynomial degree, spline regularity, and material parameters.",
        "tags": [
            "FLUX"
        ]
    },
    {
        "id": "121",
        "title": "ImageRAG: Dynamic Image Retrieval for Reference-Guided Image Generation",
        "author": [
            "Rotem Shalev-Arkushin",
            "Rinon Gal",
            "Amit H. Bermano",
            "Ohad Fried"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09411",
        "abstract": "Diffusion models enable high-quality and diverse visual content synthesis. However, they struggle to generate rare or unseen concepts. To address this challenge, we explore the usage of Retrieval-Augmented Generation (RAG) with image generation models. We propose ImageRAG, a method that dynamically retrieves relevant images based on a given text prompt, and uses them as context to guide the generation process. Prior approaches that used retrieved images to improve generation, trained models specifically for retrieval-based generation. In contrast, ImageRAG leverages the capabilities of existing image conditioning models, and does not require RAG-specific training. Our approach is highly adaptable and can be applied across different model types, showing significant improvement in generating rare and fine-grained concepts using different base models.\nOur project page is available at: https://rotem-shalev.github.io/ImageRAG",
        "tags": [
            "Diffusion",
            "RAG"
        ]
    },
    {
        "id": "122",
        "title": "Analysis of harmonic average method for interface problems with discontinuous solutions and fluxe",
        "author": [
            "Kejia Pan",
            "Hengrui Xu",
            "Zhilin Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09413",
        "abstract": "Harmonic average method has been widely utilized to deal with heterogeneous coefficients in solving differential equations. One remarkable advantage of the harmonic averaging method is that no derivative of the coefficient is needed. Furthermore, the coefficient matrix of the finite difference equations is an M-matrix which guarantees the stability of the algorithm. It has been numerically observed but not theoretically proved that the method produces second order pointwise accuracy when the solution and flux are continuous even if the coefficient has finite discontinuities for which the method is inconsistent ($O(1)$ in the local truncation errors). It has been believed that there are some fortunate error cancellations. The harmonic average method does not converge when the solution or the flux has finite discontinuities. In this paper, not only we rigorously prove the second order convergence of the harmonic averaging method for one-dimensional interface problem when the coefficient has a finite discontinuities and the solution and the flux are continuous, but also proposed an {\\em improved harmonic average method} that is also second order accurate (in the $L^{\\infty}$ norm), which allows discontinuous solutions and fluxes along with the discontinuous coefficients. The key in the convergence proof is the construction of the Green's function. The proof shows how the error cancellations occur in a subtle way. Numerical experiments in both 1D and 2D confirmed the theoretical proof of the improved harmonic average method.",
        "tags": [
            "FLUX"
        ]
    },
    {
        "id": "123",
        "title": "Rethinking Evaluation Metrics for Grammatical Error Correction: Why Use a Different Evaluation Process than Human?",
        "author": [
            "Takumi Goto",
            "Yusuke Sakai",
            "Taro Watanabe"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09416",
        "abstract": "One of the goals of automatic evaluation metrics in grammatical error correction (GEC) is to rank GEC systems such that it matches human preferences. However, current automatic evaluations are based on procedures that diverge from human evaluation. Specifically, human evaluation derives rankings by aggregating sentence-level relative evaluation results, e.g., pairwise comparisons, using a rating algorithm, whereas automatic evaluation averages sentence-level absolute scores to obtain corpus-level scores, which are then sorted to determine rankings. In this study, we propose an aggregation method for existing automatic evaluation metrics which aligns with human evaluation methods to bridge this gap. We conducted experiments using various metrics, including edit-based metrics, $n$-gram based metrics, and sentence-level metrics, and show that resolving the gap improves results for the most of metrics on the SEEDA benchmark. We also found that even BERT-based metrics sometimes outperform the metrics of GPT-4. We publish our unified implementation of the metrics and meta-evaluations.",
        "tags": [
            "BERT",
            "GPT"
        ]
    },
    {
        "id": "124",
        "title": "On multi-token prediction for efficient LLM inference",
        "author": [
            "Somesh Mehra",
            "Javier Alonso Garcia",
            "Lukas Mauch"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09419",
        "abstract": "We systematically investigate multi-token prediction (MTP) capabilities within LLMs pre-trained for next-token prediction (NTP). We first show that such models inherently possess MTP capabilities via numerical marginalization over intermediate token probabilities, though performance is data-dependent and improves with model scale. Furthermore, we explore the challenges of integrating MTP heads into frozen LLMs and find that their hidden layers are strongly specialized for NTP, making adaptation non-trivial. Finally, we show that while joint training of MTP heads with the backbone improves performance, it cannot fully overcome this barrier, prompting further research in this direction. Our findings provide a deeper understanding of MTP applied to pretrained LLMs, informing strategies for accelerating inference through parallel token prediction.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "125",
        "title": "Multicontinuum Modeling of Time-Fractional Diffusion-Wave Equation in Heterogeneous Media",
        "author": [
            "Huiran Bai",
            "Dmitry Ammosov",
            "Yin Yang",
            "Wei Xie",
            "Mohammed Al Kobaisi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09428",
        "abstract": "This paper considers a time-fractional diffusion-wave equation with a high-contrast heterogeneous diffusion coefficient. A numerical solution to this problem can present great computational challenges due to its multiscale nature. Therefore, in this paper, we derive a multicontinuum time-fractional diffusion-wave model using the multicontinuum homogenization method. For this purpose, we formulate constraint cell problems considering various homogenized effects. These cell problems are implemented in oversampled regions to avoid boundary effects. By solving the cell problems, we obtain multicontinuum expansions of fine-scale solutions. Then, using these multicontinuum expansions and supposing the smoothness of the macroscopic variables, we rigorously derive the corresponding multicontinuum model. Finally, we present numerical results for two-dimensional model problems with different time-fractional derivatives to verify the accuracy of our proposed approach.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "126",
        "title": "Redistribute Ensemble Training for Mitigating Memorization in Diffusion Models",
        "author": [
            "Xiaoliu Guan",
            "Yu Wu",
            "Huayang Huang",
            "Xiao Liu",
            "Jiaxu Miao",
            "Yi Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09434",
        "abstract": "Diffusion models, known for their tremendous ability to generate high-quality samples, have recently raised concerns due to their data memorization behavior, which poses privacy risks. Recent methods for memory mitigation have primarily addressed the issue within the context of the text modality in cross-modal generation tasks, restricting their applicability to specific conditions. In this paper, we propose a novel method for diffusion models from the perspective of visual modality, which is more generic and fundamental for mitigating memorization. Directly exposing visual data to the model increases memorization risk, so we design a framework where models learn through proxy model parameters instead. Specially, the training dataset is divided into multiple shards, with each shard training a proxy model, then aggregated to form the final model. Additionally, practical analysis of training losses illustrates that the losses for easily memorable images tend to be obviously lower. Thus, we skip the samples with abnormally low loss values from the current mini-batch to avoid memorizing. However, balancing the need to skip memorization-prone samples while maintaining sufficient training data for high-quality image generation presents a key challenge. Thus, we propose IET-AGC+, which redistributes highly memorizable samples between shards, to mitigate these samples from over-skipping. Furthermore, we dynamically augment samples based on their loss values to further reduce memorization. Extensive experiments and analysis on four datasets show that our method successfully reduces memory capacity while maintaining performance. Moreover, we fine-tune the pre-trained diffusion models, e.g., Stable Diffusion, and decrease the memorization score by 46.7\\%, demonstrating the effectiveness of our method. Code is available in: https://github.com/liuxiao-guan/IET_AGC.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "127",
        "title": "Objective quantification of mood states using large language models",
        "author": [
            "Jakub Onysk",
            "Quentin Huys"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09487",
        "abstract": "Emotional states influence human behaviour and cognition, leading to diverse thought trajectories. Similarly, Large Language Models (LLMs) showcase an excellent level of response consistency across wide-ranging contexts (prompts). We leverage these parallels to establish a framework for quantifying mental states. Our approach utilises self-report questionnaires that reliably assess these states due to their inherent sensitivity to patterns of co-occurring responses. Specifically, we recruited a large sample of participants (N=422) to investigate how well an LLM (Mistral-7B-OpenOrca) quantifies a heterogenous set of depressive mood states measured with participants' open-ended responses to a depression questionnaire. We show LLM responses to held-out multiple-choice questions, given participants' open-ended answers, correlate strongly (r: 0.52-0.84) with true questionnaire scores, demonstrating LLM's generalisation from mood representations. We explore a link between these representations and factor analysis. Using ridge regression, we find depression-related subspaces within LLM hidden states. We show these subspaces to be predictive of participants' \"Depression\" and \"Somatic & Emotional Distress\" factor scores, as well as suicidality severity. Overall, LLMs can provide quantitative measures of mental states. The reliability of these hinges upon how informative the questions we ask participants are. Used correctly, this approach could supplement mental state assessment in a variety of settings.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "128",
        "title": "AttentionSmithy: A Modular Framework for Rapid Transformer Development and Customization",
        "author": [
            "Caleb Cranney",
            "Jesse G. Meyer"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09503",
        "abstract": "Transformer architectures have transformed AI applications but remain complex to customize for domain experts lacking low-level implementation expertise. We introduce AttentionSmithy, a modular software package that simplifies transformer innovation by breaking down key components into reusable building blocks: attention modules, feed-forward networks, normalization layers, and positional encodings. Users can rapidly prototype and evaluate transformer variants without extensive coding. Our framework supports four positional encoding strategies and integrates with neural architecture search for automated design. We validate AttentionSmithy by replicating the original transformer under resource constraints and optimizing translation performance by combining positional encodings. Additionally, we demonstrate its adaptability in gene-specific modeling, achieving over 95% accuracy in cell type classification. These case studies highlight AttentionSmithy's potential to accelerate research across diverse fields by removing framework implementation barriers.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "129",
        "title": "When and How Does CLIP Enable Domain and Compositional Generalization?",
        "author": [
            "Elias Kempf",
            "Simon Schrodi",
            "Max Argus",
            "Thomas Brox"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09507",
        "abstract": "The remarkable generalization performance of contrastive vision-language models like CLIP is often attributed to the diversity of their training distributions. However, key questions remain unanswered: Can CLIP generalize to an entirely unseen domain when trained on a diverse mixture of domains (domain generalization)? Can it generalize to unseen classes within partially seen domains (compositional generalization)? What factors affect such generalization? To answer these questions, we trained CLIP models on systematically constructed training distributions with controlled domain diversity and object class exposure. Our experiments show that domain diversity is essential for both domain and compositional generalization, yet compositional generalization can be surprisingly weaker than domain generalization when the training distribution contains a suboptimal subset of the test domain. Through data-centric and mechanistic analyses, we find that successful generalization requires learning of shared representations already in intermediate layers and shared circuitry.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "130",
        "title": "EQ-VAE: Equivariance Regularized Latent Space for Improved Generative Image Modeling",
        "author": [
            "Theodoros Kouzelis",
            "Ioannis Kakogeorgiou",
            "Spyros Gidaris",
            "Nikos Komodakis"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09509",
        "abstract": "Latent generative models have emerged as a leading approach for high-quality image synthesis. These models rely on an autoencoder to compress images into a latent space, followed by a generative model to learn the latent distribution. We identify that existing autoencoders lack equivariance to semantic-preserving transformations like scaling and rotation, resulting in complex latent spaces that hinder generative performance. To address this, we propose EQ-VAE, a simple regularization approach that enforces equivariance in the latent space, reducing its complexity without degrading reconstruction quality. By finetuning pre-trained autoencoders with EQ-VAE, we enhance the performance of several state-of-the-art generative models, including DiT, SiT, REPA and MaskGIT, achieving a 7 speedup on DiT-XL/2 with only five epochs of SD-VAE fine-tuning. EQ-VAE is compatible with both continuous and discrete autoencoders, thus offering a versatile enhancement for a wide range of latent generative models. Project page and code: https://eq-vae.github.io/.",
        "tags": [
            "DiT",
            "VAE"
        ]
    },
    {
        "id": "131",
        "title": "SQ-GAN: Semantic Image Communications Using Masked Vector Quantization",
        "author": [
            "Francesco Pezone",
            "Sergio Barbarossa",
            "Giuseppe Caire"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09520",
        "abstract": "This work introduces Semantically Masked VQ-GAN (SQ-GAN), a novel approach integrating generative models to optimize image compression for semantic/task-oriented communications. SQ-GAN employs off-the-shelf semantic semantic segmentation and a new specifically developed semantic-conditioned adaptive mask module (SAMM) to selectively encode semantically significant features of the images. SQ-GAN outperforms state-of-the-art image compression schemes such as JPEG2000 and BPG across multiple metrics, including perceptual quality and semantic segmentation accuracy on the post-decoding reconstructed image, at extreme low compression rates expressed in bits per pixel.",
        "tags": [
            "GAN",
            "Segmentation",
            "Vector Quantization"
        ]
    },
    {
        "id": "132",
        "title": "Mind the Gap! Choice Independence in Using Multilingual LLMs for Persuasive Co-Writing Tasks in Different Languages",
        "author": [
            "Shreyan Biswas",
            "Alexander Erlei",
            "Ujwal Gadiraju"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09532",
        "abstract": "Recent advances in generative AI have precipitated a proliferation of novel writing assistants. These systems typically rely on multilingual large language models (LLMs), providing globalized workers the ability to revise or create diverse forms of content in different languages. However, there is substantial evidence indicating that the performance of multilingual LLMs varies between languages. Users who employ writing assistance for multiple languages are therefore susceptible to disparate output quality. Importantly, recent research has shown that people tend to generalize algorithmic errors across independent tasks, violating the behavioral axiom of choice independence. In this paper, we analyze whether user utilization of novel writing assistants in a charity advertisement writing task is affected by the AI's performance in a second language. Furthermore, we quantify the extent to which these patterns translate into the persuasiveness of generated charity advertisements, as well as the role of peoples' beliefs about LLM utilization in their donation choices. Our results provide evidence that writers who engage with an LLM-based writing assistant violate choice independence, as prior exposure to a Spanish LLM reduces subsequent utilization of an English LLM. While these patterns do not affect the aggregate persuasiveness of the generated advertisements, people's beliefs about the source of an advertisement (human versus AI) do. In particular, Spanish-speaking female participants who believed that they read an AI-generated advertisement strongly adjusted their donation behavior downwards. Furthermore, people are generally not able to adequately differentiate between human-generated and LLM-generated ads. Our work has important implications for the design, development, integration, and adoption of multilingual LLMs as assistive agents -- particularly in writing tasks.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "133",
        "title": "Long-Term TalkingFace Generation via Motion-Prior Conditional Diffusion Model",
        "author": [
            "Fei Shen",
            "Cong Wang",
            "Junyao Gao",
            "Qin Guo",
            "Jisheng Dang",
            "Jinhui Tang",
            "Tat-Seng Chua"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09533",
        "abstract": "Recent advances in conditional diffusion models have shown promise for generating realistic TalkingFace videos, yet challenges persist in achieving consistent head movement, synchronized facial expressions, and accurate lip synchronization over extended generations. To address these, we introduce the \\textbf{M}otion-priors \\textbf{C}onditional \\textbf{D}iffusion \\textbf{M}odel (\\textbf{MCDM}), which utilizes both archived and current clip motion priors to enhance motion prediction and ensure temporal consistency. The model consists of three key elements: (1) an archived-clip motion-prior that incorporates historical frames and a reference frame to preserve identity and context; (2) a present-clip motion-prior diffusion model that captures multimodal causality for accurate predictions of head movements, lip sync, and expressions; and (3) a memory-efficient temporal attention mechanism that mitigates error accumulation by dynamically storing and updating motion features. We also release the \\textbf{TalkingFace-Wild} dataset, a multilingual collection of over 200 hours of footage across 10 languages. Experimental results demonstrate the effectiveness of MCDM in maintaining identity and motion continuity for long-term TalkingFace generation. Code, models, and datasets will be publicly available.",
        "tags": [
            "CLIP",
            "Diffusion"
        ]
    },
    {
        "id": "134",
        "title": "EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents",
        "author": [
            "Rui Yang",
            "Hanyang Chen",
            "Junyu Zhang",
            "Mark Zhao",
            "Cheng Qian",
            "Kangrui Wang",
            "Qineng Wang",
            "Teja Venkat Koripella",
            "Marziyeh Movahedi",
            "Manling Li",
            "Heng Ji",
            "Huan Zhang",
            "Tong Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09560",
        "abstract": "Leveraging Multi-modal Large Language Models (MLLMs) to create embodied agents offers a promising avenue for tackling real-world tasks. While language-centric embodied agents have garnered substantial attention, MLLM-based embodied agents remain underexplored due to the lack of comprehensive evaluation frameworks. To bridge this gap, we introduce EmbodiedBench, an extensive benchmark designed to evaluate vision-driven embodied agents. EmbodiedBench features: (1) a diverse set of 1,128 testing tasks across four environments, ranging from high-level semantic tasks (e.g., household) to low-level tasks involving atomic actions (e.g., navigation and manipulation); and (2) six meticulously curated subsets evaluating essential agent capabilities like commonsense reasoning, complex instruction understanding, spatial awareness, visual perception, and long-term planning. Through extensive experiments, we evaluated 13 leading proprietary and open-source MLLMs within EmbodiedBench. Our findings reveal that: MLLMs excel at high-level tasks but struggle with low-level manipulation, with the best model, GPT-4o, scoring only 28.9% on average. EmbodiedBench provides a multifaceted standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance MLLM-based embodied agents. Our code is available at https://embodiedbench.github.io.",
        "tags": [
            "GPT",
            "Large Language Models"
        ]
    },
    {
        "id": "135",
        "title": "Enhancing Traffic Safety Analysis with Digital Twin Technology: Integrating Vehicle Dynamics and Environmental Factors into Microscopic Traffic Simulation",
        "author": [
            "Guanhao Xu",
            "Jianfei Chen",
            "Zejiang Wang",
            "Anye Zhou",
            "Max Schrader",
            "Joshua Bittle",
            "Yunli Shao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09561",
        "abstract": "Traffic safety is a critical concern in transportation engineering and urban planning. Traditional traffic safety analysis requires trained observers to collect data in the field, which is time-consuming, labor-intensive, and sometimes inaccurate. In recent years, microscopic traffic simulation, which simulates individual vehicles' movements within a transportation network, have been utilized to study traffic safety. However, microscopic traffic simulation only focuses on traffic-related factors, such as traffic volume, traffic signals, and lane configurations, neglecting vehicle dynamics and environment-related factors like weather and lighting conditions, which can significantly impact traffic safety. In light of this, this paper explores the application of digital twin technology in traffic safety analysis, integrating vehicle simulators, which consider vehicle dynamics and environmental factors, and microscopic traffic simulators, which simulate the operations of traffic flow, for enhanced safety evaluations. Various scenarios, including different weather conditions and visibility levels, are simulated using a digital twin of a road segment in Tuscaloosa, Alabama. The simulations employ Surrogate Safety Measures (SSMs) like Time to Collision (TTC) and Deceleration Rate to Avoid a Crash (DRAC) to assess safety under varying conditions. The results demonstrate that traffic digital twin can identify potential safety issues that traditional microscopic simulation cannot, providing insights for improving traffic control strategies and transportation infrastructure to enhance traffic safety.",
        "tags": [
            "SSMs"
        ]
    },
    {
        "id": "136",
        "title": "Self-Calibrating Gaussian Splatting for Large Field of View Reconstruction",
        "author": [
            "Youming Deng",
            "Wenqi Xian",
            "Guandao Yang",
            "Leonidas Guibas",
            "Gordon Wetzstein",
            "Steve Marschner",
            "Paul Debevec"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09563",
        "abstract": "In this paper, we present a self-calibrating framework that jointly optimizes camera parameters, lens distortion and 3D Gaussian representations, enabling accurate and efficient scene reconstruction. In particular, our technique enables high-quality scene reconstruction from Large field-of-view (FOV) imagery taken with wide-angle lenses, allowing the scene to be modeled from a smaller number of images. Our approach introduces a novel method for modeling complex lens distortions using a hybrid network that combines invertible residual networks with explicit grids. This design effectively regularizes the optimization process, achieving greater accuracy than conventional camera models. Additionally, we propose a cubemap-based resampling strategy to support large FOV images without sacrificing resolution or introducing distortion artifacts. Our method is compatible with the fast rasterization of Gaussian Splatting, adaptable to a wide variety of camera lens distortion, and demonstrates state-of-the-art performance on both synthetic and real-world datasets.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "137",
        "title": "Diffusing DeBias: a Recipe for Turning a Bug into a Feature",
        "author": [
            "Massimiliano Ciranni",
            "Vito Paolo Pastore",
            "Roberto Di Via",
            "Enzo Tartaglione",
            "Francesca Odone",
            "Vittorio Murino"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09564",
        "abstract": "Deep learning model effectiveness in classification tasks is often challenged by the quality and quantity of training data which, whenever containing strong spurious correlations between specific attributes and target labels, can result in unrecoverable biases in model predictions. Tackling these biases is crucial in improving model generalization and trust, especially in real-world scenarios. This paper presents Diffusing DeBias (DDB), a novel approach acting as a plug-in for common methods in model debiasing while exploiting the inherent bias-learning tendency of diffusion models. Our approach leverages conditional diffusion models to generate synthetic bias-aligned images, used to train a bias amplifier model, to be further employed as an auxiliary method in different unsupervised debiasing approaches. Our proposed method, which also tackles the common issue of training set memorization typical of this type of tech- niques, beats current state-of-the-art in multiple benchmark datasets by significant margins, demonstrating its potential as a versatile and effective tool for tackling dataset bias in deep learning applications.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "138",
        "title": "Optimizing GPT for Video Understanding: Zero-Shot Performance and Prompt Engineering",
        "author": [
            "Mark Beliaev",
            "Victor Yang",
            "Madhura Raju",
            "Jiachen Sun",
            "Xinghai Hu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09573",
        "abstract": "In this study, we tackle industry challenges in video content classification by exploring and optimizing GPT-based models for zero-shot classification across seven critical categories of video quality. We contribute a novel approach to improving GPT's performance through prompt optimization and policy refinement, demonstrating that simplifying complex policies significantly reduces false negatives. Additionally, we introduce a new decomposition-aggregation-based prompt engineering technique, which outperforms traditional single-prompt methods. These experiments, conducted on real industry problems, show that thoughtful prompt design can substantially enhance GPT's performance without additional finetuning, offering an effective and scalable solution for improving video classification systems across various domains in industry.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "139",
        "title": "Polymind: Parallel Visual Diagramming with Large Language Models to Support Prewriting Through Microtasks",
        "author": [
            "Qian Wan",
            "Jiannan Li",
            "Huanchen Wang",
            "Zhicong Lu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09577",
        "abstract": "Prewriting is the process of generating and organising ideas before a first draft. It consists of a combination of informal, iterative, and semi-structured strategies such as visual diagramming, which poses a challenge for collaborating with large language models (LLMs) in a turn-taking conversational manner. We present Polymind, a visual diagramming tool that leverages multiple LLM-powered agents to support prewriting. The system features a parallel collaboration workflow in place of the turn-taking conversational interactions. It defines multiple ``microtasks'' to simulate group collaboration scenarios such as collaborative writing and group brainstorming. Instead of repetitively prompting a chatbot for various purposes, Polymind enables users to orchestrate multiple microtasks simultaneously. Users can configure and delegate customised microtasks, and manage their microtasks by specifying task requirements and toggling visibility and initiative. Our evaluation revealed that, compared to ChatGPT, users had more customizability over collaboration with Polymind, and were thus able to quickly expand personalised writing ideas during prewriting.",
        "tags": [
            "ChatGPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "140",
        "title": "Rolling Ahead Diffusion for Traffic Scene Simulation",
        "author": [
            "Yunpeng Liu",
            "Matthew Niedoba",
            "William Harvey",
            "Adam Scibior",
            "Berend Zwartsenberg",
            "Frank Wood"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09587",
        "abstract": "Realistic driving simulation requires that NPCs not only mimic natural driving behaviors but also react to the behavior of other simulated agents. Recent developments in diffusion-based scenario generation focus on creating diverse and realistic traffic scenarios by jointly modelling the motion of all the agents in the scene. However, these traffic scenarios do not react when the motion of agents deviates from their modelled trajectories. For example, the ego-agent can be controlled by a stand along motion planner. To produce reactive scenarios with joint scenario models, the model must regenerate the scenario at each timestep based on new observations in a Model Predictive Control (MPC) fashion. Although reactive, this method is time-consuming, as one complete possible future for all NPCs is generated per simulation step. Alternatively, one can utilize an autoregressive model (AR) to predict only the immediate next-step future for all NPCs. Although faster, this method lacks the capability for advanced planning. We present a rolling diffusion based traffic scene generation model which mixes the benefits of both methods by predicting the next step future and simultaneously predicting partially noised further future steps at the same time. We show that such model is efficient compared to diffusion model based AR, achieving a beneficial compromise between reactivity and computational efficiency.",
        "tags": [
            "Diffusion",
            "MPC"
        ]
    },
    {
        "id": "141",
        "title": "Logical forms complement probability in understanding language model (and human) performance",
        "author": [
            "Yixuan Wang",
            "Freda Shi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09589",
        "abstract": "With the increasing interest in using large language models (LLMs) for planning in natural language, understanding their behaviors becomes an important research question. This work conducts a systematic investigation of LLMs' ability to perform logical reasoning in natural language. We introduce a controlled dataset of hypothetical and disjunctive syllogisms in propositional and modal logic and use it as the testbed for understanding LLM performance. Our results lead to novel insights in predicting LLM behaviors: in addition to the probability of input (Gonen et al., 2023; McCoy et al., 2024), logical forms should be considered as orthogonal factors. In addition, we show similarities and differences between the logical reasoning performances of humans and LLMs by comparing LLM and human behavioral results.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "142",
        "title": "Censor Dependent Variational Inference",
        "author": [
            "Chuanhui Liu",
            "Xiao Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09591",
        "abstract": "This paper provides a comprehensive analysis of variational inference in latent variable models for survival analysis, emphasizing the distinctive challenges associated with applying variational methods to survival data. We identify a critical weakness in the existing methodology, demonstrating how a poorly designed variational distribution may hinder the objective of survival analysis tasks--modeling time-to-event distributions. We prove that the optimal variational distribution, which perfectly bounds the log-likelihood, may depend on the censoring mechanism. To address this issue, we propose censor-dependent variational inference (CDVI), tailored for latent variable models in survival analysis. More practically, we introduce CD-CVAE, a V-structure Variational Autoencoder (VAE) designed for the scalable implementation of CDVI. Further discussion extends some existing theories and training techniques to survival analysis. Extensive experiments validate our analysis and demonstrate significant improvements in the estimation of individual survival distributions.",
        "tags": [
            "VAE"
        ]
    },
    {
        "id": "143",
        "title": "KIMAs: A Configurable Knowledge Integrated Multi-Agent System",
        "author": [
            "Zitao Li",
            "Fei Wei",
            "Yuexiang Xie",
            "Dawei Gao",
            "Weirui Kuang",
            "Zhijian Ma",
            "Bingchen Qian",
            "Yaliang Li",
            "Bolin Ding"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09596",
        "abstract": "Knowledge-intensive conversations supported by large language models (LLMs) have become one of the most popular and helpful applications that can assist people in different aspects. Many current knowledge-intensive applications are centered on retrieval-augmented generation (RAG) techniques. While many open-source RAG frameworks facilitate the development of RAG-based applications, they often fall short in handling practical scenarios complicated by heterogeneous data in topics and formats, conversational context management, and the requirement of low-latency response times. This technical report presents a configurable knowledge integrated multi-agent system, KIMAs, to address these challenges. KIMAs features a flexible and configurable system for integrating diverse knowledge sources with 1) context management and query rewrite mechanisms to improve retrieval accuracy and multi-turn conversational coherency, 2) efficient knowledge routing and retrieval, 3) simple but effective filter and reference generation mechanisms, and 4) optimized parallelizable multi-agent pipeline execution. Our work provides a scalable framework for advancing the deployment of LLMs in real-world settings. To show how KIMAs can help developers build knowledge-intensive applications with different scales and emphases, we demonstrate how we configure the system to three applications already running in practice with reliable performance.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "144",
        "title": "Do LLMs Recognize Your Preferences? Evaluating Personalized Preference Following in LLMs",
        "author": [
            "Siyan Zhao",
            "Mingyi Hong",
            "Yang Liu",
            "Devamanyu Hazarika",
            "Kaixiang Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09597",
        "abstract": "Large Language Models (LLMs) are increasingly used as chatbots, yet their ability to personalize responses to user preferences remains limited. We introduce PrefEval, a benchmark for evaluating LLMs' ability to infer, memorize and adhere to user preferences in a long-context conversational setting. PrefEval comprises 3,000 manually curated user preference and query pairs spanning 20 topics. PrefEval contains user personalization or preference information in both explicit and implicit forms, and evaluates LLM performance using a generation and a classification task. With PrefEval, we evaluated the aforementioned preference following capabilities of 10 open-source and proprietary LLMs in multi-session conversations with varying context lengths up to 100k tokens. We benchmark with various prompting, iterative feedback, and retrieval-augmented generation methods. Our benchmarking effort reveals that state-of-the-art LLMs face significant challenges in proactively following users' preferences during conversations. In particular, in zero-shot settings, preference following accuracy falls below 10% at merely 10 turns (~3k tokens) across most evaluated models. Even with advanced prompting and retrieval methods, preference following still deteriorates in long-context conversations. Furthermore, we show that fine-tuning on PrefEval significantly improves performance. We believe PrefEval serves as a valuable resource for measuring, understanding, and enhancing LLMs' preference following abilities, paving the way for personalized conversational agents. Our code and dataset are available at https://prefeval.github.io/.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "145",
        "title": "SelfCite: Self-Supervised Alignment for Context Attribution in Large Language Models",
        "author": [
            "Yung-Sung Chuang",
            "Benjamin Cohen-Wang",
            "Shannon Zejiang Shen",
            "Zhaofeng Wu",
            "Hu Xu",
            "Xi Victoria Lin",
            "James Glass",
            "Shang-Wen Li",
            "Wen-tau Yih"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09604",
        "abstract": "We introduce SelfCite, a novel self-supervised approach that aligns LLMs to generate high-quality, fine-grained, sentence-level citations for the statements in their generated responses. Instead of only relying on costly and labor-intensive annotations, SelfCite leverages a reward signal provided by the LLM itself through context ablation: If a citation is necessary, removing the cited text from the context should prevent the same response; if sufficient, retaining the cited text alone should preserve the same response. This reward can guide the inference-time best-of-N sampling strategy to improve citation quality significantly, as well as be used in preference optimization to directly fine-tune the models for generating better citations. The effectiveness of SelfCite is demonstrated by increasing citation F1 up to 5.3 points on the LongBench-Cite benchmark across five long-form question answering tasks.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "146",
        "title": "Human-LLM Coevolution: Evidence from Academic Writing",
        "author": [
            "Mingmeng Geng",
            "Roberto Trotta"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09606",
        "abstract": "With a statistical analysis of arXiv paper abstracts, we report a marked drop in the frequency of several words previously identified as overused by ChatGPT, such as \"delve\", starting soon after they were pointed out in early 2024. The frequency of certain other words favored by ChatGPT, such as \"significant\", has instead kept increasing. These phenomena suggest that some authors of academic papers have adapted their use of large language models (LLMs), for example, by selecting outputs or applying modifications to the LLM-generated content. Such coevolution and cooperation of humans and LLMs thus introduce additional challenges to the detection of machine-generated text in real-world scenarios. Estimating the impact of LLMs on academic writing by examining word frequency remains feasible, and more attention should be paid to words that were already frequently employed, including those that have decreased in frequency.",
        "tags": [
            "ChatGPT",
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "147",
        "title": "Score-of-Mixture Training: Training One-Step Generative Models Made Simple",
        "author": [
            "Tejas Jayashankar",
            "J. Jon Ryu",
            "Gregory Wornell"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09609",
        "abstract": "We propose Score-of-Mixture Training (SMT), a novel framework for training one-step generative models by minimizing a class of divergences called the $\\alpha$-skew Jensen-Shannon divergence. At its core, SMT estimates the score of mixture distributions between real and fake samples across multiple noise levels. Similar to consistency models, our approach supports both training from scratch (SMT) and distillation using a pretrained diffusion model, which we call Score-of-Mixture Distillation (SMD). It is simple to implement, requires minimal hyperparameter tuning, and ensures stable training. Experiments on CIFAR-10 and ImageNet 64x64 show that SMT/SMD are competitive with and can even outperform existing methods.",
        "tags": [
            "Consistency Models",
            "Diffusion"
        ]
    },
    {
        "id": "148",
        "title": "Designing a Conditional Prior Distribution for Flow-Based Generative Models",
        "author": [
            "Noam Issachar",
            "Mohammad Salama",
            "Raanan Fattal",
            "Sagie Benaim"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09611",
        "abstract": "Flow-based generative models have recently shown impressive performance for conditional generation tasks, such as text-to-image generation. However, current methods transform a general unimodal noise distribution to a specific mode of the target data distribution. As such, every point in the initial source distribution can be mapped to every point in the target distribution, resulting in long average paths. To this end, in this work, we tap into a non-utilized property of conditional flow-based models: the ability to design a non-trivial prior distribution. Given an input condition, such as a text prompt, we first map it to a point lying in data space, representing an ``average\" data point with the minimal average distance to all data points of the same conditional mode (e.g., class). We then utilize the flow matching formulation to map samples from a parametric distribution centered around this point to the conditional target distribution. Experimentally, our method significantly improves training times and generation efficiency (FID, KID and CLIP alignment scores) compared to baselines, producing high quality samples using fewer sampling steps.",
        "tags": [
            "CLIP",
            "Flow Matching",
            "Text-to-Image"
        ]
    },
    {
        "id": "149",
        "title": "Latent Radiance Fields with 3D-aware 2D Representations",
        "author": [
            "Chaoyi Zhou",
            "Xi Liu",
            "Feng Luo",
            "Siyu Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09613",
        "abstract": "Latent 3D reconstruction has shown great promise in empowering 3D semantic understanding and 3D generation by distilling 2D features into the 3D space. However, existing approaches struggle with the domain gap between 2D feature space and 3D representations, resulting in degraded rendering performance. To address this challenge, we propose a novel framework that integrates 3D awareness into the 2D latent space. The framework consists of three stages: (1) a correspondence-aware autoencoding method that enhances the 3D consistency of 2D latent representations, (2) a latent radiance field (LRF) that lifts these 3D-aware 2D representations into 3D space, and (3) a VAE-Radiance Field (VAE-RF) alignment strategy that improves image decoding from the rendered 2D representations. Extensive experiments demonstrate that our method outperforms the state-of-the-art latent 3D reconstruction approaches in terms of synthesis performance and cross-dataset generalizability across diverse indoor and outdoor scenes. To our knowledge, this is the first work showing the radiance field representations constructed from 2D latent representations can yield photorealistic 3D reconstruction performance.",
        "tags": [
            "3D",
            "VAE"
        ]
    },
    {
        "id": "150",
        "title": "RigAnything: Template-Free Autoregressive Rigging for Diverse 3D Assets",
        "author": [
            "Isabella Liu",
            "Zhan Xu",
            "Wang Yifan",
            "Hao Tan",
            "Zexiang Xu",
            "Xiaolong Wang",
            "Hao Su",
            "Zifan Shi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09615",
        "abstract": "We present RigAnything, a novel autoregressive transformer-based model, which makes 3D assets rig-ready by probabilistically generating joints, skeleton topologies, and assigning skinning weights in a template-free manner. Unlike most existing auto-rigging methods, which rely on predefined skeleton template and are limited to specific categories like humanoid, RigAnything approaches the rigging problem in an autoregressive manner, iteratively predicting the next joint based on the global input shape and the previous prediction. While autoregressive models are typically used to generate sequential data, RigAnything extends their application to effectively learn and represent skeletons, which are inherently tree structures. To achieve this, we organize the joints in a breadth-first search (BFS) order, enabling the skeleton to be defined as a sequence of 3D locations and the parent index. Furthermore, our model improves the accuracy of position prediction by leveraging diffusion modeling, ensuring precise and consistent placement of joints within the hierarchy. This formulation allows the autoregressive model to efficiently capture both spatial and hierarchical relationships within the skeleton. Trained end-to-end on both RigNet and Objaverse datasets, RigAnything demonstrates state-of-the-art performance across diverse object types, including humanoids, quadrupeds, marine creatures, insects, and many more, surpassing prior methods in quality, robustness, generalizability, and efficiency. Please check our website for more details: https://www.liuisabella.com/RigAnything.",
        "tags": [
            "3D",
            "Diffusion",
            "Transformer"
        ]
    },
    {
        "id": "151",
        "title": "Variational Rectified Flow Matching",
        "author": [
            "Pengsheng Guo",
            "Alexander G. Schwing"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09616",
        "abstract": "We study Variational Rectified Flow Matching, a framework that enhances classic rectified flow matching by modeling multi-modal velocity vector-fields. At inference time, classic rectified flow matching 'moves' samples from a source distribution to the target distribution by solving an ordinary differential equation via integration along a velocity vector-field. At training time, the velocity vector-field is learnt by linearly interpolating between coupled samples one drawn from the source and one drawn from the target distribution randomly. This leads to ''ground-truth'' velocity vector-fields that point in different directions at the same location, i.e., the velocity vector-fields are multi-modal/ambiguous. However, since training uses a standard mean-squared-error loss, the learnt velocity vector-field averages ''ground-truth'' directions and isn't multi-modal. In contrast, variational rectified flow matching learns and samples from multi-modal flow directions. We show on synthetic data, MNIST, CIFAR-10, and ImageNet that variational rectified flow matching leads to compelling results.",
        "tags": [
            "Flow Matching",
            "Rectified Flow"
        ]
    },
    {
        "id": "152",
        "title": "Exploring the Potential of Encoder-free Architectures in 3D LMMs",
        "author": [
            "Yiwen Tang",
            "Zoey Guo",
            "Zhuhao Wang",
            "Ray Zhang",
            "Qizhi Chen",
            "Junli Liu",
            "Delin Qu",
            "Zhigang Wang",
            "Dong Wang",
            "Xuelong Li",
            "Bin Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09620",
        "abstract": "Encoder-free architectures have been preliminarily explored in the 2D visual domain, yet it remains an open question whether they can be effectively applied to 3D understanding scenarios. In this paper, we present the first comprehensive investigation into the potential of encoder-free architectures to overcome the challenges of encoder-based 3D Large Multimodal Models (LMMs). These challenges include the failure to adapt to varying point cloud resolutions and the point features from the encoder not meeting the semantic needs of Large Language Models (LLMs). We identify key aspects for 3D LMMs to remove the encoder and enable the LLM to assume the role of the 3D encoder: 1) We propose the LLM-embedded Semantic Encoding strategy in the pre-training stage, exploring the effects of various point cloud self-supervised losses. And we present the Hybrid Semantic Loss to extract high-level semantics. 2) We introduce the Hierarchical Geometry Aggregation strategy in the instruction tuning stage. This incorporates inductive bias into the LLM early layers to focus on the local details of the point clouds. To the end, we present the first Encoder-free 3D LMM, ENEL. Our 7B model rivals the current state-of-the-art model, ShapeLLM-13B, achieving 55.0%, 50.92%, and 42.7% on the classification, captioning, and VQA tasks, respectively. Our results demonstrate that the encoder-free architecture is highly promising for replacing encoder-based architectures in the field of 3D understanding. The code is released at https://github.com/Ivan-Tang-3D/ENEL",
        "tags": [
            "3D",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "153",
        "title": "MME-CoT: Benchmarking Chain-of-Thought in Large Multimodal Models for Reasoning Quality, Robustness, and Efficiency",
        "author": [
            "Dongzhi Jiang",
            "Renrui Zhang",
            "Ziyu Guo",
            "Yanwei Li",
            "Yu Qi",
            "Xinyan Chen",
            "Liuhui Wang",
            "Jianhan Jin",
            "Claire Guo",
            "Shen Yan",
            "Bo Zhang",
            "Chaoyou Fu",
            "Peng Gao",
            "Hongsheng Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09621",
        "abstract": "Answering questions with Chain-of-Thought (CoT) has significantly enhanced the reasoning capabilities of Large Language Models (LLMs), yet its impact on Large Multimodal Models (LMMs) still lacks a systematic assessment and in-depth investigation. In this paper, we introduce MME-CoT, a specialized benchmark evaluating the CoT reasoning performance of LMMs, spanning six domains: math, science, OCR, logic, space-time, and general scenes. As the first comprehensive study in this area, we propose a thorough evaluation suite incorporating three novel metrics that assess the reasoning quality, robustness, and efficiency at a fine-grained level. Leveraging curated high-quality data and a unique evaluation strategy, we conduct an in-depth analysis of state-of-the-art LMMs, uncovering several key insights: 1) Models with reflection mechanism demonstrate a superior CoT quality, with Kimi k1.5 outperforming GPT-4o and demonstrating the highest quality results; 2) CoT prompting often degrades LMM performance on perception-heavy tasks, suggesting a potentially harmful overthinking behavior; and 3) Although the CoT quality is high, LMMs with reflection exhibit significant inefficiency in both normal response and self-correction phases. We hope MME-CoT serves as a foundation for advancing multimodal reasoning in LMMs. Project Page: https://mmecot.github.io/",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "154",
        "title": "Theoretical Benefit and Limitation of Diffusion Language Model",
        "author": [
            "Guhao Feng",
            "Yihan Geng",
            "Jian Guan",
            "Wei Wu",
            "Liwei Wang",
            "Di He"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09622",
        "abstract": "Diffusion language models have emerged as a promising approach for text generation. One would naturally expect this method to be an efficient replacement for autoregressive models since multiple tokens can be sampled in parallel during each diffusion step. However, its efficiency-accuracy trade-off is not yet well understood. In this paper, we present a rigorous theoretical analysis of a widely used type of diffusion language model, the Masked Diffusion Model (MDM), and find that its effectiveness heavily depends on the target evaluation metric. Under mild conditions, we prove that when using perplexity as the metric, MDMs can achieve near-optimal perplexity in sampling steps regardless of sequence length, demonstrating that efficiency can be achieved without sacrificing performance. However, when using the sequence error rate--which is important for understanding the \"correctness\" of a sequence, such as a reasoning chain--we show that the required sampling steps must scale linearly with sequence length to obtain \"correct\" sequences, thereby eliminating MDM's efficiency advantage over autoregressive models. Our analysis establishes the first theoretical foundation for understanding the benefits and limitations of MDMs. All theoretical findings are supported by empirical studies.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "155",
        "title": "Embed Any NeRF: Graph Meta-Networks for Neural Tasks on Arbitrary NeRF Architectures",
        "author": [
            "Francesco Ballerini",
            "Pierluigi Zama Ramirez",
            "Samuele Salti",
            "Luigi Di Stefano"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09623",
        "abstract": "Neural Radiance Fields (NeRFs) have emerged as a groundbreaking paradigm for representing 3D objects and scenes by encoding shape and appearance information into the weights of a neural network. Recent works have shown how such weights can be used as input to frameworks processing them to solve deep learning tasks. Yet, these frameworks can only process NeRFs with a specific, predefined architecture. In this paper, we present the first framework that can ingest NeRFs with multiple architectures and perform inference on architectures unseen at training time. We achieve this goal by training a Graph Meta-Network in a representation learning framework. Moreover, we show how a contrastive objective is conducive to obtaining an architecture-agnostic latent space. In experiments on both MLP-based and tri-planar NeRFs, our approach demonstrates robust performance in classification and retrieval tasks that either matches or exceeds that of existing frameworks constrained to single architectures, thus providing the first architecture-agnostic method to perform tasks on NeRFs by processing their weights.",
        "tags": [
            "3D",
            "NeRF"
        ]
    },
    {
        "id": "156",
        "title": "Unpaired Image-to-Image Translation with Content Preserving Perspective: A Review",
        "author": [
            "Mehran Safayani",
            "Behnaz Mirzapour",
            "Hanieh Aghaebrahimian",
            "Nasrin Salehi",
            "Hamid Ravaee"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08667",
        "abstract": "Image-to-image translation (I2I) transforms an image from a source domain to a target domain while preserving source content. Most computer vision applications are in the field of image-to-image translation, such as style transfer, image segmentation, and photo enhancement. The degree of preservation of the content of the source images in the translation process can be different according to the problem and the intended application. From this point of view, in this paper, we divide the different tasks in the field of image-to-image translation into three categories: Fully Content preserving, Partially Content preserving, and Non-Content preserving. We present different tasks, datasets, methods, results of methods for these three categories in this paper. We make a categorization for I2I methods based on the architecture of different models and study each category separately. In addition, we introduce well-known evaluation criteria in the I2I translation field. Specifically, nearly 70 different I2I models were analyzed, and more than 10 quantitative evaluation metrics and 30 distinct tasks and datasets relevant to the I2I translation problem were both introduced and assessed. Translating from simulation to real images could be well viewed as an application of fully content preserving or partially content preserving unsupervised image-to-image translation methods. So, we provide a benchmark for Sim-to-Real translation, which can be used to evaluate different methods. In general, we conclude that because of the different extent of the obligation to preserving content in various applications, it is better to consider this issue in choosing a suitable I2I model for a specific application.",
        "tags": [
            "Segmentation",
            "Style Transfer"
        ]
    },
    {
        "id": "157",
        "title": "Generic Structural Stability for $2 \\times 2$ Systems of Hyperbolic Conservation Laws",
        "author": [
            "Hong Kiat Tan",
            "Andrea L. Bertozzi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.08998",
        "abstract": "This paper presents a proof of generic structural stability for Riemann solutions to $2 \\times 2$ system of hyperbolic conservation laws in one spatial variable, without diffusive terms. This means that for almost every left and right state, shocks and rarefaction solutions of the same type are preserved via perturbations of the flux functions. The main assumptions for this proof involve standard assumptions on strict hyperbolicity and genuine non-linearity, a technical assumption on directionality of rarefaction curve, and the regular manifold (submersion) assumption motivated by concepts in differential topology. We show that the structural stability of the Riemann solutions is related to the transversality of the Hugoniot loci and rarefaction curves in the state space. The regular manifold assumption is required to invoke a variant of a theorem from differential topology, Thom's parametric transversality theorem, to illustrate the genericity of transversality of these curves. This in turn implies the genericity of structural stability. We then illustrate the applications of this theorem to two examples: the p-system and a $2 \\times 2$ system governing the evolution of gravity-driven monodisperse particle-laden thin films. In particular, we illustrate how one can verify all the above assumptions for the former, and apply the theorem to different numerical and physical aspects of the system governing the latter.",
        "tags": [
            "FLUX"
        ]
    },
    {
        "id": "158",
        "title": "Dynamic Rolling Horizon Optimization for Network-Constrained V2X Value Stacking of Electric Vehicles Under Uncertainties",
        "author": [
            "Canchen Jiang",
            "Ariel Liebman",
            "Bo Jie",
            "Hao Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09290",
        "abstract": "Electric vehicle (EV) coordination can provide significant benefits through vehicle-to-everything (V2X) by interacting with the grid, buildings, and other EVs. This work aims to develop a V2X value-stacking framework, including vehicle-to-building (V2B), vehicle-to-grid (V2G), and energy trading, to maximize economic benefits for residential communities while maintaining distribution voltage. This work also seeks to quantify the impact of prediction errors related to building load, renewable energy, and EV arrivals. A dynamic rolling-horizon optimization (RHO) method is employed to leverage multiple revenue streams and maximize the potential of EV coordination. To address energy uncertainties, including hourly local building load, local photovoltaic (PV) generation, and EV arrivals, this work develops a Transformer-based forecasting model named Gated Recurrent Units-Encoder-Temporal Fusion Decoder (GRU-EN-TFD). The simulation results, using real data from Australia's National Electricity Market, and the Independent System Operators in New England and New York in the US, reveal that V2X value stacking can significantly reduce energy costs. The proposed GRU-EN-TFD model outperforms the benchmark forecast model. Uncertainties in EV arrivals have a more substantial impact on value-stacking performance, highlighting the significance of its accurate forecast. This work provides new insights into the dynamic interactions among residential communities, unlocking the full potential of EV batteries.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "159",
        "title": "Joint Attention Mechanism Learning to Facilitate Opto-physiological Monitoring during Physical Activity",
        "author": [
            "Xiaoyu Zheng",
            "Sijung Hu",
            "Vincent Dwyer",
            "Mahsa Derakhshani",
            "Laura Barrett"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09291",
        "abstract": "Opto-physiological monitoring is a non-contact technique for measuring cardiac signals, i.e., photoplethysmography (PPG). Quality PPG signals directly lead to reliable physiological readings. However, PPG signal acquisition procedures are often accompanied by spurious motion artefacts (MAs), especially during low-to-high-intensity physical activity. This study proposes a practical adversarial learning approach for opto-physiological monitoring by using a generative adversarial network with an attention mechanism (AM-GAN) to model motion noise and to allow MA removal. The AM-GAN learns an MA-resistant mapping from raw and noisy signals to clear PPG signals in an adversarial manner, guided by an attention mechanism to directly translate the motion reference of triaxial acceleration to the MAs appearing in the raw signal. The AM-GAN was experimented with three various protocols engaged with 39 subjects in various physical activities. The average absolute error for heart rate (HR) derived from the MA-free PPG signal via the AM-GAN, is 1.81 beats/min for the IEEE-SPC dataset and 3.86 beats/min for the PPGDalia dataset. The same procedure applied to an in-house LU dataset resulted in average absolute errors for HR and respiratory rate (RR) of less than 1.37 beats/min and 2.49 breaths/min, respectively. The study demonstrates the robustness and resilience of AM-GAN, particularly during low-to-high-intensity physical activities.",
        "tags": [
            "GAN"
        ]
    },
    {
        "id": "160",
        "title": "Non-asymptotic Analysis of Diffusion Annealed Langevin Monte Carlo for Generative Modelling",
        "author": [
            "Paula Cordero-Encinar",
            "O.Deniz Akyildiz",
            "Andrew B. Duncan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09306",
        "abstract": "We investigate the theoretical properties of general diffusion (interpolation) paths and their Langevin Monte Carlo implementation, referred to as diffusion annealed Langevin Monte Carlo (DALMC), under weak conditions on the data distribution. Specifically, we analyse and provide non-asymptotic error bounds for the annealed Langevin dynamics where the path of distributions is defined as Gaussian convolutions of the data distribution as in diffusion models. We then extend our results to recently proposed heavy-tailed (Student's t) diffusion paths, demonstrating their theoretical properties for heavy-tailed data distributions for the first time. Our analysis provides theoretical guarantees for a class of score-based generative models that interpolate between a simple distribution (Gaussian or Student's t) and the data distribution in finite time. This approach offers a broader perspective compared to standard score-based diffusion approaches, which are typically based on a forward Ornstein-Uhlenbeck (OU) noising process.",
        "tags": [
            "Diffusion",
            "Score-Based Generative"
        ]
    },
    {
        "id": "161",
        "title": "Transformer-Enhanced Variational Autoencoder for Crystal Structure Prediction",
        "author": [
            "Ziyi Chen",
            "Yang Yuan",
            "Siming Zheng",
            "Jialong Guo",
            "Sihan Liang",
            "Yangang Wang",
            "Zongguo Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09423",
        "abstract": "Crystal structure forms the foundation for understanding the physical and chemical properties of materials. Generative models have emerged as a new paradigm in crystal structure prediction(CSP), however, accurately capturing key characteristics of crystal structures, such as periodicity and symmetry, remains a significant challenge. In this paper, we propose a Transformer-Enhanced Variational Autoencoder for Crystal Structure Prediction (TransVAE-CSP), who learns the characteristic distribution space of stable materials, enabling both the reconstruction and generation of crystal structures. TransVAE-CSP integrates adaptive distance expansion with irreducible representation to effectively capture the periodicity and symmetry of crystal structures, and the encoder is a transformer network based on an equivariant dot product attention mechanism. Experimental results on the carbon_24, perov_5, and mp_20 datasets demonstrate that TransVAE-CSP outperforms existing methods in structure reconstruction and generation tasks under various modeling metrics, offering a powerful tool for crystal structure design and optimization.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "162",
        "title": "DiffRenderGAN: Addressing Training Data Scarcity in Deep Segmentation Networks for Quantitative Nanomaterial Analysis through Differentiable Rendering and Generative Modelling",
        "author": [
            "Dennis Possart",
            "Leonid Mill",
            "Florian Vollnhals",
            "Tor Hildebrand",
            "Peter Suter",
            "Mathis Hoffmann",
            "Jonas Utz",
            "Daniel Augsburger",
            "Mareike Thies",
            "Mingxuan Wu",
            "Fabian Wagner",
            "George Sarau",
            "Silke Christiansen",
            "Katharina Breininger"
        ],
        "pdf": "https://arxiv.org/pdf/2502.09477",
        "abstract": "Nanomaterials exhibit distinctive properties governed by parameters such as size, shape, and surface characteristics, which critically influence their applications and interactions across technological, biological, and environmental contexts. Accurate quantification and understanding of these materials are essential for advancing research and innovation. In this regard, deep learning segmentation networks have emerged as powerful tools that enable automated insights and replace subjective methods with precise quantitative analysis. However, their efficacy depends on representative annotated datasets, which are challenging to obtain due to the costly imaging of nanoparticles and the labor-intensive nature of manual annotations. To overcome these limitations, we introduce DiffRenderGAN, a novel generative model designed to produce annotated synthetic data. By integrating a differentiable renderer into a Generative Adversarial Network (GAN) framework, DiffRenderGAN optimizes textural rendering parameters to generate realistic, annotated nanoparticle images from non-annotated real microscopy images. This approach reduces the need for manual intervention and enhances segmentation performance compared to existing synthetic data methods by generating diverse and realistic data. Tested on multiple ion and electron microscopy cases, including titanium dioxide (TiO$_2$), silicon dioxide (SiO$_2$)), and silver nanowires (AgNW), DiffRenderGAN bridges the gap between synthetic and real data, advancing the quantification and understanding of complex nanomaterial systems.",
        "tags": [
            "GAN",
            "Segmentation"
        ]
    }
]