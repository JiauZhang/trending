[
    {
        "id": "1",
        "title": "A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations",
        "author": [
            "Mang Ye",
            "Xuankun Rong",
            "Wenke Huang",
            "Bo Du",
            "Nenghai Yu",
            "Dacheng Tao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14881",
        "abstract": "With the rapid advancement of Large Vision-Language Models (LVLMs), ensuring their safety has emerged as a crucial area of research. This survey provides a comprehensive analysis of LVLM safety, covering key aspects such as attacks, defenses, and evaluation methods. We introduce a unified framework that integrates these interrelated components, offering a holistic perspective on the vulnerabilities of LVLMs and the corresponding mitigation strategies. Through an analysis of the LVLM lifecycle, we introduce a classification framework that distinguishes between inference and training phases, with further subcategories to provide deeper insights. Furthermore, we highlight limitations in existing research and outline future directions aimed at strengthening the robustness of LVLMs. As part of our research, we conduct a set of safety evaluations on the latest LVLM, Deepseek Janus-Pro, and provide a theoretical analysis of the results. Our findings provide strategic recommendations for advancing LVLM safety and ensuring their secure and reliable deployment in high-stakes, real-world applications. This survey aims to serve as a cornerstone for future research, facilitating the development of models that not only push the boundaries of multimodal intelligence but also adhere to the highest standards of security and ethical integrity. Furthermore, to aid the growing research in this field, we have created a public repository to continuously compile and update the latest work on LVLM safety: https://github.com/XuankunRong/Awesome-LVLM-Safety .",
        "tags": [
            "DeepSeek"
        ]
    },
    {
        "id": "2",
        "title": "From 16-Bit to 1-Bit: Visual KV Cache Quantization for Memory-Efficient Multimodal Large Language Models",
        "author": [
            "Zeliang Zhang",
            "Yifan Zhu",
            "Susan Liang",
            "Zhiyuan Wang",
            "Jiani Liu",
            "Haiting Lin",
            "Mingjie Zhao",
            "Chenliang Xu",
            "Kun Wan",
            "Wentian Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14882",
        "abstract": "Multimodal Large Language Models (MLLMs) have achieved remarkable success across various applications, yet their computational overhead during deployment remains a critical challenge. While Key-Value (KV) caching improves inference efficiency by trading memory for computation, the growing memory footprint from storing extensive KV caches reduces throughput and limits long-term execution on devices with constrained GPU memory. Existing approaches primarily focus on dropping unimportant tokens to reduce the KV cache size, mitigating memory constraints at the cost of potential information loss. In contrast, we propose a simple yet effective visual quantization strategy that preserves all visual tokens while significantly reducing memory consumption. To achieve an extreme quantization ratio, i.e., 1-bit quantization, we propose group-specific quantization and quantile-based quantization approaches, motivated by the inherent patterns of the KV cache. Our method is plug-and-play, enabling seamless integration into various MLLMs to improve memory efficiency without architectural modifications. Extensive experiments demonstrate that our approach effectively reduces memory overhead while maintaining computational efficiency and preserving multimodal performance.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "3",
        "title": "SEM-CLIP: Precise Few-Shot Learning for Nanoscale Defect Detection in Scanning Electron Microscope Image",
        "author": [
            "Qian Jin",
            "Yuqi Jiang",
            "Xudong Lu",
            "Yumeng Liu",
            "Yining Chen",
            "Dawei Gao",
            "Qi Sun",
            "Cheng Zhuo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14884",
        "abstract": "In the field of integrated circuit manufacturing, the detection and classification of nanoscale wafer defects are critical for subsequent root cause analysis and yield enhancement. The complex background patterns observed in scanning electron microscope (SEM) images and the diverse textures of the defects pose significant challenges. Traditional methods usually suffer from insufficient data, labels, and poor transferability. In this paper, we propose a novel few-shot learning approach, SEM-CLIP, for accurate defect classification and segmentation. SEM-CLIP customizes the Contrastive Language-Image Pretraining (CLIP) model to better focus on defect areas and minimize background distractions, thereby enhancing segmentation accuracy. We employ text prompts enriched with domain knowledge as prior information to assist in precise analysis. Additionally, our approach incorporates feature engineering with textual guidance to categorize defects more effectively. SEM-CLIP requires little annotated data, substantially reducing labor demands in the semiconductor industry. Extensive experimental validation demonstrates that our model achieves impressive classification and segmentation results under few-shot learning scenarios.",
        "tags": [
            "CLIP",
            "Detection",
            "Segmentation"
        ]
    },
    {
        "id": "4",
        "title": "Surgical Scene Understanding in the Era of Foundation AI Models: A Comprehensive Review",
        "author": [
            "Ufaq Khan",
            "Umair Nawaz",
            "Adnan Qayyum",
            "Shazad Ashraf",
            "Muhammad Bilal",
            "Junaid Qadir"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14886",
        "abstract": "Recent advancements in machine learning (ML) and deep learning (DL), particularly through the introduction of foundational models (FMs), have significantly enhanced surgical scene understanding within minimally invasive surgery (MIS). This paper surveys the integration of state-of-the-art ML and DL technologies, including Convolutional Neural Networks (CNNs), Vision Transformers (ViTs), and foundational models like the Segment Anything Model (SAM), into surgical workflows. These technologies improve segmentation accuracy, instrument tracking, and phase recognition in surgical endoscopic video analysis. The paper explores the challenges these technologies face, such as data variability and computational demands, and discusses ethical considerations and integration hurdles in clinical settings. Highlighting the roles of FMs, we bridge the technological capabilities with clinical needs and outline future research directions to enhance the adaptability, efficiency, and ethical alignment of AI applications in surgery. Our findings suggest that substantial progress has been made; however, more focused efforts are required to achieve seamless integration of these technologies into clinical workflows, ensuring they complement surgical practice by enhancing precision, reducing risks, and optimizing patient outcomes.",
        "tags": [
            "SAM",
            "Segment Anything",
            "Segmentation"
        ]
    },
    {
        "id": "5",
        "title": "Vision-Enhanced Time Series Forecasting via Latent Diffusion Models",
        "author": [
            "Weilin Ruan",
            "Siru Zhong",
            "Haomin Wen",
            "Yuxuan Liang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14887",
        "abstract": "Diffusion models have recently emerged as powerful frameworks for generating high-quality images. While recent studies have explored their application to time series forecasting, these approaches face significant challenges in cross-modal modeling and transforming visual information effectively to capture temporal patterns. In this paper, we propose LDM4TS, a novel framework that leverages the powerful image reconstruction capabilities of latent diffusion models for vision-enhanced time series forecasting. Instead of introducing external visual data, we are the first to use complementary transformation techniques to convert time series into multi-view visual representations, allowing the model to exploit the rich feature extraction capabilities of the pre-trained vision encoder. Subsequently, these representations are reconstructed using a latent diffusion model with a cross-modal conditioning mechanism as well as a fusion module. Experimental results demonstrate that LDM4TS outperforms various specialized forecasting models for time series forecasting tasks.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "6",
        "title": "The Multi-Faceted Monosemanticity in Multimodal Representations",
        "author": [
            "Hanqi Yan",
            "Xiangxiang Cui",
            "Lu Yin",
            "Paul Pu Liang",
            "Yulan He",
            "Yifei Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14888",
        "abstract": "In this paper, we leverage recent advancements in feature monosemanticity to extract interpretable features from deep multimodal models, offering a data-driven understanding of modality gaps. Specifically, we investigate CLIP (Contrastive Language-Image Pretraining), a prominent visual-language representation model trained on extensive image-text pairs. Building upon interpretability tools developed for single-modal models, we extend these methodologies to assess multi-modal interpretability of CLIP features. Additionally, we introduce the Modality Dominance Score (MDS) to attribute the interpretability of each feature to its respective modality. Next, we transform CLIP features into a more interpretable space, enabling us to categorize them into three distinct classes: vision features (single-modal), language features (single-modal), and visual-language features (cross-modal). Our findings reveal that this categorization aligns closely with human cognitive understandings of different modalities. We also demonstrate significant use cases of this modality-specific features including detecting gender bias, adversarial attack defense and text-to-image model editing. These results indicate that large-scale multimodal models, equipped with task-agnostic interpretability tools, offer valuable insights into key connections and distinctions between different modalities.",
        "tags": [
            "CLIP",
            "Text-to-Image"
        ]
    },
    {
        "id": "7",
        "title": "Narrowing Information Bottleneck Theory for Multimodal Image-Text Representations Interpretability",
        "author": [
            "Zhiyu Zhu",
            "Zhibo Jin",
            "Jiayu Zhang",
            "Nan Yang",
            "Jiahao Huang",
            "Jianlong Zhou",
            "Fang Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14889",
        "abstract": "The task of identifying multimodal image-text representations has garnered increasing attention, particularly with models such as CLIP (Contrastive Language-Image Pretraining), which demonstrate exceptional performance in learning complex associations between images and text. Despite these advancements, ensuring the interpretability of such models is paramount for their safe deployment in real-world applications, such as healthcare. While numerous interpretability methods have been developed for unimodal tasks, these approaches often fail to transfer effectively to multimodal contexts due to inherent differences in the representation structures. Bottleneck methods, well-established in information theory, have been applied to enhance CLIP's interpretability. However, they are often hindered by strong assumptions or intrinsic randomness. To overcome these challenges, we propose the Narrowing Information Bottleneck Theory, a novel framework that fundamentally redefines the traditional bottleneck approach. This theory is specifically designed to satisfy contemporary attribution axioms, providing a more robust and reliable solution for improving the interpretability of multimodal models. In our experiments, compared to state-of-the-art methods, our approach enhances image interpretability by an average of 9%, text interpretability by an average of 58.83%, and accelerates processing speed by 63.95%. Our code is publicly accessible at https://github.com/LMBTough/NIB.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "8",
        "title": "WeedVision: Multi-Stage Growth and Classification of Weeds using DETR and RetinaNet for Precision Agriculture",
        "author": [
            "Taminul Islam",
            "Toqi Tahamid Sarker",
            "Khaled R Ahmed",
            "Cristiana Bernardi Rankrape",
            "Karla Gage"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14890",
        "abstract": "Weed management remains a critical challenge in agriculture, where weeds compete with crops for essential resources, leading to significant yield losses. Accurate detection of weeds at various growth stages is crucial for effective management yet challenging for farmers, as it requires identifying different species at multiple growth phases. This research addresses these challenges by utilizing advanced object detection models, specifically, the Detection Transformer (DETR) with a ResNet50 backbone and RetinaNet with a ResNeXt101 backbone, to identify and classify 16 weed species of economic concern across 174 classes, spanning their 11 weeks growth stages from seedling to maturity. A robust dataset comprising 203,567 images was developed, meticulously labeled by species and growth stage. The models were rigorously trained and evaluated, with RetinaNet demonstrating superior performance, achieving a mean Average Precision (mAP) of 0.907 on the training set and 0.904 on the test set, compared to DETR's mAP of 0.854 and 0.840, respectively. RetinaNet also outperformed DETR in recall and inference speed of 7.28 FPS, making it more suitable for real time applications. Both models showed improved accuracy as plants matured. This research provides crucial insights for developing precise, sustainable, and automated weed management strategies, paving the way for real time species specific detection systems and advancing AI-assisted agriculture through continued innovation in model development and early detection accuracy.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "9",
        "title": "CoDiff: Conditional Diffusion Model for Collaborative 3D Object Detection",
        "author": [
            "Zhe Huang",
            "Shuo Wang",
            "Yongcai Wang",
            "Lei Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14891",
        "abstract": "Collaborative 3D object detection holds significant importance in the field of autonomous driving, as it greatly enhances the perception capabilities of each individual agent by facilitating information exchange among multiple agents. However, in practice, due to pose estimation errors and time delays, the fusion of information across agents often results in feature representations with spatial and temporal noise, leading to detection errors. Diffusion models naturally have the ability to denoise noisy samples to the ideal data, which motivates us to explore the use of diffusion models to address the noise problem between multi-agent systems. In this work, we propose CoDiff, a novel robust collaborative perception framework that leverages the potential of diffusion models to generate more comprehensive and clearer feature representations. To the best of our knowledge, this is the first work to apply diffusion models to multi-agent collaborative perception. Specifically, we project high-dimensional feature map into the latent space of a powerful pre-trained autoencoder. Within this space, individual agent information serves as a condition to guide the diffusion model's sampling. This process denoises coarse feature maps and progressively refines the fused features. Experimental study on both simulated and real-world datasets demonstrates that the proposed framework CoDiff consistently outperforms existing relevant methods in terms of the collaborative object detection performance, and exhibits highly desired robustness when the pose and delay information of agents is with high-level noise.",
        "tags": [
            "3D",
            "Detection",
            "Diffusion",
            "Pose Estimation"
        ]
    },
    {
        "id": "10",
        "title": "NOTA: Multimodal Music Notation Understanding for Visual Large Language Model",
        "author": [
            "Mingni Tang",
            "Jiajia Li",
            "Lu Yang",
            "Zhiqiang Zhang",
            "Jinghao Tian",
            "Zuchao Li",
            "Lefei Zhang",
            "Ping Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14893",
        "abstract": "Symbolic music is represented in two distinct forms: two-dimensional, visually intuitive score images, and one-dimensional, standardized text annotation sequences. While large language models have shown extraordinary potential in music, current research has primarily focused on unimodal symbol sequence text. Existing general-domain visual language models still lack the ability of music notation understanding. Recognizing this gap, we propose NOTA, the first large-scale comprehensive multimodal music notation dataset. It consists of 1,019,237 records, from 3 regions of the world, and contains 3 tasks. Based on the dataset, we trained NotaGPT, a music notation visual large language model. Specifically, we involve a pre-alignment training phase for cross-modal alignment between the musical notes depicted in music score images and their textual representation in ABC notation. Subsequent training phases focus on foundational music information extraction, followed by training on music notation analysis. Experimental results demonstrate that our NotaGPT-7B achieves significant improvement on music understanding, showcasing the effectiveness of NOTA and the training pipeline. Our datasets are open-sourced at https://huggingface.co/datasets/MYTH-Lab/NOTA-dataset.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "11",
        "title": "High-Dynamic Radar Sequence Prediction for Weather Nowcasting Using Spatiotemporal Coherent Gaussian Representation",
        "author": [
            "Ziye Wang",
            "Yiran Qin",
            "Lin Zeng",
            "Ruimao Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14895",
        "abstract": "Weather nowcasting is an essential task that involves predicting future radar echo sequences based on current observations, offering significant benefits for disaster management, transportation, and urban planning. Current prediction methods are limited by training and storage efficiency, mainly focusing on 2D spatial predictions at specific altitudes. Meanwhile, 3D volumetric predictions at each timestamp remain largely unexplored. To address such a challenge, we introduce a comprehensive framework for 3D radar sequence prediction in weather nowcasting, using the newly proposed SpatioTemporal Coherent Gaussian Splatting (STC-GS) for dynamic radar representation and GauMamba for efficient and accurate forecasting. Specifically, rather than relying on a 4D Gaussian for dynamic scene reconstruction, STC-GS optimizes 3D scenes at each frame by employing a group of Gaussians while effectively capturing their movements across consecutive frames. It ensures consistent tracking of each Gaussian over time, making it particularly effective for prediction tasks. With the temporally correlated Gaussian groups established, we utilize them to train GauMamba, which integrates a memory mechanism into the Mamba framework. This allows the model to learn the temporal evolution of Gaussian groups while efficiently handling a large volume of Gaussian tokens. As a result, it achieves both efficiency and accuracy in forecasting a wide range of dynamic meteorological radar signals. The experimental results demonstrate that our STC-GS can efficiently represent 3D radar sequences with over $16\\times$ higher spatial resolution compared with the existing 3D representation methods, while GauMamba outperforms state-of-the-art methods in forecasting a broad spectrum of high-dynamic weather conditions.",
        "tags": [
            "3D",
            "Gaussian Splatting",
            "Mamba"
        ]
    },
    {
        "id": "12",
        "title": "Can AI mimic the human ability to define neologisms?",
        "author": [
            "Georgios P. Georgiou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14900",
        "abstract": "One ongoing debate in linguistics is whether Artificial Intelligence (AI) can effectively mimic human performance in language-related tasks. While much research has focused on various linguistic abilities of AI, little attention has been given to how it defines neologisms formed through different word formation processes. This study addresses this gap by examining the degree of agreement between human and AI-generated responses in defining three types of Greek neologisms: blends, compounds, and derivatives. The study employed an online experiment in which human participants selected the most appropriate definitions for neologisms, while ChatGPT received identical prompts. The results revealed fair agreement between human and AI responses for blends and derivatives but no agreement for compounds. However, when considering the majority response among humans, agreement with AI was high for blends and derivatives. These findings highlight the complexity of human language and the challenges AI still faces in capturing its nuances. In particular, they suggest a need for integrating more advanced semantic networks and contextual learning mechanisms into AI models to improve their interpretation of complex word formations, especially compounds.",
        "tags": [
            "ChatGPT"
        ]
    },
    {
        "id": "13",
        "title": "PathRAG: Pruning Graph-based Retrieval Augmented Generation with Relational Paths",
        "author": [
            "Boyu Chen",
            "Zirui Guo",
            "Zidan Yang",
            "Yuluo Chen",
            "Junze Chen",
            "Zhenghao Liu",
            "Chuan Shi",
            "Cheng Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14902",
        "abstract": "Retrieval-augmented generation (RAG) improves the response quality of large language models (LLMs) by retrieving knowledge from external databases. Typical RAG approaches split the text database into chunks, organizing them in a flat structure for efficient searches. To better capture the inherent dependencies and structured relationships across the text database, researchers propose to organize textual information into an indexing graph, known asgraph-based RAG. However, we argue that the limitation of current graph-based RAG methods lies in the redundancy of the retrieved information, rather than its insufficiency. Moreover, previous methods use a flat structure to organize retrieved information within the prompts, leading to suboptimal performance. To overcome these limitations, we propose PathRAG, which retrieves key relational paths from the indexing graph, and converts these paths into textual form for prompting LLMs. Specifically, PathRAG effectively reduces redundant information with flow-based pruning, while guiding LLMs to generate more logical and coherent responses with path-based prompting. Experimental results show that PathRAG consistently outperforms state-of-the-art baselines across six datasets and five evaluation dimensions. The code is available at the following link: https://github.com/BUPT-GAMMA/PathRAG",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "14",
        "title": "Think Inside the JSON: Reinforcement Strategy for Strict LLM Schema Adherence",
        "author": [
            "Bhavik Agarwal",
            "Ishan Joshi",
            "Viktoria Rojkova"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14905",
        "abstract": "In this paper, we address the challenge of enforcing strict schema adherence in large language model (LLM) generation by leveraging LLM reasoning capabilities. Building on the DeepSeek R1 reinforcement learning framework, our approach trains structured reasoning skills of a 1.5B parameter model through a novel pipeline that combines synthetic reasoning dataset construction with custom reward functions under Group Relative Policy Optimization (GRPO). Specifically, we first perform R1 reinforcement learning on a 20K sample unstructured-to-structured dataset, mirroring the original DeepSeek R1 methods, to establish core reasoning abilities. Subsequently, we performed supervised fine-tuning on a separate 10K reasoning sample dataset, focusing on refining schema adherence for downstream tasks. Despite the relatively modest training scope, requiring approximately 20 hours on an 8xH100 GPU cluster for GRPO training and 3 hours on 1xA100 for SFT, our model demonstrates robust performance in enforcing schema consistency. We compare our ThinkJSON approach against the original DeepSeek R1 (671B), distilled versions of DeepSeek R1 (Qwen-1.5B and Qwen-7B), and Gemini 2.0 Flash (70B), showcasing its effectiveness in real-world applications. Our results underscore the practical utility of a resource-efficient framework for schema-constrained text generation.",
        "tags": [
            "DeepSeek",
            "Qwen"
        ]
    },
    {
        "id": "15",
        "title": "Beyond Words: Exploring Cultural Value Sensitivity in Multimodal Models",
        "author": [
            "Srishti Yadav",
            "Zhi Zhang",
            "Daniel Hershcovich",
            "Ekaterina Shutova"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14906",
        "abstract": "Investigating value alignment in Large Language Models (LLMs) based on cultural context has become a critical area of research. However, similar biases have not been extensively explored in large vision-language models (VLMs). As the scale of multimodal models continues to grow, it becomes increasingly important to assess whether images can serve as reliable proxies for culture and how these values are embedded through the integration of both visual and textual data. In this paper, we conduct a thorough evaluation of multimodal model at different scales, focusing on their alignment with cultural values. Our findings reveal that, much like LLMs, VLMs exhibit sensitivity to cultural values, but their performance in aligning with these values is highly context-dependent. While VLMs show potential in improving value understanding through the use of images, this alignment varies significantly across contexts highlighting the complexities and underexplored challenges in the alignment of multimodal models.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "16",
        "title": "GneissWeb: Preparing High Quality Data for LLMs at Scale",
        "author": [
            "Hajar Emami Gohari",
            "Swanand Ravindra Kadhe",
            "Syed Yousaf Shah. Constantin Adam",
            "Abdulhamid Adebayo",
            "Praneet Adusumilli",
            "Farhan Ahmed",
            "Nathalie Baracaldo Angel",
            "Santosh Borse",
            "Yuan-Chi Chang",
            "Xuan-Hong Dang",
            "Nirmit Desai",
            "Ravital Eres",
            "Ran Iwamoto",
            "Alexei Karve",
            "Yan Koyfman",
            "Wei-Han Lee",
            "Changchang Liu",
            "Boris Lublinsky",
            "Takuyo Ohko",
            "Pablo Pesce",
            "Maroun Touma",
            "Shiqiang Wang",
            "Shalisha Witherspoon",
            "Herbert Woisetschlager",
            "David Wood",
            "Kun-Lung Wu",
            "Issei Yoshida",
            "Syed Zawad",
            "Petros Zerfos",
            "Yi Zhou",
            "Bishwaranjan Bhattacharjee"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14907",
        "abstract": "Data quantity and quality play a vital role in determining the performance of Large Language Models (LLMs). High-quality data, in particular, can significantly boost the LLM's ability to generalize on a wide range of downstream tasks. Large pre-training datasets for leading LLMs remain inaccessible to the public, whereas many open datasets are small in size (less than 5 trillion tokens), limiting their suitability for training large models.\nIn this paper, we introduce GneissWeb, a large dataset yielding around 10 trillion tokens that caters to the data quality and quantity requirements of training LLMs. Our GneissWeb recipe that produced the dataset consists of sharded exact sub-string deduplication and a judiciously constructed ensemble of quality filters. GneissWeb achieves a favorable trade-off between data quality and quantity, producing models that outperform models trained on state-of-the-art open large datasets (5+ trillion tokens).\nWe show that models trained using GneissWeb dataset outperform those trained on FineWeb-V1.1.0 by 2.73 percentage points in terms of average score computed on a set of 11 commonly used benchmarks (both zero-shot and few-shot) for pre-training dataset evaluation. When the evaluation set is extended to 20 benchmarks (both zero-shot and few-shot), models trained using GneissWeb still achieve a 1.75 percentage points advantage over those trained on FineWeb-V1.1.0.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "17",
        "title": "KOALA: Knowledge Conflict Augmentations for Robustness in Vision Language Models",
        "author": [
            "Peter Carragher",
            "Nikitha Rao",
            "Abhinand Jha",
            "R Raghav",
            "Kathleen M. Carley"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14908",
        "abstract": "The robustness of large language models (LLMs) against knowledge conflicts in unimodal question answering systems has been well studied. However, the effect of conflicts in information sources on vision language models (VLMs) in multimodal settings has not yet been explored. In this work, we propose \\segsub, a framework that applies targeted perturbations to image sources to study and improve the robustness of VLMs against three different types of knowledge conflicts, namely parametric, source, and counterfactual conflicts. Contrary to prior findings that showed that LLMs are sensitive to parametric conflicts arising from textual perturbations, we find VLMs are largely robust to image perturbation. On the other hand, VLMs perform poorly on counterfactual examples (<30% accuracy) and fail to reason over source conflicts (<1% accuracy). We also find a link between hallucinations and image context, with GPT-4o prone to hallucination when presented with highly contextualized counterfactual examples. While challenges persist with source conflicts, finetuning models significantly improves reasoning over counterfactual samples. Our findings highlight the need for VLM training methodologies that enhance their reasoning capabilities, particularly in addressing complex knowledge conflicts between multimodal sources.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "18",
        "title": "EvoP: Robust LLM Inference via Evolutionary Pruning",
        "author": [
            "Shangyu Wu",
            "Hongchao Du",
            "Ying Xiong",
            "Shuai Chen",
            "Tei-wei Kuo",
            "Nan Guan",
            "Chun Jason Xue"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14910",
        "abstract": "Large Language Models (LLMs) have achieved remarkable success in natural language processing tasks, but their massive size and computational demands hinder their deployment in resource-constrained environments. Existing structured pruning methods address this issue by removing redundant structures (e.g., elements, channels, layers) from the model. However, these methods employ a heuristic pruning strategy, which leads to suboptimal performance. Besides, they also ignore the data characteristics when pruning the model.\nTo overcome these limitations, we propose EvoP, an evolutionary pruning framework for robust LLM inference. EvoP first presents a cluster-based calibration dataset sampling (CCDS) strategy for creating a more diverse calibration dataset. EvoP then introduces an evolutionary pruning pattern searching (EPPS) method to find the optimal pruning pattern. Compared to existing structured pruning techniques, EvoP achieves the best performance while maintaining the best efficiency. Experiments across different LLMs and different downstream tasks validate the effectiveness of the proposed EvoP, making it a practical and scalable solution for deploying LLMs in real-world applications.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "19",
        "title": "Batayan: A Filipino NLP benchmark for evaluating Large Language Models",
        "author": [
            "Jann Railey Montalan",
            "Jimson Paulo Layacan",
            "David Demitri Africa",
            "Richell Isaiah Flores",
            "Michael T. Lopez II",
            "Theresa Denise Magsajo",
            "Anjanette Cayabyab",
            "William Chandra Tjhi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14911",
        "abstract": "Recent advances in large language models (LLMs) have demonstrated remarkable capabilities on widely benchmarked high-resource languages; however, linguistic nuances of under-resourced languages remain unexplored. We introduce Batayan, a holistic Filipino benchmark designed to systematically evaluate LLMs across three key natural language processing (NLP) competencies: understanding, reasoning, and generation. Batayan consolidates eight tasks, covering both Tagalog and code-switched Taglish utterances. Our rigorous, native-speaker-driven annotation process ensures fluency and authenticity to the complex morphological and syntactic structures of Filipino, alleviating a pervasive translationese bias in existing Filipino corpora. We report empirical results on a variety of multilingual LLMs, highlighting significant performance gaps that signal the under-representation of Filipino in pretraining corpora, the unique hurdles in modeling Filipino's rich morphology and construction, and the importance of explicit Filipino language support and instruction tuning. Moreover, we discuss the practical challenges encountered in dataset construction and propose principled solutions for building culturally and linguistically-faithful resources in under-represented languages. We also provide a public benchmark and leaderboard as a clear foundation for iterative, community-driven progress in Filipino NLP.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "20",
        "title": "Universal Semantic Embeddings of Chemical Elements for Enhanced Materials Inference and Discovery",
        "author": [
            "Yunze Jia",
            "Yuehui Xian",
            "Yangyang Xu",
            "Pengfei Dang",
            "Xiangdong Ding",
            "Jun Sun",
            "Yumei Zhou",
            "Dezhen Xue"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14912",
        "abstract": "We present a framework for generating universal semantic embeddings of chemical elements to advance materials inference and discovery. This framework leverages ElementBERT, a domain-specific BERT-based natural language processing model trained on 1.29 million abstracts of alloy-related scientific papers, to capture latent knowledge and contextual relationships specific to alloys. These semantic embeddings serve as robust elemental descriptors, consistently outperforming traditional empirical descriptors with significant improvements across multiple downstream tasks. These include predicting mechanical and transformation properties, classifying phase structures, and optimizing materials properties via Bayesian optimization. Applications to titanium alloys, high-entropy alloys, and shape memory alloys demonstrate up to 23% gains in prediction accuracy. Our results show that ElementBERT surpasses general-purpose BERT variants by encoding specialized alloy knowledge. By bridging contextual insights from scientific literature with quantitative inference, our framework accelerates the discovery and optimization of advanced materials, with potential applications extending beyond alloys to other material classes.",
        "tags": [
            "BERT"
        ]
    },
    {
        "id": "21",
        "title": "What Is a Good Caption? A Comprehensive Visual Caption Benchmark for Evaluating Both Correctness and Coverage of MLLMs",
        "author": [
            "Zhihang Liu",
            "Chen-Wei Xie",
            "Bin Wen",
            "Feiwu Yu",
            "Jixuan Chen",
            "Boqiang Zhang",
            "Nianzu Yang",
            "Pandeng Li",
            "Yun Zheng",
            "Hongtao Xie"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14914",
        "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) have rendered traditional visual captioning benchmarks obsolete, as they primarily evaluate short descriptions with outdated metrics. While recent benchmarks address these limitations by decomposing captions into visual elements and adopting model-based evaluation, they remain incomplete-overlooking critical aspects, while providing vague, non-explanatory scores. To bridge this gap, we propose CV-CapBench, a Comprehensive Visual Caption Benchmark that systematically evaluates caption quality across 6 views and 13 dimensions. CV-CapBench introduces precision, recall, and hit rate metrics for each dimension, uniquely assessing both correctness and coverage. Experiments on leading MLLMs reveal significant capability gaps, particularly in dynamic and knowledge-intensive dimensions. These findings provide actionable insights for future research. The code and data will be released.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "22",
        "title": "Sce2DriveX: A Generalized MLLM Framework for Scene-to-Drive Learning",
        "author": [
            "Rui Zhao",
            "Qirui Yuan",
            "Jinyu Li",
            "Haofeng Hu",
            "Yun Li",
            "Chengyuan Zheng",
            "Fei Gao"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14917",
        "abstract": "End-to-end autonomous driving, which directly maps raw sensor inputs to low-level vehicle controls, is an important part of Embodied AI. Despite successes in applying Multimodal Large Language Models (MLLMs) for high-level traffic scene semantic understanding, it remains challenging to effectively translate these conceptual semantics understandings into low-level motion control commands and achieve generalization and consensus in cross-scene driving. We introduce Sce2DriveX, a human-like driving chain-of-thought (CoT) reasoning MLLM framework. Sce2DriveX utilizes multimodal joint learning from local scene videos and global BEV maps to deeply understand long-range spatiotemporal relationships and road topology, enhancing its comprehensive perception and reasoning capabilities in 3D dynamic/static scenes and achieving driving generalization across scenes. Building on this, it reconstructs the implicit cognitive chain inherent in human driving, covering scene understanding, meta-action reasoning, behavior interpretation analysis, motion planning and control, thereby further bridging the gap between autonomous driving and human thought processes. To elevate model performance, we have developed the first extensive Visual Question Answering (VQA) driving instruction dataset tailored for 3D spatial understanding and long-axis task reasoning. Extensive experiments demonstrate that Sce2DriveX achieves state-of-the-art performance from scene understanding to end-to-end driving, as well as robust generalization on the CARLA Bench2Drive benchmark.",
        "tags": [
            "3D",
            "Large Language Models"
        ]
    },
    {
        "id": "23",
        "title": "RAPTOR: Refined Approach for Product Table Object Recognition",
        "author": [
            "Eliott Thomas",
            "Mickael Coustaty",
            "Aurelie Joseph",
            "Elodie Carel",
            "Vincent Poulain D'Andecy",
            "Jean-Marc Ogier"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14918",
        "abstract": "Extracting tables from documents is a critical task across various industries, especially on business documents like invoices and reports. Existing systems based on DEtection TRansformer (DETR) such as TAble TRansformer (TATR), offer solutions for Table Detection (TD) and Table Structure Recognition (TSR) but face challenges with diverse table formats and common errors like incorrect area detection and overlapping columns. This research introduces RAPTOR, a modular post-processing system designed to enhance state-of-the-art models for improved table extraction, particularly for product tables. RAPTOR addresses recurrent TD and TSR issues, improving both precision and structural predictions. For TD, we use DETR (trained on ICDAR 2019) and TATR (trained on PubTables-1M and FinTabNet), while TSR only relies on TATR. A Genetic Algorithm is incorporated to optimize RAPTOR's module parameters, using a private dataset of product tables to align with industrial needs. We evaluate our method on two private datasets of product tables, the public DOCILE dataset (which contains tables similar to our target product tables), and the ICDAR 2013 and ICDAR 2019 datasets. The results demonstrate that while our approach excels at product tables, it also maintains reasonable performance across diverse table formats. An ablation study further validates the contribution of each module in our system.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "24",
        "title": "The Canary's Echo: Auditing Privacy Risks of LLM-Generated Synthetic Text",
        "author": [
            "Matthieu Meeus",
            "Lukas Wutschitz",
            "Santiago Zanella-BÃ©guelin",
            "Shruti Tople",
            "Reza Shokri"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14921",
        "abstract": "How much information about training samples can be gleaned from synthetic data generated by Large Language Models (LLMs)? Overlooking the subtleties of information flow in synthetic data generation pipelines can lead to a false sense of privacy. In this paper, we design membership inference attacks (MIAs) that target data used to fine-tune pre-trained LLMs that are then used to synthesize data, particularly when the adversary does not have access to the fine-tuned model but only to the synthetic data. We show that such data-based MIAs do significantly better than a random guess, meaning that synthetic data leaks information about the training data. Further, we find that canaries crafted to maximize vulnerability to model-based MIAs are sub-optimal for privacy auditing when only synthetic data is released. Such out-of-distribution canaries have limited influence on the model's output when prompted to generate useful, in-distribution synthetic data, which drastically reduces their vulnerability. To tackle this problem, we leverage the mechanics of auto-regressive models to design canaries with an in-distribution prefix and a high-perplexity suffix that leave detectable traces in synthetic data. This enhances the power of data-based MIAs and provides a better assessment of the privacy risks of releasing synthetic data generated by LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "25",
        "title": "SIFT: Grounding LLM Reasoning in Contexts via Stickers",
        "author": [
            "Zihao Zeng",
            "Xuyao Huang",
            "Boxiu Li",
            "Zhijie Deng"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14922",
        "abstract": "This paper identifies the misinterpretation of the context can be a significant issue during the reasoning process of large language models, spanning from smaller models like Llama3.2-3B-Instruct to cutting-edge ones like DeepSeek-R1. For example, in the phrase \"10 dollars per kilo,\" LLMs might not recognize that \"per\" means \"for each,\" leading to calculation errors. We introduce a novel, post-training approach called **Stick to the Facts (SIFT)** to tackle this. SIFT leverages increasing inference-time compute to ground LLM reasoning in contexts. At the core of SIFT lies the *Sticker*, which is generated by the model itself to explicitly emphasize the key information within the context. Given the curated Sticker, SIFT generates two predictions -- one from the original query and one from the query augmented with the Sticker. If they differ, the Sticker is sequentially refined via *forward* optimization (to better align the extracted facts with the query) and *inverse* generation (to conform with the model's inherent tendencies) for more faithful reasoning outcomes. Studies across diverse models (from 3B to 100B+) and benchmarks (e.g., GSM8K, MATH-500) reveal consistent performance improvements. Notably, SIFT improves the pass@1 accuracy of DeepSeek-R1 on AIME2024 from 78.33% to **85.67**%, establishing a new state-of-the-art in the open-source community. The code is available at https://github.com/zhijie-group/SIFT.",
        "tags": [
            "DeepSeek",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "26",
        "title": "A Tale of Two Structures: Do LLMs Capture the Fractal Complexity of Language?",
        "author": [
            "Ibrahim Alabdulmohsin",
            "Andreas Steiner"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14924",
        "abstract": "Language exhibits a fractal structure in its information-theoretic complexity (i.e. bits per token), with self-similarity across scales and long-range dependence (LRD). In this work, we investigate whether large language models (LLMs) can replicate such fractal characteristics and identify conditions-such as temperature setting and prompting method-under which they may fail. Moreover, we find that the fractal parameters observed in natural language are contained within a narrow range, whereas those of LLMs' output vary widely, suggesting that fractal parameters might prove helpful in detecting a non-trivial portion of LLM-generated texts. Notably, these findings, and many others reported in this work, are robust to the choice of the architecture; e.g. Gemini 1.0 Pro, Mistral-7B and Gemma-2B. We also release a dataset comprising of over 240,000 articles generated by various LLMs (both pretrained and instruction-tuned) with different decoding temperatures and prompting methods, along with their corresponding human-generated texts. We hope that this work highlights the complex interplay between fractal properties, prompting, and statistical mimicry in LLMs, offering insights for generating, evaluating and detecting synthetic texts.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "27",
        "title": "DeepSeek-V3, GPT-4, Phi-4, and LLaMA-3.3 generate correct code for LoRaWAN-related engineering task",
        "author": [
            "Daniel Fernandes",
            "JoÃ£o P. Matos-Carvalho",
            "Carlos M. Fernandes",
            "Nuno Fachada"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14926",
        "abstract": "This paper investigates the performance of 16 Large Language Models (LLMs) in automating LoRaWAN-related engineering tasks involving optimal placement of drones and received power calculation under progressively complex zero-shot, natural language prompts. The primary research question is whether lightweight, locally executed LLMs can generate correct Python code for these tasks. To assess this, we compared locally run models against state-of-the-art alternatives, such as GPT-4 and DeepSeek-V3, which served as reference points. By extracting and executing the Python functions generated by each model, we evaluated their outputs on a zero-to-five scale. Results show that while DeepSeek-V3 and GPT-4 consistently provided accurate solutions, certain smaller models-particularly Phi-4 and LLaMA-3.3-also demonstrated strong performance, underscoring the viability of lightweight alternatives. Other models exhibited errors stemming from incomplete understanding or syntactic issues. These findings illustrate the potential of LLM-based approaches for specialized engineering applications while highlighting the need for careful model selection, rigorous prompt design, and targeted domain fine-tuning to achieve reliable outcomes.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "28",
        "title": "RAGVA: Engineering Retrieval Augmented Generation-based Virtual Assistants in Practice",
        "author": [
            "Rui Yang",
            "Michael Fu",
            "Chakkrit Tantithamthavorn",
            "Chetan Arora",
            "Lisa Vandenhurk",
            "Joey Chua"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14930",
        "abstract": "Retrieval-augmented generation (RAG)-based applications are gaining prominence due to their ability to leverage large language models (LLMs). These systems excel at combining retrieval mechanisms with generative capabilities, resulting in more accurate, contextually relevant responses that enhance user experience. In particular, Transurban, a road operation company, is replacing its rule-based virtual assistant (VA) with a RAG-based VA (RAGVA) to offer more flexible customer interactions and support a wider range of scenarios. In this paper, drawing from the experience at Transurban, we present a comprehensive step-by-step guide for building a conversational application and how to engineer a RAGVA. These guides aim to serve as references for future researchers and practitioners. While the engineering processes for traditional software applications are well-established, the development and evaluation of RAG-based applications are still in their early stages, with numerous emerging challenges remaining uncharted. To address this gap, we conduct a focus group study with Transurban practitioners regarding developing and evaluating their RAGVA. We identified eight challenges encountered by the engineering team and proposed eight future directions that should be explored to advance the development of RAG-based applications. This study contributes to the foundational understanding of a RAG-based conversational application and the emerging AI software engineering challenges it presents.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "29",
        "title": "Hier-SLAM++: Neuro-Symbolic Semantic SLAM with a Hierarchically Categorical Gaussian Splatting",
        "author": [
            "Boying Li",
            "Vuong Chi Hao",
            "Peter J. Stuckey",
            "Ian Reid",
            "Hamid Rezatofighi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14931",
        "abstract": "We propose Hier-SLAM++, a comprehensive Neuro-Symbolic semantic 3D Gaussian Splatting SLAM method with both RGB-D and monocular input featuring an advanced hierarchical categorical representation, which enables accurate pose estimation as well as global 3D semantic mapping. The parameter usage in semantic SLAM systems increases significantly with the growing complexity of the environment, making scene understanding particularly challenging and costly. To address this problem, we introduce a novel and general hierarchical representation that encodes both semantic and geometric information in a compact form into 3D Gaussian Splatting, leveraging the capabilities of large language models (LLMs) as well as the 3D generative model. By utilizing the proposed hierarchical tree structure, semantic information is symbolically represented and learned in an end-to-end manner. We further introduce a novel semantic loss designed to optimize hierarchical semantic information through both inter-level and cross-level optimization. Additionally, we propose an improved SLAM system to support both RGB-D and monocular inputs using a feed-forward model. To the best of our knowledge, this is the first semantic monocular Gaussian Splatting SLAM system, significantly reducing sensor requirements for 3D semantic understanding and broadening the applicability of semantic Gaussian SLAM system. We conduct experiments on both synthetic and real-world datasets, demonstrating superior or on-par performance with state-of-the-art NeRF-based and Gaussian-based SLAM systems, while significantly reducing storage and training time requirements.",
        "tags": [
            "3D",
            "Gaussian Splatting",
            "LLMs",
            "Large Language Models",
            "NeRF",
            "Pose Estimation",
            "SLAM"
        ]
    },
    {
        "id": "30",
        "title": "Learning to Retrieve and Reason on Knowledge Graph through Active Self-Reflection",
        "author": [
            "Han Zhang",
            "Langshi Zhou",
            "Hanfang Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14932",
        "abstract": "Extensive research has investigated the integration of large language models (LLMs) with knowledge graphs to enhance the reasoning process. However, understanding how models perform reasoning utilizing structured graph knowledge remains underexplored. Most existing approaches rely on LLMs or retrievers to make binary judgments regarding the utilization of knowledge, which is too coarse. Meanwhile, there is still a lack of feedback mechanisms for reflection and correction throughout the entire reasoning path. This paper proposes an Active self-Reflection framework for knowledge Graph reasoning ARG, introducing for the first time an end-to-end training approach to achieve iterative reasoning grounded on structured graphs. Within the framework, the model leverages special tokens to \\textit{actively} determine whether knowledge retrieval is necessary, performs \\textit{reflective} critique based on the retrieved knowledge, and iteratively reasons over the knowledge graph. The reasoning paths generated by the model exhibit high interpretability, enabling deeper exploration of the model's understanding of structured knowledge. Ultimately, the proposed model achieves outstanding results compared to existing baselines in knowledge graph reasoning tasks.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "31",
        "title": "GS-Cache: A GS-Cache Inference Framework for Large-scale Gaussian Splatting Models",
        "author": [
            "Miao Tao",
            "Yuanzhen Zhou",
            "Haoran Xu",
            "Zeyu He",
            "Zhenyu Yang",
            "Yuchang Zhang",
            "Zhongling Su",
            "Linning Xu",
            "Zhenxiang Ma",
            "Rong Fu",
            "Hengjie Li",
            "Xingcheng Zhang",
            "Jidong Zhai"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14938",
        "abstract": "Rendering large-scale 3D Gaussian Splatting (3DGS) model faces significant challenges in achieving real-time, high-fidelity performance on consumer-grade devices. Fully realizing the potential of 3DGS in applications such as virtual reality (VR) requires addressing critical system-level challenges to support real-time, immersive experiences. We propose GS-Cache, an end-to-end framework that seamlessly integrates 3DGS's advanced representation with a highly optimized rendering system. GS-Cache introduces a cache-centric pipeline to eliminate redundant computations, an efficiency-aware scheduler for elastic multi-GPU rendering, and optimized CUDA kernels to overcome computational bottlenecks. This synergy between 3DGS and system design enables GS-Cache to achieve up to 5.35x performance improvement, 35% latency reduction, and 42% lower GPU memory usage, supporting 2K binocular rendering at over 120 FPS with high visual quality. By bridging the gap between 3DGS's representation power and the demands of VR systems, GS-Cache establishes a scalable and efficient framework for real-time neural rendering in immersive environments.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "32",
        "title": "Online hand gesture recognition using Continual Graph Transformers",
        "author": [
            "Rim Slama",
            "Wael Rabah",
            "Hazem Wannous"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14939",
        "abstract": "Online continuous action recognition has emerged as a critical research area due to its practical implications in real-world applications, such as human-computer interaction, healthcare, and robotics. Among various modalities, skeleton-based approaches have gained significant popularity, demonstrating their effectiveness in capturing 3D temporal data while ensuring robustness to environmental variations. However, most existing works focus on segment-based recognition, making them unsuitable for real-time, continuous recognition scenarios. In this paper, we propose a novel online recognition system designed for real-time skeleton sequence streaming. Our approach leverages a hybrid architecture combining Spatial Graph Convolutional Networks (S-GCN) for spatial feature extraction and a Transformer-based Graph Encoder (TGE) for capturing temporal dependencies across frames. Additionally, we introduce a continual learning mechanism to enhance model adaptability to evolving data distributions, ensuring robust recognition in dynamic environments. We evaluate our method on the SHREC'21 benchmark dataset, demonstrating its superior performance in online hand gesture recognition. Our approach not only achieves state-of-the-art accuracy but also significantly reduces false positive rates, making it a compelling solution for real-time applications. The proposed system can be seamlessly integrated into various domains, including human-robot collaboration and assistive technologies, where natural and intuitive interaction is crucial.",
        "tags": [
            "3D",
            "Robot",
            "Robotics",
            "Transformer"
        ]
    },
    {
        "id": "33",
        "title": "FacaDiffy: Inpainting Unseen Facade Parts Using Diffusion Models",
        "author": [
            "Thomas Froech",
            "Olaf Wysocki",
            "Yan Xia",
            "Junyu Xie",
            "Benedikt Schwab",
            "Daniel Cremers",
            "Thomas H. Kolbe"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14940",
        "abstract": "High-detail semantic 3D building models are frequently utilized in robotics, geoinformatics, and computer vision. One key aspect of creating such models is employing 2D conflict maps that detect openings' locations in building facades. Yet, in reality, these maps are often incomplete due to obstacles encountered during laser scanning. To address this challenge, we introduce FacaDiffy, a novel method for inpainting unseen facade parts by completing conflict maps with a personalized Stable Diffusion model. Specifically, we first propose a deterministic ray analysis approach to derive 2D conflict maps from existing 3D building models and corresponding laser scanning point clouds. Furthermore, we facilitate the inpainting of unseen facade objects into these 2D conflict maps by leveraging the potential of personalizing a Stable Diffusion model. To complement the scarcity of real-world training data, we also develop a scalable pipeline to produce synthetic conflict maps using random city model generators and annotated facade images. Extensive experiments demonstrate that FacaDiffy achieves state-of-the-art performance in conflict map completion compared to various inpainting baselines and increases the detection rate by $22\\%$ when applying the completed conflict maps for high-definition 3D semantic building reconstruction. The code is be publicly available in the corresponding GitHub repository: https://github.com/ThomasFroech/InpaintingofUnseenFacadeObjects",
        "tags": [
            "3D",
            "Detection",
            "Diffusion",
            "Inpainting",
            "Robotics"
        ]
    },
    {
        "id": "34",
        "title": "GenAI vs. Human Fact-Checkers: Accurate Ratings, Flawed Rationales",
        "author": [
            "Yuehong Cassandra Tai",
            "Khushi Navin Patni",
            "Nicholas Daniel Hemauer",
            "Bruce Desmarais",
            "Yu-Ru Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14943",
        "abstract": "Despite recent advances in understanding the capabilities and limits of generative artificial intelligence (GenAI) models, we are just beginning to understand their capacity to assess and reason about the veracity of content. We evaluate multiple GenAI models across tasks that involve the rating of, and perceived reasoning about, the credibility of information. The information in our experiments comes from content that subnational U.S. politicians post to Facebook. We find that GPT-4o, one of the most used AI models in consumer applications, outperforms other models, but all models exhibit only moderate agreement with human coders. Importantly, even when GenAI models accurately identify low-credibility content, their reasoning relies heavily on linguistic features and ``hard'' criteria, such as the level of detail, source reliability, and language formality, rather than an understanding of veracity. We also assess the effectiveness of summarized versus full content inputs, finding that summarized content holds promise for improving efficiency without sacrificing accuracy. While GenAI has the potential to support human fact-checkers in scaling misinformation detection, our results caution against relying solely on these models.",
        "tags": [
            "Detection",
            "GPT"
        ]
    },
    {
        "id": "35",
        "title": "Learning to Solve and Verify: A Self-Play Framework for Code and Test Generation",
        "author": [
            "Zi Lin",
            "Sheng Shen",
            "Jingbo Shang",
            "Jason Weston",
            "Yixin Nie"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14948",
        "abstract": "Recent advances in large language models (LLMs) have improved their performance on coding benchmarks. However, improvement is plateauing due to the exhaustion of readily available high-quality data. Prior work has shown the potential of synthetic self-instruct data, but naively training on a model's own outputs can cause error accumulation, especially in coding tasks, where generalization may collapse due to overly simple or erroneous training data, highlighting the need for rigorous quality checks on synthetic data. In this work, we explore an effective approach whereby the model itself verifies the correctness of its own data. We thus propose Sol-Ver, a self-play solver-verifier framework that jointly improves a single model's code and test generation capacity. By iteratively refining code (LLM-as-a-solver) and tests (LLM-as-a-verifier) together, we boost both capabilities without relying on human annotations or larger teacher models. Experiments with the Llama 3.1 8B model demonstrate substantial performance enhancements, achieving average relative improvements of 19.63% in code generation and 17.49% in test generation on MBPP and LiveCodeBench.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "36",
        "title": "KITAB-Bench: A Comprehensive Multi-Domain Benchmark for Arabic OCR and Document Understanding",
        "author": [
            "Ahmed Heakl",
            "Abdullah Sohail",
            "Mukul Ranjan",
            "Rania Hossam",
            "Ghazi Ahmed",
            "Mohamed El-Geish",
            "Omar Maher",
            "Zhiqiang Shen",
            "Fahad Khan",
            "Salman Khan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14949",
        "abstract": "With the growing adoption of Retrieval-Augmented Generation (RAG) in document processing, robust text recognition has become increasingly critical for knowledge extraction. While OCR (Optical Character Recognition) for English and other languages benefits from large datasets and well-established benchmarks, Arabic OCR faces unique challenges due to its cursive script, right-to-left text flow, and complex typographic and calligraphic features. We present KITAB-Bench, a comprehensive Arabic OCR benchmark that fills the gaps in current evaluation systems. Our benchmark comprises 8,809 samples across 9 major domains and 36 sub-domains, encompassing diverse document types including handwritten text, structured tables, and specialized coverage of 21 chart types for business intelligence. Our findings show that modern vision-language models (such as GPT-4, Gemini, and Qwen) outperform traditional OCR approaches (like EasyOCR, PaddleOCR, and Surya) by an average of 60% in Character Error Rate (CER). Furthermore, we highlight significant limitations of current Arabic OCR models, particularly in PDF-to-Markdown conversion, where the best model Gemini-2.0-Flash achieves only 65% accuracy. This underscores the challenges in accurately recognizing Arabic text, including issues with complex fonts, numeral recognition errors, word elongation, and table structure detection. This work establishes a rigorous evaluation framework that can drive improvements in Arabic document analysis methods and bridge the performance gap with English OCR technologies.",
        "tags": [
            "Detection",
            "GPT",
            "Qwen",
            "RAG"
        ]
    },
    {
        "id": "37",
        "title": "Beyond No: Quantifying AI Over-Refusal and Emotional Attachment Boundaries",
        "author": [
            "David Noever",
            "Grant Rosario"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14975",
        "abstract": "We present an open-source benchmark and evaluation framework for assessing emotional boundary handling in Large Language Models (LLMs). Using a dataset of 1156 prompts across six languages, we evaluated three leading LLMs (GPT-4o, Claude-3.5 Sonnet, and Mistral-large) on their ability to maintain appropriate emotional boundaries through pattern-matched response analysis. Our framework quantifies responses across seven key patterns: direct refusal, apology, explanation, deflection, acknowledgment, boundary setting, and emotional awareness. Results demonstrate significant variation in boundary-handling approaches, with Claude-3.5 achieving the highest overall score (8.69/10) and producing longer, more nuanced responses (86.51 words on average). We identified a substantial performance gap between English (average score 25.62) and non-English interactions (< 0.22), with English responses showing markedly higher refusal rates (43.20% vs. < 1% for non-English). Pattern analysis revealed model-specific strategies, such as Mistral's preference for deflection (4.2%) and consistently low empathy scores across all models (< 0.06). Limitations include potential oversimplification through pattern matching, lack of contextual understanding in response analysis, and binary classification of complex emotional responses. Future work should explore more nuanced scoring methods, expand language coverage, and investigate cultural variations in emotional boundary expectations. Our benchmark and methodology provide a foundation for systematic evaluation of LLM emotional intelligence and boundary-setting capabilities.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "38",
        "title": "EigenShield: Causal Subspace Filtering via Random Matrix Theory for Adversarially Robust Vision-Language Models",
        "author": [
            "Nastaran Darabi",
            "Devashri Naik",
            "Sina Tayebati",
            "Dinithi Jayasuriya",
            "Ranganath Krishnan",
            "Amit Ranjan Trivedi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14976",
        "abstract": "Vision-Language Models (VLMs) inherit adversarial vulnerabilities of Large Language Models (LLMs), which are further exacerbated by their multimodal nature. Existing defenses, including adversarial training, input transformations, and heuristic detection, are computationally expensive, architecture-dependent, and fragile against adaptive attacks. We introduce EigenShield, an inference-time defense leveraging Random Matrix Theory to quantify adversarial disruptions in high-dimensional VLM representations. Unlike prior methods that rely on empirical heuristics, EigenShield employs the spiked covariance model to detect structured spectral deviations. Using a Robustness-based Nonconformity Score (RbNS) and quantile-based thresholding, it separates causal eigenvectors, which encode semantic information, from correlational eigenvectors that are susceptible to adversarial artifacts. By projecting embeddings onto the causal subspace, EigenShield filters adversarial noise without modifying model parameters or requiring adversarial training. This architecture-independent, attack-agnostic approach significantly reduces the attack success rate, establishing spectral analysis as a principled alternative to conventional defenses. Our results demonstrate that EigenShield consistently outperforms all existing defenses, including adversarial training, UNIGUARD, and CIDER.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "39",
        "title": "LAVID: An Agentic LVLM Framework for Diffusion-Generated Video Detection",
        "author": [
            "Qingyuan Liu",
            "Yun-Yun Tsai",
            "Ruijian Zha",
            "Victoria Li",
            "Pengyuan Shi",
            "Chengzhi Mao",
            "Junfeng Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14994",
        "abstract": "The impressive achievements of generative models in creating high-quality videos have raised concerns about digital integrity and privacy vulnerabilities. Recent works of AI-generated content detection have been widely studied in the image field (e.g., deepfake), yet the video field has been unexplored. Large Vision Language Model (LVLM) has become an emerging tool for AI-generated content detection for its strong reasoning and multimodal capabilities. It breaks the limitations of traditional deep learning based methods faced with like lack of transparency and inability to recognize new artifacts. Motivated by this, we propose LAVID, a novel LVLMs-based ai-generated video detection with explicit knowledge enhancement. Our insight list as follows: (1) The leading LVLMs can call external tools to extract useful information to facilitate its own video detection task; (2) Structuring the prompt can affect LVLM's reasoning ability to interpret information in video content. Our proposed pipeline automatically selects a set of explicit knowledge tools for detection, and then adaptively adjusts the structure prompt by self-rewriting. Different from prior SOTA that trains additional detectors, our method is fully training-free and only requires inference of the LVLM for detection. To facilitate our research, we also create a new benchmark \\vidfor with high-quality videos generated from multiple sources of video generation tools. Evaluation results show that LAVID improves F1 scores by 6.2 to 30.2% over the top baselines on our datasets across four SOTA LVLMs.",
        "tags": [
            "Detection",
            "Diffusion",
            "Video Generation"
        ]
    },
    {
        "id": "40",
        "title": "LLM-Microscope: Uncovering the Hidden Role of Punctuation in Context Memory of Transformers",
        "author": [
            "Anton Razzhigaev",
            "Matvey Mikhalchuk",
            "Temurbek Rahmatullaev",
            "Elizaveta Goncharova",
            "Polina Druzhinina",
            "Ivan Oseledets",
            "Andrey Kuznetsov"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15007",
        "abstract": "We introduce methods to quantify how Large Language Models (LLMs) encode and store contextual information, revealing that tokens often seen as minor (e.g., determiners, punctuation) carry surprisingly high context. Notably, removing these tokens -- especially stopwords, articles, and commas -- consistently degrades performance on MMLU and BABILong-4k, even if removing only irrelevant tokens. Our analysis also shows a strong correlation between contextualization and linearity, where linearity measures how closely the transformation from one layer's embeddings to the next can be approximated by a single linear mapping. These findings underscore the hidden importance of filler tokens in maintaining context. For further exploration, we present LLM-Microscope, an open-source toolkit that assesses token-level nonlinearity, evaluates contextual memory, visualizes intermediate layer contributions (via an adapted Logit Lens), and measures the intrinsic dimensionality of representations. This toolkit illuminates how seemingly trivial tokens can be critical for long-range understanding.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "41",
        "title": "Contextualizing Search Queries In-Context Learning for Conversational Rewriting with LLMs",
        "author": [
            "Raymond Wilson",
            "Chase Carter",
            "Cole Graham"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15009",
        "abstract": "Conversational query rewriting is crucial for effective conversational search, yet traditional supervised methods require substantial labeled data, which is scarce in low-resource settings. This paper introduces Prompt-Guided In-Context Learning, a novel approach that leverages the in-context learning capabilities of Large Language Models (LLMs) for few-shot conversational query rewriting. Our method employs carefully designed prompts, incorporating task descriptions, input/output format specifications, and a small set of illustrative examples, to guide pre-trained LLMs to generate context-independent queries without explicit fine-tuning. Extensive experiments on benchmark datasets, TREC and Taskmaster-1, demonstrate that our approach significantly outperforms strong baselines, including supervised models and contrastive co-training methods, across various evaluation metrics such as BLEU, ROUGE-L, Success Rate, and MRR. Ablation studies confirm the importance of in-context examples, and human evaluations further validate the superior fluency, relevance, and context utilization of our generated rewrites. The results highlight the potential of prompt-guided in-context learning as an efficient and effective paradigm for low-resource conversational query rewriting, reducing the reliance on extensive labeled data and complex training procedures.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "42",
        "title": "Obliviate: Efficient Unmemorization for Protecting Intellectual Property in Large Language Models",
        "author": [
            "Mark Russinovich",
            "Ahmed Salem"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15010",
        "abstract": "Recent copyright agreements between AI companies and content creators have highlighted the need for precise control over language models' ability to reproduce copyrighted content. While existing approaches rely on either complete concept removal through unlearning or simple output filtering, we propose Obliviate, a novel post-training technique that selectively prevents verbatim reproduction of specific text while preserving semantic understanding.\nObliviate operates by selecting tokens within memorized sequences and modifying the model's probability distribution to prevent exact reproduction while maintaining contextual understanding. We evaluate Obliviate on multiple large language models (LLaMA-3.1 8B, LLaMA-3.1-instruct 8B, Qwen-2.5-7B, and Yi-1.5 6B) across both synthetic memorization tasks and organic copyright content. Our results demonstrate that Obliviate achieves orders of magnitude reduction, e.g., 100x, in verbatim memorization while maintaining model performance within 1% of baseline on standard benchmarks (HellaSwag, MMLU, TruthfulQA, and Winogrande). This makes Obliviate particularly suitable for practical deployment scenarios where companies need to efficiently address copyright concerns in pretrained models without compromising their general capabilities.",
        "tags": [
            "LLaMA",
            "Large Language Models",
            "Qwen"
        ]
    },
    {
        "id": "43",
        "title": "TimeDistill: Efficient Long-Term Time Series Forecasting with MLP via Cross-Architecture Distillation",
        "author": [
            "Juntong Ni",
            "Zewen Liu",
            "Shiyu Wang",
            "Ming Jin",
            "Wei Jin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15016",
        "abstract": "Transformer-based and CNN-based methods demonstrate strong performance in long-term time series forecasting. However, their high computational and storage requirements can hinder large-scale deployment. To address this limitation, we propose integrating lightweight MLP with advanced architectures using knowledge distillation (KD). Our preliminary study reveals different models can capture complementary patterns, particularly multi-scale and multi-period patterns in the temporal and frequency domains. Based on this observation, we introduce TimeDistill, a cross-architecture KD framework that transfers these patterns from teacher models (e.g., Transformers, CNNs) to MLP. Additionally, we provide a theoretical analysis, demonstrating that our KD approach can be interpreted as a specialized form of mixup data augmentation. TimeDistill improves MLP performance by up to 18.6%, surpassing teacher models on eight datasets. It also achieves up to 7X faster inference and requires 130X fewer parameters. Furthermore, we conduct extensive evaluations to highlight the versatility and effectiveness of TimeDistill.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "44",
        "title": "Using tournaments to calculate AUROC for zero-shot classification with LLMs",
        "author": [
            "Wonjin Yoon",
            "Ian Bulovic",
            "Timothy A. Miller"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15018",
        "abstract": "Large language models perform surprisingly well on many zero-shot classification tasks, but are difficult to fairly compare to supervised classifiers due to the lack of a modifiable decision boundary. In this work, we propose and evaluate a method that converts binary classification tasks into pairwise comparison tasks, obtaining relative rankings from LLMs. Repeated pairwise comparisons can be used to score instances using the Elo rating system (used in chess and other competitions), inducing a confidence ordering over instances in a dataset. We evaluate scheduling algorithms for their ability to minimize comparisons, and show that our proposed algorithm leads to improved classification performance, while also providing more information than traditional zero-shot classification.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "45",
        "title": "Simpler Fast Vision Transformers with a Jumbo CLS Token",
        "author": [
            "Anthony Fuller",
            "Yousef Yassin",
            "Daniel G. Kyrollos",
            "Evan Shelhamer",
            "James R. Green"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15021",
        "abstract": "We introduce a simple enhancement to the global processing of vision transformers (ViTs) to improve accuracy while maintaining throughput. Our approach, Jumbo, creates a wider CLS token, which is split to match the patch token width before attention, processed with self-attention, and reassembled. After attention, Jumbo applies a dedicated, wider FFN to this token. Jumbo significantly improves over ViT+Registers on ImageNet-1K at high speeds (by 3.2% for ViT-tiny and 13.5% for ViT-nano); these Jumbo models even outperform specialized compute-efficient models while preserving the architectural advantages of plain ViTs. Although Jumbo sees no gains for ViT-small on ImageNet-1K, it gains 3.4% on ImageNet-21K over ViT+Registers. Both findings indicate that Jumbo is most helpful when the ViT is otherwise too narrow for the task. Finally, we show that Jumbo can be easily adapted to excel on data beyond images, e.g., time series.",
        "tags": [
            "ViT"
        ]
    },
    {
        "id": "46",
        "title": "A Meta-Evaluation of Style and Attribute Transfer Metrics",
        "author": [
            "Amalie Brogaard Pauli",
            "Isabelle Augenstein",
            "Ira Assent"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15022",
        "abstract": "LLMs make it easy to rewrite text in any style, be it more polite, persuasive, or more positive. We present a large-scale study of evaluation metrics for style and attribute transfer with a focus on content preservation; meaning content not attributed to the style shift is preserved. The de facto evaluation approach uses lexical or semantic similarity metrics often between source sentences and rewrites. While these metrics are not designed to distinguish between style or content differences, empirical meta-evaluation shows a reasonable correlation to human judgment. In fact, recent works find that LLMs prompted as evaluators are only comparable to semantic similarity metrics, even though intuitively, the LLM approach should better fit the task. To investigate this discrepancy, we benchmark 8 metrics for evaluating content preservation on existing datasets and additionally construct a new test set that better aligns with the meta-evaluation aim. Indeed, we then find that the empirical conclusion aligns with the intuition: content preservation metrics for style/attribute transfer must be conditional on the style shift. To support this, we propose a new efficient zero-shot evaluation method using the likelihood of the next token. We hope our meta-evaluation can foster more research on evaluating content preservation metrics, and also to ensure fair evaluation of methods for conducting style transfer.",
        "tags": [
            "LLMs",
            "Style Transfer"
        ]
    },
    {
        "id": "47",
        "title": "CHOIR: Chat-based Helper for Organizational Intelligence Repository",
        "author": [
            "Sangwook Lee",
            "Adnan Abbas",
            "Yan Chen",
            "Sang Won Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15030",
        "abstract": "Modern organizations frequently rely on chat-based platforms (e.g., Slack, Microsoft Teams, and Discord) for day-to-day communication and decision-making. As conversations evolve, organizational knowledge can get buried, prompting repeated searches and discussions. While maintaining shared documents, such as Wiki articles for the organization, offers a partial solution, it requires manual and timely efforts to keep it up to date, and it may not effectively preserve the social and contextual aspect of prior discussions. Moreover, reaching a consensus on document updates with relevant stakeholders can be time-consuming and complex. To address these challenges, we introduce CHOIR (Chat-based Helper for Organizational Intelligence Repository), a chatbot that integrates seamlessly with chat platforms. CHOIR automatically identifies and proposes edits to related documents, initiates discussions with relevant team members, and preserves contextual revision histories. By embedding knowledge management directly into chat environments and leveraging LLMs, CHOIR simplifies manual updates and supports consensus-driven editing based on maintained context with revision histories. We plan to design, deploy, and evaluate CHOIR in the context of maintaining an organizational memory for a research lab. We describe the chatbot's motivation, design, and early implementation to show how CHOIR streamlines collaborative document management.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "48",
        "title": "Notions of Stack-manipulating Computation and Relative Monads (Extended Version)",
        "author": [
            "Yuchen Jiang",
            "Runze Xue",
            "Max S. New"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15031",
        "abstract": "Monads provide a simple and concise interface to user-defined computational effects in functional programming languages. This enables equational reasoning about effects, abstraction over monadic interfaces and the development of monad transformer stacks to combine different effects. Compiler implementors and assembly code programmers similarly virtualize effects, and would benefit from similar abstractions if possible. However, the implementation details of effects seem disconnected from the high-level monad interface: at this lower level much of the design is in the layout of the runtime stack, which is not accessible in a high-level programming language.\nWe demonstrate that the monadic interface can be faithfully adapted from high-level functional programming to a lower level setting with explicit stack manipulation. We use a polymorphic call-by-push-value (CBPV) calculus as a setting that captures the essence of stack-manipulation, with a type system that allows programs to define domain-specific stack structures. Within this setting, we show that the existing category-theoretic notion of a relative monad can be used to model the stack-based implementation of computational effects. To demonstrate generality, we adapt a variety of standard monads to relative monads. Additionally, we show that stack-manipulating programs can benefit from a generalization of do-notation we call \"monadic blocks\" that allow all CBPV code to be reinterpreted to work with an arbitrary relative monad. As an application, we show that all relative monads extend automatically to relative monad transformers, a process which is not automatic for monads in pure languages.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "49",
        "title": "Benchmarking Android Malware Detection: Rethinking the Role of Traditional and Deep Learning Models",
        "author": [
            "Guojun Liu",
            "Doina Caragea",
            "Xinming Ou",
            "Sankardas Roy"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15041",
        "abstract": "Android malware detection has been extensively studied using both traditional machine learning (ML) and deep learning (DL) approaches. While many state-of-the-art detection models, particularly those based on DL, claim superior performance, they often rely on limited comparisons, lacking comprehensive benchmarking against traditional ML models across diverse datasets. This raises concerns about the robustness of DL-based approaches' performance and the potential oversight of simpler, more efficient ML models. In this paper, we conduct a systematic evaluation of Android malware detection models across four datasets: three recently published, publicly available datasets and a large-scale dataset we systematically collected. We implement a range of traditional ML models, including Random Forests (RF) and CatBoost, alongside advanced DL models such as Capsule Graph Neural Networks (CapsGNN), BERT-based models, and ExcelFormer based models. Our results reveal that while advanced DL models can achieve strong performance, they are often compared against an insufficient number of traditional ML baselines. In many cases, simpler and more computationally efficient ML models achieve comparable or even superior performance. These findings highlight the need for rigorous benchmarking in Android malware detection research. We encourage future studies to conduct more comprehensive benchmarking comparisons between traditional and advanced models to ensure a more accurate assessment of detection capabilities. To facilitate further research, we provide access to our dataset, including app IDs, hash values, and labels.",
        "tags": [
            "BERT",
            "Detection"
        ]
    },
    {
        "id": "50",
        "title": "DDAT: Diffusion Policies Enforcing Dynamically Admissible Robot Trajectories",
        "author": [
            "Jean-Baptiste Bouvier",
            "Kanghyun Ryu",
            "Kartik Nagpal",
            "Qiayuan Liao",
            "Koushil Sreenath",
            "Negar Mehr"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15043",
        "abstract": "Diffusion models excel at creating images and videos thanks to their multimodal generative capabilities. These same capabilities have made diffusion models increasingly popular in robotics research, where they are used for generating robot motion. However, the stochastic nature of diffusion models is fundamentally at odds with the precise dynamical equations describing the feasible motion of robots. Hence, generating dynamically admissible robot trajectories is a challenge for diffusion models. To alleviate this issue, we introduce DDAT: Diffusion policies for Dynamically Admissible Trajectories to generate provably admissible trajectories of black-box robotic systems using diffusion models. A sequence of states is a dynamically admissible trajectory if each state of the sequence belongs to the reachable set of its predecessor by the robot's equations of motion. To generate such trajectories, our diffusion policies project their predictions onto a dynamically admissible manifold during both training and inference to align the objective of the denoiser neural network with the dynamical admissibility constraint. The auto-regressive nature of these projections along with the black-box nature of robot dynamics render these projections immensely challenging. We thus enforce admissibility by iteratively sampling a polytopic under-approximation of the reachable set of a state onto which we project its predicted successor, before iterating this process with the projected successor. By producing accurate trajectories, this projection eliminates the need for diffusion models to continually replan, enabling one-shot long-horizon trajectory planning. We demonstrate that our framework generates higher quality dynamically admissible robot trajectories through extensive simulations on a quadcopter and various MuJoCo environments, along with real-world experiments on a Unitree GO1 and GO2.",
        "tags": [
            "Diffusion",
            "Robot",
            "Robotics"
        ]
    },
    {
        "id": "51",
        "title": "FIP: Endowing Robust Motion Capture on Daily Garment by Fusing Flex and Inertial Sensors",
        "author": [
            "Jiawei Fang",
            "Ruonan Zheng",
            "Yuanyao",
            "Xiaoxia Gao",
            "Chengxu Zuo",
            "Shihui Guo",
            "Yiyue Luo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15058",
        "abstract": "What if our clothes could capture our body motion accurately? This paper introduces Flexible Inertial Poser (FIP), a novel motion-capturing system using daily garments with two elbow-attached flex sensors and four Inertial Measurement Units (IMUs). To address the inevitable sensor displacements in loose wearables which degrade joint tracking accuracy significantly, we identify the distinct characteristics of the flex and inertial sensor displacements and develop a Displacement Latent Diffusion Model and a Physics-informed Calibrator to compensate for sensor displacements based on such observations, resulting in a substantial improvement in motion capture accuracy. We also introduce a Pose Fusion Predictor to enhance multimodal sensor fusion. Extensive experiments demonstrate that our method achieves robust performance across varying body shapes and motions, significantly outperforming SOTA IMU approaches with a 19.5% improvement in angular error, a 26.4% improvement in elbow angular error, and a 30.1% improvement in positional error. FIP opens up opportunities for ubiquitous human-computer interactions and diverse interactive applications such as Metaverse, rehabilitation, and fitness analysis.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "52",
        "title": "More for Keys, Less for Values: Adaptive KV Cache Quantization",
        "author": [
            "Mohsen Hariri",
            "Lam Nguyen",
            "Sixu Chen",
            "Shaochen Zhong",
            "Qifan Wang",
            "Xia Hu",
            "Xiaotian Han",
            "Vipin Chaudhary"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15075",
        "abstract": "This paper introduces an information-aware quantization framework that adaptively compresses the key-value (KV) cache in large language models (LLMs). Although prior work has underscored the distinct roles of key and value cache during inference, our systematic analysis -- examining singular value distributions, spectral norms, and Frobenius norms -- reveals, for the first time, that key matrices consistently exhibit higher norm values and are more sensitive to quantization than value matrices. Furthermore, our theoretical analysis shows that matrices with higher spectral norms amplify quantization errors more significantly. Motivated by these insights, we propose a mixed-precision quantization strategy, KV-AdaQuant, which allocates more bit-width for keys and fewer for values since key matrices have higher norm values. With the same total KV bit budget, this approach effectively mitigates error propagation across transformer layers while achieving significant memory savings. Our extensive experiments on multiple LLMs (1B--70B) demonstrate that our mixed-precision quantization scheme maintains high model accuracy even under aggressive compression. For instance, using 4-bit for Key and 2-bit for Value achieves an accuracy of 75.2%, whereas reversing the assignment (2-bit for Key and 4-bit for Value) yields only 54.7% accuracy. The code is available at https://tinyurl.com/kv-adaquant",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "53",
        "title": "Hardware-Friendly Static Quantization Method for Video Diffusion Transformers",
        "author": [
            "Sanghyun Yi",
            "Qingfeng Liu",
            "Mostafa El-Khamy"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15077",
        "abstract": "Diffusion Transformers for video generation have gained significant research interest since the impressive performance of SORA. Efficient deployment of such generative-AI models on GPUs has been demonstrated with dynamic quantization. However, resource-constrained devices cannot support dynamic quantization, and need static quantization of the models for their efficient deployment on AI processors. In this paper, we propose a novel method for the post-training quantization of OpenSora\\cite{opensora}, a Video Diffusion Transformer, without relying on dynamic quantization techniques. Our approach employs static quantization, achieving video quality comparable to FP16 and dynamically quantized ViDiT-Q methods, as measured by CLIP, and VQA metrics. In particular, we utilize per-step calibration data to adequately provide a post-training statically quantized model for each time step, incorporating channel-wise quantization for weights and tensor-wise quantization for activations. By further applying the smooth-quantization technique, we can obtain high-quality video outputs with the statically quantized models. Extensive experimental results demonstrate that static quantization can be a viable alternative to dynamic quantization for video diffusion transformers, offering a more efficient approach without sacrificing performance.",
        "tags": [
            "CLIP",
            "Diffusion",
            "Diffusion Transformer",
            "Sora",
            "Transformer",
            "Video Generation"
        ]
    },
    {
        "id": "54",
        "title": "Can Hallucination Correction Improve Video-Language Alignment?",
        "author": [
            "Lingjun Zhao",
            "Mingyang Xie",
            "Paola Cascante-Bonilla",
            "Hal DaumÃ© III",
            "Kwonjoon Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15079",
        "abstract": "Large Vision-Language Models often generate hallucinated content that is not grounded in its visual inputs. While prior work focuses on mitigating hallucinations, we instead explore leveraging hallucination correction as a training objective to improve video-language alignment. We introduce HACA, a self-training framework learning to correct hallucinations in descriptions that do not align with the video content. By identifying and correcting inconsistencies, HACA enhances the model's ability to align video and textual representations for spatio-temporal reasoning. Our experimental results show consistent gains in video-caption binding and text-to-video retrieval tasks, demonstrating that hallucination correction-inspired tasks serve as an effective strategy for improving vision and language alignment.",
        "tags": [
            "Text-to-Video"
        ]
    },
    {
        "id": "55",
        "title": "UPCORE: Utility-Preserving Coreset Selection for Balanced Unlearning",
        "author": [
            "Vaidehi Patil",
            "Elias Stengel-Eskin",
            "Mohit Bansal"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15082",
        "abstract": "User specifications or legal frameworks often require information to be removed from pretrained models, including large language models (LLMs). This requires deleting or \"forgetting\" a set of data points from an already-trained model, which typically degrades its performance on other data points. Thus, a balance must be struck between removing information and keeping the model's other abilities intact, with a failure to balance this trade-off leading to poor deletion or an unusable model. To this end, we propose UPCORE (Utility-Preserving Coreset Selection), a method-agnostic data selection framework for mitigating collateral damage during unlearning. Finding that the model damage is correlated with the variance of the model's representations on the forget set, we selectively prune the forget set to remove outliers, thereby minimizing model degradation after unlearning. We evaluate UPCORE across three standard unlearning methods consistently achieving a superior balance between the competing objectives of deletion efficacy and model preservation. To better evaluate this trade-off, we introduce a new metric, measuring the area-under-the-curve (AUC) across standard metrics. We find that UPCORE improves both standard metrics and AUC, benefitting from positive transfer between the coreset and pruned points while reducing negative transfer from the forget set to points outside of it.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "56",
        "title": "Is Safety Standard Same for Everyone? User-Specific Safety Evaluation of Large Language Models",
        "author": [
            "Yeonjun In",
            "Wonjoong Kim",
            "Kanghoon Yoon",
            "Sungchul Kim",
            "Mehrab Tanjim",
            "Kibum Kim",
            "Chanyoung Park"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15086",
        "abstract": "As the use of large language model (LLM) agents continues to grow, their safety vulnerabilities have become increasingly evident. Extensive benchmarks evaluate various aspects of LLM safety by defining the safety relying heavily on general standards, overlooking user-specific standards. However, safety standards for LLM may vary based on a user-specific profiles rather than being universally consistent across all users. This raises a critical research question: Do LLM agents act safely when considering user-specific safety standards? Despite its importance for safe LLM use, no benchmark datasets currently exist to evaluate the user-specific safety of LLMs. To address this gap, we introduce U-SAFEBENCH, the first benchmark designed to assess user-specific aspect of LLM safety. Our evaluation of 18 widely used LLMs reveals current LLMs fail to act safely when considering user-specific safety standards, marking a new discovery in this field. To address this vulnerability, we propose a simple remedy based on chain-of-thought, demonstrating its effectiveness in improving user-specific safety. Our benchmark and code are available at https://github.com/yeonjun-in/U-SafeBench.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "57",
        "title": "Analyze the Neurons, not the Embeddings: Understanding When and Where LLM Representations Align with Humans",
        "author": [
            "Masha Fedzechkina",
            "Eleonora Gualdoni",
            "Sinead Williamson",
            "Katherine Metcalf",
            "Skyler Seto",
            "Barry-John Theobald"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15090",
        "abstract": "Modern large language models (LLMs) achieve impressive performance on some tasks, while exhibiting distinctly non-human-like behaviors on others. This raises the question of how well the LLM's learned representations align with human representations. In this work, we introduce a novel approach to the study of representation alignment: we adopt a method from research on activation steering to identify neurons responsible for specific concepts (e.g., 'cat') and then analyze the corresponding activation patterns. Our findings reveal that LLM representations closely align with human representations inferred from behavioral data. Notably, this alignment surpasses that of word embeddings, which have been center stage in prior work on human and model alignment. Additionally, our approach enables a more granular view of how LLMs represent concepts. Specifically, we show that LLMs organize concepts in a way that reflects hierarchical relationships interpretable to humans (e.g., 'animal'-'dog').",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "58",
        "title": "Optimizing Singular Spectrum for Large Language Model Compression",
        "author": [
            "Dengjie Li",
            "Tiancheng Shen",
            "Yao Zhou",
            "Baisong Yang",
            "Zhongying Liu",
            "Masheng Yang",
            "Bernard Ghanem",
            "Yibo Yang",
            "Yujie Zhong",
            "Ming-Hsuan Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15092",
        "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities, yet prohibitive parameter complexity often hinders their deployment. Existing singular value decomposition (SVD) based compression methods simply deem singular values as importance scores of decomposed components. However, this importance ordered by singular values does not necessarily correlate with the performance of a downstream task. In this work, we introduce SoCo (Singular spectrum optimization for large language model Compression), a novel compression framework that learns to rescale the decomposed components of SVD in a data-driven manner. Concretely, we employ a learnable diagonal matrix to assign importance scores for singular spectrum and develop a three-stage training process that progressively refines these scores from initial coarse compression to fine-grained sparsification-thereby striking an effective balance between aggressive model compression and performance preservation. Thanks to the learnable singular spectrum, SoCo adaptively prunes components according to the sparsified importance scores, rather than relying on the fixed order of singular values. More importantly, the remaining components with amplified importance scores can compensate for the loss of the pruned ones. Experimental evaluations across multiple LLMs and benchmarks demonstrate that SoCo surpasses the state-of-the-art methods in model compression.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "59",
        "title": "Judging It, Washing It: Scoring and Greenwashing Corporate Climate Disclosures using Large Language Models",
        "author": [
            "Marianne Chuang",
            "Gabriel Chuang",
            "Cheryl Chuang",
            "John Chuang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15094",
        "abstract": "We study the use of large language models (LLMs) to both evaluate and greenwash corporate climate disclosures. First, we investigate the use of the LLM-as-a-Judge (LLMJ) methodology for scoring company-submitted reports on emissions reduction targets and progress. Second, we probe the behavior of an LLM when it is prompted to greenwash a response subject to accuracy and length constraints. Finally, we test the robustness of the LLMJ methodology against responses that may be greenwashed using an LLM. We find that two LLMJ scoring systems, numerical rating and pairwise comparison, are effective in distinguishing high-performing companies from others, with the pairwise comparison system showing greater robustness against LLM-greenwashed responses.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "60",
        "title": "Detecting Student Intent for Chat-Based Intelligent Tutoring Systems",
        "author": [
            "Ella Cutler",
            "Zachary Levonian",
            "S. Thomas Christie"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15096",
        "abstract": "Chat interfaces for intelligent tutoring systems (ITSs) enable interactivity and flexibility. However, when students interact with chat interfaces, they expect dialogue-driven navigation from the system and can express frustration and disinterest if this is not provided. Intent detection systems help students navigate within an ITS, but detecting students' intent during open-ended dialogue is challenging. We designed an intent detection system in a chatbot ITS, classifying a student's intent between continuing the current lesson or switching to a new lesson. We explore the utility of four machine learning approaches for this task - including both conventional classification approaches and fine-tuned large language models - finding that using an intent classifier introduces trade-offs around implementation cost, accuracy, and prediction time. We argue that implementing intent detection in chat interfaces can reduce frustration and support student learning.",
        "tags": [
            "Detection",
            "Large Language Models"
        ]
    },
    {
        "id": "61",
        "title": "LUME: LLM Unlearning with Multitask Evaluations",
        "author": [
            "Anil Ramakrishna",
            "Yixin Wan",
            "Xiaomeng Jin",
            "Kai-Wei Chang",
            "Zhiqi Bu",
            "Bhanukiran Vinzamuri",
            "Volkan Cevher",
            "Mingyi Hong",
            "Rahul Gupta"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15097",
        "abstract": "Unlearning aims to remove copyrighted, sensitive, or private content from large language models (LLMs) without a full retraining. In this work, we develop a multi-task unlearning benchmark (LUME) which features three tasks: (1) unlearn synthetically generated creative short novels, (2) unlearn synthetic biographies with sensitive information, and (3) unlearn a collection of public biographies. We further release two fine-tuned LLMs of 1B and 7B parameter sizes as the target models. We conduct detailed evaluations of several recently proposed unlearning algorithms and present results on carefully crafted metrics to understand their behavior and limitations.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "62",
        "title": "Leveraging ChatGPT for Sponsored Ad Detection and Keyword Extraction in YouTube Videos",
        "author": [
            "Brice Valentin Kok-Shun",
            "Johnny Chan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15102",
        "abstract": "This work-in-progress paper presents a novel approach to detecting sponsored advertisement segments in YouTube videos and comparing the advertisement with the main content. Our methodology involves the collection of 421 auto-generated and manual transcripts which are then fed into a prompt-engineered GPT-4o for ad detection, a KeyBERT for keyword extraction, and another iteration of ChatGPT for category identification. The results revealed a significant prevalence of product-related ads across various educational topics, with ad categories refined using GPT-4o into succinct 9 content and 4 advertisement categories. This approach provides a scalable and efficient alternative to traditional ad detection methods while offering new insights into the types and relevance of ads embedded within educational content. This study highlights the potential of LLMs in transforming ad detection processes and improving our understanding of advertisement strategies in digital media.",
        "tags": [
            "ChatGPT",
            "Detection",
            "GPT",
            "LLMs"
        ]
    },
    {
        "id": "63",
        "title": "Unveiling Reasoning Thresholds in Language Models: Scaling, Fine-Tuning, and Interpretability through Attention Maps",
        "author": [
            "Yen-Che Hsiao",
            "Abhishek Dutta"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15120",
        "abstract": "This study investigates the in-context learning capabilities of various decoder-only transformer-based language models with different model sizes and training data, including GPT2, SmolLM2, OpenELM, TinyLlama, Stable LM, and Gemma 2. We identify a critical parameter threshold (~1.6 billion), beyond which reasoning performance improves significantly in tasks such as commonsense reasoning in multiple-choice question answering and deductive reasoning. Specifically, models above this threshold achieve better success rates in chain-of-thought (CoT) prompting for deductive reasoning tasks, especially those requiring longer reasoning chains, such as proof by contradiction and disjunction elimination. To address limitations in sub-threshold models, we demonstrate that fine-tuning with task-specific exemplars substantially enhances reasoning performance, enabling accurate CoT generation even without additional exemplars in the prompt for tasks with shorter reasoning chains. Finally, our analysis of attention maps reveals that models capable of generating correct CoTs exhibit higher token-level attention scores on subsequent correct tokens and the correct parts of speech, providing interpretability insights into reasoning processes. These findings collectively advance understanding of reasoning capabilities in decoder-only transformer-based models. The code is available at: https://github.com/AnnonymousForPapers/CoT_Reasoning_Test.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "64",
        "title": "Curvature Corrected Nonnegative Manifold Data Factorization",
        "author": [
            "Joyce Chew",
            "Willem Diepeveen",
            "Deanna Needell"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15124",
        "abstract": "Data with underlying nonlinear structure are collected across numerous application domains, necessitating new data processing and analysis methods adapted to nonlinear domain structure. Riemannanian manifolds present a rich environment in which to develop such tools, as manifold-valued data arise in a variety of scientific settings, and Riemannian geometry provides a solid theoretical grounding for geometric data analysis. Low-rank approximations, such as nonnegative matrix factorization (NMF), are the foundation of many Euclidean data analysis methods, so adaptations of these factorizations for manifold-valued data are important building blocks for further development of manifold data analysis. In this work, we propose curvature corrected nonnegative manifold data factorization (CC-NMDF) as a geometry-aware method for extracting interpretable factors from manifold-valued data, analogous to nonnegative matrix factorization. We develop an efficient iterative algorithm for computing CC-NMDF and demonstrate our method on real-world diffusion tensor magnetic resonance imaging data.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "65",
        "title": "DAM-Seg: Anatomically accurate cardiac segmentation using Dense Associative Networks",
        "author": [
            "Zahid Ullah",
            "Jihie Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15128",
        "abstract": "Deep learning-based cardiac segmentation has seen significant advancements over the years. Many studies have tackled the challenge of anatomically incorrect segmentation predictions by introducing auxiliary modules. These modules either post-process segmentation outputs or enforce consistency between specific points to ensure anatomical correctness. However, such approaches often increase network complexity, require separate training for these modules, and may lack robustness in scenarios with poor visibility. To address these limitations, we propose a novel transformer-based architecture that leverages dense associative networks to learn and retain specific patterns inherent to cardiac inputs. Unlike traditional methods, our approach restricts the network to memorize a limited set of patterns. During forward propagation, a weighted sum of these patterns is used to enforce anatomical correctness in the output. Since these patterns are input-independent, the model demonstrates enhanced robustness, even in cases with poor visibility. The proposed pipeline was evaluated on two publicly available datasets, CAMUS and CardiacNet. Experimental results indicate that our model consistently outperforms baseline approaches across all metrics, highlighting its effectiveness and reliability for cardiac segmentation tasks.",
        "tags": [
            "Segmentation",
            "Transformer"
        ]
    },
    {
        "id": "66",
        "title": "TransMamba: Fast Universal Architecture Adaption from Transformers to Mamba",
        "author": [
            "Xiuwei Chen",
            "Sihao Lin",
            "Xiao Dong",
            "Zisheng Chen",
            "Meng Cao",
            "Jianhua Han",
            "Hang Xu",
            "Xiaodan Liang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15130",
        "abstract": "Transformers have been favored in both uni-modal and multi-modal foundation models for their flexible scalability in attention modules. Consequently, a number of pre-trained Transformer models, e.g., LLaVA, CLIP, and DEIT, are publicly available. Recent research has introduced subquadratic architectures like Mamba, which enables global awareness with linear complexity. Nevertheless, training specialized subquadratic architectures from scratch for certain tasks is both resource-intensive and time-consuming. As a motivator, we explore cross-architecture training to transfer the ready knowledge in existing Transformer models to alternative architecture Mamba, termed TransMamba. Our approach employs a two-stage strategy to expedite training new Mamba models, ensuring effectiveness in across uni-modal and cross-modal tasks. Concerning architecture disparities, we project the intermediate features into an aligned latent space before transferring knowledge. On top of that, a Weight Subcloning and Adaptive Bidirectional distillation method (WSAB) is introduced for knowledge transfer without limitations on varying layer counts. For cross-modal learning, we propose a cross-Mamba module that integrates language awareness into Mamba's visual features, enhancing the cross-modal interaction capabilities of Mamba architecture. Despite using less than 75% of the training data typically required for training from scratch, TransMamba boasts substantially stronger performance across various network architectures and downstream tasks, including image classification, visual question answering, and text-video retrieval. The code will be publicly available.",
        "tags": [
            "CLIP",
            "LLaVA",
            "Mamba",
            "Transformer"
        ]
    },
    {
        "id": "67",
        "title": "CoT-ICL Lab: A Petri Dish for Studying Chain-of-Thought Learning from In-Context Demonstrations",
        "author": [
            "Vignesh Kothapalli",
            "Hamed Firooz",
            "Maziar Sanjabi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15132",
        "abstract": "We introduce CoT-ICL Lab, a framework and methodology to generate synthetic tokenized datasets and systematically study chain-of-thought (CoT) in-context learning (ICL) in language models. CoT-ICL Lab allows fine grained control over the complexity of in-context examples by decoupling (1) the causal structure involved in chain token generation from (2) the underlying token processing functions. We train decoder-only transformers (up to 700M parameters) on these datasets and show that CoT accelerates the accuracy transition to higher values across model sizes. In particular, we find that model depth is crucial for leveraging CoT with limited in-context examples, while more examples help shallow models match deeper model performance. Additionally, limiting the diversity of token processing functions throughout training improves causal structure learning via ICL. We also interpret these transitions by analyzing transformer embeddings and attention maps. Overall, CoT-ICL Lab serves as a simple yet powerful testbed for theoretical and empirical insights into ICL and CoT in language models.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "68",
        "title": "Chain-of-Rank: Enhancing Large Language Models for Domain-Specific RAG in Edge Device",
        "author": [
            "Juntae Lee",
            "Jihwan Bang",
            "Seunghan Yang",
            "Kyuhong Shim",
            "Simyung Chang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15134",
        "abstract": "Retrieval-augmented generation (RAG) with large language models (LLMs) is especially valuable in specialized domains, where precision is critical. To more specialize the LLMs into a target domain, domain-specific RAG has recently been developed by allowing the LLM to access the target domain early via finetuning. The domain-specific RAG makes more sense in resource-constrained environments like edge devices, as they should perform a specific task (e.g. personalization) reliably using only small-scale LLMs. While the domain-specific RAG is well-aligned with edge devices in this respect, it often relies on widely-used reasoning techniques like chain-of-thought (CoT). The reasoning step is useful to understand the given external knowledge, and yet it is computationally expensive and difficult for small-scale LLMs to learn it. Tackling this, we propose the Chain of Rank (CoR) which shifts the focus from intricate lengthy reasoning to simple ranking of the reliability of input external documents. Then, CoR reduces computational complexity while maintaining high accuracy, making it particularly suited for resource-constrained environments. We attain the state-of-the-art (SOTA) results in benchmarks, and analyze its efficacy.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "69",
        "title": "Do LLMs Make Mistakes Like Students? Exploring Natural Alignment between Language Models and Human Error Patterns",
        "author": [
            "Naiming Liu",
            "Shashank Sonkar",
            "Richard G. Baraniuk"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15140",
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in various educational tasks, yet their alignment with human learning patterns, particularly in predicting which incorrect options students are most likely to select in multiple-choice questions (MCQs), remains underexplored. Our work investigates the relationship between LLM generation likelihood and student response distributions in MCQs with a specific focus on distractor selections. We collect a comprehensive dataset of MCQs with real-world student response distributions to explore two fundamental research questions: (1). RQ1 - Do the distractors that students more frequently select correspond to those that LLMs assign higher generation likelihood to? (2). RQ2 - When an LLM selects a incorrect choice, does it choose the same distractor that most students pick? Our experiments reveals moderate correlations between LLM-assigned probabilities and student selection patterns for distractors in MCQs. Additionally, when LLMs make mistakes, they are more likley to select the same incorrect answers that commonly mislead students, which is a pattern consistent across both small and large language models. Our work provides empirical evidence that despite LLMs' strong performance on generating educational content, there remains a gap between LLM's underlying reasoning process and human cognitive processes in identifying confusing distractors. Our findings also have significant implications for educational assessment development. The smaller language models could be efficiently utilized for automated distractor generation as they demonstrate similar patterns in identifying confusing answer choices as larger language models. This observed alignment between LLMs and student misconception patterns opens new opportunities for generating high-quality distractors that complement traditional human-designed distractors.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "70",
        "title": "Investigating the Adaptive Robustness with Knowledge Conflicts in LLM-based Multi-Agent Systems",
        "author": [
            "Tianjie Ju",
            "Bowen Wang",
            "Hao Fei",
            "Mong-Li Lee",
            "Wynne Hsu",
            "Yun Li",
            "Qianren Wang",
            "Pengzhou Cheng",
            "Zongru Wu",
            "Zhuosheng Zhang",
            "Gongshen Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15153",
        "abstract": "Recent advances in Large Language Models (LLMs) have upgraded them from sophisticated text generators to autonomous agents capable of corporation and tool use in multi-agent systems (MASs). However, the robustness of these LLM-based MASs, especially under knowledge conflicts, remains unclear. In this paper, we design four comprehensive metrics to investigate the robustness of MASs when facing mild or task-critical knowledge conflicts. We first analyze mild knowledge conflicts introduced by heterogeneous agents and find that they do not harm system robustness but instead improve collaborative decision-making. Next, we investigate task-critical knowledge conflicts by synthesizing knowledge conflicts and embedding them into one of the agents. Our results show that these conflicts have surprisingly little to no impact on MAS robustness. Furthermore, we observe that MASs demonstrate certain self-repairing capabilities by reducing their reliance on knowledge conflicts and adopting alternative solution paths to maintain stability. Finally, we conduct ablation studies on the knowledge conflict number, agent number, and interaction rounds, finding that the self-repairing capability of MASs has intrinsic limits, and all findings hold consistently across various factors. Our code is publicly available at https://github.com/wbw625/MultiAgentRobustness.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "71",
        "title": "Extreme Speech Classification in the Era of LLMs: Exploring Open-Source and Proprietary Models",
        "author": [
            "Sarthak Mahajan",
            "Nimmi Rangaswamy"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15155",
        "abstract": "In recent years, widespread internet adoption and the growth in userbase of various social media platforms have led to an increase in the proliferation of extreme speech online. While traditional language models have demonstrated proficiency in distinguishing between neutral text and non-neutral text (i.e. extreme speech), categorizing the diverse types of extreme speech presents significant challenges. The task of extreme speech classification is particularly nuanced, as it requires a deep understanding of socio-cultural contexts to accurately interpret the intent of the language used by the speaker. Even human annotators often disagree on the appropriate classification of such content, emphasizing the complex and subjective nature of this task. The use of human moderators also presents a scaling issue, necessitating the need for automated systems for extreme speech classification. The recent launch of ChatGPT has drawn global attention to the potential applications of Large Language Models (LLMs) across a diverse variety of tasks. Trained on vast and diverse corpora, and demonstrating the ability to effectively capture and encode contextual information, LLMs emerge as highly promising tools for tackling this specific task of extreme speech classification. In this paper, we leverage the Indian subset of the extreme speech dataset from Maronikolakis et al. (2022) to develop an effective classification framework using LLMs. We evaluate open-source Llama models against closed-source OpenAI models, finding that while pre-trained LLMs show moderate efficacy, fine-tuning with domain-specific data significantly enhances performance, highlighting their adaptability to linguistic and contextual nuances. Although GPT-based models outperform Llama models in zero-shot settings, the performance gap disappears after fine-tuning.",
        "tags": [
            "ChatGPT",
            "GPT",
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "72",
        "title": "M3-AGIQA: Multimodal, Multi-Round, Multi-Aspect AI-Generated Image Quality Assessment",
        "author": [
            "Chuan Cui",
            "Kejiang Chen",
            "Zhihua Wei",
            "Wen Shen",
            "Weiming Zhang",
            "Nenghai Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15167",
        "abstract": "The rapid advancement of AI-generated image (AGI) models has introduced significant challenges in evaluating their quality, which requires considering multiple dimensions such as perceptual quality, prompt correspondence, and authenticity. To address these challenges, we propose M3-AGIQA, a comprehensive framework for AGI quality assessment that is Multimodal, Multi-Round, and Multi-Aspect. Our approach leverages the capabilities of Multimodal Large Language Models (MLLMs) as joint text and image encoders and distills advanced captioning capabilities from online MLLMs into a local model via Low-Rank Adaptation (LoRA) fine-tuning. The framework includes a structured multi-round evaluation mechanism, where intermediate image descriptions are generated to provide deeper insights into the quality, correspondence, and authenticity aspects. To align predictions with human perceptual judgments, a predictor constructed by an xLSTM and a regression head is incorporated to process sequential logits and predict Mean Opinion Scores (MOSs). Extensive experiments conducted on multiple benchmark datasets demonstrate that M3-AGIQA achieves state-of-the-art performance, effectively capturing nuanced aspects of AGI quality. Furthermore, cross-dataset validation confirms its strong generalizability. The code is available at https://github.com/strawhatboy/M3-AGIQA.",
        "tags": [
            "Large Language Models",
            "LoRA",
            "Low-Rank Adaptation"
        ]
    },
    {
        "id": "73",
        "title": "mStyleDistance: Multilingual Style Embeddings and their Evaluation",
        "author": [
            "Justin Qiu",
            "Jiacheng Zhu",
            "Ajay Patel",
            "Marianna Apidianaki",
            "Chris Callison-Burch"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15168",
        "abstract": "Style embeddings are useful for stylistic analysis and style transfer; however, only English style embeddings have been made available. We introduce Multilingual StyleDistance (mStyleDistance), a multilingual style embedding model trained using synthetic data and contrastive learning. We train the model on data from nine languages and create a multilingual STEL-or-Content benchmark (Wegmann et al., 2022) that serves to assess the embeddings' quality. We also employ our embeddings in an authorship verification task involving different languages. Our results show that mStyleDistance embeddings outperform existing models on these multilingual style benchmarks and generalize well to unseen features and languages. We make our model publicly available at https://huggingface.co/StyleDistance/mstyledistance .",
        "tags": [
            "Style Transfer"
        ]
    },
    {
        "id": "74",
        "title": "Hierarchical Context Transformer for Multi-level Semantic Scene Understanding",
        "author": [
            "Luoying Hao",
            "Yan Hu",
            "Yang Yue",
            "Li Wu",
            "Huazhu Fu",
            "Jinming Duan",
            "Jiang Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15184",
        "abstract": "A comprehensive and explicit understanding of surgical scenes plays a vital role in developing context-aware computer-assisted systems in the operating theatre. However, few works provide systematical analysis to enable hierarchical surgical scene understanding. In this work, we propose to represent the tasks set [phase recognition --> step recognition --> action and instrument detection] as multi-level semantic scene understanding (MSSU). For this target, we propose a novel hierarchical context transformer (HCT) network and thoroughly explore the relations across the different level tasks. Specifically, a hierarchical relation aggregation module (HRAM) is designed to concurrently relate entries inside multi-level interaction information and then augment task-specific features. To further boost the representation learning of the different tasks, inter-task contrastive learning (ICL) is presented to guide the model to learn task-wise features via absorbing complementary information from other tasks. Furthermore, considering the computational costs of the transformer, we propose HCT+ to integrate the spatial and temporal adapter to access competitive performance on substantially fewer tunable parameters. Extensive experiments on our cataract dataset and a publicly available endoscopic PSI-AVA dataset demonstrate the outstanding performance of our method, consistently exceeding the state-of-the-art methods by a large margin. The code is available at https://github.com/Aurora-hao/HCT.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "75",
        "title": "TETRIS: Optimal Draft Token Selection for Batch Speculative Decoding",
        "author": [
            "Zhaoxuan Wu",
            "Zijian Zhou",
            "Arun Verma",
            "Alok Prakash",
            "Daniela Rus",
            "Bryan Kian Hsiang Low"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15197",
        "abstract": "We propose TETRIS, a novel method that optimizes the total throughput of batch speculative decoding in multi-request settings. Unlike existing methods that optimize for a single request or a group of requests as a whole, TETRIS actively selects the most promising draft tokens (for every request in a batch) to be accepted when verified in parallel, resulting in fewer rejected tokens and hence less wasted computing resources. Such an effective resource utilization to achieve fast inference in large language models (LLMs) is especially important to service providers with limited inference capacity. Compared to baseline speculative decoding, TETRIS yields a consistently higher acceptance rate and more effective utilization of the limited inference capacity. We show theoretically and empirically that TETRIS outperforms baseline speculative decoding and existing methods that dynamically select draft tokens, leading to a more efficient batch inference in LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "76",
        "title": "GNN-Coder: Boosting Semantic Code Retrieval with Combined GNNs and Transformer",
        "author": [
            "Yufan Ye",
            "Pu Pang",
            "Ting Zhang",
            "Hua Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15202",
        "abstract": "Code retrieval is a crucial component in modern software development, particularly in large-scale projects. However, existing approaches relying on sequence-based models often fail to fully exploit the structural dependencies inherent in code, leading to suboptimal retrieval performance, particularly with structurally complex code fragments. In this paper, we introduce GNN-Coder, a novel framework based on Graph Neural Network (GNN) to utilize Abstract Syntax Tree (AST). We make the first attempt to study how GNN-integrated Transformer can promote the development of semantic retrieval tasks by capturing the structural and semantic features of code. We further propose an innovative graph pooling method tailored for AST, utilizing the number of child nodes as a key feature to highlight the intrinsic topological relationships within the AST. This design effectively integrates both sequential and hierarchical representations, enhancing the model's ability to capture code structure and semantics. Additionally, we introduce the Mean Angular Margin (MAM), a novel metric for quantifying the uniformity of code embedding distributions, providing a standardized measure of feature separability. The proposed method achieves a lower MAM, indicating a more discriminative feature representation. This underscores GNN-Coder's superior ability to distinguish between code snippets, thereby enhancing retrieval accuracy. Experimental results show that GNN-Coder significantly boosts retrieval performance, with a 1\\%-10\\% improvement in MRR on the CSN dataset, and a notable 20\\% gain in zero-shot performance on the CosQA dataset.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "77",
        "title": "FlipConcept: Tuning-Free Multi-Concept Personalization for Text-to-Image Generation",
        "author": [
            "Young Beom Woo",
            "Sun Eung Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15203",
        "abstract": "Recently, methods that integrate multiple personalized concepts into a single image have garnered significant attention in the field of text-to-image (T2I) generation. However, existing methods experience performance degradation in complex scenes with multiple objects due to distortions in non-personalized regions. To address this issue, we propose FlipConcept, a novel approach that seamlessly integrates multiple personalized concepts into a single image without requiring additional tuning. We introduce guided appearance attention to accurately mimic the appearance of a personalized concept as intended. Additionally, we introduce mask-guided noise mixing to protect non-personalized regions during editing. Lastly, we apply background dilution to minimize attribute leakage, which is the undesired blending of personalized concept attributes with other objects in the image. In our experiments, we demonstrate that the proposed method, despite not requiring tuning, outperforms existing models in both single and multiple personalized concept inference.",
        "tags": [
            "Text-to-Image"
        ]
    },
    {
        "id": "78",
        "title": "Unveiling Attractor Cycles in Large Language Models: A Dynamical Systems View of Successive Paraphrasing",
        "author": [
            "Zhilin Wang",
            "Yafu Li",
            "Jianhao Yan",
            "Yu Cheng",
            "Yue Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15208",
        "abstract": "Dynamical systems theory provides a framework for analyzing iterative processes and evolution over time. Within such systems, repetitive transformations can lead to stable configurations, known as attractors, including fixed points and limit cycles. Applying this perspective to large language models (LLMs), which iteratively map input text to output text, provides a principled approach to characterizing long-term behaviors. Successive paraphrasing serves as a compelling testbed for exploring such dynamics, as paraphrases re-express the same underlying meaning with linguistic variation. Although LLMs are expected to explore a diverse set of paraphrases in the text space, our study reveals that successive paraphrasing converges to stable periodic states, such as 2-period attractor cycles, limiting linguistic diversity. This phenomenon is attributed to the self-reinforcing nature of LLMs, as they iteratively favour and amplify certain textual forms over others. This pattern persists with increasing generation randomness or alternating prompts and LLMs. These findings underscore inherent constraints in LLM generative capability, while offering a novel dynamical systems perspective for studying their expressive potential.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "79",
        "title": "The Evolving Landscape of LLM- and VLM-Integrated Reinforcement Learning",
        "author": [
            "Sheila Schoepp",
            "Masoud Jafaripour",
            "Yingyue Cao",
            "Tianpei Yang",
            "Fatemeh Abdollahi",
            "Shadan Golestan",
            "Zahin Sufiyan",
            "Osmar R. Zaiane",
            "Matthew E. Taylor"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15214",
        "abstract": "Reinforcement learning (RL) has shown impressive results in sequential decision-making tasks. Meanwhile, Large Language Models (LLMs) and Vision-Language Models (VLMs) have emerged, exhibiting impressive capabilities in multimodal understanding and reasoning. These advances have led to a surge of research integrating LLMs and VLMs into RL. In this survey, we review representative works in which LLMs and VLMs are used to overcome key challenges in RL, such as lack of prior knowledge, long-horizon planning, and reward design. We present a taxonomy that categorizes these LLM/VLM-assisted RL approaches into three roles: agent, planner, and reward. We conclude by exploring open problems, including grounding, bias mitigation, improved representations, and action advice. By consolidating existing research and identifying future directions, this survey establishes a framework for integrating LLMs and VLMs into RL, advancing approaches that unify natural language and visual understanding with sequential decision-making.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RL"
        ]
    },
    {
        "id": "80",
        "title": "FormalSpecCpp: A Dataset of C++ Formal Specifications created using LLMs",
        "author": [
            "Madhurima Chakraborty",
            "Peter Pirkelbauer",
            "Qing Yi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15217",
        "abstract": "FormalSpecCpp is a dataset designed to fill the gap in standardized benchmarks for verifying formal specifications in C++ programs. To the best of our knowledge, this is the first comprehensive collection of C++ programs with well-defined preconditions and postconditions. It provides a structured benchmark for evaluating specification inference tools and testing theaccuracy of generated specifications. Researchers and developers can use this dataset to benchmark specification inference tools,fine-tune Large Language Models (LLMs) for automated specification generation, and analyze the role of formal specifications in improving program verification and automated testing. By making this dataset publicly available, we aim to advance research in program verification, specification inference, and AI-assisted software development. The dataset and the code are available at https://github.com/MadhuNimmo/FormalSpecCpp.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "81",
        "title": "Auto-Bench: An Automated Benchmark for Scientific Discovery in LLMs",
        "author": [
            "Tingting Chen",
            "Srinivas Anumasa",
            "Beibei Lin",
            "Vedant Shah",
            "Anirudh Goyal",
            "Dianbo Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15224",
        "abstract": "Given the remarkable performance of Large Language Models (LLMs), an important question arises: Can LLMs conduct human-like scientific research and discover new knowledge, and act as an AI scientist? Scientific discovery is an iterative process that demands efficient knowledge updating and encoding. It involves understanding the environment, identifying new hypotheses, and reasoning about actions; however, no standardized benchmark specifically designed for scientific discovery exists for LLM agents. In response to these limitations, we introduce a novel benchmark, \\textit{Auto-Bench}, that encompasses necessary aspects to evaluate LLMs for scientific discovery in both natural and social sciences. Our benchmark is based on the principles of causal graph discovery. It challenges models to uncover hidden structures and make optimal decisions, which includes generating valid justifications. By engaging interactively with an oracle, the models iteratively refine their understanding of underlying interactions, the chemistry and social interactions, through strategic interventions. We evaluate state-of-the-art LLMs, including GPT-4, Gemini, Qwen, Claude, and Llama, and observe a significant performance drop as the problem complexity increases, which suggests an important gap between machine and human intelligence that future development of LLMs need to take into consideration.",
        "tags": [
            "GPT",
            "LLMs",
            "LLaMA",
            "Large Language Models",
            "Qwen"
        ]
    },
    {
        "id": "82",
        "title": "Understand User Opinions of Large Language Models via LLM-Powered In-the-Moment User Experience Interviews",
        "author": [
            "Mengqiao Liu",
            "Tevin Wang",
            "Cassandra A. Cohen",
            "Sarah Li",
            "Chenyan Xiong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15226",
        "abstract": "Which large language model (LLM) is better? Every evaluation tells a story, but what do users really think about current LLMs? This paper presents CLUE, an LLM-powered interviewer that conducts in-the-moment user experience interviews, right after users interacted with LLMs, and automatically gathers insights about user opinions from massive interview logs. We conduct a study with thousands of users to understand user opinions on mainstream LLMs, recruiting users to first chat with a target LLM and then interviewed by CLUE. Our experiments demonstrate that CLUE captures interesting user opinions, for example, the bipolar views on the displayed reasoning process of DeepSeek-R1 and demands for information freshness and multi-modality. Our collected chat-and-interview logs will be released.",
        "tags": [
            "DeepSeek",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "83",
        "title": "A General Pseudonymization Framework for Cloud-Based LLMs: Replacing Privacy Information in Controlled Text Generation",
        "author": [
            "Shilong Hou",
            "Ruilin Shang",
            "Zi Long",
            "Xianghua Fu",
            "Yin Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15233",
        "abstract": "An increasing number of companies have begun providing services that leverage cloud-based large language models (LLMs), such as ChatGPT. However, this development raises substantial privacy concerns, as users' prompts are transmitted to and processed by the model providers. Among the various privacy protection methods for LLMs, those implemented during the pre-training and fine-tuning phrases fail to mitigate the privacy risks associated with the remote use of cloud-based LLMs by users. On the other hand, methods applied during the inference phrase are primarily effective in scenarios where the LLM's inference does not rely on privacy-sensitive information. In this paper, we outline the process of remote user interaction with LLMs and, for the first time, propose a detailed definition of a general pseudonymization framework applicable to cloud-based LLMs. The experimental results demonstrate that the proposed framework strikes an optimal balance between privacy protection and utility. The code for our method is available to the public at https://github.com/Mebymeby/Pseudonymization-Framework.",
        "tags": [
            "ChatGPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "84",
        "title": "From Documents to Dialogue: Building KG-RAG Enhanced AI Assistants",
        "author": [
            "Manisha Mukherjee",
            "Sungchul Kim",
            "Xiang Chen",
            "Dan Luo",
            "Tong Yu",
            "Tung Mai"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15237",
        "abstract": "The Adobe Experience Platform AI Assistant is a conversational tool that enables organizations to interact seamlessly with proprietary enterprise data through a chatbot. However, due to access restrictions, Large Language Models (LLMs) cannot retrieve these internal documents, limiting their ability to generate accurate zero-shot responses. To overcome this limitation, we use a Retrieval-Augmented Generation (RAG) framework powered by a Knowledge Graph (KG) to retrieve relevant information from external knowledge sources, enabling LLMs to answer questions over private or previously unseen document collections. In this paper, we propose a novel approach for building a high-quality, low-noise KG. We apply several techniques, including incremental entity resolution using seed concepts, similarity-based filtering to deduplicate entries, assigning confidence scores to entity-relation pairs to filter for high-confidence pairs, and linking facts to source documents for provenance. Our KG-RAG system retrieves relevant tuples, which are added to the user prompts context before being sent to the LLM generating the response. Our evaluation demonstrates that this approach significantly enhances response relevance, reducing irrelevant answers by over 50% and increasing fully relevant answers by 88% compared to the existing production system.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "85",
        "title": "Comparative Analysis of Large Language Models for Context-Aware Code Completion using SAFIM Framework",
        "author": [
            "Hang Zhang",
            "Yanxin Shen",
            "Lun Wang",
            "Chuanqi Shi",
            "Shaoshuai Du",
            "Yiyi Tao",
            "Yixian Shen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15243",
        "abstract": "The advent of Large Language Models (LLMs) has revolutionized code completion, transforming it into a more intelligent and context-aware feature in modern integrated development environments. These advancements have significantly enhanced developers' ability to write efficient and error-free code. This study evaluates the performance of several chat-based LLMs, including Gemini 1.5 Flash, Gemini 1.5 Pro, GPT-4o, GPT-4o-mini, and GPT-4 Turbo, using the Syntax-Aware Fill-in-the-Middle (SAFIM) dataset. This benchmark is specifically designed to assess models' capabilities in syntax-sensitive code generation. Performance metrics, such as cosine similarity with ground-truth completions and latency, were employed to measure both accuracy and efficiency. The findings reveal substantial differences in the models' code completion abilities, offering valuable insights into their respective strengths and weaknesses. This work provides a comparative analysis that underscores the trade-offs between accuracy and speed, establishing a benchmark for future advancements in LLM-based code completion.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "86",
        "title": "An approach for API synthesis using large language models",
        "author": [
            "Hua Zhong",
            "Shan Jiang",
            "Sarfraz Khurshid"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15246",
        "abstract": "APIs play a pivotal role in modern software development by enabling seamless communication and integration between various systems, applications, and services. Component-based API synthesis is a form of program synthesis that constructs an API by assembling predefined components from a library. Existing API synthesis techniques typically implement dedicated search strategies over bounded spaces of possible implementations, which can be very large and time consuming to explore. In this paper, we present a novel approach of using large language models (LLMs) in API synthesis. LLMs offer a foundational technology to capture developer insights and provide an ideal framework for enabling more effective API synthesis. We perform an experimental evaluation of our approach using 135 real-world programming tasks, and compare it with FrAngel, a state-of-the-art API synthesis tool. The experimental results show that our approach completes 133 of the tasks, and overall outperforms FrAngel. We believe LLMs provide a very useful foundation for tackling the problem of API synthesis, in particular, and program synthesis, in general.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "87",
        "title": "LightMamba: Efficient Mamba Acceleration on FPGA with Quantization and Hardware Co-design",
        "author": [
            "Renjie Wei",
            "Songqiang Xu",
            "Linfeng Zhong",
            "Zebin Yang",
            "Qingyu Guo",
            "Yuan Wang",
            "Runsheng Wang",
            "Meng Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15260",
        "abstract": "State space models (SSMs) like Mamba have recently attracted much attention. Compared to Transformer-based large language models (LLMs), Mamba achieves linear computation complexity with the sequence length and demonstrates superior performance. However, Mamba is hard to accelerate due to the scattered activation outliers and the complex computation dependency, rendering existing LLM accelerators inefficient. In this paper, we propose LightMamba that co-designs the quantization algorithm and FPGA accelerator architecture for efficient Mamba inference. We first propose an FPGA-friendly post-training quantization algorithm that features rotation-assisted quantization and power-of-two SSM quantization to reduce the majority of computation to 4-bit. We further design an FPGA accelerator that partially unrolls the Mamba computation to balance the efficiency and hardware costs. Through computation reordering as well as fine-grained tiling and fusion, the hardware utilization and memory efficiency of the accelerator get drastically improved. We implement LightMamba on Xilinx Versal VCK190 FPGA and achieve 4.65x to 6.06x higher energy efficiency over the GPU baseline. When evaluated on Alveo U280 FPGA, LightMamba reaches 93 tokens/s, which is 1.43x that of the GPU baseline.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Mamba",
            "SSMs",
            "State Space Models",
            "Transformer"
        ]
    },
    {
        "id": "88",
        "title": "Retrieval-Augmented Speech Recognition Approach for Domain Challenges",
        "author": [
            "Peng Shen",
            "Xugang Lu",
            "Hisashi Kawai"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15264",
        "abstract": "Speech recognition systems often face challenges due to domain mismatch, particularly in real-world applications where domain-specific data is unavailable because of data accessibility and confidentiality constraints. Inspired by Retrieval-Augmented Generation (RAG) techniques for large language models (LLMs), this paper introduces a LLM-based retrieval-augmented speech recognition method that incorporates domain-specific textual data at the inference stage to enhance recognition performance. Rather than relying on domain-specific textual data during the training phase, our model is trained to learn how to utilize textual information provided in prompts for LLM decoder to improve speech recognition performance. Benefiting from the advantages of the RAG retrieval mechanism, our approach efficiently accesses locally available domain-specific documents, ensuring a convenient and effective process for solving domain mismatch problems. Experiments conducted on the CSJ database demonstrate that the proposed method significantly improves speech recognition accuracy and achieves state-of-the-art results on the CSJ dataset, even without relying on the full training data.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "89",
        "title": "Analyzing the Inner Workings of Transformers in Compositional Generalization",
        "author": [
            "Ryoma Kumon",
            "Hitomi Yanaka"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15277",
        "abstract": "The compositional generalization abilities of neural models have been sought after for human-like linguistic competence. The popular method to evaluate such abilities is to assess the models' input-output behavior. However, that does not reveal the internal mechanisms, and the underlying competence of such models in compositional generalization remains unclear. To address this problem, we explore the inner workings of a Transformer model by finding an existing subnetwork that contributes to the generalization performance and by performing causal analyses on how the model utilizes syntactic features. We find that the model depends on syntactic features to output the correct answer, but that the subnetwork with much better generalization performance than the whole model relies on a non-compositional algorithm in addition to the syntactic features. We also show that the subnetwork improves its generalization performance relatively slowly during the training compared to the in-distribution one, and the non-compositional solution is acquired in the early stages of the training.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "90",
        "title": "CopyJudge: Automated Copyright Infringement Identification and Mitigation in Text-to-Image Diffusion Models",
        "author": [
            "Shunchang Liu",
            "Zhuan Shi",
            "Lingjuan Lyu",
            "Yaochu Jin",
            "Boi Faltings"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15278",
        "abstract": "Assessing whether AI-generated images are substantially similar to copyrighted works is a crucial step in resolving copyright disputes. In this paper, we propose CopyJudge, an automated copyright infringement identification framework that leverages large vision-language models (LVLMs) to simulate practical court processes for determining substantial similarity between copyrighted images and those generated by text-to-image diffusion models. Specifically, we employ an abstraction-filtration-comparison test framework with multi-LVLM debate to assess the likelihood of infringement and provide detailed judgment rationales. Based on the judgments, we further introduce a general LVLM-based mitigation strategy that automatically optimizes infringing prompts by avoiding sensitive expressions while preserving the non-infringing content. Besides, our approach can be enhanced by exploring non-infringing noise vectors within the diffusion latent space via reinforcement learning, even without modifying the original prompts. Experimental results show that our identification method achieves comparable state-of-the-art performance, while offering superior generalization and interpretability across various forms of infringement, and that our mitigation method could more effectively mitigate memorization and IP infringement without losing non-infringing expressions.",
        "tags": [
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "91",
        "title": "BundleFlow: Deep Menus for Combinatorial Auctions by Diffusion-Based Optimization",
        "author": [
            "Tonghan Wang",
            "Yanchen Jiang",
            "David C. Parkes"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15283",
        "abstract": "Differentiable economics -- the use of deep learning for auction design -- has driven progress in the automated design of multi-item auctions with additive or unit-demand valuations. However, little progress has been made for optimal combinatorial auctions (CAs), even for the single bidder case, because we need to overcome the challenge of the bundle space growing exponentially with the number of items. For example, when learning a menu of allocation-price choices for a bidder in a CA, each menu element needs to efficiently and flexibly specify a probability distribution on bundles. In this paper, we solve this problem in the single-bidder CA setting by generating a bundle distribution through an ordinary differential equation (ODE) applied to a tractable initial distribution, drawing inspiration from generative models, especially score-based diffusion models and continuous normalizing flow. Our method, BundleFlow, uses deep learning to find suitable ODE-based transforms of initial distributions, one transform for each menu element, so that the overall menu achieves high expected revenue. Our method achieves 1.11$-$2.23$\\times$ higher revenue compared with automated mechanism design baselines on the single-bidder version of CATS, a standard CA testbed, and scales to problems with up to 150 items. Relative to a baseline that also learns allocations in menu elements, our method reduces the training iterations by 3.6$-$9.5$\\times$ and cuts training time by about 80% in settings with 50 and 100 items.",
        "tags": [
            "Diffusion",
            "ODE"
        ]
    },
    {
        "id": "92",
        "title": "Soybean pod and seed counting in both outdoor fields and indoor laboratories using unions of deep neural networks",
        "author": [
            "Tianyou Jiang",
            "Mingshun Shao",
            "Tianyi Zhang",
            "Xiaoyu Liu",
            "Qun Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15286",
        "abstract": "Automatic counting soybean pods and seeds in outdoor fields allows for rapid yield estimation before harvesting, while indoor laboratory counting offers greater accuracy. Both methods can significantly accelerate the breeding process. However, it remains challenging for accurately counting pods and seeds in outdoor fields, and there are still no accurate enough tools for counting pods and seeds in laboratories. In this study, we developed efficient deep learning models for counting soybean pods and seeds in both outdoor fields and indoor laboratories. For outdoor fields, annotating not only visible seeds but also occluded seeds makes YOLO have the ability to estimate the number of soybean seeds that are occluded. Moreover, we enhanced YOLO architecture by integrating it with HQ-SAM (YOLO-SAM), and domain adaptation techniques (YOLO-DA), to improve model robustness and generalization across soybean images taken in outdoor fields. Testing on soybean images from the outdoor field, we achieved a mean absolute error (MAE) of 6.13 for pod counting and 10.05 for seed counting. For the indoor setting, we utilized Mask-RCNN supplemented with a Swin Transformer module (Mask-RCNN-Swin), models were trained exclusively on synthetic training images generated from a small set of labeled data. This approach resulted in near-perfect accuracy, with an MAE of 1.07 for pod counting and 1.33 for seed counting across actual laboratory images from two distinct studies.",
        "tags": [
            "SAM",
            "Transformer"
        ]
    },
    {
        "id": "93",
        "title": "Bridging Bug Localization and Issue Fixing: A Hierarchical Localization Framework Leveraging Large Language Models",
        "author": [
            "Jianming Chang",
            "Xin Zhou",
            "Lulu Wang",
            "David Lo",
            "Bixin Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15292",
        "abstract": "Automated issue fixing is a critical task in software debugging and has recently garnered significant attention from academia and industry. However, existing fixing techniques predominantly focus on the repair phase, often overlooking the importance of improving the preceding bug localization phase. As a foundational step in issue fixing, bug localization plays a pivotal role in determining the overall effectiveness of the entire process.\nTo enhance the precision of issue fixing by accurately identifying bug locations in large-scale projects, this paper presents BugCerberus, the first hierarchical bug localization framework powered by three customized large language models. First, BugCerberus analyzes intermediate representations of bug-related programs at file, function, and statement levels and extracts bug-related contextual information from the representations. Second, BugCerberus designs three customized LLMs at each level using bug reports and contexts to learn the patterns of bugs. Finally, BugCerberus hierarchically searches for bug-related code elements through well-tuned models to localize bugs at three levels. With BugCerberus, we further investigate the impact of bug localization on the issue fixing.\nWe evaluate BugCerberus on the widely-used benchmark SWE-bench-lite. The experimental results demonstrate that BugCerberus outperforms all baselines. Specifically, at the fine-grained statement level, BugCerberus surpasses the state-of-the-art in Top-N (N=1, 3, 5, 10) by 16.5%, 5.4%, 10.2%, and 23.1%, respectively. Moreover, in the issue fixing experiments, BugCerberus improves the fix rate of the existing issue fixing approach Agentless by 17.4% compared to the best baseline, highlighting the significant impact of enhanced bug localization on automated issue fixing.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "94",
        "title": "Round Attention: A Novel Round-Level Attention Mechanism to Accelerate LLM Inference",
        "author": [
            "Yaohua Tang",
            "Zhicheng Hu",
            "Kun Cheng",
            "Fan Mo",
            "Qiheng Lv",
            "Hua Wang",
            "Zhi Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15294",
        "abstract": "The increasing context window size in large language models (LLMs) has improved their ability to handle complex, long-text tasks. However, as the conversation rounds continue, it is required to store a large amount of KV cache in GPU memory, which significantly affects the efficiency and even availability of the model serving systems. This paper analyzes dialogue data from real users and discovers that the LLM inference manifests a watershed layer, after which the distribution of round-level attention shows notable similarity. We propose Round Attention, a novel round-level attention mechanism that only recalls and computes the KV cache of the most relevant rounds. The experiments show that our method saves 55\\% memory usage without compromising model performance.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "95",
        "title": "SVDq: 1.25-bit and 410x Key Cache Compression for LLM Attention",
        "author": [
            "Hong Yankun",
            "Li Xing",
            "Zhen Hui-Ling",
            "Yu Xianzhi",
            "Liu Wulong",
            "Yuan Mingxuan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15304",
        "abstract": "For the efficient inference of Large Language Models (LLMs), the effective compression of key-value (KV) cache is essential. Three main types of KV cache compression techniques, namely sparsity, channel compression, and quantization, have been identified. This study presents SVDq, a Singular Value Decomposition (SVD) - based mixed precision quantization method for K cache. Initially, K cache is transformed into latent channels using SVD basis representations. Since the values in latent channels decay rapidly and become negligible after only a few latent channels, our method then incorporates importance-aware quantization and compression for latent channels. This enables the effective allocation of higher precision to more significant channels. Theoretically, we prove that SVDq results in quantization errors (x0.1 or even lower) that are much lower than those of per-channel key quantization in the original space. Our findings based on RULER and LongBench benchmarks demonstrate that SVDq can achieve an equivalent key cache precision as low as 1.25-bit. When combined with key sparsity, it can reach a key compression ratio of up to 410x for attention computation, all while maintaining comparable model performance. Notably, our method is nearly lossless for LongBench datasets. This indicates that SVDq enables high-precision low-bit quantization, providing a more efficient solution for KV cache compression in LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "96",
        "title": "DynamicGSG: Dynamic 3D Gaussian Scene Graphs for Environment Adaptation",
        "author": [
            "Luzhou Ge",
            "Xiangyu Zhu",
            "Zhuo Yang",
            "Xuesong Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15309",
        "abstract": "In real-world scenarios, the environment changes caused by agents or human activities make it extremely challenging for robots to perform various long-term tasks. To effectively understand and adapt to dynamic environments, the perception system of a robot needs to extract instance-level semantic information, reconstruct the environment in a fine-grained manner, and update its environment representation in memory according to environment changes. To address these challenges, We propose \\textbf{DynamicGSG}, a dynamic, high-fidelity, open-vocabulary scene graph generation system leveraging Gaussian splatting. Our system comprises three key components: (1) constructing hierarchical scene graphs using advanced vision foundation models to represent the spatial and semantic relationships of objects in the environment, (2) designing a joint feature loss to optimize the Gaussian map for incremental high-fidelity reconstruction, and (3) updating the Gaussian map and scene graph according to real environment changes for long-term environment adaptation. Experiments and ablation studies demonstrate the performance and efficacy of the proposed method in terms of semantic segmentation, language-guided object retrieval, and reconstruction quality. Furthermore, we have validated the dynamic updating capabilities of our system in real laboratory environments. The source code will be released at:~\\href{https://github.com/GeLuzhou/Dynamic-GSG}{https://github.com/GeLuzhou/DynamicGSG}.",
        "tags": [
            "3D",
            "Gaussian Splatting",
            "Robot",
            "Segmentation"
        ]
    },
    {
        "id": "97",
        "title": "SentiFormer: Metadata Enhanced Transformer for Image Sentiment Analysis",
        "author": [
            "Bin Feng",
            "Shulan Ruan",
            "Mingzheng Yang",
            "Dongxuan Han",
            "Huijie Liu",
            "Kai Zhang",
            "Qi Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15322",
        "abstract": "As more and more internet users post images online to express their daily emotions, image sentiment analysis has attracted increasing attention. Recently, researchers generally tend to design different neural networks to extract visual features from images for sentiment analysis. Despite the significant progress, metadata, the data (e.g., text descriptions and keyword tags) for describing the image, has not been sufficiently explored in this task. In this paper, we propose a novel Metadata Enhanced Transformer for sentiment analysis (SentiFormer) to fuse multiple metadata and the corresponding image into a unified framework. Specifically, we first obtain multiple metadata of the image and unify the representations of diverse data. To adaptively learn the appropriate weights for each metadata, we then design an adaptive relevance learning module to highlight more effective information while suppressing weaker ones. Moreover, we further develop a cross-modal fusion module to fuse the adaptively learned representations and make the final prediction. Extensive experiments on three publicly available datasets demonstrate the superiority and rationality of our proposed method.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "98",
        "title": "Detecting Future-related Contexts of Entity Mentions",
        "author": [
            "Puneet Prashar",
            "Krishna Mohan Shukla",
            "Adam Jatowt"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15332",
        "abstract": "The ability to automatically identify whether an entity is referenced in a future context can have multiple applications including decision making, planning and trend forecasting. This paper focuses on detecting implicit future references in entity-centric texts, addressing the growing need for automated temporal analysis in information processing. We first present a novel dataset of 19,540 sentences built around popular entities sourced from Wikipedia, which consists of future-related and non-future-related contexts in which those entities appear. As a second contribution, we evaluate the performance of several Language Models including also Large Language Models (LLMs) on the task of distinguishing future-oriented content in the absence of explicit temporal references.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "99",
        "title": "Attention Eclipse: Manipulating Attention to Bypass LLM Safety-Alignment",
        "author": [
            "Pedram Zaree",
            "Md Abdullah Al Mamun",
            "Quazi Mishkatul Alam",
            "Yue Dong",
            "Ihsen Alouani",
            "Nael Abu-Ghazaleh"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15334",
        "abstract": "Recent research has shown that carefully crafted jailbreak inputs can induce large language models to produce harmful outputs, despite safety measures such as alignment. It is important to anticipate the range of potential Jailbreak attacks to guide effective defenses and accurate assessment of model safety. In this paper, we present a new approach for generating highly effective Jailbreak attacks that manipulate the attention of the model to selectively strengthen or weaken attention among different parts of the prompt. By harnessing attention loss, we develop more effective jailbreak attacks, that are also transferrable. The attacks amplify the success rate of existing Jailbreak algorithms including GCG, AutoDAN, and ReNeLLM, while lowering their generation cost (for example, the amplified GCG attack achieves 91.2% ASR, vs. 67.9% for the original attack on Llama2-7B/AdvBench, using less than a third of the generation time).",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "100",
        "title": "Stepwise Informativeness Search for Improving LLM Reasoning",
        "author": [
            "Siyuan Wang",
            "Enda Zhao",
            "Zhongyu Wei",
            "Xiang Ren"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15335",
        "abstract": "Advances in Large Language Models (LLMs) have significantly improved multi-step reasoning through generating free-text rationales. However, recent studies show that LLMs tend to lose focus over the middle of long contexts. This raises concerns that as reasoning progresses, LLMs may overlook information in earlier steps when decoding subsequent steps, leading to generate unreliable and redundant rationales. To address this, we propose guiding LLMs to generate more accurate and concise step-by-step rationales by (1) proactively referencing information from underutilized prior steps, and (2) minimizing redundant information between new and existing steps. We introduce stepwise informativeness search, an inference-time tree search framework incorporating two selection heuristics: grounding-guided selection which prioritizes steps paying higher attention over underutilized steps; and novelty-guided selection which encourages steps with novel conclusions. During rationale generation, we use a self-grounding strategy that prompts LLMs to explicitly reference relevant prior steps to provide premises before deduction at each step. Experimental results on four reasoning datasets demonstrate that our approach improves reasoning accuracy by generating higher-quality rationales with reduced errors and redundancy.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "101",
        "title": "Exploring Embodied Multimodal Large Models: Development, Datasets, and Future Directions",
        "author": [
            "Shoubin Chen",
            "Zehao Wu",
            "Kai Zhang",
            "Chunyu Li",
            "Baiyang Zhang",
            "Fei Ma",
            "Fei Richard Yu",
            "Qingquan Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15336",
        "abstract": "Embodied multimodal large models (EMLMs) have gained significant attention in recent years due to their potential to bridge the gap between perception, cognition, and action in complex, real-world environments. This comprehensive review explores the development of such models, including Large Language Models (LLMs), Large Vision Models (LVMs), and other models, while also examining other emerging architectures. We discuss the evolution of EMLMs, with a focus on embodied perception, navigation, interaction, and simulation. Furthermore, the review provides a detailed analysis of the datasets used for training and evaluating these models, highlighting the importance of diverse, high-quality data for effective learning. The paper also identifies key challenges faced by EMLMs, including issues of scalability, generalization, and real-time decision-making. Finally, we outline future directions, emphasizing the integration of multimodal sensing, reasoning, and action to advance the development of increasingly autonomous systems. By providing an in-depth analysis of state-of-the-art methods and identifying critical gaps, this paper aims to inspire future advancements in EMLMs and their applications across diverse domains.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "102",
        "title": "Tokenization is Sensitive to Language Variation",
        "author": [
            "Anna Wegmann",
            "Dong Nguyen",
            "David Jurgens"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15343",
        "abstract": "Variation in language is ubiquitous and often systematically linked to regional, social, and contextual factors. Tokenizers split texts into smaller units and might behave differently for less common linguistic forms. This might affect downstream LLM performance differently on two types of tasks: Tasks where the model should be robust to language variation (e.g., for semantic tasks like NLI, labels do not depend on whether a text uses British or American spelling) and tasks where the model should be sensitive to language variation (e.g., for form-based tasks like authorship verification, labels depend on whether a text uses British or American spelling). We pre-train BERT base models for the popular Byte-Pair Encoding algorithm to investigate how key algorithmic design choices impact downstream models' performances: fitting corpus, pre-tokenizer and vocabulary size. We find that the best tokenizer varies on the two task types -- with the pre-tokenizer having the biggest impact on performance. Further, we introduce a new approach to estimate tokenizer impact on downstream LLM performance, showing significant improvement over techniques like RÃ©nyi efficiency. We encourage more work on language variation and its relation to tokenizers and thus LLM performance.",
        "tags": [
            "BERT"
        ]
    },
    {
        "id": "103",
        "title": "Constructing a Norm for Children's Scientific Drawing: Distribution Features Based on Semantic Similarity of Large Language Models",
        "author": [
            "Yi Zhang",
            "Fan Wei",
            "Jingyi Li",
            "Yan Wang",
            "Yanyan Yu",
            "Jianli Chen",
            "Zipo Cai",
            "Xinyu Liu",
            "Wei Wang",
            "Peng Wang",
            "Zhong Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15348",
        "abstract": "The use of children's drawings to examining their conceptual understanding has been proven to be an effective method, but there are two major problems with previous research: 1. The content of the drawings heavily relies on the task, and the ecological validity of the conclusions is low; 2. The interpretation of drawings relies too much on the subjective feelings of the researchers. To address this issue, this study uses the Large Language Model (LLM) to identify 1420 children's scientific drawings (covering 9 scientific themes/concepts), and uses the word2vec algorithm to calculate their semantic similarity. The study explores whether there are consistent drawing representations for children on the same theme, and attempts to establish a norm for children's scientific drawings, providing a baseline reference for follow-up children's drawing research. The results show that the representation of most drawings has consistency, manifested as most semantic similarity greater than 0.8. At the same time, it was found that the consistency of the representation is independent of the accuracy (of LLM's recognition), indicating the existence of consistency bias. In the subsequent exploration of influencing factors, we used Kendall rank correlation coefficient to investigate the effects of Sample Size, Abstract Degree, and Focus Points on drawings, and used word frequency statistics to explore whether children represented abstract themes/concepts by reproducing what was taught in class.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "104",
        "title": "AttentionEngine: A Versatile Framework for Efficient Attention Mechanisms on Diverse Hardware Platforms",
        "author": [
            "Feiyang Chen",
            "Yu Cheng",
            "Lei Wang",
            "Yuqing Xia",
            "Ziming Miao",
            "Lingxiao Ma",
            "Fan Yang",
            "Jilong Xue",
            "Zhi Yang",
            "Mao Yang",
            "Haibo Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15349",
        "abstract": "Transformers and large language models (LLMs) have revolutionized machine learning, with attention mechanisms at the core of their success. As the landscape of attention variants expands, so too do the challenges of optimizing their performance, particularly across different hardware platforms. Current optimization strategies are often narrowly focused, requiring extensive manual intervention to accommodate changes in model configurations or hardware environments. In this paper, we introduce AttentionEngine, a comprehensive framework designed to streamline the optimization of attention mechanisms across heterogeneous hardware backends. By decomposing attention computation into modular operations with customizable components, AttentionEngine enables flexible adaptation to diverse algorithmic requirements. The framework further automates kernel optimization through a combination of programmable templates and a robust cross-platform scheduling strategy. Empirical results reveal performance gains of up to 10x on configurations beyond the reach of existing methods. AttentionEngine offers a scalable, efficient foundation for developing and deploying attention mechanisms with minimal manual tuning. Our code has been open-sourced and is available at https://github.com/microsoft/AttentionEngine.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "105",
        "title": "ARS: Automatic Routing Solver with Large Language Models",
        "author": [
            "Kai Li",
            "Fei Liu",
            "Zhenkun Wang",
            "Xialiang Tong",
            "Xiongwei Han",
            "Mingxuan Yuan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15359",
        "abstract": "Real-world Vehicle Routing Problems (VRPs) are characterized by a variety of practical constraints, making manual solver design both knowledge-intensive and time-consuming. Although there is increasing interest in automating the design of routing algorithms, existing research has explored only a limited array of VRP variants and fails to adequately address the complex and prevalent constraints encountered in real-world situations. To fill this gap, this paper introduces RoutBench, a benchmark of 1,000 VRP variants derived from 24 attributes, for evaluating the effectiveness of automatic routing solvers in addressing complex constraints. Along with RoutBench, we present the Automatic Routing Solver (ARS), which employs Large Language Model (LLM) agents to enhance a backbone algorithm framework by automatically generating constraint-aware heuristic code, based on problem descriptions and several representative constraints selected from a database. Our experiments show that ARS outperforms state-of-the-art LLM-based methods and commonly used solvers, automatically solving 91.67% of common VRPs and achieving at least a 30% improvement across all benchmarks.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "106",
        "title": "Evaluating Social Biases in LLM Reasoning",
        "author": [
            "Xuyang Wu",
            "Jinming Nian",
            "Zhiqiang Tao",
            "Yi Fang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15361",
        "abstract": "In the recent development of AI reasoning, large language models (LLMs) are trained to automatically generate chain-of-thought reasoning steps, which have demonstrated compelling performance on math and coding tasks. However, when bias is mixed within the reasoning process to form strong logical arguments, it could cause even more harmful results and further induce hallucinations. In this paper, we have evaluated the 8B and 32B variants of DeepSeek-R1 against their instruction tuned counterparts on the BBQ dataset, and investigated the bias that is elicited out and being amplified through reasoning steps. To the best of our knowledge, this empirical study is the first to assess bias issues in LLM reasoning.",
        "tags": [
            "DeepSeek",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "107",
        "title": "Identifying Features that Shape Perceived Consciousness in Large Language Model-based AI: A Quantitative Study of Human Responses",
        "author": [
            "Kang Bongsu",
            "Kim Jundong",
            "Yun Tae-Rim",
            "Bae Hyojin",
            "Kim Chang-Eop"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15365",
        "abstract": "This study quantitively examines which features of AI-generated text lead humans to perceive subjective consciousness in large language model (LLM)-based AI systems. Drawing on 99 passages from conversations with Claude 3 Opus and focusing on eight features -- metacognitive self-reflection, logical reasoning, empathy, emotionality, knowledge, fluency, unexpectedness, and subjective expressiveness -- we conducted a survey with 123 participants. Using regression and clustering analyses, we investigated how these features influence participants' perceptions of AI consciousness. The results reveal that metacognitive self-reflection and the AI's expression of its own emotions significantly increased perceived consciousness, while a heavy emphasis on knowledge reduced it. Participants clustered into seven subgroups, each showing distinct feature-weighting patterns. Additionally, higher prior knowledge of LLMs and more frequent usage of LLM-based chatbots were associated with greater overall likelihood assessments of AI consciousness. This study underscores the multidimensional and individualized nature of perceived AI consciousness and provides a foundation for better understanding the psychosocial implications of human-AI interaction.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "108",
        "title": "Beyond Tools: Understanding How Heavy Users Integrate LLMs into Everyday Tasks and Decision-Making",
        "author": [
            "Eunhye Kim",
            "Kiroong Choe",
            "Minju Yoo",
            "Sadat Shams Chowdhury",
            "Jinwook Seo"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15395",
        "abstract": "Large language models (LLMs) are increasingly used for both everyday and specialized tasks. While HCI research focuses on domain-specific applications, little is known about how heavy users integrate LLMs into everyday decision-making. Through qualitative interviews with heavy LLM users (n=7) who employ these systems for both intuitive and analytical thinking tasks, our findings show that participants use LLMs for social validation, self-regulation, and interpersonal guidance, seeking to build self-confidence and optimize cognitive resources. These users viewed LLMs either as rational, consistent entities or average human decision-makers. Our findings suggest that heavy LLM users develop nuanced interaction patterns beyond simple delegation, highlighting the need to reconsider how we study LLM integration in decision-making processes.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "109",
        "title": "Enhancing Vehicle Make and Model Recognition with 3D Attention Modules",
        "author": [
            "Narges Semiromizadeh",
            "Omid Nejati Manzari",
            "Shahriar B. Shokouhi",
            "Sattar Mirzakuchaki"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15398",
        "abstract": "Vehicle make and model recognition (VMMR) is a crucial component of the Intelligent Transport System, garnering significant attention in recent years. VMMR has been widely utilized for detecting suspicious vehicles, monitoring urban traffic, and autonomous driving systems. The complexity of VMMR arises from the subtle visual distinctions among vehicle models and the wide variety of classes produced by manufacturers. Convolutional Neural Networks (CNNs), a prominent type of deep learning model, have been extensively employed in various computer vision tasks, including VMMR, yielding remarkable results. As VMMR is a fine-grained classification problem, it primarily faces inter-class similarity and intra-class variation challenges. In this study, we implement an attention module to address these challenges and enhance the model's focus on critical areas containing distinguishing features. This module, which does not increase the parameters of the original model, generates three-dimensional (3-D) attention weights to refine the feature map. Our proposed model integrates the attention module into two different locations within the middle section of a convolutional model, where the feature maps from these sections offer sufficient information about the input frames without being overly detailed or overly coarse. The performance of our proposed model, along with state-of-the-art (SOTA) convolutional and transformer-based models, was evaluated using the Stanford Cars dataset. Our proposed model achieved the highest accuracy, 90.69\\%, among the compared models.",
        "tags": [
            "3D",
            "Transformer"
        ]
    },
    {
        "id": "110",
        "title": "Problem-Solving Logic Guided Curriculum In-Context Learning for LLMs Complex Reasoning",
        "author": [
            "Xuetao Ma",
            "Wenbin Jiang",
            "Hua Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15401",
        "abstract": "In-context learning (ICL) can significantly enhance the complex reasoning capabilities of large language models (LLMs), with the key lying in the selection and ordering of demonstration examples. Previous methods typically relied on simple features to measure the relevance between examples. We argue that these features are not sufficient to reflect the intrinsic connections between examples. In this study, we propose a curriculum ICL strategy guided by problem-solving logic. We select demonstration examples by analyzing the problem-solving logic and order them based on curriculum learning. Specifically, we constructed a problem-solving logic instruction set based on the BREAK dataset and fine-tuned a language model to analyze the problem-solving logic of examples. Subsequently, we selected appropriate demonstration examples based on problem-solving logic and assessed their difficulty according to the number of problem-solving steps. In accordance with the principles of curriculum learning, we ordered the examples from easy to hard to serve as contextual prompts. Experimental results on multiple benchmarks indicate that our method outperforms previous ICL approaches in terms of performance and efficiency, effectively enhancing the complex reasoning capabilities of LLMs. Our project will be publicly available subsequently.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "111",
        "title": "Semi-implicit relaxed finite volume schemes for hyperbolic multi-scale systems of conservation laws",
        "author": [
            "Andrea Thomann"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15402",
        "abstract": "In this paper a new semi-implicit relaxation scheme for the simulation of multi-scale hyperbolic conservation laws based on a Jin-Xin relaxation approach is presented. It is based on the splitting of the flux function into two or more subsystems separating the different scales of the considered model whose stiff components are relaxed thus yielding a linear structure of the resulting relaxation model on the relaxation variables. This allows the construction of a linearly implicit numerical scheme, where convective processes are discretized explicitly. Thanks to this linearity, the discrete scheme can be reformulated in linear decoupled wave-type equations resulting in the same number of evolved variables as in the original system. To obtain a scale independent numerical diffusion, centred fluxes are applied on the implicitly treated terms, whereas classical upwind schemes are applied on the explicit parts. The numerical scheme is validated by applying it on the Toro & VÃ¡zquez-CendÃ³n (2012) splitting of the Euler equations and the Fambri (2021) splitting of the ideal MHD equations where the flux is split in two, respectively three sub-systems. The performance of the numerical scheme is assessed running benchmark test-cases from the literature in one and two spatial dimensions.",
        "tags": [
            "Diffusion",
            "FLUX"
        ]
    },
    {
        "id": "112",
        "title": "HiFi-KPI: A Dataset for Hierarchical KPI Extraction from Earnings Filings",
        "author": [
            "Rasmus Aavang",
            "Giovanni Rizzi",
            "Rasmus BÃ¸ggild",
            "Alexandre Iolov",
            "Mike Zhang",
            "Johannes Bjerva"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15411",
        "abstract": "The U.S. Securities and Exchange Commission (SEC) requires that public companies file financial reports tagging numbers with the machine readable inline eXtensible Business Reporting Language (iXBRL) standard. However, the highly complex and highly granular taxonomy defined by iXBRL limits label transferability across domains. In this paper, we introduce the Hierarchical Financial Key Performance Indicator (HiFi-KPI) dataset, designed to facilitate numerical KPI extraction at specified levels of granularity from unstructured financial text. Our approach organizes a 218,126-label hierarchy using a taxonomy based grouping method, investigating which taxonomy layer provides the most meaningful structure. HiFi-KPI comprises ~1.8M paragraphs and ~5M entities, each linked to a label in the iXBRL-specific calculation and presentation taxonomies. We provide baselines using encoder-based approaches and structured extraction using Large Language Models (LLMs). To simplify LLM inference and evaluation, we additionally release HiFi-KPI Lite, a manually curated subset with four expert-mapped labels. We publicly release all artifacts",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "113",
        "title": "Beyond Translation: LLM-Based Data Generation for Multilingual Fact-Checking",
        "author": [
            "Yi-Ling Chung",
            "Aurora Cobo",
            "Pablo Serna"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15419",
        "abstract": "Robust automatic fact-checking systems have the potential to combat online misinformation at scale. However, most existing research primarily focuses on English. In this paper, we introduce MultiSynFact, the first large-scale multilingual fact-checking dataset containing 2.2M claim-source pairs designed to support Spanish, German, English, and other low-resource languages. Our dataset generation pipeline leverages Large Language Models (LLMs), integrating external knowledge from Wikipedia and incorporating rigorous claim validation steps to ensure data quality. We evaluate the effectiveness of MultiSynFact across multiple models and experimental settings. Additionally, we open-source a user-friendly framework to facilitate further research in multilingual fact-checking and dataset generation.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "114",
        "title": "Adversarial Prompt Evaluation: Systematic Benchmarking of Guardrails Against Prompt Input Attacks on LLMs",
        "author": [
            "Giulio Zizzo",
            "Giandomenico Cornacchia",
            "Kieran Fraser",
            "Muhammad Zaid Hameed",
            "Ambrish Rawat",
            "Beat Buesser",
            "Mark Purcell",
            "Pin-Yu Chen",
            "Prasanna Sattigeri",
            "Kush Varshney"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15427",
        "abstract": "As large language models (LLMs) become integrated into everyday applications, ensuring their robustness and security is increasingly critical. In particular, LLMs can be manipulated into unsafe behaviour by prompts known as jailbreaks. The variety of jailbreak styles is growing, necessitating the use of external defences known as guardrails. While many jailbreak defences have been proposed, not all defences are able to handle new out-of-distribution attacks due to the narrow segment of jailbreaks used to align them. Moreover, the lack of systematisation around defences has created significant gaps in their practical application. In this work, we perform systematic benchmarking across 15 different defences, considering a broad swathe of malicious and benign datasets. We find that there is significant performance variation depending on the style of jailbreak a defence is subject to. Additionally, we show that based on current datasets available for evaluation, simple baselines can display competitive out-of-distribution performance compared to many state-of-the-art defences. Code is available at https://github.com/IBM/Adversarial-Prompt-Evaluation.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "115",
        "title": "Mixup Model Merge: Enhancing Model Merging Performance through Randomized Linear Interpolation",
        "author": [
            "Yue Zhou",
            "Yi Chang",
            "Yuan Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15434",
        "abstract": "Model merging integrates the parameters of multiple models into a unified model, combining their diverse capabilities. Existing model merging methods are often constrained by fixed parameter merging ratios. In this study, we propose Mixup Model Merge (M$^3$), an innovative approach inspired by the Mixup data augmentation technique. This method merges the parameters of two large language models (LLMs) by randomly generating linear interpolation ratios, allowing for a more flexible and comprehensive exploration of the parameter space. Extensive experiments demonstrate the superiority of our proposed M$^3$ method in merging fine-tuned LLMs: (1) it significantly improves performance across multiple tasks, (2) it enhances LLMs' out-of-distribution (OOD) robustness and adversarial robustness, (3) it achieves superior results when combined with sparsification techniques such as DARE, and (4) it offers a simple yet efficient solution that does not require additional computational resources. In conclusion, M$^3$ is a simple yet effective model merging method that significantly enhances the performance of the merged model by randomly generating contribution ratios for two fine-tuned LLMs. The code is available at https://github.com/MLGroupJLU/MixupModelMerge.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "116",
        "title": "Fed-SB: A Silver Bullet for Extreme Communication Efficiency and Performance in (Private) Federated LoRA Fine-Tuning",
        "author": [
            "Raghav Singhal",
            "Kaustubh Ponkshe",
            "Rohit Vartak",
            "Lav R. Varshney",
            "Praneeth Vepakomma"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15436",
        "abstract": "Low-Rank Adaptation (LoRA) has become ubiquitous for efficiently fine-tuning foundation models. However, federated fine-tuning using LoRA is challenging due to suboptimal updates arising from traditional federated averaging of individual adapters. Existing solutions either incur prohibitively high communication cost that scales linearly with the number of clients or suffer from performance degradation due to limited expressivity. We introduce Federated Silver Bullet (Fed-SB), a novel approach for federated fine-tuning of LLMs using LoRA-SB, a recently proposed low-rank adaptation method. LoRA-SB optimally aligns the optimization trajectory with the ideal low-rank full fine-tuning projection by learning a small square matrix (R) between adapters B and A, keeping other components fixed. Direct averaging of R guarantees exact updates, substantially reducing communication cost, which remains independent of the number of clients, and enables scalability. Fed-SB achieves state-of-the-art performance across commonsense reasoning, arithmetic reasoning, and language inference tasks while reducing communication costs by up to 230x. In private settings, Fed-SB further improves performance by (1) reducing trainable parameters, thereby lowering the noise required for differential privacy and (2) avoiding noise amplification introduced by other methods. Overall, Fed-SB establishes a new Pareto frontier in the tradeoff between communication and performance, offering an efficient and scalable solution for both private and non-private federated fine-tuning. Our code is publicly available at https://github.com/CERT-Lab/fed-sb.",
        "tags": [
            "LLMs",
            "LoRA",
            "Low-Rank Adaptation"
        ]
    },
    {
        "id": "117",
        "title": "On the Effectiveness of Large Language Models in Writing Alloy Formulas",
        "author": [
            "Yang Hong",
            "Shan Jiang",
            "Yulei Fu",
            "Sarfraz Khurshid"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15441",
        "abstract": "Declarative specifications have a vital role to play in developing safe and dependable software systems. Writing specifications correctly, however, remains particularly challenging. This paper presents a controlled experiment on using large language models (LLMs) to write declarative formulas in the well-known language Alloy. Our use of LLMs is three-fold. One, we employ LLMs to write complete Alloy formulas from given natural language descriptions (in English). Two, we employ LLMs to create alternative but equivalent formulas in Alloy with respect to given Alloy formulas. Three, we employ LLMs to complete sketches of Alloy formulas and populate the holes in the sketches by synthesizing Alloy expressions and operators so that the completed formulas accurately represent the desired properties (that are given in natural language). We conduct the experimental evaluation using 11 well-studied subject specifications and employ two popular LLMs, namely ChatGPT and DeepSeek. The experimental results show that the LLMs generally perform well in synthesizing complete Alloy formulas from input properties given in natural language or in Alloy, and are able to enumerate multiple unique solutions. Moreover, the LLMs are also successful at completing given sketches of Alloy formulas with respect to natural language descriptions of desired properties (without requiring test cases). We believe LLMs offer a very exciting advance in our ability to write specifications, and can help make specifications take a pivotal role in software development and enhance our ability to build robust software.",
        "tags": [
            "ChatGPT",
            "DeepSeek",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "118",
        "title": "When Compression Meets Model Compression: Memory-Efficient Double Compression for Large Language Models",
        "author": [
            "Weilan Wang",
            "Yu Mao",
            "Dongdong Tang",
            "Hongchao Du",
            "Nan Guan",
            "Chun Jason Xue"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15443",
        "abstract": "Large language models (LLMs) exhibit excellent performance in various tasks. However, the memory requirements of LLMs present a great challenge when deploying on memory-limited devices, even for quantized LLMs. This paper introduces a framework to compress LLM after quantization further, achieving about 2.2x compression ratio. A compression-aware quantization is first proposed to enhance model weight compressibility by re-scaling the model parameters before quantization, followed by a pruning method to improve further. Upon this, we notice that decompression can be a bottleneck during practical scenarios. We then give a detailed analysis of the trade-off between memory usage and latency brought by the proposed method. A speed-adaptive method is proposed to overcome it. The experimental results show inference with the compressed model can achieve a 40% reduction in memory size with negligible loss in accuracy and inference speed.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "119",
        "title": "A fast convergence algorithm based on binary integer programming for expert load balancing in MoE LLMs",
        "author": [
            "Yuan Sun"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15451",
        "abstract": "MoE (Mixture-of-Expert) architectures appear frequently in large language models, and the number of experts can be over one hundred recently. However, the expert load imbalance problem always happens in MoE model pre-training, which will cause routing collapse or increased computational overhead. In order to balance loads on experts, we propose BIP-Based Balancing, an expert load balancing algorithm based on binary integer programming (BIP). The algorithm maintains an additional vector q that can help change the top-K order of s by solving a binary integer programming with very small time costs. In simulation experiments, we observe that BIP-Based Balancing make imbalance disappoint very fast, while the final sum of routine scores decreases very little. Our algorithm achieves nearly perfect trade-off between expert load balance and pre-training efficiency under the simulation view.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "120",
        "title": "R-LoRA: Random Initialization of Multi-Head LoRA for Multi-Task Learning",
        "author": [
            "Jinda Liu",
            "Yi Chang",
            "Yuan Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15455",
        "abstract": "Fine-tuning large language models (LLMs) is prohibitively expensive in terms of computational and memory costs. Low-rank Adaptation (LoRA), as one of the most popular parameter-efficient fine-tuning (PEFT) methods, offers a cost-effective alternative by approximating the model changes $\\Delta W \\in \\mathbb{R}^{m \\times n}$ through the product of down-projection matrix $A \\in \\mathbb{R}^{m \\times r}$ and head matrix $B \\in \\mathbb{R}^{r \\times n}$, where $r \\ll \\min(m, n)$. In real-world scenarios, LLMs are fine-tuned on data from multiple domains to perform tasks across various fields, embodying multi-task learning (MTL). LoRA often underperforms in such complex scenarios. To enhance LoRA's capability in multi-task learning, we propose R-LoRA, which incorporates Multi-Head Randomization. Multi-Head Randomization diversifies the head matrices through Multi-Head Random Initialization and Multi-Head Dropout, enabling more efficient learning of task-specific features while maintaining shared knowledge representation. Extensive experiments demonstrate that R-LoRA is better at capturing task-specific knowledge, thereby improving performance in multi-task scenarios. The code is available at https://github.com/jinda-liu/R-LoRA.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "LoRA",
            "Low-Rank Adaptation"
        ]
    },
    {
        "id": "121",
        "title": "Memory Helps, but Confabulation Misleads: Understanding Streaming Events in Videos with MLLMs",
        "author": [
            "Gengyuan Zhang",
            "Mingcong Ding",
            "Tong Liu",
            "Yao Zhang",
            "Volker Tresp"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15457",
        "abstract": "Multimodal large language models (MLLMs) have demonstrated strong performance in understanding videos holistically, yet their ability to process streaming videos-videos are treated as a sequence of visual events-remains underexplored. Intuitively, leveraging past events as memory can enrich contextual and temporal understanding of the current event. In this paper, we show that leveraging memories as contexts helps MLLMs better understand video events. However, because such memories rely on predictions of preceding events, they may contain misinformation, leading to confabulation and degraded performance. To address this, we propose a confabulation-aware memory modification method that mitigates confabulated memory for memory-enhanced event understanding.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "122",
        "title": "PAPI: Exploiting Dynamic Parallelism in Large Language Model Decoding with a Processing-In-Memory-Enabled Computing System",
        "author": [
            "Yintao He",
            "Haiyu Mao",
            "Christina Giannoula",
            "Mohammad Sadrosadati",
            "Juan GÃ³mez-Luna",
            "Huawei Li",
            "Xiaowei Li",
            "Ying Wang",
            "Onur Mutlu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15470",
        "abstract": "Large language models (LLMs) are widely used for natural language understanding and text generation. An LLM model relies on a time-consuming step called LLM decoding to generate output tokens. Several prior works focus on improving the performance of LLM decoding using parallelism techniques, such as batching and speculative decoding. State-of-the-art LLM decoding has both compute-bound and memory-bound kernels. Some prior works statically identify and map these different kernels to a heterogeneous architecture consisting of both processing-in-memory (PIM) units and computation-centric accelerators. We observe that characteristics of LLM decoding kernels (e.g., whether or not a kernel is memory-bound) can change dynamically due to parameter changes to meet user and/or system demands, making (1) static kernel mapping to PIM units and computation-centric accelerators suboptimal, and (2) one-size-fits-all approach of designing PIM units inefficient due to a large degree of heterogeneity even in memory-bound kernels.\nIn this paper, we aim to accelerate LLM decoding while considering the dynamically changing characteristics of the kernels involved. We propose PAPI (PArallel Decoding with PIM), a PIM-enabled heterogeneous architecture that exploits dynamic scheduling of compute-bound or memory-bound kernels to suitable hardware units. PAPI has two key mechanisms: (1) online kernel characterization to dynamically schedule kernels to the most suitable hardware units at runtime and (2) a PIM-enabled heterogeneous computing system that harmoniously orchestrates both computation-centric processing units and hybrid PIM units with different computing capabilities. Our experimental results on three broadly-used LLMs show that PAPI achieves 1.8$\\times$ and 11.1$\\times$ speedups over a state-of-the-art heterogeneous LLM accelerator and a state-of-the-art PIM-only LLM accelerator, respectively.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "123",
        "title": "FaultGPT: Industrial Fault Diagnosis Question Answering System by Vision Language Models",
        "author": [
            "Jiao Chen",
            "Ruyi Huang",
            "Zuohong Lv",
            "Jianhua Tang",
            "Weihua Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15481",
        "abstract": "Recently, employing single-modality large language models based on mechanical vibration signals as Tuning Predictors has introduced new perspectives in intelligent fault diagnosis. However, the potential of these methods to leverage multimodal data remains underexploited, particularly in complex mechanical systems where relying on a single data source often fails to capture comprehensive fault information. In this paper, we present FaultGPT, a novel model that generates fault diagnosis reports directly from raw vibration signals. By leveraging large vision-language models (LVLM) and text-based supervision, FaultGPT performs end-to-end fault diagnosis question answering (FDQA), distinguishing itself from traditional classification or regression approaches. Specifically, we construct a large-scale FDQA instruction dataset for instruction tuning of LVLM. This dataset includes vibration time-frequency image-text label pairs and human instruction-ground truth pairs. To enhance the capability in generating high-quality fault diagnosis reports, we design a multi-scale cross-modal image decoder to extract fine-grained fault semantics and conducted instruction tuning without introducing additional training parameters into the LVLM. Extensive experiments, including fault diagnosis report generation, few-shot and zero-shot evaluation across multiple datasets, validate the superior performance and adaptability of FaultGPT in diverse industrial scenarios.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "124",
        "title": "Enhancing RWKV-based Language Models for Long-Sequence Text Generation",
        "author": [
            "Xinghan Pan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15485",
        "abstract": "This paper presents an enhanced RWKV-based language generation model designed to improve long-sequence text processing. We propose an adaptive token shift and gating mechanism to better capture long-range dependencies in text generation. Through a series of experiments, we compare the baseline RWKV model with the enhanced model, evaluating performance in terms of forward propagation time, text generation quality, and automatic evaluation metrics such as perplexity, BLEU, and ROUGE. Experimental results show that the enhanced model significantly improves generation quality, especially in BLEU and ROUGE scores, and demonstrates stronger context-capturing ability in long-text generation tasks.",
        "tags": [
            "RWKV"
        ]
    },
    {
        "id": "125",
        "title": "ExpliCa: Evaluating Explicit Causal Reasoning in Large Language Models",
        "author": [
            "Martina Miliani",
            "Serenna Auriemma",
            "Alessandro Bondielli",
            "Emmanuele Chersoni",
            "Lucia Passaro",
            "Irene Sucameli",
            "Alessandro Lenci"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15487",
        "abstract": "Large Language Models (LLMs) are increasingly used in tasks requiring interpretive and inferential accuracy. In this paper, we introduce ExpliCa, a new dataset for evaluating LLMs in explicit causal reasoning. ExpliCa uniquely integrates both causal and temporal relations presented in different linguistic orders and explicitly expressed by linguistic connectives. The dataset is enriched with crowdsourced human acceptability ratings. We tested LLMs on ExpliCa through prompting and perplexity-based metrics. We assessed seven commercial and open-source LLMs, revealing that even top models struggle to reach 0.80 accuracy. Interestingly, models tend to confound temporal relations with causal ones, and their performance is also strongly influenced by the linguistic order of the events. Finally, perplexity-based scores and prompting performance are differently affected by model size.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "126",
        "title": "Programmers Aren't Obsolete Yet: A Syllabus for Teaching CS Students to Responsibly Use Large Language Models for Code Generation",
        "author": [
            "Bruno Pereira Cipriano",
            "LÃºcio Studer Ferreira"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15493",
        "abstract": "Large Language Models (LLMs) have emerged as powerful tools for automating code generation, offering immense potential to enhance programmer productivity. However, their non-deterministic nature and reliance on user input necessitate a robust understanding of programming fundamentals to ensure their responsible and effective use. In this paper, we argue that foundational computing skills remain crucial in the age of LLMs. We propose a syllabus focused on equipping computer science students to responsibly embrace LLMs as performance enhancement tools. This work contributes to the discussion on the why, when, and how of integrating LLMs into computing education, aiming to better prepare programmers to leverage these tools without compromising foundational software development principles.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "127",
        "title": "Scale-Distribution Decoupling: Enabling Stable and Effective Training of Large Language Models",
        "author": [
            "Ya Wang",
            "Zhijian Zhuo",
            "Yutao Zeng",
            "Xun Zhou",
            "Jian Yang",
            "Xiaoqing Li"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15499",
        "abstract": "Training stability is a persistent challenge in the pre-training of large language models (LLMs), particularly for architectures such as Post-Norm Transformers, which are prone to gradient explosion and dissipation. In this paper, we propose Scale-Distribution Decoupling (SDD), a novel approach that stabilizes training by explicitly decoupling the scale and distribution of the weight matrix in fully-connected layers. SDD applies a normalization mechanism to regulate activations and a learnable scaling vector to maintain well-conditioned gradients, effectively preventing $\\textbf{gradient explosion and dissipation}$. This separation improves optimization efficiency, particularly in deep networks, by ensuring stable gradient propagation. Experimental results demonstrate that our method stabilizes training across various LLM architectures and outperforms existing techniques in different normalization configurations. Furthermore, the proposed method is lightweight and compatible with existing frameworks, making it a practical solution for stabilizing LLM training. Code is available at https://github.com/kaihemo/SDD.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "128",
        "title": "Construction and Evaluation of LLM-based agents for Semi-Autonomous penetration testing",
        "author": [
            "Masaya Kobayashi",
            "Masane Fuchi",
            "Amar Zanashir",
            "Tomonori Yoneda",
            "Tomohiro Takagi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15506",
        "abstract": "With the emergence of high-performance large language models (LLMs) such as GPT, Claude, and Gemini, the autonomous and semi-autonomous execution of tasks has significantly advanced across various domains. However, in highly specialized fields such as cybersecurity, full autonomy remains a challenge. This difficulty primarily stems from the limitations of LLMs in reasoning capabilities and domain-specific knowledge. We propose a system that semi-autonomously executes complex cybersecurity workflows by employing multiple LLMs modules to formulate attack strategies, generate commands, and analyze results, thereby addressing the aforementioned challenges. In our experiments using Hack The Box virtual machines, we confirmed that our system can autonomously construct attack strategies, issue appropriate commands, and automate certain processes, thereby reducing the need for manual intervention.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "129",
        "title": "Activation Steering in Neural Theorem Provers",
        "author": [
            "Shashank Kirtania"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15507",
        "abstract": "Large Language Models (LLMs) have shown promise in proving formal theorems using proof assistants like Lean. However, current state of the art language models struggles to predict next step in proofs leading practitioners to use different sampling techniques to improve LLMs capabilities. We observe that the LLM is capable of predicting the correct tactic; however, it faces challenges in ranking it appropriately within the set of candidate tactics, affecting the overall selection process. To overcome this hurdle, we use activation steering to guide LLMs responses to improve the generations at the time of inference. Our results suggest that activation steering offers a promising lightweight alternative to specialized fine-tuning for enhancing theorem proving capabilities in LLMs, particularly valuable in resource-constrained environments.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "130",
        "title": "Depth-aware Fusion Method based on Image and 4D Radar Spectrum for 3D Object Detection",
        "author": [
            "Yue Sun",
            "Yeqiang Qian",
            "Chunxiang Wang",
            "Ming Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15516",
        "abstract": "Safety and reliability are crucial for the public acceptance of autonomous driving. To ensure accurate and reliable environmental perception, intelligent vehicles must exhibit accuracy and robustness in various environments. Millimeter-wave radar, known for its high penetration capability, can operate effectively in adverse weather conditions such as rain, snow, and fog. Traditional 3D millimeter-wave radars can only provide range, Doppler, and azimuth information for objects. Although the recent emergence of 4D millimeter-wave radars has added elevation resolution, the radar point clouds remain sparse due to Constant False Alarm Rate (CFAR) operations. In contrast, cameras offer rich semantic details but are sensitive to lighting and weather conditions. Hence, this paper leverages these two highly complementary and cost-effective sensors, 4D millimeter-wave radar and camera. By integrating 4D radar spectra with depth-aware camera images and employing attention mechanisms, we fuse texture-rich images with depth-rich radar data in the Bird's Eye View (BEV) perspective, enhancing 3D object detection. Additionally, we propose using GAN-based networks to generate depth images from radar spectra in the absence of depth sensors, further improving detection accuracy.",
        "tags": [
            "3D",
            "Detection",
            "GAN"
        ]
    },
    {
        "id": "131",
        "title": "Towards Swift Serverless LLM Cold Starts with ParaServe",
        "author": [
            "Chiheng Lou",
            "Sheng Qi",
            "Chao Jin",
            "Dapeng Nie",
            "Haoran Yang",
            "Xuanzhe Liu",
            "Xin Jin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15524",
        "abstract": "With the surge in number of large language models (LLMs), the industry turns to serverless computing for LLM inference serving. However, serverless LLM serving suffers from significant cold start latency and service level objective (SLO) violations due to the substantial model size, which leads to prolonged model fetching time from remote storage. We present ParaServe, a serverless LLM serving system that minimizes cold start latency through the novel use of pipeline parallelism. Our insight is that by distributing model parameters across multiple GPU servers, we can utilize their aggregated network bandwidth to concurrently fetch different parts of the model. ParaServe adopts a two-level hierarchical design. At the cluster level, ParaServe determines the optimal degree of parallelism based on user SLOs and carefully places GPU workers across servers to reduce network interference. At the worker level, ParaServe overlaps model fetching, loading, and runtime initialization to further accelerate cold starts. Additionally, ParaServe introduces pipeline consolidation, which merges parallel groups back to individual workers to maintain optimal performance for warm requests. Our comprehensive evaluations under diverse settings demonstrate that ParaServe reduces the cold start latency by up to 4.7x and improves SLO attainment by up to 1.74x compared to baselines.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "132",
        "title": "Scaling Sparse and Dense Retrieval in Decoder-Only LLMs",
        "author": [
            "Hansi Zeng",
            "Julian Killingback",
            "Hamed Zamani"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15526",
        "abstract": "Scaling large language models (LLMs) has shown great potential for improving retrieval model performance; however, previous studies have mainly focused on dense retrieval trained with contrastive loss (CL), neglecting the scaling behavior of other retrieval paradigms and optimization techniques, such as sparse retrieval and knowledge distillation (KD). In this work, we conduct a systematic comparative study on how different retrieval paradigms (sparse vs. dense) and fine-tuning objectives (CL vs. KD vs. their combination) affect retrieval performance across different model scales. Using MSMARCO passages as the training dataset, decoder-only LLMs (Llama-3 series: 1B, 3B, 8B), and a fixed compute budget, we evaluate various training configurations on both in-domain (MSMARCO, TREC DL) and out-of-domain (BEIR) benchmarks. Our key findings reveal that: (1) Scaling behaviors emerge clearly only with CL, where larger models achieve significant performance gains, whereas KD-trained models show minimal improvement, performing similarly across the 1B, 3B, and 8B scales. (2) Sparse retrieval models consistently outperform dense retrieval across both in-domain (MSMARCO, TREC DL) and out-of-domain (BEIR) benchmarks, and they demonstrate greater robustness to imperfect supervised signals. (3) We successfully scale sparse retrieval models with the combination of CL and KD losses at 8B scale, achieving state-of-the-art (SOTA) results in all evaluation sets.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "133",
        "title": "SOTOPIA-Î©: Dynamic Strategy Injection Learning and Social Instrucion Following Evaluation for Social Agents",
        "author": [
            "Wenyuan Zhang",
            "Tianyun Liu",
            "Mengxiao Song",
            "Xiaodong Li",
            "Tingwen Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15538",
        "abstract": "Despite the abundance of prior social strategies possessed by humans, there remains a paucity of research dedicated to their transfer and integration into social agents. Our proposed SOTOPIA-{\\Omega} framework aims to address and bridge this gap, with a particular focus on enhancing the social capabilities of language agents. This framework dynamically injects multi-step reasoning strategies inspired by negotiation theory, along with two simple direct strategies, into expert agents, thereby automating the construction of high-quality social dialogue training corpus. Additionally, we introduce the concept of Social Instruction Following (S-IF) and propose two new S-IF evaluation metrics that are complementary to social capability. We demonstrate that several 7B models trained on high-quality corpus not only significantly surpass the expert agent (GPT-4) in achieving social goals but also enhance S-IF performance. Analysis and variant experiments validate the advantages of dynamic construction, which can especially break the agent's prolonged deadlock.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "134",
        "title": "PIP-KAG: Mitigating Knowledge Conflicts in Knowledge-Augmented Generation via Parametric Pruning",
        "author": [
            "Pengcheng Huang",
            "Zhenghao Liu",
            "Yukun Yan",
            "Xiaoyuan Yi",
            "Hao Chen",
            "Zhiyuan Liu",
            "Maosong Sun",
            "Tong Xiao",
            "Ge Yu",
            "Chenyan Xiong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15543",
        "abstract": "Knowledge-Augmented Generation (KAG) has shown great promise in updating the internal memory of Large Language Models (LLMs) by integrating external knowledge. However, KAG inevitably faces knowledge conflicts when the internal memory contradicts external information. Current approaches to mitigating these conflicts mainly focus on improving external knowledge utilization. However, these methods have shown only limited effectiveness in mitigating the knowledge conflict problem, as internal knowledge continues to influence the generation process of LLMs. In this paper, we propose a ParametrIc Pruning-based Knowledge-Augmented Generation (PIP-KAG) approach, which prunes internal knowledge of LLMs and incorporates a plug-and-play adaptation module to help LLMs better leverage external sources. Additionally, we construct the CoConflictQA benchmark based on the hallucination of LLMs to better evaluate contextual faithfulness during answering questions. Experimental results on CoConflictQA demonstrate that PIP-KAG significantly reduces knowledge conflicts and improves context fidelity. Notably, PIP-KAG reduces LLM's parameters by 13%, enhancing parameter efficiency in LLMs within the KAG framework. All codes are available at https://github.com/OpenBMB/PIP-KAG.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "135",
        "title": "A Cautionary Tale About \"Neutrally\" Informative AI Tools Ahead of the 2025 Federal Elections in Germany",
        "author": [
            "Ina Dormuth",
            "Sven Franke",
            "Marlies Hafer",
            "Tim Katzke",
            "Alexander Marx",
            "Emmanuel MÃ¼ller",
            "Daniel Neider",
            "Markus Pauly",
            "JÃ©rÃ´me Rutinowski"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15568",
        "abstract": "In this study, we examine the reliability of AI-based Voting Advice Applications (VAAs) and large language models (LLMs) in providing objective political information. Our analysis is based upon a comparison with party responses to 38 statements of the Wahl-O-Mat, a well-established German online tool that helps inform voters by comparing their views with political party positions. For the LLMs, we identify significant biases. They exhibit a strong alignment (over 75% on average) with left-wing parties and a substantially lower alignment with center-right (smaller 50%) and right-wing parties (around 30%). Furthermore, for the VAAs, intended to objectively inform voters, we found substantial deviations from the parties' stated positions in Wahl-O-Mat: While one VAA deviated in 25% of cases, another VAA showed deviations in more than 50% of cases. For the latter, we even observed that simple prompt injections led to severe hallucinations, including false claims such as non-existent connections between political parties and right-wing extremist ties.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "136",
        "title": "Interpreting and Steering LLMs with Mutual Information-based Explanations on Sparse Autoencoders",
        "author": [
            "Xuansheng Wu",
            "Jiayi Yuan",
            "Wenlin Yao",
            "Xiaoming Zhai",
            "Ninghao Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15576",
        "abstract": "Large language models (LLMs) excel at handling human queries, but they can occasionally generate flawed or unexpected responses. Understanding their internal states is crucial for understanding their successes, diagnosing their failures, and refining their capabilities. Although sparse autoencoders (SAEs) have shown promise for interpreting LLM internal representations, limited research has explored how to better explain SAE features, i.e., understanding the semantic meaning of features learned by SAE. Our theoretical analysis reveals that existing explanation methods suffer from the frequency bias issue, where they emphasize linguistic patterns over semantic concepts, while the latter is more critical to steer LLM behaviors. To address this, we propose using a fixed vocabulary set for feature interpretations and designing a mutual information-based objective, aiming to better capture the semantic meaning behind these features. We further propose two runtime steering strategies that adjust the learned feature activations based on their corresponding explanations. Empirical results show that, compared to baselines, our method provides more discourse-level explanations and effectively steers LLM behaviors to defend against jailbreak attacks. These findings highlight the value of explanations for steering LLM behaviors in downstream applications. We will release our code and data once accepted.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "137",
        "title": "LightThinker: Thinking Step-by-Step Compression",
        "author": [
            "Jintian Zhang",
            "Yuqi Zhu",
            "Mengshu Sun",
            "Yujie Luo",
            "Shuofei Qiao",
            "Lun Du",
            "Da Zheng",
            "Huajun Chen",
            "Ningyu Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15589",
        "abstract": "Large language models (LLMs) have shown remarkable performance in complex reasoning tasks, but their efficiency is hindered by the substantial memory and computational costs associated with generating lengthy tokens. In this paper, we propose LightThinker, a novel method that enables LLMs to dynamically compress intermediate thoughts during reasoning. Inspired by human cognitive processes, LightThinker compresses verbose thought steps into compact representations and discards the original reasoning chains, thereby significantly reducing the number of tokens stored in the context window. This is achieved by training the model on when and how to perform compression through data construction, mapping hidden states to condensed gist tokens, and creating specialized attention masks. Additionally, we introduce the Dependency (Dep) metric to quantify the degree of compression by measuring the reliance on historical tokens during generation. Extensive experiments on four datasets and two models show that LightThinker reduces peak memory usage and inference time, while maintaining competitive accuracy. Our work provides a new direction for improving the efficiency of LLMs in complex reasoning tasks without sacrificing performance. Code will be released at https://github.com/zjunlp/LightThinker.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "138",
        "title": "Generalizing From Short to Long: Effective Data Synthesis for Long-Context Instruction Tuning",
        "author": [
            "Wenhao Zhu",
            "Pinzhen Chen",
            "Hanxu Hu",
            "Shujian Huang",
            "Fei Yuan",
            "Jiajun Chen",
            "Alexandra Birch"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15592",
        "abstract": "Long-context modelling for large language models (LLMs) has been a key area of recent research because many real world use cases require reasoning over longer inputs such as documents. The focus of research into modelling long context has been on how to model position and there has been little investigation into other important aspects of language modelling such as instruction tuning. Long context training examples are challenging and expensive to create and use. In this paper, we investigate how to design instruction data for the post-training phase of a long context pre-trained model: how much and what type of context is needed for optimal and efficient post-training. Our controlled study reveals that models instruction-tuned on short contexts can effectively generalize to longer ones, while also identifying other critical factors such as instruction difficulty and context composition. Based on these findings, we propose context synthesis, a novel data synthesis framework that leverages off-the-shelf LLMs to generate extended background contexts for high-quality instruction-answer pairs. Experiment results on the document-level benchmark (LongBench) demonstrate that our proposed approach outperforms previous instruction synthesis approaches and comes close to the performance of human-annotated long-context instruction data. The project will be available at: https://github.com/NJUNLP/context-synthesis.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "139",
        "title": "SafeInt: Shielding Large Language Models from Jailbreak Attacks via Safety-Aware Representation Intervention",
        "author": [
            "Jiaqi Wu",
            "Chen Chen",
            "Chunyan Hou",
            "Xiaojie Yuan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15594",
        "abstract": "With the widespread real-world deployment of large language models (LLMs), ensuring their behavior complies with safety standards has become crucial. Jailbreak attacks exploit vulnerabilities in LLMs to induce undesirable behavior, posing a significant threat to LLM safety. Previous defenses often fail to achieve both effectiveness and efficiency simultaneously. Defenses from a representation perspective offer new insights, but existing interventions cannot dynamically adjust representations based on the harmfulness of the queries. To address this limitation while ensuring both effectiveness and efficiency, we propose SafeIntervention (SafeInt), a novel defense method that shields LLMs from jailbreak attacks through safety-aware representation intervention. SafeInt is built on our analysis of the representations of jailbreak samples. It adjusts representation distributions of jailbreak samples through intervention to align them with the representations of unsafe samples while minimizing unnecessary perturbations to jailbreak-irrelevant representations. We conduct comprehensive experiments covering six jailbreak attacks, two jailbreak datasets, and two utility benchmarks. Experimental results demonstrate that SafeInt outperforms all baselines in defending LLMs against jailbreak attacks while largely maintaining utility. Additionally, we evaluate SafeInt against adaptive attacks and verify its effectiveness in mitigating real-time attacks.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "140",
        "title": "Robust Bias Detection in MLMs and its Application to Human Trait Ratings",
        "author": [
            "Ingroj Shrestha",
            "Louis Tay",
            "Padmini Srinivasan"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15600",
        "abstract": "There has been significant prior work using templates to study bias against demographic attributes in MLMs. However, these have limitations: they overlook random variability of templates and target concepts analyzed, assume equality amongst templates, and overlook bias quantification. Addressing these, we propose a systematic statistical approach to assess bias in MLMs, using mixed models to account for random effects, pseudo-perplexity weights for sentences derived from templates and quantify bias using statistical effect sizes. Replicating prior studies, we match on bias scores in magnitude and direction with small to medium effect sizes. Next, we explore the novel problem of gender bias in the context of $\\textit{personality}$ and $\\textit{character}$ traits, across seven MLMs (base and large). We find that MLMs vary; ALBERT is unbiased for binary gender but the most biased for non-binary $\\textit{neo}$, while RoBERTa-large is the most biased for binary gender but shows small to no bias for $\\textit{neo}$. There is some alignment of MLM bias and findings in psychology (human perspective) - in $\\textit{agreeableness}$ with RoBERTa-large and $\\textit{emotional stability}$ with BERT-large. There is general agreement for the remaining 3 personality dimensions: both sides observe at most small differences across gender. For character traits, human studies on gender bias are limited thus comparisons are not feasible.",
        "tags": [
            "BERT",
            "Detection"
        ]
    },
    {
        "id": "141",
        "title": "Do Multilingual LLMs Think In English?",
        "author": [
            "Lisa Schut",
            "Yarin Gal",
            "Sebastian Farquhar"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15603",
        "abstract": "Large language models (LLMs) have multilingual capabilities and can solve tasks across various languages. However, we show that current LLMs make key decisions in a representation space closest to English, regardless of their input and output languages. Exploring the internal representations with a logit lens for sentences in French, German, Dutch, and Mandarin, we show that the LLM first emits representations close to English for semantically-loaded words before translating them into the target language. We further show that activation steering in these LLMs is more effective when the steering vectors are computed in English rather than in the language of the inputs and outputs. This suggests that multilingual LLMs perform key reasoning steps in a representation that is heavily shaped by English in a way that is not transparent to system users.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "142",
        "title": "Cross-Format Retrieval-Augmented Generation in XR with LLMs for Context-Aware Maintenance Assistance",
        "author": [
            "Akos Nagy",
            "Yannis Spyridis",
            "Vasileios Argyriou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15604",
        "abstract": "This paper presents a detailed evaluation of a Retrieval-Augmented Generation (RAG) system that integrates large language models (LLMs) to enhance information retrieval and instruction generation for maintenance personnel across diverse data formats. We assessed the performance of eight LLMs, emphasizing key metrics such as response speed and accuracy, which were quantified using BLEU and METEOR scores. Our findings reveal that advanced models like GPT-4 and GPT-4o-mini significantly outperform their counterparts, particularly when addressing complex queries requiring multi-format data integration. The results validate the system's ability to deliver timely and accurate responses, highlighting the potential of RAG frameworks to optimize maintenance operations. Future research will focus on refining retrieval techniques for these models and enhancing response generation, particularly for intricate scenarios, ultimately improving the system's practical applicability in dynamic real-world environments.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "143",
        "title": "On the Robustness of Transformers against Context Hijacking for Linear Classification",
        "author": [
            "Tianle Li",
            "Chenyang Zhang",
            "Xingwu Chen",
            "Yuan Cao",
            "Difan Zou"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15609",
        "abstract": "Transformer-based Large Language Models (LLMs) have demonstrated powerful in-context learning capabilities. However, their predictions can be disrupted by factually correct context, a phenomenon known as context hijacking, revealing a significant robustness issue. To understand this phenomenon theoretically, we explore an in-context linear classification problem based on recent advances in linear transformers. In our setup, context tokens are designed as factually correct query-answer pairs, where the queries are similar to the final query but have opposite labels. Then, we develop a general theoretical analysis on the robustness of the linear transformers, which is formulated as a function of the model depth, training context lengths, and number of hijacking context tokens. A key finding is that a well-trained deeper transformer can achieve higher robustness, which aligns with empirical observations. We show that this improvement arises because deeper layers enable more fine-grained optimization steps, effectively mitigating interference from context hijacking. This is also well supported by our numerical experiments. Our findings provide theoretical insights into the benefits of deeper architectures and contribute to enhancing the understanding of transformer architectures.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "144",
        "title": "LaTIM: Measuring Latent Token-to-Token Interactions in Mamba Models",
        "author": [
            "Hugo Pitorro",
            "Marcos Treviso"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15612",
        "abstract": "State space models (SSMs), such as Mamba, have emerged as an efficient alternative to transformers for long-context sequence modeling. However, despite their growing adoption, SSMs lack the interpretability tools that have been crucial for understanding and improving attention-based architectures. While recent efforts provide insights into Mamba's internal mechanisms, they do not explicitly decompose token-wise contributions, leaving gaps in understanding how Mamba selectively processes sequences across layers. In this work, we introduce LaTIM, a novel token-level decomposition method for both Mamba-1 and Mamba-2 that enables fine-grained interpretability. We extensively evaluate our method across diverse tasks, including machine translation, copying, and retrieval-based generation, demonstrating its effectiveness in revealing Mamba's token-to-token interaction patterns.",
        "tags": [
            "Mamba",
            "SSMs",
            "State Space Models"
        ]
    },
    {
        "id": "145",
        "title": "Pick-and-place Manipulation Across Grippers Without Retraining: A Learning-optimization Diffusion Policy Approach",
        "author": [
            "Xiangtong Yao",
            "Yirui Zhou",
            "Yuan Meng",
            "Liangyu Dong",
            "Lin Hong",
            "Zitao Zhang",
            "Zhenshan Bing",
            "Kai Huang",
            "Fuchun Sun",
            "Alois Knoll"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15613",
        "abstract": "Current robotic pick-and-place policies typically require consistent gripper configurations across training and inference. This constraint imposes high retraining or fine-tuning costs, especially for imitation learning-based approaches, when adapting to new end-effectors. To mitigate this issue, we present a diffusion-based policy with a hybrid learning-optimization framework, enabling zero-shot adaptation to novel grippers without additional data collection for retraining policy. During training, the policy learns manipulation primitives from demonstrations collected using a base gripper. At inference, a diffusion-based optimization strategy dynamically enforces kinematic and safety constraints, ensuring that generated trajectories align with the physical properties of unseen grippers. This is achieved through a constrained denoising procedure that adapts trajectories to gripper-specific parameters (e.g., tool-center-point offsets, jaw widths) while preserving collision avoidance and task feasibility. We validate our method on a Franka Panda robot across six gripper configurations, including 3D-printed fingertips, flexible silicone gripper, and Robotiq 2F-85 gripper. Our approach achieves a 93.3% average task success rate across grippers (vs. 23.3-26.7% for diffusion policy baselines), supporting tool-center-point variations of 16-23.5 cm and jaw widths of 7.5-11.5 cm. The results demonstrate that constrained diffusion enables robust cross-gripper manipulation while maintaining the sample efficiency of imitation learning, eliminating the need for gripper-specific retraining. Video and code are available at https://github.com/yaoxt3/GADP.",
        "tags": [
            "3D",
            "Diffusion",
            "Robot"
        ]
    },
    {
        "id": "146",
        "title": "Pastiche Novel Generation Creating: Fan Fiction You Love in Your Favorite Author's Style",
        "author": [
            "Xueran Han",
            "Yuhan Liu",
            "Mingzhe Li",
            "Wei Liu",
            "Sen Hu",
            "Rui Yan",
            "Zhiqiang Xu",
            "Xiuying Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15616",
        "abstract": "Great novels create immersive worlds with rich character arcs, well-structured plots, and nuanced writing styles. However, current novel generation methods often rely on brief, simplistic story outlines and generate details using plain, generic language. To bridge this gap, we introduce the task of Pastiche Novel Generation, which requires the generated novels to imitate the distinctive features of the original work, including understanding character profiles, predicting plausible plot developments, and writing concrete details using vivid, expressive language. To achieve this, we propose WriterAgent, a novel generation system designed to master the core aspects of literary pastiche. WriterAgent is trained through a curriculum learning paradigm, progressing from low-level stylistic mastery to high-level narrative coherence. Its key tasks include language style learning, character modeling, plot planning, and stylish writing, ensuring comprehensive narrative control. To support this, WriterAgent leverages the WriterLoRA framework, an extension of LoRA with hierarchical and cumulative task-specific modules, each specializing in a different narrative aspect. We evaluate WriterAgent on multilingual classics like Harry Potter and Dream of the Red Chamber, demonstrating its superiority over baselines in capturing the target author's settings, character dynamics, and writing style to produce coherent, faithful narratives.",
        "tags": [
            "LoRA"
        ]
    },
    {
        "id": "147",
        "title": "Probe Pruning: Accelerating LLMs through Dynamic Pruning via Model-Probing",
        "author": [
            "Qi Le",
            "Enmao Diao",
            "Ziyan Wang",
            "Xinran Wang",
            "Jie Ding",
            "Li Yang",
            "Ali Anwar"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15618",
        "abstract": "We introduce Probe Pruning (PP), a novel framework for online, dynamic, structured pruning of Large Language Models (LLMs) applied in a batch-wise manner. PP leverages the insight that not all samples and tokens contribute equally to the model's output, and probing a small portion of each batch effectively identifies crucial weights, enabling tailored dynamic pruning for different batches. It comprises three main stages: probing, history-informed pruning, and full inference. In the probing stage, PP selects a small yet crucial set of hidden states, based on residual importance, to run a few model layers ahead. During the history-informed pruning stage, PP strategically integrates the probing states with historical states. Subsequently, it structurally prunes weights based on the integrated states and the PP importance score, a metric developed specifically to assess the importance of each weight channel in maintaining performance. In the final stage, full inference is conducted on the remaining weights. A major advantage of PP is its compatibility with existing models, as it operates without requiring additional neural network modules or fine-tuning. Comprehensive evaluations of PP on LLaMA-2/3 and OPT models reveal that even minimal probing-using just 1.5% of FLOPs-can substantially enhance the efficiency of structured pruning of LLMs. For instance, when evaluated on LLaMA-2-7B with WikiText2, PP achieves a 2.56 times lower ratio of performance degradation per unit of runtime reduction compared to the state-of-the-art method at a 40% pruning ratio. Our code is available at https://github.com/Qi-Le1/Probe_Pruning.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "148",
        "title": "Extraction multi-Ã©tiquettes de relations en utilisant des couches de Transformer",
        "author": [
            "Ngoc Luyen Le",
            "Gildas Tagny NgompÃ©"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15619",
        "abstract": "In this article, we present the BTransformer18 model, a deep learning architecture designed for multi-label relation extraction in French texts. Our approach combines the contextual representation capabilities of pre-trained language models from the BERT family - such as BERT, RoBERTa, and their French counterparts CamemBERT and FlauBERT - with the power of Transformer encoders to capture long-term dependencies between tokens. Experiments conducted on the dataset from the TextMine'25 challenge show that our model achieves superior performance, particularly when using CamemBERT-Large, with a macro F1 score of 0.654, surpassing the results obtained with FlauBERT-Large. These results demonstrate the effectiveness of our approach for the automatic extraction of complex relations in intelligence reports.",
        "tags": [
            "BERT",
            "Transformer"
        ]
    },
    {
        "id": "149",
        "title": "The Relationship Between Reasoning and Performance in Large Language Models -- o3 (mini) Thinks Harder, Not Longer",
        "author": [
            "Marthe Ballon",
            "Andres Algaba",
            "Vincent Ginis"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15631",
        "abstract": "Large language models have demonstrated remarkable progress in mathematical reasoning, leveraging chain-of-thought and test-time compute scaling. However, many open questions remain regarding the interplay between reasoning token usage and accuracy gains. In particular, when comparing models across generations, it is unclear whether improved performance results from longer reasoning chains or more efficient reasoning. We systematically analyze chain-of-thought length across o1-mini and o3-mini variants on the Omni-MATH benchmark, finding that o3-mini (m) achieves superior accuracy without requiring longer reasoning chains than o1-mini. Moreover, we show that accuracy generally declines as reasoning chains grow across all models and compute settings, even when controlling for difficulty of the questions. This accuracy drop is significantly smaller in more proficient models, suggesting that new generations of reasoning models use test-time compute more effectively. Finally, we highlight that while o3-mini (h) achieves a marginal accuracy gain over o3-mini (m), it does so by allocating substantially more reasoning tokens across all problems, even the ones that o3-mini (m) can already solve. These findings provide new insights into the relationship between model capability and reasoning length, with implications for efficiency, scaling, and evaluation methodologies.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "150",
        "title": "RGB-Only Gaussian Splatting SLAM for Unbounded Outdoor Scenes",
        "author": [
            "Sicheng Yu",
            "Chong Cheng",
            "Yifan Zhou",
            "Xiaojun Yang",
            "Hao Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15633",
        "abstract": "3D Gaussian Splatting (3DGS) has become a popular solution in SLAM, as it can produce high-fidelity novel views. However, previous GS-based methods primarily target indoor scenes and rely on RGB-D sensors or pre-trained depth estimation models, hence underperforming in outdoor scenarios. To address this issue, we propose a RGB-only gaussian splatting SLAM method for unbounded outdoor scenes--OpenGS-SLAM. Technically, we first employ a pointmap regression network to generate consistent pointmaps between frames for pose estimation. Compared to commonly used depth maps, pointmaps include spatial relationships and scene geometry across multiple views, enabling robust camera pose estimation. Then, we propose integrating the estimated camera poses with 3DGS rendering as an end-to-end differentiable pipeline. Our method achieves simultaneous optimization of camera poses and 3DGS scene parameters, significantly enhancing system tracking accuracy. Specifically, we also design an adaptive scale mapper for the pointmap regression network, which provides more accurate pointmap mapping to the 3DGS map representation. Our experiments on the Waymo dataset demonstrate that OpenGS-SLAM reduces tracking error to 9.8\\% of previous 3DGS methods, and achieves state-of-the-art results in novel view synthesis. Project Page: https://3dagentworld.github.io/opengs-slam/",
        "tags": [
            "3D",
            "Depth Estimation",
            "Gaussian Splatting",
            "Pose Estimation",
            "SLAM"
        ]
    },
    {
        "id": "151",
        "title": "Para-Lane: Multi-Lane Dataset Registering Parallel Scans for Benchmarking Novel View Synthesis",
        "author": [
            "Ziqian Ni",
            "Sicong Du",
            "Zhenghua Hou",
            "Chenming Wu",
            "Sheng Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15635",
        "abstract": "To evaluate end-to-end autonomous driving systems, a simulation environment based on Novel View Synthesis (NVS) techniques is essential, which synthesizes photo-realistic images and point clouds from previously recorded sequences under new vehicle poses, particularly in cross-lane scenarios. Therefore, the development of a multi-lane dataset and benchmark is necessary. While recent synthetic scene-based NVS datasets have been prepared for cross-lane benchmarking, they still lack the realism of captured images and point clouds. To further assess the performance of existing methods based on NeRF and 3DGS, we present the first multi-lane dataset registering parallel scans specifically for novel driving view synthesis dataset derived from real-world scans, comprising 25 groups of associated sequences, including 16,000 front-view images, 64,000 surround-view images, and 16,000 LiDAR frames. All frames are labeled to differentiate moving objects from static elements. Using this dataset, we evaluate the performance of existing approaches in various testing scenarios at different lanes and distances. Additionally, our method provides the solution for solving and assessing the quality of multi-sensor poses for multi-modal data alignment for curating such a dataset in real-world. We plan to continually add new sequences to test the generalization of existing methods across different scenarios. The dataset is released publicly at the project page: https://nizqleo.github.io/paralane-dataset/.",
        "tags": [
            "NeRF"
        ]
    },
    {
        "id": "152",
        "title": "Mantis: Lightweight Calibrated Foundation Model for User-Friendly Time Series Classification",
        "author": [
            "Vasilii Feofanov",
            "Songkang Wen",
            "Marius Alonso",
            "Romain Ilbert",
            "Hongbo Guo",
            "Malik Tiomoko",
            "Lujia Pan",
            "Jianfeng Zhang",
            "Ievgen Redko"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15637",
        "abstract": "In recent years, there has been increasing interest in developing foundation models for time series data that can generalize across diverse downstream tasks. While numerous forecasting-oriented foundation models have been introduced, there is a notable scarcity of models tailored for time series classification. To address this gap, we present Mantis, a new open-source foundation model for time series classification based on the Vision Transformer (ViT) architecture that has been pre-trained using a contrastive learning approach. Our experimental results show that Mantis outperforms existing foundation models both when the backbone is frozen and when fine-tuned, while achieving the lowest calibration error. In addition, we propose several adapters to handle the multivariate setting, reducing memory requirements and modeling channel interdependence.",
        "tags": [
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "153",
        "title": "Steering into New Embedding Spaces: Analyzing Cross-Lingual Alignment Induced by Model Interventions in Multilingual Language Models",
        "author": [
            "Anirudh Sundar",
            "Sinead Williamson",
            "Katherine Metcalf",
            "Barry-John Theobald",
            "Skyler Seto",
            "Masha Fedzechkina"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15639",
        "abstract": "Aligned representations across languages is a desired property in multilingual large language models (mLLMs), as alignment can improve performance in cross-lingual tasks. Typically alignment requires fine-tuning a model, which is computationally expensive, and sizable language data, which often may not be available. A data-efficient alternative to fine-tuning is model interventions -- a method for manipulating model activations to steer generation into the desired direction. We analyze the effect of a popular intervention (finding experts) on the alignment of cross-lingual representations in mLLMs. We identify the neurons to manipulate for a given language and introspect the embedding space of mLLMs pre- and post-manipulation. We show that modifying the mLLM's activations changes its embedding space such that cross-lingual alignment is enhanced. Further, we show that the changes to the embedding space translate into improved downstream performance on retrieval tasks, with up to 2x improvements in top-1 accuracy on cross-lingual retrieval.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "154",
        "title": "AutoTandemML: Active Learning Enhanced Tandem Neural Networks for Inverse Design Problems",
        "author": [
            "Luka Grbcic",
            "Juliane MÃ¼ller",
            "Wibe Albert de Jong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15643",
        "abstract": "Inverse design in science and engineering involves determining optimal design parameters that achieve desired performance outcomes, a process often hindered by the complexity and high dimensionality of design spaces, leading to significant computational costs. To tackle this challenge, we propose a novel hybrid approach that combines active learning with Tandem Neural Networks to enhance the efficiency and effectiveness of solving inverse design problems. Active learning allows to selectively sample the most informative data points, reducing the required dataset size without compromising accuracy. We investigate this approach using three benchmark problems: airfoil inverse design, photonic surface inverse design, and scalar boundary condition reconstruction in diffusion partial differential equations. We demonstrate that integrating active learning with Tandem Neural Networks outperforms standard approaches across the benchmark suite, achieving better accuracy with fewer training samples.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "155",
        "title": "Empowering LLMs with Logical Reasoning: A Comprehensive Survey",
        "author": [
            "Fengxiang Cheng",
            "Haoxuan Li",
            "Fenrong Liu",
            "Robert van Rooij",
            "Kun Zhang",
            "Zhouchen Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15652",
        "abstract": "Large language models (LLMs) have achieved remarkable successes on various natural language tasks. However, recent studies have found that there are still significant challenges to the logical reasoning abilities of LLMs. This paper summarizes and categorizes the main challenges into two aspects: (1) Logical question answering, LLMs often fail to generate the correct answer within complex logical problem which requires sophisticated deductive, inductive or abductive reasoning given a collection of premises and constrains. (2) Logical consistency, LLMs are prone to producing responses contradicting themselves across different questions. For example, a state-of-the-art Macaw question-answering LLM answers Yes to both questions Is a magpie a bird? and Does a bird have wings? but answers No to Does a magpie have wings?. To facilitate this research direction, we comprehensively investigate the most cutting-edge methods and propose detailed taxonomies of these methods. Specifically, to accurately answer complex logic questions, previous methods can be categorized based on reliance on external solvers, prompts, pretraining, and fine-tuning. To avoid logical contradictions, we discuss concepts and solutions of various logical consistencies, including implication, negation, transitivity, factuality consistency, and their composites. In addition, we review commonly used benchmark datasets and evaluation metrics, and discuss promising research directions, such as extensions to modal logic to account for uncertainty, and efficient algorithms satisfying multiple logical consistencies simultaneously.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "156",
        "title": "Machine-generated text detection prevents language model collapse",
        "author": [
            "George Drayson",
            "Vasileios Lampos"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15654",
        "abstract": "As Large Language Models (LLMs) become increasingly prevalent, their generated outputs are proliferating across the web, risking a future where machine-generated content dilutes human-authored text. Since web data is the primary resource for LLM pretraining, future models will be trained on an unknown portion of synthetic data. This will lead to model collapse, a degenerative process which causes models to reinforce their own errors and experience a drop in model performance. In this study, we investigate the impact of decoding strategy on model collapse, where we analyse the characteristics of the generated data during recursive training, its similarity to human references and the resulting model performance. Using the decoding strategies that lead to the most significant model degradation, we tackle the question: how to avoid model collapse when the origin (human or synthetic) of the training data is unknown. We design a novel methodology based on resampling the data distribution using importance weights from our machine-generated text detector. Our method is validated on two LLM variants (GPT-2 and SmolLM2) on the open-ended text generation task, demonstrating that we can successfully prevent model collapse and when there is enough human-authored data in the training dataset, our method improves model performance.",
        "tags": [
            "Detection",
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "157",
        "title": "Almost AI, Almost Human: The Challenge of Detecting AI-Polished Writing",
        "author": [
            "Shoumik Saha",
            "Soheil Feizi"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15666",
        "abstract": "The growing use of large language models (LLMs) for text generation has led to widespread concerns about AI-generated content detection. However, an overlooked challenge is AI-polished text, where human-written content undergoes subtle refinements using AI tools. This raises a critical question: should minimally polished text be classified as AI-generated? Misclassification can lead to false plagiarism accusations and misleading claims about AI prevalence in online content. In this study, we systematically evaluate eleven state-of-the-art AI-text detectors using our AI-Polished-Text Evaluation (APT-Eval) dataset, which contains $11.7K$ samples refined at varying AI-involvement levels. Our findings reveal that detectors frequently misclassify even minimally polished text as AI-generated, struggle to differentiate between degrees of AI involvement, and exhibit biases against older and smaller models. These limitations highlight the urgent need for more nuanced detection methodologies.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "158",
        "title": "AutoToM: Automated Bayesian Inverse Planning and Model Discovery for Open-ended Theory of Mind",
        "author": [
            "Zhining Zhang",
            "Chuanyang Jin",
            "Mung Yao Jia",
            "Tianmin Shu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15676",
        "abstract": "Theory of Mind (ToM), the ability to understand people's mental variables based on their behavior, is key to developing socially intelligent agents. Current approaches to Theory of Mind reasoning either rely on prompting Large Language Models (LLMs), which are prone to systematic errors, or use rigid, handcrafted Bayesian Theory of Mind (BToM) models, which are more robust but cannot generalize across different domains. In this work, we introduce AutoToM, an automated Bayesian Theory of Mind method for achieving open-ended machine Theory of Mind. AutoToM can operate in any domain, infer any mental variable, and conduct robust Theory of Mind reasoning of any order. Given a Theory of Mind inference problem, AutoToM first proposes an initial BToM model. It then conducts automated Bayesian inverse planning based on the proposed model, leveraging an LLM as the backend. Based on the uncertainty of the inference, it iteratively refines the model, by introducing additional mental variables and/or incorporating more timesteps in the context. Empirical evaluations across multiple Theory of Mind benchmarks demonstrate that AutoToM consistently achieves state-of-the-art performance, offering a scalable, robust, and interpretable approach to machine Theory of Mind.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "159",
        "title": "FLEKE: Federated Locate-then-Edit Knowledge Editing",
        "author": [
            "Zongkai Zhao",
            "Guozeng Xu",
            "Xiuhua Li",
            "Kaiwen Wei",
            "Jiang Zhong"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15677",
        "abstract": "Locate-then-Edit Knowledge Editing (LEKE) is a key technique for updating large language models (LLMs) without full retraining. However, existing methods assume a single-user setting and become inefficient in real-world multi-client scenarios, where decentralized organizations (e.g., hospitals, financial institutions) independently update overlapping knowledge, leading to redundant mediator knowledge vector (MKV) computations and privacy concerns. To address these challenges, we introduce Federated Locate-then-Edit Knowledge Editing (FLEKE), a novel task that enables multiple clients to collaboratively perform LEKE while preserving privacy and reducing computational overhead. To achieve this, we propose FedEdit, a two-stage framework that optimizes MKV selection and reuse. In the first stage, clients locally apply LEKE and upload the computed MKVs. In the second stage, rather than relying solely on server-based MKV sharing, FLEKE allows clients retrieve relevant MKVs based on cosine similarity, enabling knowledge re-edit and minimizing redundant computations. Experimental results on two benchmark datasets demonstrate that FedEdit retains over 96% of the performance of non-federated LEKE while significantly outperforming a FedAvg-based baseline by approximately twofold. Besides, we find that MEMIT performs more consistently than PMET in the FLEKE task with our FedEdit framework. Our code is available at https://github.com/zongkaiz/FLEKE.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "160",
        "title": "One-step Diffusion Models with $f$-Divergence Distribution Matching",
        "author": [
            "Yilun Xu",
            "Weili Nie",
            "Arash Vahdat"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15681",
        "abstract": "Sampling from diffusion models involves a slow iterative process that hinders their practical deployment, especially for interactive applications. To accelerate generation speed, recent approaches distill a multi-step diffusion model into a single-step student generator via variational score distillation, which matches the distribution of samples generated by the student to the teacher's distribution. However, these approaches use the reverse Kullback-Leibler (KL) divergence for distribution matching which is known to be mode seeking. In this paper, we generalize the distribution matching approach using a novel $f$-divergence minimization framework, termed $f$-distill, that covers different divergences with different trade-offs in terms of mode coverage and training variance. We derive the gradient of the $f$-divergence between the teacher and student distributions and show that it is expressed as the product of their score differences and a weighting function determined by their density ratio. This weighting function naturally emphasizes samples with higher density in the teacher distribution, when using a less mode-seeking divergence. We observe that the popular variational score distillation approach using the reverse-KL divergence is a special case within our framework. Empirically, we demonstrate that alternative $f$-divergences, such as forward-KL and Jensen-Shannon divergences, outperform the current best variational score distillation methods across image generation tasks. In particular, when using Jensen-Shannon divergence, $f$-distill achieves current state-of-the-art one-step generation performance on ImageNet64 and zero-shot text-to-image generation on MS-COCO. Project page: https://research.nvidia.com/labs/genair/f-distill",
        "tags": [
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "161",
        "title": "ELIP: Enhanced Visual-Language Foundation Models for Image Retrieval",
        "author": [
            "Guanqi Zhan",
            "Yuanpei Liu",
            "Kai Han",
            "Weidi Xie",
            "Andrew Zisserman"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15682",
        "abstract": "The objective in this paper is to improve the performance of text-to-image retrieval. To this end, we introduce a new framework that can boost the performance of large-scale pre-trained vision-language models, so that they can be used for text-to-image re-ranking. The approach, Enhanced Language-Image Pre-training (ELIP), uses the text query to predict a set of visual prompts to condition the ViT image encoding. ELIP can easily be applied to the commonly used CLIP/SigLIP and the state-of-the-art BLIP-2 architectures. To train the architecture with limited computing resources, we develop a 'student friendly' best practice involving global hard sample mining, and selection and curation of a large-scale dataset. On the evaluation side, we set up two new out-of-distribution benchmarks, Occluded COCO and ImageNet-R, to assess the zero-shot generalisation of the models to different domains. Benefiting from the novel architecture and data curation, experiments show our enhanced network significantly boosts CLIP/SigLIP performance and outperforms the state-of-the-art BLIP-2 model on text-to-image retrieval.",
        "tags": [
            "CLIP",
            "Text-to-Image",
            "ViT"
        ]
    },
    {
        "id": "162",
        "title": "Towards an automated workflow in materials science for combining multi-modal simulative and experimental information using data mining and large language models",
        "author": [
            "Balduin Katzer",
            "Steffen Klinder",
            "Katrin Schulz"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14904",
        "abstract": "To retrieve and compare scientific data of simulations and experiments in materials science, data needs to be easily accessible and machine readable to qualify and quantify various materials science phenomena. The recent progress in open science leverages the accessibility to data. However, a majority of information is encoded within scientific documents limiting the capability of finding suitable literature as well as material properties. This manuscript showcases an automated workflow, which unravels the encoded information from scientific literature to a machine readable data structure of texts, figures, tables, equations and meta-data, using natural language processing and language as well as vision transformer models to generate a machine-readable database. The machine-readable database can be enriched with local data, as e.g. unpublished or private material data, leading to knowledge synthesis. The study shows that such an automated workflow accelerates information retrieval, proximate context detection and material property extraction from multi-modal input data exemplarily shown for the research field of microstructural analyses of face-centered cubic single crystals. Ultimately, a Retrieval-Augmented Generation (RAG) based Large Language Model (LLM) enables a fast and efficient question answering chat bot.",
        "tags": [
            "Detection",
            "Large Language Models",
            "RAG",
            "Transformer"
        ]
    },
    {
        "id": "163",
        "title": "Optimizing Gene-Based Testing for Antibiotic Resistance Prediction",
        "author": [
            "David Hagerman",
            "Anna Johnning",
            "Roman Naeem",
            "Fredrik Kahl",
            "Erik Kristiansson",
            "Lennart Svensson"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14919",
        "abstract": "Antibiotic Resistance (AR) is a critical global health challenge that necessitates the development of cost-effective, efficient, and accurate diagnostic tools. Given the genetic basis of AR, techniques such as Polymerase Chain Reaction (PCR) that target specific resistance genes offer a promising approach for predictive diagnostics using a limited set of key genes. This study introduces GenoARM, a novel framework that integrates reinforcement learning (RL) with transformer-based models to optimize the selection of PCR gene tests and improve AR predictions, leveraging observed metadata for improved accuracy. In our evaluation, we developed several high-performing baselines and compared them using publicly available datasets derived from real-world bacterial samples representing multiple clinically relevant pathogens. The results show that all evaluated methods achieve strong and reliable performance when metadata is not utilized. When metadata is introduced and the number of selected genes increases, GenoARM demonstrates superior performance due to its capacity to approximate rewards for unseen and sparse combinations. Overall, our framework represents a major advancement in optimizing diagnostic tools for AR in clinical settings.",
        "tags": [
            "RL",
            "Transformer"
        ]
    },
    {
        "id": "164",
        "title": "Compact Latent Representation for Image Compression (CLRIC)",
        "author": [
            "Ayman A. Ameen",
            "Thomas Richter",
            "AndrÃ© Kaup"
        ],
        "pdf": "https://arxiv.org/pdf/2502.14937",
        "abstract": "Current image compression models often require separate models for each quality level, making them resource-intensive in terms of both training and storage. To address these limitations, we propose an innovative approach that utilizes latent variables from pre-existing trained models (such as the Stable Diffusion Variational Autoencoder) for perceptual image compression. Our method eliminates the need for distinct models dedicated to different quality levels. We employ overfitted learnable functions to compress the latent representation from the target model at any desired quality level. These overfitted functions operate in the latent space, ensuring low computational complexity, around $25.5$ MAC/pixel for a forward pass on images with dimensions $(1363 \\times 2048)$ pixels. This approach efficiently utilizes resources during both training and decoding. Our method achieves comparable perceptual quality to state-of-the-art learned image compression models while being both model-agnostic and resolution-agnostic. This opens up new possibilities for the development of innovative image compression methods.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "165",
        "title": "Forecasting Local Ionospheric Parameters Using Transformers",
        "author": [
            "Daniel J. Alford-Lago",
            "Christopher W. Curtis",
            "Alexander T. Ihler",
            "Katherine A. Zawdie",
            "Douglas P. Drob"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15093",
        "abstract": "We present a novel method for forecasting key ionospheric parameters using transformer-based neural networks. The model provides accurate forecasts and uncertainty quantification of the F2-layer peak plasma frequency (foF2), the F2-layer peak density height (hmF2), and total electron content (TEC) for a given geographic location. It supports a number of exogenous variables, including F10.7cm solar flux and disturbance storm time (Dst). We demonstrate how transformers can be trained in a data assimilation-like fashion that use these exogenous variables along with naÃ¯ve predictions from climatology to generate 24-hour forecasts with non-parametric uncertainty bounds. We call this method the Local Ionospheric Forecast Transformer (LIFT). We demonstrate that the trained model can generalize to new geographic locations and time periods not seen during training, and we compare its performance to that of the International Reference Ionosphere (IRI).",
        "tags": [
            "FLUX",
            "Transformer"
        ]
    },
    {
        "id": "166",
        "title": "Enhancing Speech Large Language Models with Prompt-Aware Mixture of Audio Encoders",
        "author": [
            "Weiqiao Shan",
            "Yuang Li",
            "Yuhao Zhang",
            "Yingfeng Luo",
            "Chen Xu",
            "Xiaofeng Zhao",
            "Long Meng",
            "Yunfei Lu",
            "Min Zhang",
            "Hao Yang",
            "Tong Xiao",
            "Jingbo Zhu"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15178",
        "abstract": "Connecting audio encoders with large language models (LLMs) allows the LLM to perform various audio understanding tasks, such as automatic speech recognition (ASR) and audio captioning (AC). Most research focuses on training an adapter layer to generate a unified audio feature for the LLM. However, different tasks may require distinct features that emphasize either semantic or acoustic aspects, making task-specific audio features more desirable. In this paper, we propose Prompt-aware Mixture (PaM) to enhance the Speech LLM that uses multiple audio encoders. Our approach involves using different experts to extract different features based on the prompt that indicates different tasks. Experiments demonstrate that with PaM, only one Speech LLM surpasses the best performances achieved by all single-encoder Speech LLMs on ASR, Speaker Number Verification, and AC tasks. PaM also outperforms other feature fusion baselines, such as concatenation and averaging.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "167",
        "title": "Comparative Analysis of Black Hole Mass Estimation in Type-2 AGNs: Classical vs. Quantum Machine Learning and Deep Learning Approaches",
        "author": [
            "Sathwik Narkedimilli",
            "Venkata Sriram Amballa",
            "N V Saran Kumar",
            "R Arun Kumar",
            "R Praneeth Reddy",
            "Satvik Raghav",
            "Manish M",
            "Aswath Babu H"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15297",
        "abstract": "In the case of Type-2 AGNs, estimating the mass of the black hole is challenging. Understanding how galaxies form and evolve requires considerable insight into the mass of black holes. This work compared different classical and quantum machine learning (QML) algorithms for black hole mass estimation, wherein the classical algorithms are Linear Regression, XGBoost Regression, Random Forest Regressor, Support Vector Regressor (SVR), Lasso Regression, Ridge Regression, Elastic Net Regression, Bayesian Regression, Decision Tree Regressor, Gradient Booster Regressor, Classical Neural Networks, Gated Recurrent Unit (GRU), LSTM, Deep Residual Networks (ResNets) and Transformer-Based Regression. On the other hand, quantum algorithms including Hybrid Quantum Neural Networks (QNN), Quantum Long Short-Term Memory (Q-LSTM), Sampler-QNN, Estimator-QNN, Variational Quantum Regressor (VQR), Quantum Linear Regression(Q-LR), QML with JAX optimization were also tested. The results revealed that classical algorithms gave better R^2, MAE, MSE, and RMSE results than the quantum models. Among the classical models, LSTM has the best result with an accuracy of 99.77%. Estimator-QNN has the highest accuracy for quantum algorithms with an MSE of 0.0124 and an accuracy of 99.75%. This study ascertains both the strengths and weaknesses of the classical and the quantum approaches. As far as our knowledge goes, this work could pave the way for the future application of quantum algorithms in astrophysical data analysis.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "168",
        "title": "Sheaf theory: from deep geometry to deep learning",
        "author": [
            "Anton Ayzenberg",
            "Thomas Gebhart",
            "German Magai",
            "Grigory Solomadin"
        ],
        "pdf": "https://arxiv.org/pdf/2502.15476",
        "abstract": "This paper provides an overview of the applications of sheaf theory in deep learning, data science, and computer science in general. The primary text of this work serves as a friendly introduction to applied and computational sheaf theory accessible to those with modest mathematical familiarity. We describe intuitions and motivations underlying sheaf theory shared by both theoretical researchers and practitioners, bridging classical mathematical theory and its more recent implementations within signal processing and deep learning. We observe that most notions commonly considered specific to cellular sheaves translate to sheaves on arbitrary posets, providing an interesting avenue for further generalization of these methods in applications, and we present a new algorithm to compute sheaf cohomology on arbitrary finite posets in response. By integrating classical theory with recent applications, this work reveals certain blind spots in current machine learning practices. We conclude with a list of problems related to sheaf-theoretic applications that we find mathematically insightful and practically instructive to solve. To ensure the exposition of sheaf theory is self-contained, a rigorous mathematical introduction is provided in appendices which moves from an introduction of diagrams and sheaves to the definition of derived functors, higher order cohomology, sheaf Laplacians, sheaf diffusion, and interconnections of these subjects therein.",
        "tags": [
            "Diffusion"
        ]
    }
]